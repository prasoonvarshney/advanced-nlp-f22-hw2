To	O
address	O
these	O
issues	O
,	O
in	O
our	O
proposed	O
approach	O
,	O
instead	O
of	O
representing	O
each	O
item	O
with	O
a	O
unique	O
identifier	O
,	O
we	O
choose	O
to	O
represent	O
each	O
item	O
with	O
its	O
title	O
tokens	O
,	O
which	O
are	O
further	O
mapped	O
to	O
a	O
continuous	O
vector	O
representation	O
.	O

their	O
helpful	O
comments	O
.	O

The	O
authors	O
would	O
like	O
to	O
thank	O
Sriganesh	O
Madhvanath	O
,	O
Hua	O
Yang	O
,	O
Xiaoyuan	O
Wu	O
,	O
Alan	O
Lu	O
,	O
Timothy	O
Heath	O
,	O
and	O
Kyunghyun	O
Cho	O
for	O
their	O
support	O
and	O
discussion	O
,	O
as	O
well	O
as	O
anonymous	O
reviewers	O
for	O
.	O

Acknowledgments	O
.	O

A	O
Appendix	O
.	O

We	O
demonstrate	O
the	O
superiority	O
of	O
our	O
model	O
over	O
a	O
traditional	O
neural	O
network	O
model	O
in	O
understanding	O
item	O
titles	O
and	O
learning	O
relationships	O
between	O
items	O
across	O
vast	O
inventory	O
.	O

Instead	O
of	O
directly	O
representing	O
an	O
item	O
with	O
a	O
unique	O
identifier	O
,	O
we	O
use	O
the	O
item	O
's	O
title	O
tokens	O
as	O
content	O
,	O
along	O
with	O
token	O
embeddings	O
,	O
to	O
address	O
the	O
cold	O
start	O
problem	O
.	O

In	O
this	O
paper	O
,	O
we	O
adapt	O
the	O
BERT	B-MethodName
model	O
for	O
the	O
task	O
of	O
item	B-TaskName
-	I-TaskName
based	I-TaskName
recommendations	I-TaskName
.	O

Summary	O
.	O

From	O
these	O
two	O
examples	O
,	O
we	O
see	O
that	O
the	O
proposed	O
model	O
appears	O
to	O
automatically	O
find	O
relevant	O
selection	O
criteria	O
without	O
manual	O
specification	O
,	O
as	O
well	O
as	O
make	O
decisions	O
between	O
focusing	O
on	O
a	O
specific	O
category	O
and	O
catering	O
to	O
a	O
wide	O
range	O
of	O
inventory	O
by	O
learning	O
from	O
the	O
data	O
.	O

For	O
the	O
second	O
seed	O
item	O
'	O
Microsoft	O
Surface	O
Pro	O
4	O
12.3	O
"	O
Multi	O
-	O
Touch	O
Tablet	O
(	O
Intel	O
i5	O
,	O
128	O
GB	O
)	O
+	O
Keyboard	O
'	O
,	O
the	O
recommended	O
items	O
span	O
a	O
wide	O
range	O
of	O
categories	O
including	O
tablets	O
,	O
digital	O
memberships	O
,	O
electronic	O
accessories	O
,	O
and	O
computer	O
hardware	O
.	O

For	O
the	O
first	O
seed	O
item	O
'	O
Marvel	O
Spiderman	O
T	O
-	O
shirt	O
Small	O
Black	O
Tee	O
Superhero	O
Comic	O
Book	O
Character	O
'	O
,	O
most	O
of	O
the	O
recommended	O
items	O
are	O
T	O
-	O
shirts	O
,	O
paired	O
with	O
clothing	O
accessories	O
and	O
tableware	O
decoration	O
,	O
all	O
having	O
Marvel	O
as	O
the	O
theme	O
.	O

2	O
.	O

In	O
order	O
to	O
visually	O
examine	O
the	O
quality	O
of	O
recommendations	O
,	O
we	O
present	O
the	O
recommended	O
items	O
for	O
two	O
different	O
seed	O
items	O
in	O
Table	O
.	O

It	O
is	O
also	O
clear	O
that	O
adapting	O
the	O
token	O
distribution	O
for	O
the	O
e	O
-	O
commerce	O
context	O
with	O
masked	O
language	O
model	O
within	O
BERT	B-MethodName
is	O
essential	O
for	O
achieving	O
the	O
best	O
performance	O
.	O

From	O
the	O
experiment	O
,	O
the	O
superiority	O
of	O
proposed	O
BERT	B-MethodName
model	O
for	O
item	B-TaskName
-	I-TaskName
based	I-TaskName
collaborative	I-TaskName
filtering	I-TaskName
is	O
clear	O
.	O

When	O
fine	O
tuning	O
for	O
the	O
masked	O
language	O
model	O
task	O
is	O
added	O
,	O
we	O
see	O
the	O
metrics	O
improved	O
further	O
by	O
another	O
111.0	B-MetricValue
%	I-MetricValue
,	O
38.6	B-MetricValue
%	I-MetricValue
,	O
38.3	B-MetricValue
%	I-MetricValue
,	O
and	O
64.0	B-MetricValue
%	I-MetricValue
.	O

When	O
only	O
fine	O
-	O
tuned	O
for	O
the	O
Next	O
Purchase	O
Prediction	O
task	O
,	O
our	O
model	O
exceeds	O
the	O
baseline	O
by	O
310.9	B-MetricValue
%	I-MetricValue
,	O
96.6	B-MetricValue
%	I-MetricValue
,	O
93.9	B-MetricValue
%	I-MetricValue
,	O
and	O
150.3	B-MetricValue
%	I-MetricValue
in	O
precision@1	B-MetricName
,	O
precision@10	B-MetricName
,	O
recall@10	B-MetricName
,	O
and	O
NDCG@10	B-MetricName
respectively	O
.	O

We	O
observe	O
that	O
the	O
proposed	O
BERT	B-MethodName
model	O
greatly	O
outperforms	O
the	O
LSTM	B-MethodName
-	O
based	O
model	O
.	O

We	O
believe	O
its	O
a	O
practical	O
experiment	O
setting	O
,	O
as	O
for	O
a	O
large	O
-	O
scale	O
e	O
-	O
commerce	O
platform	O
,	O
a	O
massive	O
amount	O
of	O
new	O
items	O
would	O
be	O
created	O
every	O
moment	O
,	O
and	O
ignoring	O
those	O
items	O
from	O
the	O
recommender	O
system	O
would	O
be	O
costly	O
and	O
inefficient	O
.	O

Following	O
the	O
same	O
reason	O
,	O
other	O
approaches	O
relying	O
on	O
unique	O
item	O
identifier	O
(	O
e.g.	O
itemId	O
)	O
could	O
n't	O
be	O
considered	O
either	O
in	O
our	O
experiment	O
.	O

We	O
do	O
not	O
consider	O
the	O
traditional	O
item	O
-	O
toitem	O
collaborative	O
filtering	O
model	O
(	O
Linden	O
et	O
al	O
.	O
,	O
2003	O
)	O
here	O
since	O
the	O
evaluation	O
is	O
conducted	O
assuming	O
a	O
complete	O
cold	O
-	O
start	O
setting	O
,	O
with	O
all	O
seed	O
items	O
unobserved	O
in	O
the	O
training	O
set	O
,	O
resulting	O
in	O
complete	O
failure	O
of	O
such	O
a	O
model	O
.	O

1	O
.	O

The	O
results	O
of	O
our	O
evaluation	O
are	O
presented	O
in	O
Table	O
.	O

Results	O
.	O

For	O
each	O
positive	O
sample	O
containing	O
a	O
seed	O
item	O
and	O
a	O
ground	O
-	O
truth	O
co	O
-	O
purchased	O
item	O
,	O
we	O
paired	O
the	O
seed	O
item	O
with	O
999	O
random	O
negative	O
samples	O
,	O
and	O
for	O
testing	O
,	O
we	O
use	O
the	O
trained	O
model	O
to	O
rank	O
the	O
total	O
of	O
1000	O
items	O
given	O
each	O
seed	O
item	O
.	O

For	O
testing	O
,	O
in	O
order	O
to	O
mimic	O
the	O
cold	O
-	O
start	O
scenario	O
in	O
the	O
production	O
system	O
wherein	O
traditional	O
item	O
-	O
item	O
collaborative	O
filtering	O
fails	O
completely	O
,	O
we	O
sampled	O
10,000	O
pairs	O
of	O
co	O
-	O
purchased	O
items	O
with	O
the	O
seed	O
item	O
not	O
present	O
in	O
the	O
training	O
set	O
.	O

Another	O
250,799	O
pairs	O
of	O
items	O
are	O
sampled	O
in	O
the	O
same	O
manner	O
for	O
use	O
as	O
a	O
validation	O
set	O
,	O
for	O
conducting	O
early	O
stopping	O
for	O
training	O
.	O

The	O
rationale	O
would	O
be	O
further	O
explained	O
with	O
the	O
presence	O
of	O
the	O
statistics	O
of	O
our	O
dataset	O
.	O

The	O
sparsity	O
of	O
data	O
forces	O
the	O
model	O
to	O
focus	O
on	O
generalization	O
rather	O
than	O
memorization	O
.	O

99.9999	O
%	O
of	O
entries	O
of	O
the	O
item	O
-	O
item	O
interaction	O
matrix	O
is	O
empty	O
.	O

We	O
collected	O
8,001,577	O
pairs	O
of	O
items	O
,	O
of	O
which	O
33	O
%	O
are	O
co	O
-	O
purchased	O
(	O
BIN	O
event	O
)	O
within	O
the	O
same	O
user	O
session	O
,	O
while	O
the	O
rest	O
are	O
randomly	O
sampled	O
as	O
negative	O
samples	O
.	O

We	O
train	O
our	O
models	O
on	O
an	O
e	O
-	O
commerce	O
website	O
data	O
.	O

Dataset	O
.	O

The	O
baseline	O
model	O
is	O
trained	O
using	O
the	O
same	O
cross	O
-	O
entropy	O
loss	O
shown	O
in	O
Eq	O
.	O
1	O
.	O

The	O
MLP	O
layer	O
with	O
logistic	O
function	O
produces	O
the	O
estimated	O
probability	O
score	O
.	O

After	O
going	O
through	O
the	O
embedding	O
layer	O
,	O
the	O
bidirectional	B-MethodName
LSTM	I-MethodName
reads	O
through	O
the	O
entire	O
sequence	O
and	O
generates	O
a	O
representation	O
at	O
the	O
last	O
timestep	O
.	O

For	O
every	O
pair	O
of	O
items	O
,	O
the	O
two	O
titles	O
are	O
concatenated	O
into	O
a	O
sequence	O
.	O

As	O
the	O
evaluation	O
is	O
conducted	O
on	O
the	O
dataset	O
having	O
a	O
complete	O
cold	O
-	O
start	O
setting	O
,	O
for	O
the	O
sake	O
of	O
comparison	O
,	O
we	O
build	O
a	O
baseline	O
model	O
consisting	O
of	O
a	O
title	O
token	O
embedding	O
layer	O
with	O
768	B-HyperparameterValue
dimensions	B-HyperparameterName
,	O
a	O
bidirectional	O
LSTM	O
layer	O
with	O
64	B-HyperparameterValue
hidden	B-HyperparameterName
units	I-HyperparameterName
,	O
and	O
a	O
2	B-HyperparameterValue
-	O
layer	B-HyperparameterName
MLP	O
with	O
128	B-HyperparameterValue
and	O
32	B-HyperparameterValue
hidden	B-HyperparameterName
units	I-HyperparameterName
respectively	O
.	O

Bi	B-MethodName
-	I-MethodName
LSTM	I-MethodName
Model	O
(	O
baseline	O
)	O
.	O

(	O
2	O
)	O
The	O
whole	O
model	O
is	O
optimized	O
against	O
the	O
joint	O
loss	O
L	O
lm	O
+	O
L	O
np	O
.	O

Given	O
the	O
set	O
of	O
chosen	O
tokens	O
M	O
,	O
the	O
corresponding	O
loss	O
for	O
masked	O
language	O
model	O
is	O
L	O
lm	O
=	O
−	O
m	O
i	O
∈M	O
log	O
p(m	O
i	O
)	O
.	O

(	O
2018	O
)	O
wherein	O
15	O
%	O
of	O
the	O
tokens	O
in	O
the	O
title	O
are	O
chosen	O
to	O
be	O
replaced	O
by	O
[	O
MASK	O
]	O
,	O
random	O
token	O
,	O
or	O
left	O
unchanged	O
,	O
with	O
a	O
probability	O
of	O
80	O
%	O
,	O
10	O
%	O
and	O
10	O
%	O
respectively	O
.	O

In	O
the	O
masked	O
language	O
model	O
task	O
,	O
we	O
follow	O
the	O
training	O
schema	O
outlined	O
in	O
Devlin	O
et	O
al	O
.	O

As	O
the	O
distribution	O
of	O
item	O
title	O
tokens	O
is	O
different	O
from	O
the	O
natural	O
language	O
corpus	O
used	O
to	O
train	O
BERT	B-MethodName
base	I-MethodName
,	O
we	O
further	O
fine	O
-	O
tune	O
the	O
model	O
for	O
the	O
masked	O
language	O
model	O
(	O
MLM	O
)	O
task	O
as	O
well	O
.	O

Masked	O
Language	O
Model	O
.	O

(	O
1	O
)	O
.	O

Given	O
the	O
positive	O
item	O
set	O
I	O
p	O
,	O
and	O
the	O
negative	O
item	O
set	O
I	O
n	O
,	O
the	O
cross	O
-	O
entropy	O
loss	O
for	O
next	O
purchase	O
prediction	O
may	O
be	O
computed	O
as	O
L	O
np	O
=	O
−	O
i	O
j	O
∈Ip	O
log	O
p(i	O
j	O
)	O
−	O
i	O
j	O
∈In	O
log(1	O
−	O
p(i	O
j	O
)	O
)	O
.	O

For	O
a	O
seed	O
item	O
,	O
its	O
positive	O
items	O
are	O
generated	O
by	O
collecting	O
items	O
purchased	O
within	O
the	O
same	O
user	O
session	O
,	O
and	O
the	O
negative	O
ones	O
are	O
randomly	O
sampled	O
.	O

Both	O
item	O
titles	O
are	O
concatenated	O
and	O
truncated	O
to	O
have	O
at	O
most	O
128	O
tokens	O
,	O
including	O
one	O
[	O
CLS	O
]	O
and	O
two	O
[	O
SEP	O
]	O
tokens	O
.	O

We	O
feed	O
seed	O
item	O
as	O
sentence	O
A	O
,	O
and	O
target	O
item	O
as	O
sentence	O
B.	O

We	O
start	O
with	O
a	O
pre	O
-	O
trained	O
BERT	B-MethodName
base	I-MethodName
model	O
,	O
and	O
fine	O
-	O
tune	O
it	O
for	O
our	O
next	O
purchase	O
prediction	O
task	O
.	O

The	O
goal	O
of	O
this	O
task	O
is	O
to	O
predict	O
the	O
next	O
item	O
a	O
user	O
is	O
going	O
to	O
purchase	O
given	O
the	O
seed	O
item	O
he	O
/	O
she	O
has	O
just	O
bought	O
.	O

Next	O
Purchase	O
Prediction	O
.	O

The	O
encoder	O
of	O
BERT	B-MethodName
base	I-MethodName
contains	O
12	B-HyperparameterValue
Transformer	O
layers	B-HyperparameterName
,	O
with	O
768	B-HyperparameterValue
hidden	B-HyperparameterName
units	I-HyperparameterName
,	O
and	O
12	B-HyperparameterValue
self	B-HyperparameterName
-	I-HyperparameterName
attention	I-HyperparameterName
heads	I-HyperparameterName
.	O

Our	O
model	O
is	O
based	O
on	O
the	O
architecture	O
of	O
BERT	B-MethodName
base	I-MethodName
(	O
Devlin	O
et	O
al	O
.	O
,	O
2018	O
)	O
.	O

Model	O
.	O

We	O
adapt	O
the	O
masked	O
language	O
modelling	O
and	O
next	O
sentence	O
prediction	O
tasks	O
from	O
the	O
natural	O
language	O
context	O
to	O
the	O
e	O
-	O
commerce	O
context	O
.	O

In	O
this	O
paper	O
,	O
we	O
propose	O
a	O
novel	O
approach	O
for	O
item	B-TaskName
-	I-TaskName
based	I-TaskName
collaborative	I-TaskName
filtering	I-TaskName
,	O
by	O
leveraging	O
the	O
BERT	B-MethodName
model	O
(	O
Devlin	O
et	O
al	O
.	O
,	O
2018	O
)	O
to	O
understand	O
item	O
titles	O
and	O
model	O
relevance	O
between	O
different	O
items	O
.	O

Due	O
to	O
the	O
recent	O
success	O
of	O
neural	O
networks	O
in	O
multiple	O
AI	O
domains	O
(	O
LeCun	O
et	O
al	O
.	O
,	O
2015	O
)	O
and	O
their	O
superior	O
modeling	O
capacity	O
,	O
a	O
number	O
of	O
research	O
efforts	O
have	O
explored	O
new	O
recommendation	O
algorithms	O
based	O
on	O
Deep	O
Learning	O
(	O
see	O
,	O
e.g.	O
,	O
Barkan	O
and	O
Koenigstein	O
,	O
2016;He	O
et	O
al	O
.	O
,	O
2017;Hidasi	O
et	O
al	O
.	O
,	O
2015;Covington	O
et	O
al	O
.	O
,	O
2016	O
)	O
.	O

Although	O
less	O
impacted	O
by	O
data	O
sparsity	O
,	O
due	O
to	O
their	O
reliance	O
on	O
content	O
rather	O
than	O
behavior	O
,	O
they	O
can	O
struggle	O
to	O
provide	O
novel	O
recommendations	O
which	O
may	O
activate	O
the	O
user	O
's	O
latent	O
interests	O
,	O
a	O
highly	O
desirable	O
quality	O
for	O
recommender	O
systems	O
(	O
Castells	O
et	O
al	O
.	O
,	O
2011	O
)	O
.	O

Content	O
-	O
based	O
recommendation	O
algorithms	O
calculate	O
similarities	O
in	O
content	O
between	O
candidate	O
items	O
and	O
seed	O
items	O
that	O
the	O
user	O
has	O
provided	O
feedback	O
for	O
(	O
which	O
may	O
be	O
implicit	O
e.g.	O
clicking	O
,	O
or	O
explicit	O
e.g.	O
rating	O
)	O
,	O
and	O
then	O
select	O
the	O
most	O
similar	O
items	O
to	O
recommend	O
.	O

However	O
,	O
for	O
highly	O
active	O
e	O
-	O
commerce	O
platforms	O
with	O
large	O
and	O
constantly	O
changing	O
inventory	O
,	O
both	O
approaches	O
are	O
severely	O
impacted	O
by	O
data	O
sparsity	O
in	O
the	O
user	O
-	O
item	O
interaction	O
matrix	O
.	O

For	O
item	B-TaskName
-	I-TaskName
based	I-TaskName
collaborative	I-TaskName
filtering	I-TaskName
(	O
see	O
,	O
e.g.	O
,	O
Linden	O
et	O
al	O
.	O
,	O
2003	O
)	O
,	O
given	O
a	O
seed	O
item	O
,	O
recommended	O
items	O
are	O
chosen	O
to	O
have	O
most	O
similar	O
user	O
feedback	O
.	O

Introduction	O
.	O

In	O
this	O
work	O
,	O
we	O
present	O
a	O
novel	O
approach	O
for	O
item	B-TaskName
-	I-TaskName
based	I-TaskName
collaborative	I-TaskName
filtering	I-TaskName
,	O
by	O
leveraging	O
BERT	B-MethodName
to	O
understand	O
items	O
,	O
and	O
score	O
relevancy	O
between	O
different	O
items	O
.	O

Item	B-TaskName
-	I-TaskName
based	I-TaskName
Collaborative	I-TaskName
Filtering	I-TaskName
with	O
BERT	B-MethodName
.	O

For	O
example	O
,	O
traditional	O
userbased	O
collaborative	O
filtering	O
recommendation	O
algorithms	O
(	O
see	O
,	O
e.g.	O
,	O
Schafer	O
et	O
al	O
.	O
,	O
2007	O
)	O
find	O
the	O
most	O
similar	O
users	O
based	O
on	O
the	O
seed	O
user	O
's	O
rated	O
items	O
,	O
and	O
then	O
recommend	O
new	O
items	O
which	O
other	O
users	O
rated	O
highly	O
.	O

However	O
,	O
these	O
have	O
their	O
own	O
limitations	O
when	O
applied	O
directly	O
to	O
real	O
-	O
world	O
ecommerce	O
platforms	O
.	O

Traditional	O
recommendation	O
algorithms	O
can	O
be	O
divided	O
into	O
two	O
types	O
:	O
collaborative	O
filtering	O
-	O
based	O
(	O
Schafer	O
et	O
al	O
.	O
,	O
2007;Linden	O
et	O
al	O
.	O
,	O
2003	O
)	O
and	O
content	O
-	O
based	O
(	O
Lops	O
et	O
al	O
.	O
,	O
2011;Pazzani	O
and	O
Billsus	O
,	O
2007	O
)	O
.	O

Recommender	O
systems	O
are	O
an	O
integral	O
part	O
of	O
ecommerce	O
platforms	O
,	O
helping	O
users	O
pick	O
out	O
items	O
of	O
interest	O
from	O
large	O
inventories	O
at	O
scale	O
.	O

We	O
conducted	O
experiments	O
on	O
a	O
large	O
-	O
scale	O
realworld	O
dataset	O
with	O
full	O
cold	O
-	O
start	O
scenario	O
,	O
and	O
the	O
proposed	O
approach	O
significantly	O
outperforms	O
the	O
popular	O
Bi	B-MethodName
-	I-MethodName
LSTM	I-MethodName
model	O
.	O

Our	O
proposed	O
method	O
could	O
address	O
problems	O
that	O
plague	O
traditional	O
recommender	O
systems	O
such	O
as	O
cold	O
start	O
,	O
and	O
"	O
more	O
of	O
the	O
same	O
"	O
recommended	O
content	O
.	O

In	O
e	O
-	O
commerce	O
,	O
recommender	O
systems	O
have	O
become	O
an	O
indispensable	O
part	O
of	O
helping	O
users	O
explore	O
the	O
available	O
inventory	O
.	O

Next	O
Purchase	O
Prediction	O
can	O
directly	O
be	O
used	O
as	O
the	O
relevance	O
scoring	O
function	O
for	O
our	O
item	O
collaborative	O
filtering	O
task	O
.	O

Since	O
the	O
distribution	O
of	O
item	O
title	O
tokens	O
differs	O
drastically	O
from	O
words	O
in	O
natural	O
language	O
which	O
the	O
original	O
BERT	B-MethodName
model	O
is	O
trained	O
on	O
,	O
retraining	O
the	O
masked	O
language	O
model	O
allows	O
better	O
understanding	O
of	O
item	O
information	O
for	O
our	O
use	O
-	O
case	O
.	O

We	O
re	O
-	O
purpose	O
these	O
tasks	O
for	O
the	O
e	O
-	O
commerce	O
context	O
into	O
Masked	O
Language	O
Model	O
on	O
Item	O
Titles	O
,	O
and	O
Next	O
Purchase	O
Prediction	O
.	O

The	O
training	O
of	O
BERT	B-MethodName
model	O
can	O
be	O
divided	O
into	O
two	O
parts	O
:	O
Masked	O
Language	O
Model	O
and	O
Next	O
Sentence	O
Prediction	O
.	O

Rather	O
than	O
the	O
traditional	O
RNN	O
/	O
CNN	O
structure	O
,	O
BERT	B-MethodName
adopts	O
transformer	O
encoder	O
as	O
a	O
language	O
model	O
,	O
and	O
use	O
attention	O
mechanism	O
to	O
calculate	O
the	O
relationship	O
between	O
input	O
and	O
output	O
.	O

Our	O
model	O
is	O
based	O
on	O
BERT	B-MethodName
(	O
Devlin	O
et	O
al	O
.	O
,	O
2018	O
)	O
.	O

The	O
goal	O
of	O
item	B-MethodName
-	I-MethodName
based	I-MethodName
collaborative	I-MethodName
filtering	I-MethodName
is	O
to	O
score	O
the	O
relevance	O
between	O
two	O
items	O
,	O
and	O
for	O
a	O
seed	O
item	O
,	O
the	O
top	O
scored	O
items	O
would	O
be	O
recommended	O
as	O
a	O
result	O
.	O

For	O
a	O
newly	O
listed	O
item	O
in	O
the	O
cold	O
-	O
start	O
setting	O
,	O
the	O
model	O
can	O
utilize	O
the	O
similarity	O
of	O
the	O
item	O
title	O
to	O
ones	O
observed	O
before	O
to	O
find	O
relevant	O
recommended	O
items	O
.	O

By	O
doing	O
so	O
,	O
essentially	O
two	O
items	O
with	O
the	O
same	O
title	O
would	O
be	O
treated	O
as	O
the	O
same	O
,	O
and	O
can	O
aggregate	O
user	O
behaviors	O
accordingly	O
.	O

In	O
addition	O
to	O
the	O
challenge	O
of	O
long	O
-	O
tail	O
recommendations	O
,	O
this	O
also	O
requires	O
the	O
recommender	O
system	O
to	O
be	O
continuously	O
retrained	O
and	O
redeployed	O
in	O
order	O
to	O
accommodate	O
newly	O
listed	O
items	O
.	O

As	O
mentioned	O
earlier	O
,	O
for	O
a	O
dynamic	O
e	O
-	O
commerce	O
platform	O
,	O
items	O
enter	O
and	O
leave	O
the	O
market	O
continuously	O
,	O
resulting	O
in	O
an	O
extremely	O
sparse	O
user	O
-	O
item	O
interaction	O
matrix	O
.	O

Item	B-MethodName
-	I-MethodName
based	I-MethodName
Collaborative	I-MethodName
Filtering	I-MethodName
with	I-MethodName
BERT	I-MethodName
.	O

•	O
We	O
conduct	O
experiments	O
on	O
a	O
large	O
-	O
scale	O
e	O
-	O
commerce	O
dataset	O
,	O
demonstrating	O
the	O
effectiveness	O
of	O
our	O
approach	O
and	O
producing	O
recommendation	B-TaskName
results	O
with	O
higher	O
quality	O
.	O

•	O
By	O
training	O
model	O
with	O
user	O
behavior	O
data	O
,	O
our	O
model	O
learns	O
user	O
's	O
latent	O
interests	O
more	O
than	O
item	O
similarities	O
,	O
while	O
traditional	O
recommendation	O
algorithms	O
and	O
some	O
pair	O
-	O
wise	O
deep	O
learning	O
algorithms	O
only	O
provide	O
similar	O
items	O
which	O
users	O
may	O
have	O
bought	O
.	O

The	O
contributions	O
of	O
this	O
work	O
are	O
summarized	O
as	O
follows	O
:	O
•	O
Instead	O
of	O
relying	O
on	O
unique	O
item	O
identifier	O
to	O
aggregate	O
history	O
information	O
,	O
we	O
only	O
use	O
item	O
's	O
title	O
as	O
content	O
,	O
along	O
with	O
token	O
embeddings	O
to	O
solve	O
the	O
cold	O
start	O
problem	O
,	O
which	O
is	O
the	O
main	O
shortcoming	O
of	O
traditional	O
recommendation	O
algorithms	O
.	O

