Considering	O
the	O
instability	O
of	O
the	O
few	O
-	O
shot	O
learning	O
,	O
we	O
run	O
each	O
experiment	O
5	O
times	O
on	O
the	O
random	O
seed	O
[	O
10,20,30,40,50	O
]	O
and	O
report	O
the	O
averaged	O
performance	O
as	O
well	O
as	O
the	O
standard	O
deviation	O
.	O

In	O
this	O
paper	O
,	O
we	O
present	O
PPT	B-MethodName
,	O
a	O
framework	O
that	O
improves	O
prompt	B-MethodName
tuning	I-MethodName
for	O
few	O
-	O
shot	O
learning	O
.	O

In	O
this	O
paper	O
,	O
we	O
study	O
few	O
-	O
shot	O
learning	O
on	O
large	O
-	O
scale	O
11B	O
PLMs	O
.	O
Conclusion	O
and	O
Future	O
Work	O
.	O

There	O
is	O
also	O
work	O
(	O
IV	O
et	O
al	O
.	O
,	O
2021	O
)	O
pointing	O
out	O
the	O
low	O
performance	O
of	O
PT	B-MethodName
for	O
few	O
-	O
shot	O
learning	O
.	O

Few	O
-	O
shot	O
Learning	O
with	O
PLMs	O
Since	O
long	O
-	O
tail	O
distribution	O
is	O
common	O
in	O
real	O
-	O
world	O
applications	O
,	O
few	O
-	O
shot	O
learning	O
is	O
quite	O
meaningful	O
for	O
the	O
stable	O
and	O
effective	O
use	O
of	O
PLMs	O
,	O
thereby	O
attracts	O
much	O
attention	O
recently	O
.	O

Few	O
-	O
shot	O
learning	O
is	O
notorious	O
for	O
its	O
instability	O
,	O
which	O
becomes	O
very	O
obvious	O
in	O
Vanilla	B-MethodName
PT	I-MethodName
.	O

In	O
this	O
section	O
,	O
we	O
present	O
pilot	O
experiments	O
of	O
PT	B-MethodName
for	O
few	O
-	O
shot	O
learning	O
.	O

Experiments	O
show	O
that	O
PPT	B-MethodName
can	O
not	O
only	O
improve	O
PT	B-MethodName
by	O
a	O
large	O
margin	O
,	O
reaching	O
or	O
even	O
outperforming	O
FT	B-MethodName
methods	O
,	O
but	O
also	O
reduce	O
the	O
variance	O
of	O
few	O
-	O
shot	O
learning	O
.	O

Hence	O
,	O
in	O
this	O
paper	O
,	O
we	O
explore	O
how	O
to	O
use	O
PLMs	O
for	O
few	O
-	O
shot	O
learning	O
in	O
an	O
efficient	O
and	O
effective	O
manner	O
through	O
PT	B-MethodName
.	O

PPT	B-MethodName
:	O
Pre	B-MethodName
-	I-MethodName
trained	I-MethodName
Prompt	I-MethodName
Tuning	I-MethodName
for	O
Few	O
-	O
shot	O
Learning	O
.	O

Results	O
have	O
shown	O
that	O
task	B-MethodName
-	I-MethodName
oriented	I-MethodName
fine	I-MethodName
-	I-MethodName
tuning	I-MethodName
can	O
outperform	O
models	O
trained	O
from	O
scratch	O
on	O
a	O
series	O
of	O
NLP	O
tasks	O
.	O

Then	O
,	O
all	O
parameters	O
of	O
both	O
PLMs	O
and	O
additional	O
heads	O
are	O
tuned	O
using	O
task	O
-	O
specific	O
data	O
.	O

To	O
adapt	O
these	O
PLMs	O
to	O
downstream	O
NLP	O
tasks	O
,	O
task	B-TaskName
-	I-TaskName
oriented	I-TaskName
fine	I-TaskName
-	I-TaskName
tuning	I-TaskName
has	O
been	O
proposed	O
,	O
where	O
researchers	O
use	O
PLMs	O
as	O
the	O
backbone	O
and	O
add	O
some	O
task	O
-	O
specific	O
heads	O
to	O
optimize	O
task	O
-	O
specific	O
objectives	O
.	O

Given	O
the	O
input	O
x	O
=	O
(	O
s	O
)	O
,	O
we	O
have	O
:	O
Based	O
on	O
the	O
PVP	O
pre	O
i	O
,	O
the	O
design	O
of	O
PVP	O
k	O
i	O
is	O
similar	O
to	O
that	O
of	O
English	O
tasks	O
.	O

Sentence	B-TaskName
-	I-TaskName
Pair	I-TaskName
Classification	I-TaskName
Given	O
the	O
input	O
x	O
=	O
(	O
s	O
1	O
,	O
s	O
2	O
)	O
,	O
the	O
label	O
list	O
Y	O
=	O
[	O
0	O
,	O
1	O
,	O
2	O
]	O
,	O
we	O
have	O
:	O
Multiple	B-TaskName
-	I-TaskName
Choice	I-TaskName
Classification	I-TaskName
Given	O
a	O
input	O
x	O
consisting	O
of	O
a	O
query	O
and	O
six	O
candidates	O
:	O
x	O
=	O
(	O
s	O
q	O
,	O
s	O
1	O
,	O
s	O
2	O
,	O
•	O
•	O
•	O
,	O
s	O
6	O
)	O
,	O
we	O
convert	O
x	O
to	O
a	O
language	O
sequence	O
by	O
defining	O
the	O
PVP	O
pre	O
i	O
as	O
follows	O
:	O
Single	B-TaskName
-	I-TaskName
Sentence	I-TaskName
Classification	I-TaskName
Similar	O
to	O
the	O
English	O
scenario	O
,	O
we	O
take	O
sentiment	O
classification	O
as	O
an	O
example	O
.	O

Just	O
like	O
English	O
scenarios	O
,	O
all	O
these	O
PVPs	O
are	O
simple	O
and	O
intuitive	O
.	O

We	O
describe	O
the	O
PVP	O
pre	O
i	O
for	O
Chinese	O
datasets	O
in	O
this	O
section	O
.	O

B	O
PVPs	O
for	O
Chinese	O
Tasks	O
.	O

For	O
Chinese	O
experiments	O
,	O
we	O
use	O
four	O
datasets	O
from	O
CLUE	B-DatasetName
(	O
Xu	O
et	O
al	O
.	O
,	O
2020	O
)	O
(	O
CMNLI	B-DatasetName
3	I-DatasetName
,	O
OCNLI	B-DatasetName
(	O
Hu	O
et	O
al	O
.	O
,	O
2020	O
)	O
,	O
TNews	B-DatasetName
3	I-DatasetName
,	O
C	B-DatasetName
3	I-DatasetName
(	O
Sun	O
et	O
al	O
.	O
,	O
2020	O
)	O
)	O
,	O
two	O
sentiment	B-TaskName
analysis	I-TaskName
datasets	O
(	O
ChnSent	B-DatasetName
4	I-DatasetName
and	O
Amazon	B-DatasetName
Reviews	I-DatasetName
4	I-DatasetName
)	O
,	O
and	O
one	O
extra	O
natural	B-TaskName
language	I-TaskName
inference	I-TaskName
dataset	O
LCQMC	B-DatasetName
(	O
Liu	O
et	O
al	O
.	O
,	O
2018	O
)	O
.	O

(	O
2021	O
)	O
to	O
use	O
original	O
validation	O
sets	O
for	O
testing	O
.	O

(	O
2021	O
)	O
and	O
Gao	O
et	O
al	O
.	O

Since	O
some	O
of	O
the	O
test	O
sets	O
of	O
the	O
datasets	O
we	O
used	O
is	O
not	O
publicly	O
available	O
,	O
we	O
follow	O
Zhang	O
et	O
al	O
.	O

A	O
Dataset	O
Information	O
.	O

Appendices	O
.	O

This	O
work	O
was	O
also	O
supported	O
by	O
the	O
Guoqiang	O
Institute	O
of	O
Tsinghua	O
University	O
,	O
with	O
Grant	O
No	O
.	O
2019GQG1	O
and	O
2020GQG0005	O
.	O

This	O
work	O
was	O
supported	O
by	O
the	O
National	O
Science	O
Foundation	O
for	O
Distinguished	O
Young	O
Scholars	O
(	O
with	O
No	O
.	O
62125604	O
)	O
and	O
the	O
NSFC	O
projects	O
(	O
Key	O
project	O
with	O
No	O
.	O
61936010	O
and	O
regular	O
project	O
with	O
No	O
.	O
61876096	O
)	O
.	O

Acknowledgements	O
.	O

E	O
Training	O
Consumption	O
.	O

The	O
hard	O
prompts	O
corresponding	O
to	O
each	O
task	O
format	O
are	O
shown	O
in	O
Table	O
7	O
.	O

For	O
simplicity	O
,	O
we	O
choose	O
the	O
best	O
hard	O
prompts	O
for	O
each	O
task	O
format	O
(	O
e.g.	O
sentence	B-TaskName
-	I-TaskName
pair	I-TaskName
classification	I-TaskName
,	O
multiple	B-TaskName
-	I-TaskName
choice	I-TaskName
classification	I-TaskName
,	O
and	O
single	O
-	O
sentence	O
classification	O
)	O
based	O
on	O
PT	B-MethodName
in	O
pilot	O
experiments	O
and	O
directly	O
use	O
them	O
in	O
Hybrid	B-MethodName
PPT	I-MethodName
.	O

In	O
this	O
section	O
,	O
we	O
describe	O
the	O
hard	O
prompts	O
we	O
use	O
in	O
Hybrid	B-MethodName
PT	I-MethodName
and	O
Hybrid	B-MethodName
PPT	I-MethodName
.	O

D	O
Hard	O
Prompts	O
.	O

The	O
thresholds	O
of	O
the	O
label	O
0	O
∼	O
4	O
are	O
[	O
0.95	O
,	O
0.50	O
,	O
0.50	O
,	O
0.50	O
,	O
0.70	O
]	O
.	O

We	O
set	O
different	O
minimal	O
classification	O
confidence	O
thresholds	O
for	O
the	O
5	O
labels	O
to	O
control	O
annotation	O
quality	O
and	O
balance	O
the	O
label	O
.	O

We	O
choose	O
the	O
checkpoint	O
with	O
the	O
highest	O
accuracy	O
on	O
the	O
validation	O
set	O
,	O
which	O
is	O
70.53	O
at	O
the	O
5	O
-	O
th	O
epoch	O
,	O
to	O
annotate	O
the	O
label	O
.	O

We	O
use	O
learning	B-HyperparameterName
rate	I-HyperparameterName
1e-4	B-HyperparameterValue
,	O
batch	B-HyperparameterName
size	I-HyperparameterName
16	B-HyperparameterValue
,	O
warm	B-HyperparameterName
-	I-HyperparameterName
up	I-HyperparameterName
rate	I-HyperparameterName
0.01	B-HyperparameterValue
,	O
and	O
train	O
the	O
model	O
for	O
10	B-HyperparameterValue
epochs	B-HyperparameterName
.	O

Single	B-TaskName
-	I-TaskName
Sentence	I-TaskName
Classification	I-TaskName
We	O
use	O
the	O
RoBERTa	B-MethodName
BASE	I-MethodName
model	O
trained	O
on	O
the	O
Yelp-5	B-DatasetName
dataset	O
to	O
annotate	O
pseudo	O
labels	O
on	O
the	O
unlabeled	O
data	O
.	O

The	O
input	O
configurations	O
of	O
different	O
option	O
numbers	O
is	O
shown	O
in	O
Table	O
9	O
.	O

To	O
fit	O
in	O
the	O
max	O
input	O
length	O
,	O
we	O
truncate	O
the	O
query	O
sentence	O
to	O
389	O
tokens	O
and	O
the	O
options	O
to	O
86	O
tokens	O
.	O

We	O
also	O
filter	O
out	O
the	O
sentences	O
with	O
less	O
than	O
5	O
tokens	O
.	O

Sentence	B-TaskName
-	I-TaskName
Pair	I-TaskName
Classification	I-TaskName
In	O
the	O
next	O
sentence	O
prediction	O
task	O
,	O
we	O
set	O
the	O
two	O
sentences	O
next	O
to	O
each	O
other	O
as	O
label	O
2	O
,	O
those	O
from	O
the	O
same	O
document	O
but	O
not	O
true	O
next	O
sentence	O
as	O
1	O
,	O
and	O
those	O
from	O
different	O
documents	O
as	O
0	O
.	O

The	O
details	O
of	O
constructing	O
the	O
pre	O
-	O
training	O
data	O
for	O
each	O
task	O
are	O
as	O
follows	O
.	O

We	O
evaluate	O
the	O
performance	O
on	O
the	O
validation	O
set	O
every	O
2,000	O
steps	O
and	O
choose	O
the	O
prompt	O
with	O
the	O
lowest	O
validation	O
loss	O
.	O

We	O
split	B-HyperparameterName
5	B-HyperparameterValue
%	I-HyperparameterValue
data	O
for	O
validation	O
and	O
the	O
rest	O
for	O
pre	O
-	O
training	O
.	O

We	O
set	O
the	O
batch	B-HyperparameterName
size	I-HyperparameterName
as	O
256	B-HyperparameterValue
,	O
the	O
max	B-HyperparameterName
input	I-HyperparameterName
length	I-HyperparameterName
as	O
512	B-HyperparameterValue
,	O
and	O
train	O
the	O
prompts	O
for	O
at	O
most	O
200,000	B-HyperparameterValue
steps	B-HyperparameterName
.	O

Across	O
all	O
tasks	O
,	O
we	O
use	O
the	O
"	O
inverse	O
square	O
root	O
"	O
learning	O
rate	O
scheduler	O
(	O
Raffel	O
et	O
al	O
.	O
,	O
2020	O
)	O
and	O
set	O
the	O
learning	B-HyperparameterName
rate	I-HyperparameterName
in	O
this	O
scheduler	O
as	O
0.1	B-HyperparameterValue
with	O
no	O
warmup	O
steps	O
.	O

We	O
use	O
the	O
sampled	O
10	O
GB	O
data	O
to	O
construct	O
the	O
pre	O
-	O
training	O
data	O
for	O
each	O
task	O
format	O
for	O
prompt	B-MethodName
pre	I-MethodName
-	I-MethodName
training	I-MethodName
.	O

C.3	O
Prompt	O
Pre	O
-	O
Training	O
.	O

Therefore	O
,	O
we	O
search	O
for	O
the	O
learning	B-HyperparameterName
rate	I-HyperparameterName
in	O
[	O
5e-3	B-HyperparameterValue
,	O
1e-2	B-HyperparameterValue
,	O
2e-2	B-HyperparameterValue
,	O
5e-2	B-HyperparameterValue
]	O
and	O
choose	O
the	O
model	O
with	O
the	O
best	O
performance	O
on	O
the	O
validation	O
set	O
.	O

steps	O
.	O

Generally	O
,	O
small	O
models	O
prefer	O
large	O
learning	B-HyperparameterName
rates	I-HyperparameterName
.	O

Similar	O
to	O
FT	B-MethodName
,	O
we	O
fix	O
the	O
batch	B-HyperparameterName
size	I-HyperparameterName
as	O
16	B-HyperparameterValue
and	O
train	O
the	O
model	O
for	O
50	B-HyperparameterValue
epochs	B-HyperparameterName
,	O
while	O
evaluating	O
the	O
model	O
every	O
6	O
Model	O
Size	O
Searching	O
Interval	O
Small	O
2e-4	B-HyperparameterValue
,	O
5e-4	B-HyperparameterValue
,	O
1e-3	B-HyperparameterValue
Base	O
2e-4	B-HyperparameterValue
,	O
5e-4	B-HyperparameterValue
,	O
1e-3	B-HyperparameterValue
Large	O
5e-5	B-HyperparameterValue
,	O
1e-4	B-HyperparameterValue
,	O
2e-4	B-HyperparameterValue
XL	O
3e-5	B-HyperparameterValue
,	O
5e-5	B-HyperparameterValue
,	O
1e-4	B-HyperparameterValue
XXL	O
3e-6	B-HyperparameterValue
,	O
5e-6	B-HyperparameterValue
,	O
1e-5	B-HyperparameterValue
Table	O
8	O
:	O
The	O
searching	O
intervals	O
of	O
learning	B-HyperparameterName
rates	I-HyperparameterName
for	O
the	O
models	O
with	O
different	O
sizes	O
.	O

When	O
adapting	O
the	O
model	O
to	O
downstream	O
tasks	O
,	O
we	O
only	O
tune	O
the	O
soft	O
prompts	O
with	O
the	O
entire	O
model	O
fixed	O
.	O

We	O
choose	O
the	O
model	O
performing	O
the	O
best	O
on	O
the	O
validation	O
set	O
and	O
evaluate	O
it	O
on	O
the	O
test	O
set	O
.	O

We	O
train	O
the	O
model	O
for	O
50	B-HyperparameterValue
epochs	B-HyperparameterName
and	O
do	O
evaluation	O
every	O
6	O
optimization	O
steps	O
.	O

Therefore	O
,	O
we	O
search	O
for	O
the	O
learning	B-HyperparameterName
rates	I-HyperparameterName
in	O
varied	O
intervals	O
and	O
show	O
each	O
model	O
size	O
and	O
its	O
corresponding	O
searching	O
interval	O
in	O
Table	O
8	O
.	O

In	O
this	O
way	O
,	O
we	O
train	O
the	O
largest	O
11B	O
model	O
with	O
16	O
NVIDIA	O
V100	O
32	O
G	O
GPUs	O
.	O
We	O
find	O
that	O
different	O
sized	O
models	O
prefer	O
significantly	O
different	O
learning	B-HyperparameterName
rates	I-HyperparameterName
.	O

For	O
all	O
models	O
,	O
we	O
fix	O
the	O
batch	B-HyperparameterName
size	I-HyperparameterName
as	O
16	B-HyperparameterValue
.	O

We	O
describe	O
the	O
details	O
of	O
the	O
training	O
hyper	O
-	O
parameters	O
in	O
the	O
following	O
sections	O
.	O

For	O
models	O
in	O
other	O
sizes	O
,	O
we	O
all	O
use	O
full	O
-	O
precision	O
training	O
.	O

We	O
also	O
use	O
mixedprecision	O
training	O
(	O
Micikevicius	O
et	O
al	O
.	O
,	O
2018	O
)	O
and	O
ZeRO	O
(	O
Rajbhandari	O
et	O
al	O
.	O
,	O
2020	O
)	O
stage-1	O
provided	O
in	O
DeepSpeed	O
(	O
Rasley	O
et	O
al	O
.	O
,	O
2020	O
)	O
to	O
reduce	O
GPU	O
memory	O
usage	O
.	O

Due	O
to	O
the	O
resource	O
limit	O
,	O
for	O
11B	O
models	O
,	O
we	O
adopt	O
model	O
parallelism	O
(	O
Shoeybi	O
et	O
al	O
.	O
,	O
2019	O
)	O
and	O
store	O
a	O
model	O
with	O
4	O
GPU	O
devices	O
.	O

C	O
Training	O
Details	O
.	O

(	O
3	O
)	O
Beyond	O
the	O
soft	O
prompt	O
,	O
studying	O
whether	O
unified	O
task	O
pre	O
-	O
training	O
helps	O
the	O
pre	O
-	O
trained	O
language	O
models	O
itself	O
.	O

(	O
2	O
)	O
Evaluating	O
the	O
few	O
-	O
shot	O
performance	O
of	O
other	O
parameter	B-MethodName
-	I-MethodName
efficient	I-MethodName
tuning	I-MethodName
approaches	O
(	O
He	O
et	O
al	O
.	O
,	O
2022	O
)	O
and	O
adapting	O
unified	O
task	O
pre	O
-	O
training	O
to	O
them	O
.	O

There	O
are	O
three	O
important	O
directions	O
for	O
future	O
work	O
:	O
(	O
1	O
)	O
Designing	O
unified	O
task	O
formats	O
and	O
the	O
corresponding	O
pre	O
-	O
training	O
objectives	O
for	O
other	O
kinds	O
of	O
tasks	O
such	O
as	O
language	O
generation	O
and	O
relation	O
extraction	O
.	O

Then	O
,	O
we	O
design	O
self	O
-	O
supervised	O
pre	O
-	O
training	O
tasks	O
for	O
each	O
format	O
and	O
pre	O
-	O
train	O
prompts	O
on	O
these	O
tasks	O
.	O

We	O
propose	O
to	O
firstly	O
unify	O
downstream	O
tasks	O
to	O
several	O
formats	O
.	O

But	O
they	O
mostly	O
focus	O
on	O
PLMs	O
with	O
fewer	O
than	O
400	O
M	O
parameters	O
.	O

(	O
2021	O
)	O
also	O
discuss	O
reasonable	O
fewshot	O
settings	O
by	O
restricting	O
the	O
size	O
of	O
validation	O
set	O
and	O
proposing	O
a	O
unified	O
framework	O
to	O
evaluate	O
few	O
-	O
shot	O
performance	O
.	O

(	O
2021	O
)	O
;	O
Bragg	O
et	O
al	O
.	O

Apart	O
from	O
GPT-3	B-MethodName
(	O
Brown	O
et	O
al	O
.	O
,	O
2020	O
)	O
and	O
PET	B-MethodName
(	O
Schick	O
and	O
Schütze	O
,	O
2021a	O
)	O
which	O
demonstrates	O
the	O
superiority	O
of	O
PLMs	O
in	O
few	O
-	O
shot	O
scenarios	O
,	O
some	O
later	O
works	O
Perez	O
et	O
al	O
.	O

To	O
step	O
forward	O
,	O
some	O
works	O
(	O
Li	O
and	O
Liang	O
,	O
2021;Qin	O
and	O
Eisner	O
,	O
2021;Lester	O
et	O
al	O
.	O
,	O
2021	O
)	O
propose	O
to	O
only	O
tune	O
soft	O
prompts	O
and	O
fix	O
the	O
entire	O
PLM	O
parameters	O
.	O

Different	O
from	O
hard	O
prompts	O
using	O
concrete	O
and	O
discrete	O
tokens	O
,	O
soft	O
prompts	O
are	O
composed	O
of	O
several	O
continuous	O
learnable	O
embeddings	O
,	O
and	O
these	O
embeddings	O
are	O
randomly	O
initialized	O
.	O

(	O
2021b	O
)	O
explore	O
to	O
combine	O
hard	O
prompts	O
and	O
soft	O
prompts	O
.	O

(	O
2021	O
)	O
;	O
Zhong	O
et	O
al	O
.	O

(	O
2021b	O
)	O
;	O
Hambardzumyan	O
et	O
al	O
.	O

(	O
2021	O
)	O
;	O
Han	O
et	O
al	O
.	O

To	O
overcome	O
the	O
shortcomings	O
of	O
discrete	O
spaces	O
,	O
Li	O
and	O
Liang	O
(	O
2021	O
)	O
;	O
Liu	O
et	O
al	O
.	O

However	O
,	O
these	O
works	O
still	O
restrict	O
auto	O
-	O
generated	O
prompts	O
to	O
discrete	O
spaces	O
which	O
are	O
usually	O
sub	O
-	O
optimal	O
.	O

Considering	O
manually	O
designing	O
prompts	O
is	O
both	O
time	O
-	O
consuming	O
and	O
difficult	O
to	O
find	O
the	O
best	O
choice	O
,	O
later	O
works	O
(	O
Gao	O
et	O
al	O
.	O
,	O
2021;Jiang	O
et	O
al	O
.	O
,	O
2020;Shin	O
et	O
al	O
.	O
,	O
2020	O
)	O
proposed	O
to	O
generate	O
prompts	O
automatically	O
.	O

These	O
pioneering	O
works	O
demonstrate	O
that	O
language	O
prompts	O
can	O
effectively	O
stimulate	O
the	O
knowledge	O
from	O
PLMs	O
.	O
Encouraged	O
by	O
this	O
,	O
manually	O
designing	O
hard	O
prompts	O
consisting	O
of	O
discrete	O
words	O
is	O
first	O
used	O
in	O
prompt	B-MethodName
-	I-MethodName
oriented	I-MethodName
fine	I-MethodName
-	I-MethodName
tuning	I-MethodName
Schick	O
and	O
Schütze	O
(	O
2021a	O
,	O
b	O
)	O
.	O

In	O
knowledge	O
probing	O
,	O
language	O
triggers	O
are	O
widely	O
used	O
to	O
induce	O
PLMs	O
to	O
generate	O
relational	O
facts	O
.	O

Knowledge	O
probing	O
(	O
Petroni	O
et	O
al	O
.	O
,	O
2019;Trinh	O
and	O
Le	O
,	O
2018;Davison	O
et	O
al	O
.	O
,	O
2019	O
)	O
is	O
the	O
seminal	O
work	O
that	O
stimulates	O
the	O
development	O
of	O
prompts	O
.	O

In	O
prompt	B-MethodName
-	I-MethodName
oriented	I-MethodName
finetuning	I-MethodName
,	O
downstream	O
tasks	O
are	O
also	O
formalized	O
as	O
language	O
modeling	O
problems	O
by	O
inserting	O
language	O
prompts	O
,	O
and	O
the	O
results	O
of	O
language	O
modeling	O
can	O
correspond	O
to	O
the	O
solutions	O
of	O
downstream	O
tasks	O
.	O

To	O
overcome	O
the	O
gap	O
between	O
pretraining	O
and	O
downstream	O
tasks	O
,	O
prompt	B-MethodName
-	I-MethodName
oriented	I-MethodName
fine	I-MethodName
-	I-MethodName
tuning	I-MethodName
is	O
introduced	O
.	O

Prompt	B-MethodName
-	I-MethodName
oriented	I-MethodName
Fine	I-MethodName
-	I-MethodName
tuning	I-MethodName
Most	O
existing	O
PLMs	O
are	O
pre	O
-	O
trained	O
with	O
language	O
modeling	O
objectives	O
,	O
yet	O
the	O
objectives	O
of	O
downstream	O
tasks	O
are	O
quite	O
different	O
.	O

PLMs	O
and	O
Task	O
-	O
oriented	O
Fine	O
-	O
tuning	O
Recently	O
,	O
various	O
powerful	O
PLMs	O
have	O
been	O
proposed	O
,	O
such	O
as	O
GPT	B-MethodName
(	O
Radford	O
et	O
al	O
.	O
,	O
2018	O
)	O
,	O
BERT	B-MethodName
(	O
Devlin	O
et	O
al	O
.	O
,	O
2019	O
)	O
,	O
RoBERTa	B-MethodName
(	O
Liu	O
et	O
al	O
.	O
,	O
2019	O
)	O
and	O
T5	B-MethodName
(	O
Raffel	O
et	O
al	O
.	O
,	O
2020	O
)	O
.	O

Since	O
PPT	B-MethodName
still	O
converges	O
a	O
bit	O
slower	O
than	O
FT	B-MethodName
,	O
how	O
to	O
further	O
accelerate	O
the	O
convergence	O
of	O
PT	B-MethodName
is	O
worth	O
studying	O
in	O
future	O
work	O
.	O

Related	O
Works	O
.	O

We	O
give	O
a	O
more	O
detailed	O
analysis	O
of	O
the	O
training	O
consumption	O
in	O
the	O
Appendix	O
E.	O

As	O
shown	O
in	O
Figure	O
5	O
,	O
with	O
the	O
pre	O
-	O
trained	O
initialization	O
,	O
PPT	B-MethodName
speeds	O
up	O
the	O
convergence	O
of	O
Vanilla	B-MethodName
PT	I-MethodName
on	O
both	O
RACE	B-DatasetName
-	I-DatasetName
m	I-DatasetName
and	O
CB	B-DatasetName
datasets	O
.	O

We	O
also	O
compare	O
different	O
tuning	O
approaches	O
given	O
the	O
full	O
training	O
data	O
.	O

For	O
32	B-HyperparameterValue
to	O
128	B-HyperparameterValue
samples	B-HyperparameterName
,	O
PPT	B-MethodName
is	O
consistently	O
better	O
than	O
PT	B-MethodName
,	O
and	O
the	O
performances	O
of	O
the	O
three	O
methods	O
gradually	O
converge	O
when	O
the	O
number	O
grows	O
to	O
256	B-HyperparameterValue
.	O

In	O
Figure	O
4	O
,	O
we	O
show	O
the	O
trend	O
of	O
these	O
methods	O
on	O
the	O
RACE	B-DatasetName
-	I-DatasetName
m	I-DatasetName
and	O
CB	B-DatasetName
datasets	O
.	O

Sample	O
Efficiency	O
.	O

We	O
report	O
the	O
mean	O
and	O
the	O
standard	O
deviation	O
over	O
3	O
random	O
seeds	O
on	O
the	O
validation	O
set	O
.	O

When	O
the	O
number	O
grows	O
,	O
the	O
performance	O
of	O
these	O
methods	O
becomes	O
closer	O
.	O

Based	O
on	O
this	O
observation	O
,	O
an	O
intuitive	O
extension	O
of	O
our	O
method	O
is	O
to	O
further	O
pre	O
-	O
train	O
the	O
entire	O
model	O
with	O
PVP	O
pre	O
i	O
and	O
fine	O
-	O
tune	O
the	O
model	O
to	O
the	O
corresponding	O
downstream	O
tasks	O
.	O

Prompt	O
pre	O
-	O
training	O
bridges	O
this	O
gap	O
to	O
some	O
extend	O
.	O

This	O
indicates	O
that	O
there	O
still	O
remains	O
a	O
gap	O
between	O
masked	O
language	O
modeling	O
and	O
downstream	O
tasks	O
.	O

The	O
second	O
is	O
the	O
hybrid	O
strategy	O
in	O
Section	O
2	O
.	O

This	O
means	O
pre	O
-	O
training	O
soft	O
prompts	O
and	O
using	O
hybrid	O
prompts	O
are	O
complementary	O
.	O

First	O
,	O
larger	O
models	O
achieve	O
better	O
overall	O
performance	O
,	O
which	O
means	O
increasing	O
the	O
model	O
size	O
still	O
helps	O
under	O
the	O
few	O
-	O
shot	O
setting	O
.	O

Effectiveness	O
From	O
the	O
Table	O
4	O
we	O
have	O
four	O
observations	O
.	O

The	O
main	O
results	O
of	O
English	O
and	O
Chinese	O
datasets	O
are	O
shown	O
in	O
Table	O
4	O
.	O

Main	O
Results	O
.	O

We	O
use	O
the	O
Yelp-5	B-DatasetName
(	O
Zhang	O
et	O
al	O
.	O
,	O
2015a	O
)	O
dataset	O
to	O
train	O
the	O
RoBERTa	B-MethodName
BASE	I-MethodName
model	O
mentioned	O
in	O
Section	O
3.2.3	O
.	O
More	O
details	O
of	O
the	O
training	O
hyper	O
-	O
parameters	O
can	O
be	O
found	O
in	O
the	O
Appendix	O
C.	O

For	O
prompt	O
pre	O
-	O
training	O
,	O
we	O
sample	O
10	O
GB	O
data	O
from	O
OpenWebText	B-DatasetName
(	O
Gokaslan	O
et	O
al	O
.	O
,	O
2019	O
)	O
for	O
English	O
tasks	O
and	O
10	O
GB	O
data	O
from	O
WuDaoCorpora	B-DatasetName
(	O
Yuan	O
et	O
al	O
.	O
,	O
2021	O
)	O
for	O
Chinese	O
tasks	O
.	O

As	O
a	O
result	O
,	O
the	O
tunable	O
parameters	O
is	O
only	O
100×4096	O
=	O
4.1	O
×	O
10	O
5	O
=	O
410K.	O

Since	O
CPM-2	B-MethodName
does	O
not	O
provide	O
other	O
size	O
models	O
,	O
we	O
compare	O
it	O
with	O
mT5	B-MethodName
(	O
Xue	O
et	O
al	O
.	O
,	O
2021	O
)	O
of	O
various	O
sizes	O
.	O

Therefore	O
,	O
we	O
randomly	O
select	O
8	O
samples	O
for	O
each	O
label	O
.	O

For	O
tasks	O
with	O
more	O
than	O
5	O
labels	O
like	O
TNews	O
and	O
YahooAnswer	O
,	O
it	O
is	O
hard	O
to	O
compose	O
a	O
dataset	O
with	O
label	O
-	O
balanced	O
samples	O
.	O

As	O
described	O
in	O
Section	O
2	O
,	O
for	O
tasks	O
with	O
fewer	O
than	O
5	O
labels	O
,	O
we	O
construct	O
D	O
train	O
and	O
D	O
dev	O
with	O
32	O
samples	O
from	O
the	O
original	O
training	O
data	O
and	O
ensure	O
the	O
number	O
of	O
labels	O
is	O
balanced	O
.	O

We	O
conduct	O
experiments	O
on	O
both	O
Chinese	O
and	O
English	O
tasks	O
(	O
see	O
Table	O
3	O
)	O
.	O

Setup	O
.	O

Experiments	O
.	O

We	O
use	O
the	O
PVP	O
in	O
Section	O
3.2.2	O
for	O
pre	O
-	O
training	O
,	O
and	O
then	O
apply	O
pre	O
-	O
trained	O
soft	O
prompts	O
to	O
cover	O
the	O
above	O
mentioned	O
three	O
classification	O
tasks	O
.	O

Since	O
different	O
tasks	O
may	O
have	O
different	O
candidate	O
numbers	O
and	O
lengths	O
,	O
we	O
construct	O
pretraining	O
samples	O
with	O
option	O
numbers	O
varying	O
from	O
2	O
to	O
16	O
2	O
and	O
option	O
lengths	O
from	O
50	O
to	O
20	O
.	O

They	O
tune	O
the	O
entire	O
model	O
with	O
this	O
meta	O
task	O
on	O
a	O
collection	O
of	O
QA	O
datasets	O
and	O
then	O
transfer	O
to	O
other	O
classification	O
tasks	O
under	O
low	O
-	O
resource	O
settings	O
.	O

(	O
2021a	O
)	O
use	O
some	O
hard	O
prompts	O
to	O
unify	O
several	O
tasks	O
as	O
a	O
meta	O
question	O
answering	O
task	O
.	O

Recently	O
,	O
Zhong	O
et	O
al	O
.	O

Constructing	O
a	O
unified	O
PVP	O
is	O
similar	O
to	O
the	O
idea	O
of	O
MultiQA	B-DatasetName
(	O
Talmor	O
and	O
Berant	O
,	O
2019	O
)	O
and	O
Uni	B-DatasetName
-	I-DatasetName
fiedQA	I-DatasetName
(	O
Khashabi	O
et	O
al	O
.	O
,	O
2020	O
)	O
.	O

Note	O
that	O
in	O
this	O
way	O
,	O
the	O
pre	O
-	O
trained	O
PVPs	O
can	O
be	O
used	O
in	O
single	B-TaskName
text	I-TaskName
classification	I-TaskName
tasks	O
from	O
arbitrary	O
domains	O
and	O
with	O
much	O
more	O
labels	O
.	O

For	O
single	B-TaskName
-	I-TaskName
sentence	I-TaskName
classification	I-TaskName
,	O
the	O
query	O
is	O
the	O
input	O
sentence	O
and	O
the	O
options	O
are	O
the	O
concrete	O
labels	O
.	O

Unifying	O
Task	O
Formats	O
.	O

Therefore	O
,	O
the	O
method	O
described	O
in	O
the	O
following	O
section	O
is	O
proposed	O
to	O
solve	O
this	O
problem	O
.	O

Although	O
the	O
above	O
method	O
improves	O
the	O
model	O
performance	O
,	O
we	O
have	O
to	O
point	O
out	O
that	O
it	O
is	O
still	O
limited	O
to	O
generalize	O
to	O
other	O
single	B-TaskName
-	I-TaskName
text	I-TaskName
classifications	I-TaskName
in	O
different	O
domains	O
and	O
with	O
different	O
numbers	O
of	O
labels	O
.	O

For	O
those	O
with	O
fewer	O
than	O
5	O
labels	O
,	O
we	O
choose	O
a	O
subset	O
from	O
v	O
pre	O
i	O
(	O
Y	O
)	O
as	O
labels	O
.	O

(	O
5	O
)	O
For	O
sentiment	O
classification	O
tasks	O
with	O
5	O
labels	O
,	O
we	O
can	O
use	O
PVP	O
k	O
i	O
=	O
PVP	O
pre	O
i	O
.	O

X	O
.	O
"	O
,	O
v	O
pre	O
i	O
(	O
Y	O
)	O
=	O
[	O
terrible	O
,	O
bad	O
,	O
maybe	O
,	O
good	O
,	O
great	O
]	O
.	O

(	O
f	O
pre	O
i	O
,	O
v	O
pre	O
i	O
)	O
is	O
given	O
as	O
f	O
pre	O
i	O
(	O
x	O
)	O
=	O
"	O
s.	O

Then	O
with	O
a	O
sentence	O
s	O
from	O
the	O
corpus	O
,	O
we	O
have	O
the	O
input	O
x	O
=	O
(	O
s	O
)	O
and	O
the	O
label	O
set	O
Y	O
=	O
{	O
1	O
,	O
2	O
,	O
3	O
,	O
4	O
,	O
5	O
}	O
.	O

Taking	O
sentiment	O
classification	O
as	O
an	O
example	O
,	O
we	O
use	O
another	O
small	O
model	O
to	O
annotate	O
sentiment	O
labels	O
for	O
the	O
sentences	O
from	O
the	O
pre	O
-	O
training	O
corpus	O
and	O
filter	O
out	O
those	O
with	O
low	O
classification	O
probability	O
.	O

For	O
single	B-TaskName
-	I-TaskName
sentence	I-TaskName
classification	I-TaskName
,	O
we	O
create	O
pseudo	O
labels	O
for	O
prompt	O
pre	O
-	O
training	O
.	O

Single	B-TaskName
-	I-TaskName
Sentence	I-TaskName
Classification	I-TaskName
.	O

We	O
concatenate	O
them	O
to	O
form	O
the	O
query	O
.	O

A.s1	O
•	O
•	O
•	O
F.s6.Answer	O
is	O
X	O
.	O
"	O
,	O
v	O
pre	O
i	O
(	O
Y	O
)	O
=	O
[	O
A	O
,	O
B	O
,	O
C	O
,	O
D	O
,	O
E	O
,	O
F].(4	O
)	O
Most	O
multiple	B-TaskName
-	I-TaskName
choice	I-TaskName
tasks	O
can	O
use	O
{	O
f	O
pre	O
i	O
,	O
v	O
pre	O
i	O
}	O
directly	O
as	O
their	O
PVPs	O
.	O
For	O
tasks	O
like	O
reading	B-TaskName
comprehension	I-TaskName
,	O
the	O
input	O
may	O
contain	O
a	O
passage	O
and	O
a	O
question	O
.	O

For	O
x	O
=	O
(	O
s	O
q	O
,	O
s	O
1	O
,	O
s	O
2	O
,	O
•	O
•	O
•	O
,	O
s	O
6	O
)	O
,	O
(	O
f	O
pre	O
i	O
,	O
v	O
pre	O
i	O
)	O
is	O
given	O
as	O
f	O
pre	O
i	O
(	O
x	O
)	O
=	O
"	O
sq	O
?	O

These	O
candidates	O
consist	O
of	O
the	O
right	O
answer	O
,	O
one	O
sentence	O
from	O
the	O
same	O
document	O
but	O
is	O
not	O
adjacent	O
to	O
the	O
query	O
,	O
and	O
four	O
sentences	O
from	O
other	O
documents	O
.	O

Given	O
a	O
sentence	O
as	O
the	O
query	O
s	O
q	O
,	O
the	O
model	O
is	O
trained	O
to	O
select	O
the	O
adjacent	O
sentence	O
from	O
six	O
candidates	O
,	O
denoted	O
as	O
s	O
1	O
∼	O
s	O
6	O
and	O
thus	O
the	O
label	O
set	O
is	O
Y	O
=	O
{	O
1	O
,	O
2	O
,	O
3	O
,	O
4	O
,	O
5	O
,	O
6	O
}	O
.	O

We	O
design	O
a	O
next	O
sentence	O
selection	O
task	O
to	O
pre	O
-	O
train	O
the	O
prompt	O
.	O

If	O
a	O
task	O
requires	O
to	O
measure	O
the	O
similarity	O
between	O
two	O
sentences	O
,	O
the	O
probability	O
over	O
{	O
no	O
,	O
yes	O
}	O
can	O
serve	O
for	O
this	O
task	O
.	O

(	O
3	O
)	O
Designing	O
PVP	O
k	O
i	O
=	O
(	O
f	O
k	O
i	O
,	O
v	O
k	O
i	O
)	O
according	O
k	O
i	O
=	O
v	O
pre	O
i	O
.	O

PVP	O
pre	O
i	O
=	O
(	O
f	O
pre	O
i	O
,	O
v	O
pre	O
i	O
)	O
is	O
given	O
as	O
f	O
pre	O
i	O
(	O
x	O
)	O
=	O
"	O
s1	O
X	O
.s2	O
"	O
,	O
v	O
pre	O
i	O
(	O
Y	O
)	O
=	O
[	O
no	O
,	O
maybe	O
,	O
yes	O
]	O
.	O

We	O
consider	O
the	O
label	O
set	O
|Y|	O
≤	O
3	O
because	O
this	O
covers	O
most	O
sentence	O
pair	O
tasks	O
.	O

To	O
construct	O
signal	O
from	O
unlabeled	O
documents	O
,	O
we	O
set	O
the	O
two	O
sentences	O
next	O
to	O
each	O
other	O
as	O
label	O
2	O
,	O
those	O
from	O
the	O
same	O
document	O
but	O
not	O
true	O
next	O
sentences	O
as	O
1	O
,	O
and	O
those	O
from	O
different	O
documents	O
as	O
0	O
.	O

These	O
labels	O
in	O
Y	O
can	O
respectively	O
indicate	O
that	O
the	O
semantic	O
relation	O
between	O
two	O
sentences	O
is	O
coherent	O
(	O
with	O
label	O
2	O
)	O
,	O
similar	O
(	O
1	O
)	O
and	O
irrelevant	O
(	O
0	O
)	O
.	O

(	O
2019	O
)	O
to	O
a	O
3	O
-	O
class	O
classification	O
with	O
labels	O
Y	O
=	O
{	O
0	O
,	O
1	O
,	O
2	O
}	O
as	O
the	O
pretraining	O
task	O
.	O

To	O
design	O
a	O
PVP	O
for	O
these	O
tasks	O
,	O
we	O
extend	O
the	O
next	O
sentence	O
prediction	O
in	O
Devlin	O
et	O
al	O
.	O

Sentence	B-TaskName
-	I-TaskName
pair	I-TaskName
classification	I-TaskName
tasks	O
such	O
as	O
natural	O
language	O
inference	O
and	O
sentence	O
similarity	O
take	O
two	O
sentences	O
x	O
=	O
(	O
s	O
1	O
,	O
s	O
2	O
)	O
as	O
the	O
input	O
.	O

In	O
this	O
section	O
,	O
we	O
take	O
three	O
typical	O
classification	O
tasks	O
as	O
examples	O
to	O
describe	O
the	O
design	O
of	O
patternverbalizer	O
pairs	O
PVP	O
pre	O
i	O
for	O
prompt	O
pre	O
-	O
training	O
.	O

Designing	O
Pattern	O
-	O
Verbalizer	O
Pairs	O
for	O
Pre	O
-	O
training	O
.	O

Then	O
,	O
for	O
each	O
task	O
PVP	O
k	O
i	O
in	O
T	O
i	O
,	O
we	O
continue	O
to	O
optimize	O
Eq	O
.	O
(	O
2	O
)	O
by	O
using	O
P	O
i	O
as	O
the	O
soft	O
prompts	O
initialization	O
.	O

After	O
pre	O
-	O
training	O
soft	O
prompts	O
on	O
these	O
tasks	O
with	O
all	O
model	O
parameters	O
fixed	O
,	O
we	O
get	O
m	O
pre	O
-	O
trained	O
prompts	O
{	O
P	O
1	O
,	O
P	O
2	O
,	O
...	O
,	O
P	O
m	O
}	O
.	O

For	O
each	O
group	O
,	O
we	O
design	O
a	O
corresponding	O
pre	O
-	O
training	O
task	O
PVP	O
pre	O
i	O
=	O
(	O
f	O
pre	O
i	O
,	O
v	O
pre	O
i	O
)	O
.	O

Formally	O
,	O
suppose	O
we	O
can	O
divide	O
downstream	O
tasks	O
into	O
m	O
groups	O
{	O
T	O
1	O
,	O
T	O
2	O
,	O
...	O
,	O
T	O
m	O
}	O
,	O
where	O
T	O
i	O
is	O
the	O
set	O
containing	O
n	O
i	O
downstream	O
tasks	O
:	O
{	O
PVP	O
1	O
i	O
,	O
PVP	O
2	O
i	O
,	O
...	O
,	O
PVP	O
n	O
i	O
i	O
}	O
,	O
where	O
PVP	O
k	O
i	O
=	O
(	O
f	O
k	O
i	O
,	O
v	O
k	O
i	O
)	O
.	O

Therefore	O
,	O
soft	O
prompts	O
pre	O
-	O
trained	O
by	O
NSP	O
can	O
be	O
a	O
good	O
initialization	O
for	O
these	O
sentence	O
-	O
pair	O
tasks	O
.	O

As	O
shown	O
in	O
Figure	O
3	O
,	O
these	O
tasks	O
all	O
take	O
two	O
sentences	O
as	O
input	O
and	O
compare	O
their	O
semantic	O
meanings	O
.	O

We	O
notice	O
that	O
some	O
groups	O
of	O
downstream	O
tasks	O
are	O
related	O
to	O
certain	O
self	O
-	O
supervised	O
tasks	O
built	O
on	O
unlabeled	O
pre	O
-	O
training	O
corpora	O
.	O

Inspired	O
by	O
this	O
,	O
we	O
propose	O
to	O
pre	O
-	O
train	O
soft	O
prompts	O
.	O

Recently	O
,	O
pre	O
-	O
training	O
has	O
been	O
proven	O
to	O
be	O
an	O
effective	O
method	O
to	O
find	O
a	O
good	O
model	O
initialization	O
.	O

However	O
,	O
we	O
find	O
it	O
hard	O
to	O
learn	O
effective	O
soft	O
prompts	O
,	O
which	O
may	O
result	O
in	O
low	O
performance	O
in	O
various	O
few	O
-	O
shot	O
scenarios	O
.	O

With	O
f	O
(	O
•	O
)	O
and	O
v(•	O
)	O
,	O
a	O
classification	O
task	O
can	O
be	O
represented	O
by	O
a	O
pattern	O
-	O
verbalizer	O
pair	O
(	O
f	O
,	O
v	O
):	O
arg	O
max	O
θ	O
x	O
log	O
p	O
y|x	O
;	O
θ	O
=	O
arg	O
max	O
θ	O
x	O
log	O
p	O
X	O
=	O
v(y)|f	O
(	O
x	O
)	O
;	O
θ	O
,	O
(	O
1	O
)	O
where	O
θ	O
indicates	O
all	O
tunable	O
parameters	O
,	O
especially	O
the	O
parameters	O
of	O
PLMs	O
.	O
For	O
convenience	O
,	O
we	O
use	O
"	O
PVP	O
"	O
to	O
denote	O
this	O
pattern	O
-	O
verbalizer	O
pair	O
(	O
Schick	O
and	O
Schütze	O
,	O
2021a	O
)	O
.	O

Then	O
,	O
a	O
verbalizer	O
v	O
:	O
Y	O
→	O
V	O
*	O
is	O
used	O
to	O
map	O
y	O
to	O
some	O
label	O
tokens	O
v(y	O
)	O
.	O

Taking	O
classification	O
for	O
example	O
,	O
given	O
an	O
input	O
sentence	O
x	O
∈	O
V	O
*	O
and	O
its	O
label	O
y	O
∈	O
Y	O
,	O
a	O
pattern	O
mapping	O
f	O
:	O
V	O
*	O
→	O
V	O
*	O
is	O
first	O
applied	O
to	O
convert	O
x	O
into	O
a	O
new	O
sequence	O
f	O
(	O
x	O
)	O
,	O
where	O
V	O
is	O
the	O
vocabulary	O
of	O
PLMs	O
.	O
f	O
(	O
x	O
)	O
not	O
only	O
adds	O
some	O
prompt	O
tokens	O
as	O
hints	O
,	O
but	O
also	O
preserves	O
the	O
mask	O
token	O
X	O
to	O
let	O
PLMs	O
predict	O
tokens	O
at	O
the	O
masked	O
positions	O
.	O

As	O
shown	O
in	O
Figure	O
1	O
(	O
c	O
)	O
,	O
to	O
reduce	O
the	O
objective	O
gap	O
between	O
pre	O
-	O
training	O
and	O
downstream	O
tasks	O
,	O
promptoriented	O
fine	O
-	O
tuning	O
converts	O
downstream	O
tasks	O
into	O
cloze	O
-	O
style	O
objectives	O
.	O

Overview	O
.	O

use	O
these	O
pre	O
-	O
trained	O
prompts	O
for	O
specific	O
tasks	O
.	O

This	O
suggests	O
that	O
observations	O
on	O
small	O
models	O
can	O
not	O
be	O
directly	O
adapted	O
to	O
large	O
models	O
and	O
finding	O
a	O
good	O
initialization	O
for	O
soft	O
prompts	O
is	O
yet	O
to	O
be	O
explored	O
.	O

However	O
,	O
from	O
the	O
experiments	O
on	O
SST-2	B-DatasetName
(	O
Socher	O
et	O
al	O
.	O
,	O
2013	O
)	O
and	O
BoolQ	B-DatasetName
(	O
Clark	O
et	O
al	O
.	O
,	O
2019	O
)	O
(	O
Table	O
2	O
)	O
,	O
we	O
find	O
that	O
for	O
the	O
11B	O
model	O
,	O
real	O
word	O
initialization	O
has	O
little	O
or	O
even	O
negative	O
impact	O
on	O
the	O
performance	O
in	O
few	O
-	O
shot	O
scenarios	O
.	O

The	O
effectiveness	O
of	O
this	O
approach	O
has	O
been	O
verified	O
on	O
small	O
PLMs	O
(	O
fewer	O
than	O
3B	O
parameters	O
)	O
in	O
previous	O
works	O
(	O
Lester	O
et	O
al	O
.	O
,	O
2021	O
)	O
.	O

In	O
real	O
word	O
initialization	O
,	O
we	O
use	O
the	O
embeddings	O
of	O
concrete	O
words	O
to	O
initialize	O
the	O
soft	O
prompt	O
and	O
test	O
four	O
initialization	O
strategies	O
.	O

Real	O
Word	O
Initialization	O
.	O

In	O
general	O
,	O
common	O
words	O
that	O
explain	O
the	O
meaning	O
of	O
corresponding	O
labels	O
work	O
well	O
.	O

From	O
Table	O
1	O
we	O
can	O
see	O
that	O
the	O
choices	O
of	O
verbalizers	O
influence	O
the	O
performance	O
remarkably	O
.	O

(	O
2021	O
in	O
Figure	O
1	O
(	O
c	O
)	O
and	O
(	O
d	O
)	O
,	O
the	O
verbalizer	O
maps	O
the	O
label	O
"	O
Positive	O
"	O
to	O
"	O
great	O
"	O
.	O

Verbalizer	O
Selection	O
Verbalizer	O
maps	O
taskspecific	O
labels	O
to	O
concrete	O
tokens	O
.	O

Furthermore	O
,	O
different	O
hard	O
prompts	O
affect	O
the	O
performance	O
remarkably	O
,	O
therefore	O
much	O
human	O
labor	O
for	O
prompt	O
design	O
and	O
selection	O
is	O
needed	O
.	O

In	O
Table	O
1	O
,	O
we	O
show	O
the	O
results	O
of	O
combining	O
soft	O
prompts	O
P	O
with	O
three	O
manually	O
designed	O
hard	O
prompts	O
and	O
two	O
auto	O
-	O
generated	O
hard	O
prompts	O
(	O
Gao	O
et	O
al	O
.	O
,	O
2021	O
)	O
on	O
a	O
sentiment	B-TaskName
classification	I-TaskName
task	O
(	O
Socher	O
et	O
al	O
.	O
,	O
2013	O
)	O
.	O

However	O
,	O
previous	O
works	O
train	O
soft	O
prompts	O
jointly	O
with	O
the	O
entire	O
model	O
.	O

Hybrid	B-MethodName
Prompt	I-MethodName
Tuning	I-MethodName
In	O
hybrid	B-MethodName
prompt	I-MethodName
tuning	I-MethodName
,	O
both	O
soft	O
and	O
hard	O
prompts	O
are	O
used	O
(	O
Liu	O
et	O
al	O
.	O
,	O
2021;Han	O
et	O
al	O
.	O
,	O
2021b	O
)	O
.	O

(	O
2021	O
)	O
to	O
use	O
the	O
original	O
validation	O
set	O
as	O
the	O
test	O
set	O
D	O
test	O
,	O
which	O
means	O
|D	O
test	O
|	O
|D	O
train	O
|	O
=	O
|D	O
dev	O
|	O
.	O

(	O
2021	O
)	O
and	O
Gao	O
et	O
al	O
.	O

We	O
analyze	O
three	O
strategies	O
including	O
hybrid	B-MethodName
prompt	I-MethodName
tuning	I-MethodName
,	O
verbalizer	O
selec-	O
(	O
Perez	O
et	O
al	O
.	O
,	O
2021	O
)	O
.	O

To	O
ensure	O
the	O
generalization	O
of	O
pre	O
-	O
trained	O
prompts	O
,	O
we	O
group	O
typical	O
classification	O
tasks	O
into	O
three	O
formats	O
:	O
sentencepair	B-TaskName
classification	I-TaskName
,	O
multiple	B-TaskName
-	I-TaskName
choice	I-TaskName
classification	I-TaskName
,	O
and	O
single	B-TaskName
-	I-TaskName
text	I-TaskName
classification	I-TaskName
,	O
each	O
format	O
corresponding	O
to	O
one	O
self	O
-	O
supervised	O
pre	O
-	O
training	O
task	O
.	O

We	O
follow	O
Zhang	O
et	O
al	O
.	O

To	O
help	O
the	O
model	O
find	O
suitable	O
prompts	O
,	O
we	O
pretrain	O
these	O
tokens	O
with	O
self	O
-	O
supervised	O
tasks	O
on	O
large	O
-	O
scale	O
unlabeled	O
corpora	O
.	O

The	O
above	O
observations	O
reveal	O
that	O
prompt	O
searching	O
for	O
PLMs	O
is	O
not	O
trivial	O
,	O
and	O
carefully	O
initialized	O
soft	O
prompt	O
tokens	O
is	O
crucial	O
.	O

First	O
,	O
soft	O
prompts	O
can	O
be	O
learned	O
end	O
-	O
to	O
-	O
end	O
in	O
comparison	O
to	O
hard	O
prompts	O
.	O

These	O
continuous	O
prompts	O
are	O
generally	O
randomly	O
initialized	O
and	O
learned	O
end	O
-	O
toend	O
.	O

To	O
address	O
this	O
challenge	O
,	O
Lester	O
et	O
al	O
.	O

As	O
shown	O
in	O
Figure	O
1	O
,	O
compared	O
to	O
task	O
-	O
oriented	O
finetuning	O
,	O
prompt	O
-	O
oriented	O
fine	O
-	O
tuning	O
is	O
more	O
similar	O
to	O
the	O
pre	O
-	O
training	O
objectives	O
(	O
masked	O
language	O
modeling	O
)	O
,	O
thereby	O
helping	O
to	O
better	O
use	O
knowledge	O
in	O
PLMs	O
and	O
often	O
obtaining	O
better	O
performance	O
.	O

As	O
shown	O
in	O
Figure	O
1	O
(	O
c	O
)	O
,	O
by	O
adding	O
the	O
prompt	O
"	O
It	O
was	O
X	O
.	O
"	O
to	O
a	O
sentence	O
,	O
we	O
can	O
determine	O
its	O
sentiment	O
polarity	O
with	O
PLMs	O
by	O
predicting	O
"	O
great	O
"	O
or	O
"	O
terrible	O
"	O
at	O
the	O
mask	O
position	O
.	O

In	O
promptoriented	O
fine	O
-	O
tuning	O
,	O
data	O
samples	O
are	O
converted	O
to	O
sequences	O
containing	O
prompt	O
tokens	O
,	O
and	O
downstream	O
tasks	O
are	O
formalized	O
as	O
language	O
modeling	O
problems	O
.	O

The	O
second	O
one	O
is	O
prompt	O
-	O
oriented	O
finetuning	O
(	O
Schick	O
and	O
Schütze	O
,	O
2021a	O
)	O
,	O
which	O
is	O
inspired	O
by	O
the	O
recent	O
works	O
utilizing	O
language	O
prompts	O
to	O
probe	O
the	O
knowledge	O
in	O
PLMs	O
(	O
Petroni	O
et	O
al	O
.	O
,	O
2019;Brown	O
et	O
al	O
.	O
,	O
2020	O
)	O
.	O

The	O
first	O
one	O
is	O
task	O
-	O
oriented	O
fine	O
-	O
tuning	O
,	O
where	O
a	O
task	O
-	O
specific	O
head	O
is	O
added	O
on	O
top	O
of	O
PLMs	O
,	O
and	O
the	O
entire	O
model	O
is	O
then	O
fine	O
-	O
tuned	O
by	O
optimizing	O
task	O
-	O
specific	O
objectives	O
on	O
corresponding	O
training	O
data	O
.	O

As	O
shown	O
in	O
Figure	O
1	O
(	O
b	O
)	O
and	O
(	O
c	O
)	O
,	O
there	O
are	O
two	O
mainstream	O
FT	B-MethodName
approaches	O
.	O

For	O
simplicity	O
,	O
we	O
name	O
this	O
full	B-MethodName
-	I-MethodName
model	I-MethodName
tuning	I-MethodName
as	O
"	O
FT	B-MethodName
"	O
.	O

various	O
NLP	O
tasks	O
and	O
outperform	O
the	O
approach	O
of	O
learning	O
models	O
from	O
scratch	O
(	O
Han	O
et	O
al	O
.	O
,	O
2021a	O
)	O
.	O

*	O
indicates	O
equal	O
contribution	O
.	O

By	O
tuning	O
the	O
entire	O
model	O
parameters	O
,	O
the	O
versatile	O
knowledge	O
acquired	O
from	O
large	O
-	O
scale	O
unlabeled	O
corpora	O
can	O
be	O
adapted	O
to	O
handling	O
†	O
Corresponding	O
author	O
.	O

Fine	O
-	O
tuning	O
pre	O
-	O
trained	O
language	O
models	O
(	O
PLMs	O
)	O
(	O
Devlin	O
et	O
al	O
.	O
,	O
2019;Radford	O
et	O
al	O
.	O
,	O
2019;Raffel	O
et	O
al	O
.	O
,	O
2020	O
)	O
has	O
made	O
great	O
progress	O
in	O
recent	O
years	O
.	O

Introduction	O
.	O

Our	O
approach	O
is	O
effective	O
and	O
efficient	O
for	O
using	O
large	O
-	O
scale	O
PLMs	O
in	O
practice	O
.	O

Extensive	O
experiments	O
show	O
that	O
tuning	B-MethodName
pre	I-MethodName
-	I-MethodName
trained	I-MethodName
prompts	I-MethodName
for	O
downstream	O
tasks	O
can	O
reach	O
or	O
even	O
outperform	O
full	B-MethodName
-	I-MethodName
model	I-MethodName
fine	I-MethodName
-	I-MethodName
tuning	I-MethodName
under	O
both	O
full	O
-	O
data	O
and	O
few	O
-	O
shot	O
settings	O
.	O

Therefore	O
,	O
in	O
this	O
work	O
,	O
we	O
propose	O
to	O
pre	O
-	O
train	O
prompts	O
by	O
adding	O
soft	O
prompts	O
into	O
the	O
pre	O
-	O
training	O
stage	O
to	O
obtain	O
a	O
better	O
initialization	O
.	O

We	O
attribute	O
this	O
low	O
performance	O
to	O
the	O
manner	O
of	O
initializing	O
soft	O
prompts	O
.	O

Prompts	O
for	O
pre	O
-	O
trained	O
language	O
models	O
(	O
PLMs	O
)	O
have	O
shown	O
remarkable	O
performance	O
by	O
bridging	O
the	O
gap	O
between	O
pre	O
-	O
training	O
tasks	O
and	O
various	O
downstream	O
tasks	O
.	O

For	O
English	O
experiments	O
,	O
we	O
use	O
a	O
dataset	O
from	O
GLUE	O
(	O
Wang	O
et	O
al	O
.	O
,	O
2019b	O
)	O
(	O
SST-2	B-DatasetName
(	O
Socher	O
et	O
al	O
.	O
,	O
2013	O
)	O
)	O
,	O
datasets	O
from	O
Su	O
-	O
perGLUE	O
(	O
Wang	O
et	O
al	O
.	O
,	O
2019a	O
)	O
,	O
(	O
BoolQ	B-DatasetName
(	O
Clark	O
et	O
al	O
.	O
,	O
2019	O
)	O
,	O
CB	O
(	O
De	O
Marneffe	O
et	O
al	O
.	O
,	O
2019	O
)	O
,	O
andRTE	O
(	O
Dagan	O
et	O
al	O
.	O
,	O
2006	O
)	O
)	O
,	O
two	O
extra	O
single	O
-	O
text	O
classification	O
datasets	O
(	O
SST-5	O
(	O
Socher	O
et	O
al	O
.	O
,	O
2013	O
)	O
and	O
YahooAnswers	O
(	O
Zhang	O
et	O
al	O
.	O
,	O
2015b	O
)	O
)	O
,	O
and	O
two	O
standard	O
question	O
answering	O
datasets	O
(	O
RACEmiddle	O
and	O
RACE	O
-	O
high	O
)	O
(	O
Lai	O
et	O
al	O
.	O
,	O
2017	O
)	O
for	O
multiple	B-TaskName
-	I-TaskName
choice	I-TaskName
classification	I-TaskName
.	O

For	O
PPT	B-MethodName
,	O
the	O
consump-	O
.	O

We	O
analyze	O
the	O
time	O
and	O
memory	O
consumption	O
of	O
FT	B-MethodName
and	O
PT	B-MethodName
in	O
this	O
section	O
.	O

For	O
Unified	B-MethodName
PPT	I-MethodName
,	O
we	O
uniformly	O
sample	O
the	O
option	O
numbers	O
from	O
2	O
to	O
16	O
to	O
cover	O
more	O
downstream	O
circumstances	O
.	O

Multiple	B-TaskName
-	I-TaskName
Choice	I-TaskName
Classification	I-TaskName
In	O
the	O
next	O
sentence	O
selection	O
task	O
,	O
giving	O
a	O
query	O
sentence	O
,	O
the	O
options	O
contain	O
one	O
adjacent	O
sentence	O
,	O
one	O
sentence	O
from	O
the	O
same	O
document	O
as	O
the	O
query	O
,	O
and	O
four	O
from	O
the	O
different	O
documents	O
.	O

We	O
filter	O
out	O
the	O
sentences	O
with	O
less	O
than	O
5	O
tokens	O
and	O
the	O
pairs	O
in	O
which	O
the	O
two	O
sentences	O
'	O
length	O
ratios	O
are	O
larger	O
than	O
100	B-HyperparameterValue
.	O

This	O
observation	O
also	O
implies	O
that	O
PT	B-MethodName
is	O
much	O
harder	O
to	O
train	O
than	O
FT	B-MethodName
,	O
which	O
is	O
consistent	O
with	O
the	O
experiment	O
results	O
in	O
the	O
main	O
paper	O
.	O

We	O
find	O
PT	B-MethodName
requires	O
a	O
much	O
larger	O
learning	O
rate	O
than	O
FT	B-MethodName
.	O

Since	O
the	O
tunable	O
parameters	O
are	O
much	O
less	O
in	O
PT	B-MethodName
,	O
8	O
NVIDIA	O
V100	O
32	O
G	O
GPUs	O
are	O
enough	O
for	O
the	O
training	O
.	O

For	O
Prompt	B-MethodName
Tuning	I-MethodName
(	O
PT	B-MethodName
)	O
,	O
we	O
add	O
a	O
set	O
of	O
soft	O
prompts	O
before	O
the	O
input	O
text	O
.	O

C.2	O
Prompt	B-MethodName
Tuning	I-MethodName
.	O

For	O
Full	B-MethodName
-	I-MethodName
Model	I-MethodName
Tuning	I-MethodName
(	O
FT	B-MethodName
)	O
,	O
we	O
tune	O
the	O
entire	O
parameters	O
of	O
the	O
model	O
without	O
concatenating	O
soft	O
prompts	O
.	O

C.1	O
Full	B-MethodName
-	I-MethodName
Model	I-MethodName
Tuning	I-MethodName
.	O

Extensive	O
experiments	O
show	O
that	O
our	O
method	O
significantly	O
outperforms	O
other	O
prompt	B-MethodName
tuning	I-MethodName
baselines	O
,	O
performing	O
comparable	O
or	O
even	O
better	O
than	O
full	B-MethodName
-	I-MethodName
model	I-MethodName
tuning	I-MethodName
.	O

Finally	O
,	O
we	O
do	O
prompt	B-MethodName
tuning	I-MethodName
on	O
downstream	O
tasks	O
based	O
on	O
the	O
pre	O
-	O
trained	O
initialization	O
.	O

When	O
models	O
are	O
large	O
enough	O
,	O
this	O
method	O
can	O
be	O
comparable	O
to	O
full	B-MethodName
-	I-MethodName
model	I-MethodName
tuning	I-MethodName
.	O

We	O
argue	O
that	O
PPT	B-MethodName
can	O
be	O
an	O
effective	O
solution	O
to	O
this	O
problem	O
.	O

In	O
addition	O
,	O
we	O
observe	O
that	O
although	O
PT	B-MethodName
is	O
faster	O
than	O
FT	B-MethodName
in	O
a	O
single	O
optimization	O
step	O
,	O
it	O
converges	O
much	O
slower	O
,	O
which	O
results	O
in	O
an	O
even	O
longer	O
training	O
time	O
.	O

From	O
Table	O
6	O
,	O
we	O
can	O
see	O
that	O
PPT	B-MethodName
and	O
Unified	B-MethodName
PPT	I-MethodName
still	O
outperform	O
the	O
Vanilla	B-MethodName
PT	I-MethodName
on	O
most	O
datasets	O
.	O

We	O
discuss	O
how	O
the	O
performance	O
of	O
FT	B-MethodName
,	O
PT	B-MethodName
,	O
and	O
PPT	B-MethodName
varies	O
when	O
the	O
number	O
of	O
training	O
samples	O
increases	O
.	O

Table	O
6	O
:	O
The	O
performance	O
of	O
FT	B-MethodName
,	O
PT	B-MethodName
,	O
PPT	B-MethodName
,	O
and	O
Unified	B-MethodName
PPT	I-MethodName
when	O
the	O
full	O
training	O
datasets	O
are	O
available	O
.	O

For	O
the	O
small	O
number	O
of	O
samples	O
,	O
PPT	B-MethodName
is	O
consistently	O
better	O
than	O
Vanilla	B-MethodName
PT	I-MethodName
.	O

However	O
,	O
we	O
can	O
see	O
that	O
Unified	B-MethodName
PPT	I-MethodName
still	O
achieves	O
the	O
best	O
performance	O
,	O
even	O
exceeding	O
FT	B-MethodName
by	O
a	O
large	O
margin	O
.	O

We	O
do	O
not	O
use	O
PPT	B-MethodName
for	O
singlesentence	O
classification	O
discussed	O
in	O
Section	O
3.2.3	O
because	O
it	O
is	O
hard	O
to	O
find	O
other	O
suitable	O
datasets	O
to	O
train	O
the	O
pseudo	O
label	O
annotator	O
.	O

PT	B-MethodName
(	O
MC	B-TaskName
)	O
means	O
we	O
solve	O
the	O
task	O
in	O
a	O
multiple	B-TaskName
-	I-TaskName
choice	I-TaskName
classification	I-TaskName
format	O
without	O
prompt	O
pre	O
-	O
training	O
.	O

For	O
some	O
datasets	O
like	O
SST-2	B-DatasetName
,	O
the	O
variance	O
reaches	O
15.5	O
which	O
means	O
the	O
model	O
does	O
not	O
perform	O
better	O
than	O
random	O
guesses	O
under	O
some	O
a	O
verbalizer	O
to	O
map	O
the	O
labels	O
to	O
the	O
intuitively	O
selected	O
words	O
.	O

Fourth	O
,	O
PPT	B-MethodName
results	O
in	O
lower	O
variances	O
on	O
most	O
of	O
the	O
datasets	O
.	O

However	O
,	O
since	O
we	O
focus	O
on	O
PT	B-MethodName
in	O
this	O
paper	O
,	O
we	O
leave	O
this	O
as	O
future	O
work	O
.	O

Third	O
,	O
PPT	B-MethodName
outperforms	O
FT	B-MethodName
on	O
all	O
Chinese	O
datasets	O
and	O
most	O
English	O
datasets	O
.	O

Similar	O
phenomenons	O
are	O
observed	O
on	O
other	O
datasets	O
like	O
RACE	B-DatasetName
-	I-DatasetName
m	I-DatasetName
,	O
LCQMC	B-DatasetName
,	O
and	O
C	B-DatasetName
3	I-DatasetName
,	O
where	O
adding	O
hard	O
prompts	O
to	O
PPT	B-MethodName
continues	O
to	O
improve	O
results	O
.	O

Although	O
PPT	B-MethodName
is	O
worse	O
than	O
Hybrid	B-MethodName
PT	I-MethodName
on	O
BoolQ	B-DatasetName
,	O
combining	O
PPT	B-MethodName
and	O
hard	O
prompts	O
(	O
Hybrid	B-MethodName
PPT	I-MethodName
)	O
outperforms	O
all	O
baselines	O
.	O

Second	O
,	O
PPT	B-MethodName
outperforms	O
Vanilla	B-MethodName
PT	I-MethodName
and	O
LM	B-MethodName
Adaption	I-MethodName
on	O
most	O
datasets	O
significantly	O
.	O

Since	O
CPM-2	B-MethodName
outperforms	O
mT5	B-MethodName
-	I-MethodName
XXL	I-MethodName
across	O
all	O
tasks	O
,	O
we	O
use	O
CPM-2	B-MethodName
as	O
the	O
base	O
model	O
.	O

Note	O
that	O
for	O
Chinese	O
experiments	O
,	O
CPM-2	B-MethodName
and	O
mT5	B-MethodName
-	I-MethodName
XXL	I-MethodName
share	O
the	O
same	O
parameter	O
scale	O
.	O

Therefore	O
,	O
we	O
study	O
PT	B-MethodName
on	O
the	O
large	O
-	O
scale	O
pre	O
-	O
trained	O
model	O
.	O

We	O
test	O
two	O
variants	O
of	O
PPT	B-MethodName
:	O
Hybrid	B-MethodName
PPT	I-MethodName
,	O
in	O
which	O
carefully	O
designed	O
hard	O
prompts	O
are	O
combined	O
with	O
pre	O
-	O
trained	O
soft	O
prompt	O
,	O
and	O
Unified	B-MethodName
PPT	I-MethodName
,	O
in	O
which	O
all	O
tasks	O
are	O
unified	O
in	O
the	O
multiple	B-TaskName
-	I-TaskName
choice	I-TaskName
classification	I-TaskName
format	O
.	O

(	O
2021	O
)	O
in	O
which	O
the	O
T5	B-MethodName
model	O
is	O
further	O
pre	O
-	O
trained	O
for	O
10	O
K	O
steps	O
with	O
language	O
modeling	O
to	O
reduce	O
the	O
gap	O
between	O
the	O
pre	O
-	O
training	O
and	O
PT	B-MethodName
.	O

We	O
also	O
consider	O
LM	B-MethodName
Adaption	I-MethodName
used	O
in	O
Lester	O
et	O
al	O
.	O

The	O
first	O
baseline	O
is	O
Vanilla	B-MethodName
PT	I-MethodName
,	O
where	O
the	O
soft	O
prompts	O
are	O
randomly	O
initialized	O
from	O
a	O
normal	O
distribution	O
.	O

In	O
the	O
block	O
PT	B-MethodName
,	O
we	O
show	O
the	O
results	O
of	O
PPT	B-MethodName
and	O
other	O
baselines	O
.	O

In	O
the	O
block	O
FT	B-MethodName
,	O
we	O
present	O
the	O
FT	B-MethodName
results	O
of	O
the	O
T5	B-MethodName
model	O
from	O
the	O
size	O
small	O
to	O
XXL	O
.	O

Compared	O
with	O
the	O
11B	O
(	O
1.1	O
×	O
10	O
10	O
)	O
parameters	O
of	O
FT	B-MethodName
,	O
PT	B-MethodName
only	O
needs	O
to	O
store	O
3000	O
times	O
smaller	O
parameters	O
for	O
each	O
task	O
.	O

Consistently	O
,	O
we	O
use	O
100	B-HyperparameterValue
soft	B-HyperparameterName
tokens	I-HyperparameterName
for	O
PT	B-MethodName
.	O

For	O
Chinese	O
datasets	O
,	O
we	O
do	O
PT	B-MethodName
based	O
on	O
a	O
11B	O
model	O
CPM-2	B-MethodName
.	O

We	O
also	O
evaluate	O
FT	B-MethodName
on	O
various	O
sizes	O
of	O
T5	B-MethodName
to	O
verify	O
that	O
larger	O
models	O
perform	O
better	O
and	O
thus	O
improving	O
PT	B-MethodName
based	O
on	O
T5	B-MethodName
-	I-MethodName
XXL	I-MethodName
is	O
meaningful	O
.	O

For	O
English	O
datasets	O
,	O
we	O
conduct	O
PT	B-MethodName
based	O
on	O
T5	B-MethodName
-	I-MethodName
XXL	I-MethodName
with	O
11B	O
parameters	O
because	O
previous	O
works	O
(	O
Lester	O
et	O
al	O
.	O
,	O
2021;Zhang	O
et	O
al	O
.	O
,	O
2022	O
)	O
have	O
shown	O
that	O
,	O
T5	B-MethodName
-	I-MethodName
XXL	I-MethodName
is	O
comparable	O
with	O
FT	B-MethodName
under	O
the	O
full	O
-	O
data	O
setting	O
.	O

However	O
,	O
our	O
PPT	B-MethodName
focuses	O
on	O
tuning	O
soft	O
prompts	O
with	O
the	O
main	O
body	O
of	O
PLMs	O
fixed	O
and	O
our	O
pretraining	O
is	O
conducted	O
on	O
fully	O
unsupervised	O
data	O
,	O
rather	O
than	O
the	O
collection	O
of	O
supervised	O
datasets	O
.	O

Specifically	O
,	O
for	O
sentence	B-TaskName
-	I-TaskName
pair	I-TaskName
classification	I-TaskName
,	O
the	O
query	O
is	O
the	O
concatenation	O
of	O
the	O
two	O
sentences	O
and	O
there	O
are	O
three	O
options	O
:	O
no	O
,	O
maybe	O
,	O
and	O
yes	O
.	O

The	O
above	O
-	O
mentioned	O
PVPs	O
for	O
pre	O
-	O
training	O
can	O
be	O
unified	O
to	O
a	O
single	O
format	O
:	O
multiple	B-TaskName
-	I-TaskName
choice	I-TaskName
classification	I-TaskName
.	O

In	O
practice	O
,	O
we	O
use	O
a	O
RoBERTa	B-MethodName
BASE	I-MethodName
(	O
Liu	O
et	O
al	O
.	O
,	O
2019	O
)	O
model	O
fine	O
-	O
tuned	O
on	O
a	O
5	O
-	O
class	O
sentiment	O
classification	O
dataset	O
other	O
than	O
the	O
few	O
-	O
shot	O
datasets	O
we	O
evaluate	O
on	O
.	O

Many	O
tasks	O
can	O
be	O
formulated	O
as	O
multiple	B-TaskName
-	I-TaskName
choice	I-TaskName
classification	I-TaskName
,	O
which	O
takes	O
a	O
query	O
and	O
several	O
answer	O
candidates	O
as	O
the	O
input	O
.	O

Multiple	B-TaskName
-	I-TaskName
Choice	I-TaskName
Classification	I-TaskName
.	O

Sentence	B-TaskName
-	I-TaskName
Pair	I-TaskName
Classification	I-TaskName
.	O

For	O
instance	O
,	O
some	O
tasks	O
in	O
the	O
form	O
of	O
sentence	B-TaskName
-	I-TaskName
pair	I-TaskName
classification	I-TaskName
,	O
such	O
as	O
natural	B-TaskName
language	I-TaskName
inference	I-TaskName
and	O
sentence	O
similarity	O
,	O
are	O
similar	O
to	O
the	O
next	O
sentence	O
prediction	O
(	O
NSP	O
)	O
(	O
Devlin	O
et	O
al	O
.	O
,	O
2019	O
)	O
task	O
used	O
in	O
the	O
pre	O
-	O
training	O
stage	O
.	O

The	O
parameter	O
initialization	O
usually	O
has	O
a	O
large	O
impact	O
on	O
the	O
difficulty	O
of	O
the	O
model	O
training	O
and	O
optimization	O
,	O
and	O
our	O
pilot	O
experiments	O
have	O
shown	O
that	O
existing	O
initialization	O
strategies	O
have	O
little	O
or	O
even	O
negative	O
impact	O
on	O
the	O
PT	B-MethodName
performance	O
of	O
large	O
-	O
scale	O
PLMs	O
.	O
We	O
refer	O
more	O
details	O
of	O
these	O
pilot	O
experiments	O
to	O
Section	O
4	O
.	O

By	O
tuning	O
P	O
,	O
Eq	O
.	O
(	O
1	O
)	O
is	O
replaced	O
by	O
arg	O
max	O
P	O
x	O
log	O
p	O
X	O
=	O
v(y	O
)	O
|	O
[	O
P	O
;	O
f	O
(	O
x	O
)	O
]	O
;	O
P	O
.(2	O
)	O
Owing	O
to	O
the	O
power	O
of	O
large	O
-	O
scale	O
PLMs	O
,	O
Eq	O
.	O
(	O
2	O
)	O
is	O
verified	O
to	O
be	O
comparable	O
to	O
these	O
FT	B-MethodName
methods	O
under	O
full	O
-	O
data	O
settings	O
.	O

In	O
PT	B-MethodName
(	O
Lester	O
et	O
al	O
.	O
,	O
2021	O
)	O
,	O
a	O
set	O
of	O
soft	O
prompts	O
P	O
are	O
concatenated	O
to	O
the	O
beginning	O
of	O
the	O
sequence	O
and	O
the	O
model	O
input	O
becomes	O
[	O
P	O
;	O
f	O
(	O
x	O
)	O
]	O
,	O
where	O
[	O
•	O
;	O
•	O
]	O
is	O
the	O
concatenation	O
operation	O
.	O

Following	O
the	O
approach	O
of	O
T5	B-MethodName
(	O
Raffel	O
et	O
al	O
.	O
,	O
2020	O
)	O
and	O
PT	B-MethodName
(	O
Lester	O
et	O
al	O
.	O
,	O
2021	O
)	O
,	O
we	O
solve	O
all	O
downstream	O
tasks	O
in	O
a	O
text	O
-	O
to	O
-	O
text	O
format	O
.	O

In	O
the	O
following	O
sections	O
,	O
we	O
describe	O
our	O
PPT	B-MethodName
framework	O
and	O
show	O
in	O
experiments	O
that	O
PPT	B-MethodName
not	O
only	O
provides	O
a	O
good	O
prompt	O
initialization	O
,	O
but	O
also	O
takes	O
advantage	O
of	O
the	O
good	O
verbalizer	O
,	O
and	O
is	O
complementary	O
to	O
hybrid	O
prompts	O
.	O

To	O
summarize	O
,	O
although	O
the	O
above	O
enhancement	O
strategies	O
can	O
not	O
help	O
PT	B-MethodName
achieve	O
comparable	O
results	O
with	O
FT	B-MethodName
under	O
few	O
-	O
shot	O
settings	O
,	O
they	O
are	O
still	O
the	O
key	O
factors	O
that	O
influence	O
the	O
PT	B-MethodName
performance	O
.	O

This	O
also	O
guides	O
our	O
verbalizer	O
selection	O
for	O
PPT	B-MethodName
in	O
Section	O
3	O
.	O

For	O
instance	O
,	O
1	O
Using	O
100	B-HyperparameterValue
soft	O
prompt	O
tokens	O
achieves	O
the	O
best	O
performance	O
in	O
Lester	O
et	O
al	O
.	O

We	O
can	O
see	O
that	O
hard	O
prompts	O
improve	O
PT	B-MethodName
,	O
but	O
still	O
under	O
-	O
perform	O
FT	B-MethodName
.	O

In	O
PT	B-MethodName
where	O
only	O
prompt	O
tokens	O
are	O
tunable	O
,	O
the	O
effectiveness	O
of	O
hybrid	O
prompts	O
is	O
under	O
-	O
explored	O
.	O

Besides	O
the	O
effectiveness	O
,	O
PPT	B-MethodName
also	O
retains	O
the	O
parameter	O
efficiency	O
of	O
PT	B-MethodName
,	O
which	O
is	O
valuable	O
for	O
future	O
applications	O
on	O
large	O
-	O
scale	O
PLMs	O
.	O
Pilot	O
Experiments	O
.	O

We	O
evaluate	O
PPT	B-MethodName
on	O
several	O
datasets	O
based	O
on	O
three	O
11B	O
PLMs	O
:	O
T5	B-MethodName
-	I-MethodName
XXL	I-MethodName
(	O
Raffel	O
et	O
al	O
.	O
,	O
2020	O
)	O
,	O
mT5	B-MethodName
-	I-MethodName
XXL	I-MethodName
(	O
Xue	O
et	O
al	O
.	O
,	O
2021	O
)	O
and	O
CPM-2	B-MethodName
(	O
Zhang	O
et	O
al	O
.	O
,	O
2022	O
)	O
in	O
few	O
-	O
shot	O
scenarios	O
.	O

We	O
name	O
this	O
Pre	B-MethodName
-	I-MethodName
trained	I-MethodName
Prompt	I-MethodName
Tuning	I-MethodName
framework	O
"	O
PPT	B-MethodName
"	O
.	O

In	O
addition	O
,	O
we	O
find	O
multiple	B-TaskName
-	I-TaskName
choice	I-TaskName
classification	I-TaskName
more	O
general	O
among	O
these	O
formats	O
and	O
we	O
can	O
unify	O
all	O
classification	O
tasks	O
to	O
this	O
format	O
.	O

Our	O
discoveries	O
are	O
as	O
follows	O
:	O
(	O
1	O
)	O
the	O
verbalizer	O
choice	O
has	O
a	O
large	O
impact	O
on	O
the	O
performance	O
;	O
(	O
2	O
)	O
simply	O
initializing	O
soft	O
prompts	O
with	O
concrete	O
word	O
embeddings	O
fails	O
to	O
improve	O
the	O
performance	O
,	O
yet	O
(	O
3	O
)	O
combining	O
soft	O
and	O
hard	O
prompts	O
is	O
helpful	O
;	O
and	O
(	O
4	O
)	O
all	O
these	O
methods	O
can	O
not	O
handle	O
few	O
-	O
shot	O
prompt	B-MethodName
tuning	I-MethodName
problems	O
well	O
.	O

Specifically	O
,	O
we	O
con	O
-	O
duct	O
pilot	O
experiments	O
to	O
empirically	O
analyze	O
the	O
effectiveness	O
of	O
PT	B-MethodName
on	O
PLMs	O
in	O
Section	O
2	O
,	O
which	O
is	O
ignored	O
by	O
most	O
existing	O
works	O
.	O

However	O
,	O
as	O
shown	O
in	O
Figure	O
2(b	O
)	O
,	O
we	O
find	O
that	O
PT	B-MethodName
performs	O
much	O
worse	O
than	O
FT	B-MethodName
under	O
few	O
-	O
shot	O
settings	O
,	O
which	O
may	O
hinder	O
the	O
application	O
of	O
PT	B-MethodName
in	O
various	O
low	O
-	O
resource	O
scenarios	O
.	O

Second	O
,	O
PT	B-MethodName
is	O
an	O
efficient	O
and	O
effective	O
paradigm	O
for	O
the	O
practical	O
use	O
of	O
largescale	O
PLMs	O
,	O
which	O
is	O
comparable	O
to	O
FT	B-MethodName
when	O
downstream	O
data	O
are	O
sufficient	O
(	O
Figure	O
2(a	O
)	O
)	O
.	O

PT	B-MethodName
has	O
two	O
promising	O
advantages	O
.	O

To	O
avoid	O
storing	O
the	O
entire	O
model	O
for	O
each	O
downstream	O
task	O
,	O
PT	B-MethodName
freezes	O
all	O
PLM	O
parameters	O
and	O
merely	O
tunes	O
soft	O
prompts	O
,	O
without	O
adding	O
any	O
intermediate	O
layers	O
and	O
task	O
-	O
specific	O
components	O
.	O

Specifically	O
,	O
PT	B-MethodName
uses	O
soft	O
prompts	O
composed	O
of	O
continuous	O
embeddings	O
instead	O
of	O
hard	O
prompts	O
(	O
discrete	O
language	O
phrases	O
)	O
.	O

(	O
2021	O
)	O
proposes	O
prompt	B-MethodName
tuning	I-MethodName
(	O
PT	B-MethodName
)	O
to	O
adapt	O
large	O
PLMs	O
to	O
downstream	O
tasks	O
cheaply	O
,	O
as	O
shown	O
in	O
Figure	O
1	O
(	O
d	O
)	O
.	O

Although	O
FT	B-MethodName
has	O
shown	O
promising	O
results	O
,	O
with	O
the	O
rapid	O
growth	O
of	O
model	O
scale	O
,	O
fine	O
-	O
tuning	O
and	O
storing	O
the	O
entire	O
large	O
model	O
for	O
each	O
downstream	O
task	O
becomes	O
much	O
more	O
expensive	O
.	O

The	O
code	O
is	O
publicly	O
available	O
at	O
https://	O
github.com/thu-coai/PPT	B-MethodName
.	O

To	O
ensure	O
the	O
generalization	O
of	O
PPT	B-MethodName
,	O
we	O
formulate	O
similar	O
classification	O
tasks	O
into	O
a	O
unified	O
task	O
form	O
and	O
pre	O
-	O
train	O
soft	O
prompts	O
for	O
this	O
unified	O
task	O
.	O

We	O
name	O
this	O
Pretrained	B-MethodName
Prompt	I-MethodName
Tuning	I-MethodName
framework	O
"	O
PPT	B-MethodName
"	O
.	O

In	O
our	O
pilot	O
experiments	O
,	O
we	O
find	O
that	O
prompt	B-MethodName
tuning	I-MethodName
performs	O
comparably	O
with	O
conventional	O
full	B-MethodName
-	I-MethodName
model	I-MethodName
tuning	I-MethodName
when	O
downstream	O
data	O
are	O
sufficient	O
,	O
whereas	O
it	O
is	O
much	O
worse	O
under	O
fewshot	O
learning	O
settings	O
,	O
which	O
may	O
hinder	O
the	O
application	O
of	O
prompt	B-MethodName
tuning	I-MethodName
.	O

However	O
,	O
prompt	B-MethodName
tuning	I-MethodName
is	O
yet	O
to	O
be	O
fully	O
explored	O
.	O

Among	O
these	O
methods	O
,	O
prompt	B-MethodName
tuning	I-MethodName
,	O
which	O
freezes	O
PLMs	O
and	O
only	O
tunes	O
soft	O
prompts	O
,	O
provides	O
an	O
efficient	O
and	O
effective	O
solution	O
for	O
adapting	O
largescale	O
PLMs	O
to	O
downstream	O
tasks	O
.	O

