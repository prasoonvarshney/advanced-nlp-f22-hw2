-DOCSTART- -X- O
Besides -X- _ O
, -X- _ O
we -X- _ O
can -X- _ O
see -X- _ O
the -X- _ O
results -X- _ O
without -X- _ O
absolute -X- _ O
value -X- _ O
operation -X- _ O
for -X- _ O
symmetry -X- _ O
is -X- _ O
worse -X- _ O
, -X- _ O
demonstrating -X- _ O
absolute -X- _ O
value -X- _ O
operation -X- _ O
is -X- _ O
necessary -X- _ O
. -X- _ O

We -X- _ O
can -X- _ O
know -X- _ O
weight -X- _ O
for -X- _ O
meaningless -X- _ O
tokens -X- _ O
is -X- _ O
effective -X- _ O
. -X- _ O

And -X- _ O
the -X- _ O
results -X- _ O
without -X- _ O
weight -X- _ O
operation -X- _ O
for -X- _ O
word -X- _ O
embeddings -X- _ O
perform -X- _ O
worse -X- _ O
. -X- _ O

We -X- _ O
can -X- _ O
see -X- _ O
the -X- _ O
results -X- _ O
without -X- _ O
" -X- _ O
Delete -X- _ O
Sequence -X- _ O
" -X- _ O
and -X- _ O
" -X- _ O
Insert -X- _ O
Sequence -X- _ O
" -X- _ O
performs -X- _ O
a -X- _ O
little -X- _ O
worse -X- _ O
, -X- _ O
proving -X- _ O
its -X- _ O
necessity -X- _ O
. -X- _ O

It -X- _ O
demonstrates -X- _ O
that -X- _ O
subtraction -X- _ O
has -X- _ O
better -X- _ O
ability -X- _ O
to -X- _ O
capture -X- _ O
the -X- _ O
difference -X- _ O
between -X- _ O
two -X- _ O
sentences -X- _ O
, -X- _ O
and -X- _ O
provides -X- _ O
better -X- _ O
instance -X- _ O
representation -X- _ O
for -X- _ O
diversity -X- _ O
rank -X- _ O
. -X- _ O

We -X- _ O
can -X- _ O
see -X- _ O
subtraction -X- _ O
operation -X- _ O
is -X- _ O
better -X- _ O
than -X- _ O
sum -X- _ O
operation -X- _ O
. -X- _ O

Table -X- _ O
4 -X- _ O
and -X- _ O
Figure -X- _ O
6 -X- _ O
report -X- _ O
accuracy -X- _ B-MetricName
and -X- _ O
learning -X- _ B-MetricName
curves -X- _ I-MetricName
respectively -X- _ O
. -X- _ O

Table -X- _ O
4 -X- _ O
: -X- _ O
Accuracy -X- _ B-MetricName
of -X- _ O
subtraction -X- _ O
operation -X- _ O
on -X- _ O
Levenshtein -X- _ O
Distance -X- _ O
. -X- _ O

the -X- _ O
two -X- _ O
sentences -X- _ O
without -X- _ O
" -X- _ O
Delete -X- _ O
Sequence -X- _ O
" -X- _ O
and -X- _ O
" -X- _ O
Insert -X- _ O
Sequence -X- _ O
" -X- _ O
( -X- _ O
Sub -X- _ O
) -X- _ O
; -X- _ O
( -X- _ O
c -X- _ O
) -X- _ O
without -X- _ O
weight -X- _ O
for -X- _ O
word -X- _ O
embeddings -X- _ O
( -X- _ O
Nowei -X- _ O
) -X- _ O
; -X- _ O
( -X- _ O
d -X- _ O
) -X- _ O
without -X- _ O
absolute -X- _ O
value -X- _ O
operation -X- _ O
for -X- _ O
symmetry -X- _ O
( -X- _ O
Noabs -X- _ O
) -X- _ O
. -X- _ O

This -X- _ O
research -X- _ O
work -X- _ O
was -X- _ O
also -X- _ O
supported -X- _ O
by -X- _ O
the -X- _ O
independent -X- _ O
research -X- _ O
project -X- _ O
of -X- _ O
National -X- _ O
Laboratory -X- _ O
of -X- _ O
Pattern -X- _ O
Recognition -X- _ O
and -X- _ O
the -X- _ O
Youth -X- _ O
Innovation -X- _ O
Promotion -X- _ O
Association -X- _ O
CAS -X- _ O
. -X- _ O

The -X- _ O
work -X- _ O
is -X- _ O
supported -X- _ O
by -X- _ O
the -X- _ O
National -X- _ O
Natural -X- _ O
Science -X- _ O
Foundation -X- _ O
of -X- _ O
China -X- _ O
under -X- _ O
Grant -X- _ O
Nos.61533018 -X- _ O
, -X- _ O
U1936207 -X- _ O
, -X- _ O
61976211 -X- _ O
, -X- _ O
and -X- _ O
61702512 -X- _ O
. -X- _ O

Acknowledgements -X- _ O
. -X- _ O

We -X- _ O
compare -X- _ O
it -X- _ O
with -X- _ O
4 -X- _ O
baselines -X- _ O
: -X- _ O
( -X- _ O
a -X- _ O
) -X- _ O
using -X- _ O
the -X- _ O
sum -X- _ O
of -X- _ O
word -X- _ O
embeddings -X- _ O
of -X- _ O
the -X- _ O
two -X- _ O
sentences -X- _ O
( -X- _ O
Sum -X- _ O
) -X- _ O
; -X- _ O
( -X- _ O
b -X- _ O
) -X- _ O
directly -X- _ O
using -X- _ O
the -X- _ O
subtraction -X- _ O
of -X- _ O
word -X- _ O
embeddings -X- _ O
of -X- _ O
. -X- _ O

( -X- _ O
2)Effectiveness -X- _ O
of -X- _ O
subtraction -X- _ O
operation -X- _ O
on -X- _ O
Levenshtein -X- _ O
Distance -X- _ O
: -X- _ O
Here -X- _ O
we -X- _ O
validate -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
the -X- _ O
operation -X- _ O
that -X- _ O
uses -X- _ O
the -X- _ O
subtraction -X- _ O
of -X- _ O
word -X- _ O
embeddings -X- _ O
between -X- _ O
" -X- _ O
Delete -X- _ O
Sequence -X- _ O
" -X- _ O
and -X- _ O
" -X- _ O
Insert -X- _ O
Sequence -X- _ O
" -X- _ O
in -X- _ O
diversity -X- _ O
criterion -X- _ O
on -X- _ O
SNLI -X- _ B-DatasetName
dataset -X- _ O
. -X- _ O

It -X- _ O
is -X- _ O
possibly -X- _ O
because -X- _ O
BERT -X- _ O
used -X- _ O
more -X- _ O
data -X- _ O
to -X- _ O
learn -X- _ O
language -X- _ O
representations -X- _ O
. -X- _ O

In -X- _ O
intuition -X- _ O
, -X- _ O
contextual -X- _ O
representations -X- _ O
are -X- _ O
more -X- _ O
exact -X- _ O
especially -X- _ O
when -X- _ O
dealing -X- _ O
with -X- _ O
polysemy -X- _ O
. -X- _ O

We -X- _ O
can -X- _ O
see -X- _ O
contextual -X- _ O
representations -X- _ O
are -X- _ O
better -X- _ O
than -X- _ O
context -X- _ O
- -X- _ O
dependent -X- _ O
representations -X- _ O
. -X- _ O

Table -X- _ O
3 -X- _ O
and -X- _ O
Figure -X- _ O
5 -X- _ O
report -X- _ O
accuracy -X- _ B-MetricName
and -X- _ O
learning -X- _ B-MetricName
curves -X- _ I-MetricName
respectively -X- _ O
. -X- _ O

We -X- _ O
evaluated -X- _ O
performance -X- _ O
by -X- _ O
calculating -X- _ O
accuracy -X- _ B-MetricName
and -X- _ O
learning -X- _ B-MetricName
curves -X- _ I-MetricName
on -X- _ O
a -X- _ O
held -X- _ O
- -X- _ O
out -X- _ O
test -X- _ O
set -X- _ O
( -X- _ O
classes -X- _ O
are -X- _ O
fairly -X- _ O
balanced -X- _ O
in -X- _ O
datasets -X- _ O
) -X- _ O
after -X- _ O
all -X- _ O
rounds -X- _ O
. -X- _ O

Batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
is -X- _ O
16 -X- _ B-HyperparameterValue
for -X- _ O
English -X- _ O
and -X- _ O
32 -X- _ B-HyperparameterValue
for -X- _ O
Chinese -X- _ O
, -X- _ O
Adam -X- _ B-HyperparameterValue
is -X- _ O
used -X- _ O
for -X- _ O
optimization -X- _ O
. -X- _ O

( -X- _ O
Configuration -X- _ O
: -X- _ O
The -X- _ O
number -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
instances -X- _ I-HyperparameterName
to -X- _ O
select -X- _ O
n -X- _ B-HyperparameterName
is -X- _ O
100 -X- _ B-HyperparameterValue
at -X- _ O
every -X- _ O
round -X- _ O
and -X- _ O
we -X- _ O
perform -X- _ O
25 -X- _ B-HyperparameterValue
rounds -X- _ B-HyperparameterName
of -X- _ O
active -X- _ O
learning -X- _ O
, -X- _ O
that -X- _ O
is -X- _ O
there -X- _ O
are -X- _ O
total -X- _ O
of -X- _ O
2500 -X- _ O
labeled -X- _ O
instances -X- _ O
for -X- _ O
training -X- _ O
in -X- _ O
the -X- _ O
end -X- _ O
. -X- _ O

( -X- _ O
4)LCQMC -X- _ B-DatasetName
: -X- _ O
an -X- _ O
open -X- _ O
- -X- _ O
domain -X- _ O
Chinese -X- _ O
question -X- _ O
matching -X- _ O
corpus -X- _ O
from -X- _ O
the -X- _ O
community -X- _ O
question -X- _ O
answering -X- _ O
website -X- _ O
Baidu -X- _ O
Knows -X- _ O
. -X- _ O

( -X- _ O
3)Quora -X- _ B-DatasetName
: -X- _ O
an -X- _ O
English -X- _ O
question -X- _ O
matching -X- _ O
corpus -X- _ O
from -X- _ O
the -X- _ O
online -X- _ O
question -X- _ O
answering -X- _ O
forum -X- _ O
Quora -X- _ O
. -X- _ O

( -X- _ O
2)MultiNLI -X- _ B-DatasetName
: -X- _ O
an -X- _ O
English -X- _ O
natural -X- _ O
language -X- _ O
inference -X- _ O
corpus -X- _ O
with -X- _ O
greater -X- _ O
linguistic -X- _ O
difficulty -X- _ O
and -X- _ O
diversity -X- _ O
. -X- _ O

( -X- _ O
1)SNLI -X- _ B-DatasetName
: -X- _ O
an -X- _ O
English -X- _ O
natural -X- _ O
language -X- _ O
inference -X- _ O
corpus -X- _ O
based -X- _ O
on -X- _ O
image -X- _ O
captioning -X- _ O
. -X- _ O

We -X- _ O
illustrate -X- _ O
it -X- _ O
in -X- _ O
2 -X- _ O
provides -X- _ O
statistics -X- _ O
of -X- _ O
these -X- _ O
datasets -X- _ O
. -X- _ O

Visualization -X- _ O
of -X- _ O
Delete -X- _ O
Sequence -X- _ O
and -X- _ O
Insert -X- _ O
Sequence -X- _ O
: -X- _ O
To -X- _ O
model -X- _ O
the -X- _ O
difference -X- _ O
between -X- _ O
two -X- _ O
sentences -X- _ O
, -X- _ O
we -X- _ O
employ -X- _ O
the -X- _ O
subtraction -X- _ O
of -X- _ O
word -X- _ O
embeddings -X- _ O
between -X- _ O
" -X- _ O
Delete -X- _ O
Sequence -X- _ O
" -X- _ O
and -X- _ O
" -X- _ O
Insert -X- _ O
Sequence -X- _ O
" -X- _ O
from -X- _ O
Levenshtein -X- _ O
Distance -X- _ O
( -X- _ O
when -X- _ O
we -X- _ O
transform -X- _ O
sentence -X- _ O
A -X- _ O
to -X- _ O
sentence -X- _ O
B -X- _ O
by -X- _ O
deleting -X- _ O
and -X- _ O
inserting -X- _ O
tokens -X- _ O
, -X- _ O
these -X- _ O
tokens -X- _ O
are -X- _ O
added -X- _ O
into -X- _ O
" -X- _ O
Delete -X- _ O
Sequence -X- _ O
" -X- _ O
and -X- _ O
" -X- _ O
Insert -X- _ O
Sequence -X- _ O
" -X- _ O
espectively -X- _ O
) -X- _ O
. -X- _ O

A -X- _ O
general -X- _ O
uncertainty -X- _ O
criterion -X- _ O
uses -X- _ O
entropy -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
defined -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O
Ent(x -X- _ O
i -X- _ O
) -X- _ O
= -X- _ O
− -X- _ O
k -X- _ O
P -X- _ O
( -X- _ O
y -X- _ O
i -X- _ O
= -X- _ O
k|x -X- _ O
i -X- _ O
) -X- _ O
log -X- _ O
P -X- _ O
( -X- _ O
y -X- _ O
i -X- _ O
= -X- _ O
k|x -X- _ O
i -X- _ O
) -X- _ O
( -X- _ O
9 -X- _ O
) -X- _ O
where -X- _ O
k -X- _ O
indexes -X- _ O
all -X- _ O
possible -X- _ O
labels -X- _ O
, -X- _ O
x -X- _ O
i -X- _ O
denotes -X- _ O
a -X- _ O
candidate -X- _ O
instance -X- _ O
that -X- _ O
is -X- _ O
made -X- _ O
up -X- _ O
of -X- _ O
a -X- _ O
pair -X- _ O
of -X- _ O
sentences -X- _ O
A -X- _ O
and -X- _ O
B -X- _ O
in -X- _ O
available -X- _ O
unlabeled -X- _ O
data -X- _ O
Q. -X- _ O

Commonly -X- _ O
, -X- _ O
the -X- _ O
criteria -X- _ O
is -X- _ O
mainly -X- _ O
based -X- _ O
on -X- _ O
uncertainty -X- _ O
criterion -X- _ O
( -X- _ O
uncertainty -X- _ B-MethodName
sampling -X- _ I-MethodName
) -X- _ O
, -X- _ O
in -X- _ O
which -X- _ O
ones -X- _ O
near -X- _ O
decision -X- _ O
boundaries -X- _ O
have -X- _ O
priority -X- _ O
to -X- _ O
be -X- _ O
selected -X- _ O
. -X- _ O

Train -X- _ O
and -X- _ O
update -X- _ O
classifier -X- _ O
M -X- _ O
based -X- _ O
on -X- _ O
P -X- _ O
6 -X- _ O
: -X- _ O
until -X- _ O
The -X- _ O
annotation -X- _ O
budget -X- _ O
is -X- _ O
exhausted -X- _ O
With -X- _ O
the -X- _ O
same -X- _ O
amount -X- _ O
of -X- _ O
labeled -X- _ O
data -X- _ O
P -X- _ O
, -X- _ O
criteria -X- _ O
for -X- _ O
instance -X- _ O
selection -X- _ O
in -X- _ O
active -X- _ O
learning -X- _ O
determine -X- _ O
the -X- _ O
classifier -X- _ O
performance -X- _ O
. -X- _ O

At -X- _ O
every -X- _ O
round -X- _ O
, -X- _ O
there -X- _ O
are -X- _ O
n -X- _ O
instances -X- _ O
to -X- _ O
be -X- _ O
selected -X- _ O
and -X- _ O
labeled -X- _ O
. -X- _ O

The -X- _ O
instance -X- _ O
selection -X- _ O
process -X- _ O
is -X- _ O
iterative -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
process -X- _ O
will -X- _ O
repeat -X- _ O
until -X- _ O
a -X- _ O
fixed -X- _ O
annotation -X- _ O
budget -X- _ O
is -X- _ O
reached -X- _ O
. -X- _ O

The -X- _ O
process -X- _ O
is -X- _ O
illustrated -X- _ O
in -X- _ O
Algorithm -X- _ O
1 -X- _ O
. -X- _ O

In -X- _ O
the -X- _ O
selection -X- _ O
criteria -X- _ O
, -X- _ O
a -X- _ O
measure -X- _ O
is -X- _ O
used -X- _ O
to -X- _ O
score -X- _ O
all -X- _ O
candidate -X- _ O
instances -X- _ O
in -X- _ O
Q -X- _ O
, -X- _ O
and -X- _ O
instances -X- _ O
maximizing -X- _ O
this -X- _ O
measure -X- _ O
are -X- _ O
selected -X- _ O
into -X- _ O
P -X- _ O
. -X- _ O

The -X- _ O
task -X- _ O
for -X- _ O
the -X- _ O
active -X- _ O
learning -X- _ O
is -X- _ O
to -X- _ O
select -X- _ O
instances -X- _ O
in -X- _ O
Q -X- _ O
based -X- _ O
on -X- _ O
some -X- _ O
criteria -X- _ O
, -X- _ O
and -X- _ O
then -X- _ O
label -X- _ O
them -X- _ O
and -X- _ O
add -X- _ O
them -X- _ O
into -X- _ O
P -X- _ O
, -X- _ O
so -X- _ O
as -X- _ O
to -X- _ O
maximize -X- _ O
classifier -X- _ O
performance -X- _ O
and -X- _ O
minimize -X- _ O
annotation -X- _ O
cost -X- _ O
. -X- _ O

P -X- _ O
is -X- _ O
for -X- _ O
training -X- _ O
a -X- _ O
classifier -X- _ O
and -X- _ O
can -X- _ O
absorb -X- _ O
new -X- _ O
instances -X- _ O
from -X- _ O
Q. -X- _ O

Standard -X- _ O
Active -X- _ O
Learning -X- _ O
: -X- _ O
In -X- _ O
a -X- _ O
general -X- _ O
active -X- _ O
learning -X- _ O
scenario -X- _ O
, -X- _ O
there -X- _ O
exists -X- _ O
a -X- _ O
small -X- _ O
set -X- _ O
of -X- _ O
labeled -X- _ O
data -X- _ O
P -X- _ O
and -X- _ O
a -X- _ O
large -X- _ O
pool -X- _ O
of -X- _ O
available -X- _ O
unlabeled -X- _ O
data -X- _ O
Q. -X- _ O

When -X- _ O
training -X- _ O
, -X- _ O
the -X- _ O
model -X- _ O
M -X- _ O
is -X- _ O
optimized -X- _ O
by -X- _ O
minimizing -X- _ O
cross -X- _ O
entropy -X- _ O
: -X- _ O
Loss -X- _ O
= -X- _ O
−P -X- _ O
( -X- _ O
y|a -X- _ O
, -X- _ O
b -X- _ O
; -X- _ O
θ -X- _ O
M -X- _ O
) -X- _ O
log -X- _ O
P -X- _ O
( -X- _ O
y|a -X- _ O
, -X- _ O
b -X- _ O
; -X- _ O
θ -X- _ O
M -X- _ O
) -X- _ O
( -X- _ O
8) -X- _ O
where -X- _ O
y -X- _ O
denotes -X- _ O
the -X- _ O
golden -X- _ O
label -X- _ O
. -X- _ O

When -X- _ O
testing -X- _ O
, -X- _ O
we -X- _ O
choose -X- _ O
the -X- _ O
label -X- _ O
with -X- _ O
the -X- _ O
highest -X- _ O
probability -X- _ O
in -X- _ O
prediction -X- _ O
distribution -X- _ O
P -X- _ O
( -X- _ O
y -X- _ O
i -X- _ O
|a -X- _ O
, -X- _ O
b -X- _ O
; -X- _ O
θ -X- _ O
M -X- _ O
) -X- _ O
as -X- _ O
output -X- _ O
, -X- _ O
where -X- _ O
θ -X- _ O
M -X- _ O
denotes -X- _ O
parameters -X- _ O
of -X- _ O
the -X- _ O
model -X- _ O
M -X- _ O
and -X- _ O
y -X- _ O
i -X- _ O
denotes -X- _ O
a -X- _ O
possible -X- _ O
label -X- _ O
. -X- _ O

And -X- _ O
there -X- _ O
is -X- _ O
a -X- _ O
sentence -X- _ O
matching -X- _ O
model -X- _ O
M -X- _ O
to -X- _ O
predict -X- _ O
a -X- _ O
label -X- _ O
ŷ -X- _ O
based -X- _ O
on -X- _ O
a -X- _ O
and -X- _ O
b. -X- _ O

, -X- _ O
e(b -X- _ O
l -X- _ O
B -X- _ O
) -X- _ O
] -X- _ O
, -X- _ O
where -X- _ O
n -X- _ O
e -X- _ O
denotes -X- _ O
the -X- _ O
vocabulary -X- _ O
size -X- _ O
, -X- _ O
d -X- _ B-HyperparameterName
denotes -X- _ O
the -X- _ O
embedding -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
and -X- _ O
e(a -X- _ O
i -X- _ O
) -X- _ O
and -X- _ O
e(b -X- _ O
j -X- _ O
) -X- _ O
denote -X- _ O
the -X- _ O
word -X- _ O
embedding -X- _ O
of -X- _ O
the -X- _ O
i -X- _ O
- -X- _ O
th -X- _ O
and -X- _ O
j -X- _ O
- -X- _ O
th -X- _ O
word -X- _ O
respectively -X- _ O
in -X- _ O
corresponding -X- _ O
sentences -X- _ O
. -X- _ O

, -X- _ O
e(a -X- _ O
l -X- _ O
A -X- _ O
) -X- _ O
] -X- _ O
and -X- _ O
b=[e(b -X- _ O
1 -X- _ O
) -X- _ O
, -X- _ O
e(b -X- _ O
2 -X- _ O
) -X- _ O
, -X- _ O
. -X- _ O

Through -X- _ O
a -X- _ O
shared -X- _ O
word -X- _ O
embedding -X- _ O
matrix -X- _ O
W -X- _ O
e -X- _ O
∈ -X- _ O
R -X- _ O
ne×d -X- _ O
, -X- _ O
we -X- _ O
can -X- _ O
obtain -X- _ O
word -X- _ O
embeddings -X- _ O
of -X- _ O
input -X- _ O
sentences -X- _ O
a=[e(a -X- _ O
1 -X- _ O
) -X- _ O
, -X- _ O
e(a -X- _ O
2 -X- _ O
) -X- _ O
, -X- _ O
. -X- _ O

, -X- _ O
b -X- _ O
l -X- _ O
B -X- _ O
] -X- _ O
, -X- _ O
where -X- _ O
a -X- _ O
i -X- _ O
and -X- _ O
b -X- _ O
j -X- _ O
denote -X- _ O
the -X- _ O
i -X- _ O
- -X- _ O
th -X- _ O
and -X- _ O
j -X- _ O
- -X- _ O
th -X- _ O
word -X- _ O
respectively -X- _ O
in -X- _ O
corresponding -X- _ O
sentences -X- _ O
, -X- _ O
and -X- _ O
l -X- _ O
A -X- _ O
and -X- _ O
l -X- _ O
B -X- _ O
denote -X- _ O
the -X- _ O
length -X- _ O
of -X- _ O
corresponding -X- _ O
sentences -X- _ O
. -X- _ O

, -X- _ O
a -X- _ O
l -X- _ O
A -X- _ O
] -X- _ O
and -X- _ O
B=[b -X- _ O
1 -X- _ O
, -X- _ O
b -X- _ O
2 -X- _ O
, -X- _ O
. -X- _ O

In -X- _ O
formal -X- _ O
, -X- _ O
we -X- _ O
have -X- _ O
two -X- _ O
sentences -X- _ O
A=[a -X- _ O
1 -X- _ O
, -X- _ O
a -X- _ O
2 -X- _ O
, -X- _ O
. -X- _ O

Appendix -X- _ O
A -X- _ O
: -X- _ O
More -X- _ O
Details -X- _ O
and -X- _ O
Discussions -X- _ O
Sentence -X- _ B-TaskName
Matching -X- _ I-TaskName
Task -X- _ O
: -X- _ O
Given -X- _ O
a -X- _ O
pair -X- _ O
of -X- _ O
sentences -X- _ O
as -X- _ O
input -X- _ O
, -X- _ O
the -X- _ O
goal -X- _ O
of -X- _ O
the -X- _ O
task -X- _ O
is -X- _ O
to -X- _ O
judge -X- _ O
the -X- _ O
relation -X- _ O
between -X- _ O
them -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
whether -X- _ O
they -X- _ O
express -X- _ O
the -X- _ O
same -X- _ O
meaning -X- _ O
. -X- _ O

Experiments -X- _ O
show -X- _ O
that -X- _ O
our -X- _ O
proposed -X- _ O
active -X- _ O
learning -X- _ O
approach -X- _ O
obtains -X- _ O
better -X- _ O
performance -X- _ O
. -X- _ O

We -X- _ O
devise -X- _ O
extra -X- _ O
linguistic -X- _ O
criteria -X- _ O
from -X- _ O
a -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
language -X- _ O
model -X- _ O
, -X- _ O
which -X- _ O
can -X- _ O
capture -X- _ O
language -X- _ O
characteristics -X- _ O
and -X- _ O
enhance -X- _ O
active -X- _ O
learning -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
combine -X- _ B-MethodName
active -X- _ I-MethodName
learning -X- _ I-MethodName
with -X- _ I-MethodName
a -X- _ I-MethodName
pre -X- _ I-MethodName
- -X- _ I-MethodName
trained -X- _ I-MethodName
language -X- _ I-MethodName
model -X- _ I-MethodName
. -X- _ O

Conclusion -X- _ O
. -X- _ O

More -X- _ O
ablation -X- _ O
discussions -X- _ O
are -X- _ O
shown -X- _ O
in -X- _ O
the -X- _ O
Appendix -X- _ O
. -X- _ O

It -X- _ O
demonstrates -X- _ O
that -X- _ O
each -X- _ O
linguistic -X- _ O
criterion -X- _ O
from -X- _ O
a -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
language -X- _ O
model -X- _ O
helps -X- _ O
capture -X- _ O
language -X- _ O
characteristics -X- _ O
and -X- _ O
enhances -X- _ O
selection -X- _ O
of -X- _ O
instances -X- _ O
. -X- _ O

We -X- _ O
can -X- _ O
see -X- _ O
each -X- _ O
combined -X- _ O
criterion -X- _ O
performs -X- _ O
better -X- _ O
than -X- _ O
a -X- _ O
single -X- _ O
uncertainty -X- _ O
criterion -X- _ O
. -X- _ O

Curves -X- _ O
are -X- _ O
also -X- _ O
illustrated -X- _ O
in -X- _ O
the -X- _ O
Appendix -X- _ O
. -X- _ O

Table -X- _ O
1 -X- _ O
reports -X- _ O
the -X- _ O
accuracy -X- _ B-MetricName
. -X- _ O

" -X- _ O
Ent -X- _ O
" -X- _ O
denotes -X- _ O
the -X- _ O
standard -X- _ O
uncertainty -X- _ O
criterion -X- _ O
, -X- _ O
" -X- _ O
E+Noi -X- _ O
/ -X- _ O
E+Cov -X- _ O
/ -X- _ O
E+Div -X- _ O
/ -X- _ O
E+All -X- _ O
" -X- _ O
denotes -X- _ O
combining -X- _ O
uncertainty -X- _ O
with -X- _ O
noise -X- _ O
/ -X- _ O
coverage -X- _ O
/ -X- _ O
diversity -X- _ O
/ -X- _ O
all -X- _ O
criteria -X- _ O
. -X- _ O

To -X- _ O
validate -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
extra -X- _ O
linguistic -X- _ O
criteria -X- _ O
, -X- _ O
we -X- _ O
separately -X- _ O
combining -X- _ O
them -X- _ O
with -X- _ O
standard -X- _ O
uncertainty -X- _ O
criterion -X- _ O
. -X- _ O

Ablation -X- _ O
Study -X- _ O
. -X- _ O

Moreover -X- _ O
, -X- _ O
we -X- _ O
show -X- _ O
the -X- _ O
relation -X- _ O
between -X- _ O
the -X- _ O
size -X- _ O
of -X- _ O
unlabeled -X- _ O
data -X- _ O
and -X- _ O
accuracy -X- _ B-MetricName
in -X- _ O
Figure -X- _ O
2 -X- _ O
( -X- _ O
6 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
can -X- _ O
see -X- _ O
the -X- _ O
superiority -X- _ O
of -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
model -X- _ O
based -X- _ O
approach -X- _ O
is -X- _ O
more -X- _ O
significant -X- _ O
for -X- _ O
larger -X- _ O
data -X- _ O
size -X- _ O
. -X- _ O

In -X- _ O
fact -X- _ O
, -X- _ O
sentence -X- _ B-TaskName
matching -X- _ I-TaskName
needs -X- _ O
to -X- _ O
capture -X- _ O
the -X- _ O
difference -X- _ O
between -X- _ O
sentences -X- _ O
and -X- _ O
gradients -X- _ O
of -X- _ O
a -X- _ O
single -X- _ O
token -X- _ O
ca -X- _ O
n't -X- _ O
reflect -X- _ O
the -X- _ O
relation -X- _ O
. -X- _ O

And -X- _ O
EGL -X- _ B-MethodName
performs -X- _ O
worse -X- _ O
than -X- _ O
the -X- _ O
standard -X- _ O
approach -X- _ O
active -X- _ B-MethodName
learning -X- _ I-MethodName
, -X- _ O
maybe -X- _ O
gradient -X- _ O
based -X- _ O
active -X- _ O
learning -X- _ O
is -X- _ O
not -X- _ O
suitable -X- _ O
for -X- _ O
sentence -X- _ O
matching -X- _ O
. -X- _ O

It -X- _ O
demonstrates -X- _ O
that -X- _ O
the -X- _ O
amount -X- _ O
of -X- _ O
labeled -X- _ O
data -X- _ O
for -X- _ O
sentence -X- _ O
matching -X- _ O
can -X- _ O
be -X- _ O
substantially -X- _ O
reduced -X- _ O
by -X- _ O
active -X- _ O
learning -X- _ O
. -X- _ O

Besides -X- _ O
, -X- _ O
active -X- _ B-MethodName
learning -X- _ I-MethodName
approaches -X- _ O
always -X- _ O
obtain -X- _ O
better -X- _ O
performance -X- _ O
than -X- _ O
random -X- _ B-MethodName
sampling -X- _ I-MethodName
. -X- _ O

We -X- _ O
can -X- _ O
know -X- _ O
that -X- _ O
extra -X- _ O
linguistic -X- _ O
criteria -X- _ O
are -X- _ O
effective -X- _ O
, -X- _ O
demonstrating -X- _ O
that -X- _ O
a -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
language -X- _ O
model -X- _ O
can -X- _ O
substantially -X- _ O
capture -X- _ O
language -X- _ O
characteristics -X- _ O
and -X- _ O
provide -X- _ O
more -X- _ O
efficient -X- _ O
instances -X- _ O
for -X- _ O
training -X- _ O
. -X- _ O

Overall -X- _ O
, -X- _ O
our -X- _ O
approach -X- _ O
obtains -X- _ O
better -X- _ O
performance -X- _ O
on -X- _ O
both -X- _ O
English -X- _ O
and -X- _ O
Chinese -X- _ O
datasets -X- _ O
. -X- _ O

Table -X- _ O
1 -X- _ O
and -X- _ O
Figure -X- _ O
2 -X- _ O
( -X- _ O
1 -X- _ O
- -X- _ O
5 -X- _ O
) -X- _ O
report -X- _ O
accuracy -X- _ B-MetricName
and -X- _ O
learning -X- _ O
curves -X- _ O
of -X- _ O
each -X- _ O
approach -X- _ O
on -X- _ O
the -X- _ O
five -X- _ O
datasets -X- _ O
. -X- _ O

Results -X- _ O
. -X- _ O

( -X- _ O
4)Pre -X- _ B-MethodName
- -X- _ I-MethodName
trained -X- _ I-MethodName
language -X- _ I-MethodName
model -X- _ I-MethodName
( -X- _ O
LM -X- _ O
) -X- _ O
is -X- _ O
our -X- _ O
proposed -X- _ O
active -X- _ O
learning -X- _ O
approach -X- _ O
. -X- _ O

( -X- _ O
3)Expected -X- _ B-MethodName
Gradient -X- _ I-MethodName
Length -X- _ I-MethodName
( -X- _ O
EGL -X- _ B-MethodName
) -X- _ O
aims -X- _ O
to -X- _ O
select -X- _ O
instances -X- _ O
expected -X- _ O
to -X- _ O
result -X- _ O
in -X- _ O
the -X- _ O
greatest -X- _ O
change -X- _ O
to -X- _ O
the -X- _ O
gradients -X- _ O
of -X- _ O
tokens -X- _ O
( -X- _ O
Settles -X- _ O
and -X- _ O
Craven -X- _ O
, -X- _ O
2008;Zhang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
. -X- _ O

( -X- _ O
2)Uncertainty -X- _ B-MethodName
sampling -X- _ I-MethodName
( -X- _ O
Entropy -X- _ B-MethodName
) -X- _ O
is -X- _ O
the -X- _ O
standard -X- _ O
entropy -X- _ O
criterion -X- _ O
( -X- _ O
Tong -X- _ O
and -X- _ O
Koller -X- _ O
, -X- _ O
2001;Zhu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2008 -X- _ O
) -X- _ O
. -X- _ O

We -X- _ O
compare -X- _ O
the -X- _ O
following -X- _ O
active -X- _ O
learning -X- _ O
approaches -X- _ O
: -X- _ O
( -X- _ O
1)Random -X- _ B-MethodName
sampling -X- _ I-MethodName
( -X- _ O
Random -X- _ B-MethodName
) -X- _ O
randomly -X- _ O
selects -X- _ O
instances -X- _ O
for -X- _ O
annotation -X- _ O
and -X- _ O
training -X- _ O
at -X- _ O
each -X- _ O
round -X- _ O
. -X- _ O

There -X- _ O
is -X- _ O
a -X- _ O
held -X- _ O
- -X- _ O
out -X- _ O
test -X- _ O
set -X- _ O
for -X- _ O
evaluation -X- _ O
after -X- _ O
all -X- _ O
rounds -X- _ O
. -X- _ O

We -X- _ O
choose -X- _ O
( -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
as -X- _ O
classifier -X- _ O
M -X- _ O
and -X- _ O
perform -X- _ O
25 -X- _ B-HyperparameterValue
rounds -X- _ B-HyperparameterName
of -X- _ O
active -X- _ O
learning -X- _ O
. -X- _ O

The -X- _ O
number -X- _ O
of -X- _ O
instances -X- _ O
to -X- _ O
select -X- _ O
at -X- _ O
every -X- _ O
round -X- _ O
is -X- _ O
n -X- _ B-HyperparameterName
= -X- _ O
100 -X- _ B-HyperparameterValue
. -X- _ O

In -X- _ O
practice -X- _ O
, -X- _ O
according -X- _ O
to -X- _ O
different -X- _ O
effectiveness -X- _ O
of -X- _ O
criteria -X- _ O
, -X- _ O
we -X- _ O
combine -X- _ O
ranks -X- _ O
of -X- _ O
criteria -X- _ O
and -X- _ O
select -X- _ O
the -X- _ O
top -X- _ O
n -X- _ B-HyperparameterName
candidate -X- _ O
instances -X- _ O
in -X- _ O
unlabeled -X- _ O
data -X- _ O
Q. -X- _ O

We -X- _ O
conduct -X- _ O
experiments -X- _ O
on -X- _ O
Both -X- _ O
English -X- _ O
and -X- _ O
Chinese -X- _ O
datasets -X- _ O
, -X- _ O
including -X- _ O
SNLI -X- _ B-DatasetName
( -X- _ O
Bowman -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
, -X- _ O
MultiNLI -X- _ B-DatasetName
( -X- _ O
Williams -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
, -X- _ O
Quora -X- _ B-DatasetName
( -X- _ O
Iyer -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
, -X- _ O
LCQMC -X- _ B-DatasetName
( -X- _ O
Liu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
BQ -X- _ B-DatasetName
( -X- _ O
Chen -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O

Settings -X- _ O
and -X- _ O
Comparisons -X- _ O
. -X- _ O

3 -X- _ O
Experiments -X- _ O
. -X- _ O

Specifically -X- _ O
, -X- _ O
we -X- _ O
sequentially -X- _ O
use -X- _ O
rank -X- _ O
uncer -X- _ O
, -X- _ O
rank -X- _ O
diver -X- _ O
, -X- _ O
rank -X- _ O
cover -X- _ O
, -X- _ O
rank -X- _ O
noise -X- _ O
to -X- _ O
select -X- _ O
top -X- _ O
8n -X- _ O
, -X- _ O
4n -X- _ O
, -X- _ O
2n -X- _ O
, -X- _ O
n -X- _ O
candidate -X- _ O
instances -X- _ O
, -X- _ O
and -X- _ O
add -X- _ O
the -X- _ O
final -X- _ O
n -X- _ O
instances -X- _ O
into -X- _ O
labeled -X- _ O
data -X- _ O
P -X- _ O
for -X- _ O
training -X- _ O
at -X- _ O
every -X- _ O
round -X- _ O
. -X- _ O

Instance -X- _ O
Selection -X- _ O
. -X- _ O

• -X- _ O
denotes -X- _ O
multiplication -X- _ O
on -X- _ O
element -X- _ O
. -X- _ O

Specifically -X- _ O
, -X- _ O
we -X- _ O
employ -X- _ O
k -X- _ O
- -X- _ O
means -X- _ O
clustering -X- _ O
algorithm -X- _ O
for -X- _ O
diversity -X- _ O
rank -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O
rank -X- _ O
diver -X- _ O
( -X- _ O
x -X- _ O
i -X- _ O
) -X- _ O
= -X- _ O
0 -X- _ O
if -X- _ O
v -X- _ O
i -X- _ O
• -X- _ O
v -X- _ O
i -X- _ O
∈ -X- _ O
O -X- _ O
diver -X- _ O
n -X- _ O
others(7 -X- _ O
) -X- _ O
where -X- _ O
O -X- _ O
diver -X- _ O
are -X- _ O
the -X- _ O
centers -X- _ O
of -X- _ O
n -X- _ O
clusters -X- _ O
of -X- _ O
{ -X- _ O
v -X- _ O
i -X- _ O
• -X- _ O
v -X- _ O
i -X- _ O
} -X- _ O
. -X- _ O

With -X- _ O
instance -X- _ O
representation -X- _ O
, -X- _ O
we -X- _ O
want -X- _ O
to -X- _ O
select -X- _ O
diverse -X- _ O
ones -X- _ O
that -X- _ O
are -X- _ O
representative -X- _ O
and -X- _ O
different -X- _ O
from -X- _ O
each -X- _ O
other -X- _ O
. -X- _ O

w -X- _ O
a -X- _ O
i -X- _ O
/w -X- _ O
b -X- _ O
j -X- _ O
denotes -X- _ O
the -X- _ O
weight -X- _ O
for -X- _ O
tokens -X- _ O
. -X- _ O

e(a -X- _ O
j -X- _ O
) -X- _ O
/e(b -X- _ O
j -X- _ O
) -X- _ O
denotes -X- _ O
word -X- _ O
embdeddings -X- _ O
. -X- _ O

Formally -X- _ O
, -X- _ O
v -X- _ O
i -X- _ O
= -X- _ O
j∈L -X- _ O
I -X- _ O
w -X- _ O
b -X- _ O
j -X- _ O
e(b -X- _ O
j -X- _ O
) -X- _ O
− -X- _ O
j∈L -X- _ O
D -X- _ O
w -X- _ O
a -X- _ O
j -X- _ O
e(a -X- _ O
j -X- _ O
) -X- _ O
( -X- _ O
5 -X- _ O
) -X- _ O
w -X- _ O
a -X- _ O
j -X- _ O
= -X- _ O
s -X- _ O
a -X- _ O
j -X- _ O
k∈l -X- _ O
A -X- _ O
s -X- _ O
a -X- _ O
k -X- _ O
, -X- _ O
w -X- _ O
b -X- _ O
j -X- _ O
= -X- _ O
s -X- _ O
b -X- _ O
j -X- _ O
k∈l -X- _ O
B -X- _ O
s -X- _ O
b -X- _ O
k -X- _ O
( -X- _ O
6 -X- _ O
) -X- _ O
where -X- _ O
s -X- _ O
a -X- _ O
i -X- _ O
/s -X- _ O
b -X- _ O
j -X- _ O
is -X- _ O
the -X- _ O
reconstruction -X- _ O
loss -X- _ O
of -X- _ O
the -X- _ O
i -X- _ O
/ -X- _ O
j -X- _ O
- -X- _ O
th -X- _ O
word -X- _ O
of -X- _ O
sentence -X- _ O
A -X- _ O
/ -X- _ O
B. -X- _ O

Intuitively -X- _ O
, -X- _ O
meaningless -X- _ O
tokens -X- _ O
such -X- _ O
as -X- _ O
preposition -X- _ O
should -X- _ O
have -X- _ O
less -X- _ O
weight -X- _ O
, -X- _ O
and -X- _ O
they -X- _ O
are -X- _ O
usually -X- _ O
easier -X- _ O
to -X- _ O
predict -X- _ O
with -X- _ O
lower -X- _ O
reconstruction -X- _ O
losses -X- _ O
. -X- _ O

Besides -X- _ O
, -X- _ O
the -X- _ O
word -X- _ O
embeddings -X- _ O
in -X- _ O
the -X- _ O
subtraction -X- _ O
are -X- _ O
weighted -X- _ O
by -X- _ O
reconstruction -X- _ O
losses -X- _ O
. -X- _ O

It -X- _ O
is -X- _ O
illustrated -X- _ O
in -X- _ O
the -X- _ O
Appendix -X- _ O
. -X- _ O

To -X- _ O
model -X- _ O
the -X- _ O
difference -X- _ O
between -X- _ O
two -X- _ O
sentences -X- _ O
, -X- _ O
we -X- _ O
employ -X- _ O
the -X- _ O
subtraction -X- _ O
of -X- _ O
word -X- _ O
embeddings -X- _ O
between -X- _ O
" -X- _ O
Delete -X- _ O
Sequence -X- _ O
" -X- _ O
L -X- _ O
D -X- _ O
and -X- _ O
" -X- _ O
Insert -X- _ O
Sequence -X- _ O
" -X- _ O
L -X- _ O
I -X- _ O
from -X- _ O
Levenshtein -X- _ O
Distance -X- _ O
( -X- _ O
when -X- _ O
we -X- _ O
transform -X- _ O
sentence -X- _ O
A -X- _ O
to -X- _ O
sentence -X- _ O
B -X- _ O
by -X- _ O
deleting -X- _ O
and -X- _ O
inserting -X- _ O
tokens -X- _ O
, -X- _ O
these -X- _ O
tokens -X- _ O
are -X- _ O
added -X- _ O
into -X- _ O
L -X- _ O
D -X- _ O
and -X- _ O
L -X- _ O
I -X- _ O
respectively -X- _ O
) -X- _ O
. -X- _ O

First -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
a -X- _ O
vector -X- _ O
v -X- _ O
i -X- _ O
for -X- _ O
instance -X- _ O
representation -X- _ O
of -X- _ O
a -X- _ O
sentence -X- _ O
pair -X- _ O
instance -X- _ O
x -X- _ O
i -X- _ O
. -X- _ O

In -X- _ O
contrast -X- _ O
, -X- _ O
diverse -X- _ O
ones -X- _ O
can -X- _ O
help -X- _ O
learn -X- _ O
more -X- _ O
various -X- _ O
language -X- _ O
expressions -X- _ O
and -X- _ O
matching -X- _ O
patterns -X- _ O
. -X- _ O

Redundant -X- _ O
instances -X- _ O
are -X- _ O
inefficient -X- _ O
and -X- _ O
waste -X- _ O
annotation -X- _ O
resources -X- _ O
. -X- _ O

Thus -X- _ O
, -X- _ O
we -X- _ O
can -X- _ O
employ -X- _ O
reconstruction -X- _ O
losses -X- _ O
to -X- _ O
capture -X- _ O
the -X- _ O
low -X- _ O
coverage -X- _ O
ones -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O
rank -X- _ O
cover -X- _ O
( -X- _ O
x -X- _ O
i -X- _ O
) -X- _ O
∝ -X- _ O
− -X- _ O
j∈l -X- _ O
A -X- _ O
c -X- _ O
a -X- _ O
j -X- _ O
s -X- _ O
a -X- _ O
j -X- _ O
j∈l -X- _ O
A -X- _ O
c -X- _ O
a -X- _ O
j -X- _ O
− -X- _ O
j∈l -X- _ O
B -X- _ O
c -X- _ O
b -X- _ O
j -X- _ O
s -X- _ O
b -X- _ O
j -X- _ O
j∈l -X- _ O
B -X- _ O
c -X- _ O
b -X- _ O
j -X- _ O
( -X- _ O
3 -X- _ O
) -X- _ O
c -X- _ O
a -X- _ O
j -X- _ O
= -X- _ O
0 -X- _ O
if -X- _ O
s -X- _ O
a -X- _ O
j -X- _ O
> -X- _ O
β -X- _ O
1 -X- _ O
others -X- _ O
, -X- _ O
c -X- _ O
b -X- _ O
j -X- _ O
= -X- _ O
0 -X- _ O
if -X- _ O
s -X- _ O
b -X- _ O
j -X- _ O
> -X- _ O
β -X- _ O
1 -X- _ O
others -X- _ O
( -X- _ O
4 -X- _ O
) -X- _ O
where -X- _ O
β -X- _ O
denotes -X- _ O
a -X- _ O
hyperparameter -X- _ O
to -X- _ O
distinguish -X- _ O
noise -X- _ O
and -X- _ O
is -X- _ O
set -X- _ O
as -X- _ O
10.0 -X- _ O
. -X- _ O
( -X- _ O
4 -X- _ O
) -X- _ O
Diversity -X- _ O
: -X- _ O
The -X- _ O
diversity -X- _ O
criterion -X- _ O
indicates -X- _ O
the -X- _ O
diversity -X- _ O
of -X- _ O
instances -X- _ O
. -X- _ O

These -X- _ O
fresh -X- _ O
instances -X- _ O
like -X- _ O
relatively -X- _ O
low -X- _ O
- -X- _ O
frequency -X- _ O
professional -X- _ O
expressions -X- _ O
usually -X- _ O
have -X- _ O
lower -X- _ O
generating -X- _ O
probabilities -X- _ O
than -X- _ O
common -X- _ O
ones -X- _ O
. -X- _ O

On -X- _ O
the -X- _ O
other -X- _ O
hand -X- _ O
, -X- _ O
the -X- _ O
classifier -X- _ O
needs -X- _ O
fresh -X- _ O
instances -X- _ O
( -X- _ O
low -X- _ O
coverage -X- _ O
) -X- _ O
to -X- _ O
enrich -X- _ O
representation -X- _ O
learning -X- _ O
. -X- _ O

On -X- _ O
the -X- _ O
one -X- _ O
hand -X- _ O
, -X- _ O
some -X- _ O
tokens -X- _ O
like -X- _ O
stop -X- _ O
words -X- _ O
are -X- _ O
meaningless -X- _ O
and -X- _ O
easy -X- _ O
to -X- _ O
model -X- _ O
( -X- _ O
high -X- _ O
coverage -X- _ O
) -X- _ O
. -X- _ O

( -X- _ O
3 -X- _ O
) -X- _ O
Coverage -X- _ O
: -X- _ O
The -X- _ O
coverage -X- _ O
criterion -X- _ O
indicates -X- _ O
whether -X- _ O
the -X- _ O
language -X- _ O
expression -X- _ O
of -X- _ O
the -X- _ O
current -X- _ O
instance -X- _ O
can -X- _ O
enrich -X- _ O
representation -X- _ O
learning -X- _ O
. -X- _ O

rank -X- _ O
noise -X- _ O
( -X- _ O
x -X- _ O
i -X- _ O
) -X- _ O
denotes -X- _ O
noise -X- _ O
rank -X- _ O
of -X- _ O
the -X- _ O
i -X- _ O
- -X- _ O
th -X- _ O
instance -X- _ O
in -X- _ O
Q -X- _ O
, -X- _ O
s -X- _ O
a -X- _ O
i -X- _ O
/s -X- _ O
b -X- _ O
i -X- _ O
is -X- _ O
the -X- _ O
reconstruction -X- _ O
loss -X- _ O
of -X- _ O
the -X- _ O
i -X- _ O
- -X- _ O
th -X- _ O
word -X- _ O
a -X- _ O
i -X- _ O
/b -X- _ O
i -X- _ O
in -X- _ O
sentence -X- _ O
A -X- _ O
/ -X- _ O
B -X- _ O
from -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
language -X- _ O
model -X- _ O
. -X- _ O

P -X- _ O
( -X- _ O
B -X- _ O
) -X- _ O
is -X- _ O
similar -X- _ O
. -X- _ O

a -X- _ O
l -X- _ O
A -X- _ O
) -X- _ O
∝ -X- _ O
l -X- _ O
A -X- _ O
i∈l -X- _ O
A -X- _ O
sa -X- _ O
i -X- _ O
. -X- _ O

Based -X- _ O
on -X- _ O
this -X- _ O
assumption -X- _ O
, -X- _ O
noise -X- _ O
criterion -X- _ O
is -X- _ O
formulated -X- _ O
about -X- _ O
losses -X- _ O
of -X- _ O
reconstructing -X- _ O
masked -X- _ O
tokens -X- _ O
: -X- _ O
rank -X- _ O
noise -X- _ O
( -X- _ O
x -X- _ O
i -X- _ O
) -X- _ O
∝ -X- _ O
−P -X- _ O
( -X- _ O
A -X- _ O
) -X- _ O
− -X- _ O
P -X- _ O
( -X- _ O
B)(2 -X- _ O
) -X- _ O
where -X- _ O
P -X- _ O
( -X- _ O
A -X- _ O
) -X- _ O
= -X- _ O
P -X- _ O
( -X- _ O
a -X- _ O
1 -X- _ O
a -X- _ O
2 -X- _ O
. -X- _ O

Thus -X- _ O
, -X- _ O
tokens -X- _ O
in -X- _ O
noisy -X- _ O
instances -X- _ O
may -X- _ O
be -X- _ O
hard -X- _ O
to -X- _ O
be -X- _ O
reconstructed -X- _ O
with -X- _ O
context -X- _ O
by -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
language -X- _ O
model -X- _ O
. -X- _ O

Noisy -X- _ O
instances -X- _ O
usually -X- _ O
have -X- _ O
rare -X- _ O
expression -X- _ O
with -X- _ O
low -X- _ O
generating -X- _ O
probability -X- _ O
. -X- _ O

Intuitively -X- _ O
, -X- _ O
instances -X- _ O
with -X- _ O
noise -X- _ O
may -X- _ O
degrade -X- _ O
the -X- _ O
labeled -X- _ O
data -X- _ O
P -X- _ O
, -X- _ O
and -X- _ O
we -X- _ O
want -X- _ O
to -X- _ O
select -X- _ O
noiseless -X- _ O
instances -X- _ O
. -X- _ O

( -X- _ O
2 -X- _ O
) -X- _ O
Noise -X- _ O
: -X- _ O
The -X- _ O
noise -X- _ O
criterion -X- _ O
indicates -X- _ O
how -X- _ O
much -X- _ O
potential -X- _ O
noise -X- _ O
there -X- _ O
is -X- _ O
in -X- _ O
an -X- _ O
instance -X- _ O
. -X- _ O

Formally -X- _ O
, -X- _ O
rank -X- _ O
uncer -X- _ O
( -X- _ O
x -X- _ O
i -X- _ O
) -X- _ O
∝ -X- _ O
−Ent(x -X- _ O
i -X- _ O
) -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
where -X- _ O
Ent(x -X- _ O
i -X- _ O
) -X- _ O
= -X- _ O
− -X- _ O
k -X- _ O
P -X- _ O
( -X- _ O
y -X- _ O
i -X- _ O
= -X- _ O
k|x -X- _ O
i -X- _ O
) -X- _ O
log -X- _ O
P -X- _ O
( -X- _ O
y -X- _ O
i -X- _ O
= -X- _ O
k|x -X- _ O
i -X- _ O
) -X- _ O
. -X- _ O

The -X- _ O
uncertainty -X- _ O
is -X- _ O
computed -X- _ O
as -X- _ O
the -X- _ O
entropy -X- _ O
, -X- _ O
and -X- _ O
we -X- _ O
can -X- _ O
obtain -X- _ O
uncertainty -X- _ O
rank -X- _ O
rank -X- _ O
uncer -X- _ O
( -X- _ O
x -X- _ O
i -X- _ O
) -X- _ O
for -X- _ O
the -X- _ O
i -X- _ O
- -X- _ O
th -X- _ O
instance -X- _ O
in -X- _ O
Q -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
entropy -X- _ O
. -X- _ O

Instances -X- _ O
with -X- _ O
high -X- _ O
uncertainty -X- _ O
are -X- _ O
more -X- _ O
helpful -X- _ O
to -X- _ O
optimize -X- _ O
the -X- _ O
classifier -X- _ O
and -X- _ O
thus -X- _ O
are -X- _ O
worthier -X- _ O
to -X- _ O
be -X- _ O
selected -X- _ O
. -X- _ O

( -X- _ O
1 -X- _ O
) -X- _ O
Uncertainty -X- _ O
: -X- _ O
The -X- _ O
uncertainty -X- _ O
criterion -X- _ O
indicates -X- _ O
classification -X- _ O
uncertainty -X- _ O
of -X- _ O
an -X- _ O
instance -X- _ O
and -X- _ O
is -X- _ O
the -X- _ O
standard -X- _ O
criterion -X- _ O
in -X- _ O
active -X- _ O
learning -X- _ O
. -X- _ O

Criteria -X- _ O
for -X- _ O
Instance -X- _ O
Selection -X- _ O
. -X- _ O

, -X- _ O
e(a -X- _ O
l -X- _ O
A -X- _ O
) -X- _ O
] -X- _ O
in -X- _ O
the -X- _ O
sentence -X- _ O
, -X- _ O
where -X- _ O
l -X- _ O
A -X- _ O
is -X- _ O
the -X- _ O
length -X- _ O
of -X- _ O
sentence -X- _ O
A. -X- _ O

The -X- _ O
other -X- _ O
is -X- _ O
word -X- _ O
embeddings -X- _ O
( -X- _ O
contextual -X- _ O
representations -X- _ O
of -X- _ O
the -X- _ O
last -X- _ O
layer -X- _ O
) -X- _ O
a=[e(a -X- _ O
1 -X- _ O
) -X- _ O
, -X- _ O
e(a -X- _ O
2 -X- _ O
) -X- _ O
, -X- _ O
. -X- _ O

One -X- _ O
is -X- _ O
the -X- _ O
cross -X- _ O
entropy -X- _ O
loss -X- _ O
s -X- _ O
a -X- _ O
i -X- _ O
of -X- _ O
reconstructing -X- _ O
of -X- _ O
the -X- _ O
i -X- _ O
- -X- _ O
th -X- _ O
word -X- _ O
a -X- _ O
i -X- _ O
in -X- _ O
sentence -X- _ O
A -X- _ O
( -X- _ O
the -X- _ O
same -X- _ O
with -X- _ O
another -X- _ O
B -X- _ O
) -X- _ O
by -X- _ O
masking -X- _ O
only -X- _ O
a -X- _ O
i -X- _ O
and -X- _ O
predicting -X- _ O
a -X- _ O
i -X- _ O
again -X- _ O
. -X- _ O

From -X- _ O
BERT -X- _ O
, -X- _ O
we -X- _ O
can -X- _ O
obtain -X- _ O
two -X- _ O
kinds -X- _ O
of -X- _ O
information -X- _ O
to -X- _ O
provide -X- _ O
linguistic -X- _ O
criteria -X- _ O
. -X- _ O

We -X- _ O
choose -X- _ O
the -X- _ O
widely -X- _ O
used -X- _ O
language -X- _ O
model -X- _ O
BERT -X- _ O
( -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
as -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
language -X- _ O
model -X- _ O
. -X- _ O

Pre -X- _ O
- -X- _ O
trained -X- _ O
Language -X- _ O
Model -X- _ O
. -X- _ O

More -X- _ O
details -X- _ O
of -X- _ O
preliminaries -X- _ O
about -X- _ O
sentence -X- _ O
matching -X- _ O
and -X- _ O
active -X- _ O
learning -X- _ O
are -X- _ O
in -X- _ O
the -X- _ O
Appendix -X- _ O
. -X- _ O

Active -X- _ O
learning -X- _ O
is -X- _ O
to -X- _ O
select -X- _ O
instances -X- _ O
in -X- _ O
Q -X- _ O
according -X- _ O
to -X- _ O
some -X- _ O
criteria -X- _ O
, -X- _ O
and -X- _ O
then -X- _ O
label -X- _ O
them -X- _ O
and -X- _ O
add -X- _ O
them -X- _ O
into -X- _ O
P -X- _ O
, -X- _ O
so -X- _ O
as -X- _ O
to -X- _ O
maximize -X- _ O
classifier -X- _ O
M -X- _ O
performance -X- _ O
and -X- _ O
minimize -X- _ O
annotation -X- _ O
cost -X- _ O
. -X- _ O

In -X- _ O
a -X- _ O
general -X- _ O
active -X- _ O
learning -X- _ O
scenario -X- _ O
, -X- _ O
there -X- _ O
is -X- _ O
a -X- _ O
small -X- _ O
set -X- _ O
of -X- _ O
labeled -X- _ O
training -X- _ O
data -X- _ O
P -X- _ O
and -X- _ O
a -X- _ O
large -X- _ O
pool -X- _ O
of -X- _ O
available -X- _ O
unlabeled -X- _ O
data -X- _ O
Q. -X- _ O

Methodology -X- _ O
. -X- _ O

Experiments -X- _ O
on -X- _ O
both -X- _ O
English -X- _ O
and -X- _ O
Chinese -X- _ O
sentence -X- _ O
matching -X- _ O
datasets -X- _ O
demonstrate -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
language -X- _ O
model -X- _ O
can -X- _ O
enhance -X- _ O
active -X- _ O
learning -X- _ O
. -X- _ O

It -X- _ O
is -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
1 -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
devise -X- _ O
linguistic -X- _ O
criteria -X- _ O
from -X- _ O
a -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
language -X- _ O
model -X- _ O
to -X- _ O
capture -X- _ O
language -X- _ O
characteristics -X- _ O
, -X- _ O
and -X- _ O
then -X- _ O
utilize -X- _ O
these -X- _ O
extra -X- _ O
linguistic -X- _ O
criteria -X- _ O
( -X- _ O
noise -X- _ O
, -X- _ O
coverage -X- _ O
and -X- _ O
diversity -X- _ O
) -X- _ O
to -X- _ O
enhance -X- _ O
active -X- _ O
learning -X- _ O
. -X- _ O

Accordingly -X- _ O
, -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
language -X- _ O
models -X- _ O
may -X- _ O
provide -X- _ O
a -X- _ O
reliable -X- _ O
way -X- _ O
to -X- _ O
help -X- _ O
capture -X- _ O
language -X- _ O
characteristics -X- _ O
. -X- _ O

Recently -X- _ O
, -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
language -X- _ O
models -X- _ O
( -X- _ O
Peters -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018;Radford -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018;Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018;Yang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
have -X- _ O
been -X- _ O
shown -X- _ O
to -X- _ O
be -X- _ O
powerful -X- _ O
for -X- _ O
learning -X- _ O
language -X- _ O
representation -X- _ O
. -X- _ O

Thus -X- _ O
, -X- _ O
how -X- _ O
to -X- _ O
devise -X- _ O
linguistic -X- _ O
criteria -X- _ O
to -X- _ O
measure -X- _ O
candidate -X- _ O
instances -X- _ O
is -X- _ O
an -X- _ O
important -X- _ O
challenge -X- _ O
. -X- _ O

To -X- _ O
be -X- _ O
more -X- _ O
specific -X- _ O
, -X- _ O
if -X- _ O
we -X- _ O
ignore -X- _ O
the -X- _ O
linguistic -X- _ O
similarity -X- _ O
, -X- _ O
we -X- _ O
may -X- _ O
select -X- _ O
redundant -X- _ O
instances -X- _ O
and -X- _ O
waste -X- _ O
many -X- _ O
annotation -X- _ O
resources -X- _ O
. -X- _ O

However -X- _ O
, -X- _ O
previous -X- _ O
active -X- _ O
learning -X- _ O
approaches -X- _ O
in -X- _ O
natural -X- _ O
language -X- _ O
processing -X- _ O
mainly -X- _ O
depend -X- _ O
on -X- _ O
the -X- _ O
entropy -X- _ O
- -X- _ O
based -X- _ O
uncertainty -X- _ O
criterion -X- _ O
( -X- _ O
Settles -X- _ O
, -X- _ O
2009 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
ignore -X- _ O
the -X- _ O
characteristics -X- _ O
of -X- _ O
natural -X- _ O
language -X- _ O
. -X- _ O

Instead -X- _ O
of -X- _ O
randomly -X- _ O
selecting -X- _ O
instances -X- _ O
, -X- _ O
active -X- _ O
learning -X- _ O
can -X- _ O
measure -X- _ O
the -X- _ O
whole -X- _ O
candidate -X- _ O
instances -X- _ O
according -X- _ O
to -X- _ O
some -X- _ O
criteria -X- _ O
, -X- _ O
and -X- _ O
then -X- _ O
select -X- _ O
more -X- _ O
efficient -X- _ O
instances -X- _ O
for -X- _ O
annotation -X- _ O
( -X- _ O
Zhang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017;Shen -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017;Erdmann -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
; -X- _ O
Kasai -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019;Xu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O

To -X- _ O
alleviate -X- _ O
this -X- _ O
problem -X- _ O
, -X- _ O
active -X- _ O
learning -X- _ O
is -X- _ O
proposed -X- _ O
to -X- _ O
achieve -X- _ O
better -X- _ O
performance -X- _ O
with -X- _ O
fewer -X- _ O
labeled -X- _ O
training -X- _ O
instances -X- _ O
( -X- _ O
Settles -X- _ O
, -X- _ O
2009 -X- _ O
) -X- _ O
. -X- _ O

If -X- _ O
large -X- _ O
labeled -X- _ O
data -X- _ O
ca -X- _ O
n't -X- _ O
be -X- _ O
obtained -X- _ O
, -X- _ O
the -X- _ O
advantages -X- _ O
of -X- _ O
deep -X- _ O
learning -X- _ O
will -X- _ O
significantly -X- _ O
diminish -X- _ O
. -X- _ O

However -X- _ O
, -X- _ O
this -X- _ O
data -X- _ O
- -X- _ O
driven -X- _ O
technique -X- _ O
typically -X- _ O
requires -X- _ O
large -X- _ O
amounts -X- _ O
of -X- _ O
manual -X- _ O
annotation -X- _ O
and -X- _ O
brings -X- _ O
much -X- _ O
cost -X- _ O
. -X- _ O

Over -X- _ O
the -X- _ O
past -X- _ O
few -X- _ O
years -X- _ O
, -X- _ O
deep -X- _ O
learning -X- _ O
as -X- _ O
a -X- _ O
data -X- _ O
- -X- _ O
driven -X- _ O
technique -X- _ O
has -X- _ O
yielded -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
results -X- _ O
on -X- _ O
sentence -X- _ B-TaskName
matching -X- _ I-TaskName
( -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017;Chen -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016;Gong -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017;Yang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016;Parikh -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016;Gong -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017;Kim -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O

Sentence -X- _ B-TaskName
matching -X- _ I-TaskName
is -X- _ O
a -X- _ O
fundamental -X- _ O
technology -X- _ O
in -X- _ O
natural -X- _ O
language -X- _ O
processing -X- _ O
. -X- _ O

Introduction -X- _ O
. -X- _ O

Experiments -X- _ O
demonstrate -X- _ O
our -X- _ O
approach -X- _ O
can -X- _ O
achieve -X- _ O
greater -X- _ O
accuracy -X- _ O
with -X- _ O
fewer -X- _ O
labeled -X- _ O
training -X- _ O
instances -X- _ O
. -X- _ O

Differing -X- _ O
from -X- _ O
previous -X- _ O
active -X- _ O
learning -X- _ O
, -X- _ O
it -X- _ O
can -X- _ O
provide -X- _ O
linguistic -X- _ O
criteria -X- _ O
from -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
language -X- _ O
model -X- _ O
to -X- _ O
measure -X- _ O
instances -X- _ O
and -X- _ O
help -X- _ O
select -X- _ O
more -X- _ O
effective -X- _ O
instances -X- _ O
for -X- _ O
annotation -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
pre -X- _ B-MethodName
- -X- _ I-MethodName
trained -X- _ I-MethodName
language -X- _ I-MethodName
model -X- _ I-MethodName
based -X- _ I-MethodName
active -X- _ I-MethodName
learning -X- _ I-MethodName
approach -X- _ I-MethodName
for -X- _ O
sentence -X- _ O
matching -X- _ O
. -X- _ O

However -X- _ O
, -X- _ O
previous -X- _ O
active -X- _ O
learning -X- _ O
approaches -X- _ O
for -X- _ O
natural -X- _ O
language -X- _ O
processing -X- _ O
mainly -X- _ O
depend -X- _ O
on -X- _ O
the -X- _ O
entropy -X- _ O
- -X- _ O
based -X- _ O
uncertainty -X- _ O
criterion -X- _ O
, -X- _ O
and -X- _ O
ignore -X- _ O
the -X- _ O
characteristics -X- _ O
of -X- _ O
natural -X- _ O
language -X- _ O
. -X- _ O

Active -X- _ O
learning -X- _ O
is -X- _ O
able -X- _ O
to -X- _ O
significantly -X- _ O
reduce -X- _ O
the -X- _ O
annotation -X- _ O
cost -X- _ O
for -X- _ O
data -X- _ O
- -X- _ O
driven -X- _ O
techniques -X- _ O
. -X- _ O

Pre -X- _ B-MethodName
- -X- _ I-MethodName
trained -X- _ I-MethodName
Language -X- _ I-MethodName
Model -X- _ I-MethodName
Based -X- _ I-MethodName
Active -X- _ I-MethodName
Learning -X- _ I-MethodName
for -X- _ O
Sentence -X- _ B-TaskName
Matching -X- _ I-TaskName
. -X- _ O

Next -X- _ O
, -X- _ O
we -X- _ O
find -X- _ O
our -X- _ O
proposed -X- _ O
method -X- _ O
outperforms -X- _ O
sentence -X- _ O
vector -X- _ O
based -X- _ O
methods -X- _ O
( -X- _ O
Topic -X- _ O
, -X- _ O
AE -X- _ O
, -X- _ O
and -X- _ O
Skip -X- _ O
) -X- _ O
. -X- _ O

