Besides	O
,	O
we	O
can	O
see	O
the	O
results	O
without	O
absolute	O
value	O
operation	O
for	O
symmetry	O
is	O
worse	O
,	O
demonstrating	O
absolute	O
value	O
operation	O
is	O
necessary	O
.	O

We	O
can	O
know	O
weight	O
for	O
meaningless	O
tokens	O
is	O
effective	O
.	O

And	O
the	O
results	O
without	O
weight	O
operation	O
for	O
word	O
embeddings	O
perform	O
worse	O
.	O

We	O
can	O
see	O
the	O
results	O
without	O
"	O
Delete	O
Sequence	O
"	O
and	O
"	O
Insert	O
Sequence	O
"	O
performs	O
a	O
little	O
worse	O
,	O
proving	O
its	O
necessity	O
.	O

It	O
demonstrates	O
that	O
subtraction	O
has	O
better	O
ability	O
to	O
capture	O
the	O
difference	O
between	O
two	O
sentences	O
,	O
and	O
provides	O
better	O
instance	O
representation	O
for	O
diversity	O
rank	O
.	O

We	O
can	O
see	O
subtraction	O
operation	O
is	O
better	O
than	O
sum	O
operation	O
.	O

Table	O
4	O
and	O
Figure	O
6	O
report	O
accuracy	B-MetricName
and	O
learning	B-MetricName
curves	I-MetricName
respectively	O
.	O

Table	O
4	O
:	O
Accuracy	B-MetricName
of	O
subtraction	O
operation	O
on	O
Levenshtein	O
Distance	O
.	O

the	O
two	O
sentences	O
without	O
"	O
Delete	O
Sequence	O
"	O
and	O
"	O
Insert	O
Sequence	O
"	O
(	O
Sub	O
)	O
;	O
(	O
c	O
)	O
without	O
weight	O
for	O
word	O
embeddings	O
(	O
Nowei	O
)	O
;	O
(	O
d	O
)	O
without	O
absolute	O
value	O
operation	O
for	O
symmetry	O
(	O
Noabs	O
)	O
.	O

This	O
research	O
work	O
was	O
also	O
supported	O
by	O
the	O
independent	O
research	O
project	O
of	O
National	O
Laboratory	O
of	O
Pattern	O
Recognition	O
and	O
the	O
Youth	O
Innovation	O
Promotion	O
Association	O
CAS	O
.	O

The	O
work	O
is	O
supported	O
by	O
the	O
National	O
Natural	O
Science	O
Foundation	O
of	O
China	O
under	O
Grant	O
Nos.61533018	O
,	O
U1936207	O
,	O
61976211	O
,	O
and	O
61702512	O
.	O

Acknowledgements	O
.	O

We	O
compare	O
it	O
with	O
4	O
baselines	O
:	O
(	O
a	O
)	O
using	O
the	O
sum	O
of	O
word	O
embeddings	O
of	O
the	O
two	O
sentences	O
(	O
Sum	O
)	O
;	O
(	O
b	O
)	O
directly	O
using	O
the	O
subtraction	O
of	O
word	O
embeddings	O
of	O
.	O

(	O
2)Effectiveness	O
of	O
subtraction	O
operation	O
on	O
Levenshtein	O
Distance	O
:	O
Here	O
we	O
validate	O
the	O
effectiveness	O
of	O
the	O
operation	O
that	O
uses	O
the	O
subtraction	O
of	O
word	O
embeddings	O
between	O
"	O
Delete	O
Sequence	O
"	O
and	O
"	O
Insert	O
Sequence	O
"	O
in	O
diversity	O
criterion	O
on	O
SNLI	B-DatasetName
dataset	O
.	O

It	O
is	O
possibly	O
because	O
BERT	O
used	O
more	O
data	O
to	O
learn	O
language	O
representations	O
.	O

In	O
intuition	O
,	O
contextual	O
representations	O
are	O
more	O
exact	O
especially	O
when	O
dealing	O
with	O
polysemy	O
.	O

We	O
can	O
see	O
contextual	O
representations	O
are	O
better	O
than	O
context	O
-	O
dependent	O
representations	O
.	O

Table	O
3	O
and	O
Figure	O
5	O
report	O
accuracy	B-MetricName
and	O
learning	B-MetricName
curves	I-MetricName
respectively	O
.	O

We	O
evaluated	O
performance	O
by	O
calculating	O
accuracy	B-MetricName
and	O
learning	B-MetricName
curves	I-MetricName
on	O
a	O
held	O
-	O
out	O
test	O
set	O
(	O
classes	O
are	O
fairly	O
balanced	O
in	O
datasets	O
)	O
after	O
all	O
rounds	O
.	O

Batch	B-HyperparameterName
size	I-HyperparameterName
is	O
16	B-HyperparameterValue
for	O
English	O
and	O
32	B-HyperparameterValue
for	O
Chinese	O
,	O
Adam	B-HyperparameterValue
is	O
used	O
for	O
optimization	O
.	O

(	O
Configuration	O
:	O
The	O
number	B-HyperparameterName
of	I-HyperparameterName
instances	I-HyperparameterName
to	O
select	O
n	B-HyperparameterName
is	O
100	B-HyperparameterValue
at	O
every	O
round	O
and	O
we	O
perform	O
25	B-HyperparameterValue
rounds	B-HyperparameterName
of	O
active	O
learning	O
,	O
that	O
is	O
there	O
are	O
total	O
of	O
2500	O
labeled	O
instances	O
for	O
training	O
in	O
the	O
end	O
.	O

(	O
4)LCQMC	B-DatasetName
:	O
an	O
open	O
-	O
domain	O
Chinese	O
question	O
matching	O
corpus	O
from	O
the	O
community	O
question	O
answering	O
website	O
Baidu	O
Knows	O
.	O

(	O
3)Quora	B-DatasetName
:	O
an	O
English	O
question	O
matching	O
corpus	O
from	O
the	O
online	O
question	O
answering	O
forum	O
Quora	O
.	O

(	O
2)MultiNLI	B-DatasetName
:	O
an	O
English	O
natural	O
language	O
inference	O
corpus	O
with	O
greater	O
linguistic	O
difficulty	O
and	O
diversity	O
.	O

(	O
1)SNLI	B-DatasetName
:	O
an	O
English	O
natural	O
language	O
inference	O
corpus	O
based	O
on	O
image	O
captioning	O
.	O

We	O
illustrate	O
it	O
in	O
2	O
provides	O
statistics	O
of	O
these	O
datasets	O
.	O

Visualization	O
of	O
Delete	O
Sequence	O
and	O
Insert	O
Sequence	O
:	O
To	O
model	O
the	O
difference	O
between	O
two	O
sentences	O
,	O
we	O
employ	O
the	O
subtraction	O
of	O
word	O
embeddings	O
between	O
"	O
Delete	O
Sequence	O
"	O
and	O
"	O
Insert	O
Sequence	O
"	O
from	O
Levenshtein	O
Distance	O
(	O
when	O
we	O
transform	O
sentence	O
A	O
to	O
sentence	O
B	O
by	O
deleting	O
and	O
inserting	O
tokens	O
,	O
these	O
tokens	O
are	O
added	O
into	O
"	O
Delete	O
Sequence	O
"	O
and	O
"	O
Insert	O
Sequence	O
"	O
espectively	O
)	O
.	O

A	O
general	O
uncertainty	O
criterion	O
uses	O
entropy	O
,	O
which	O
is	O
defined	O
as	O
follows	O
:	O
Ent(x	O
i	O
)	O
=	O
−	O
k	O
P	O
(	O
y	O
i	O
=	O
k|x	O
i	O
)	O
log	O
P	O
(	O
y	O
i	O
=	O
k|x	O
i	O
)	O
(	O
9	O
)	O
where	O
k	O
indexes	O
all	O
possible	O
labels	O
,	O
x	O
i	O
denotes	O
a	O
candidate	O
instance	O
that	O
is	O
made	O
up	O
of	O
a	O
pair	O
of	O
sentences	O
A	O
and	O
B	O
in	O
available	O
unlabeled	O
data	O
Q.	O

Commonly	O
,	O
the	O
criteria	O
is	O
mainly	O
based	O
on	O
uncertainty	O
criterion	O
(	O
uncertainty	B-MethodName
sampling	I-MethodName
)	O
,	O
in	O
which	O
ones	O
near	O
decision	O
boundaries	O
have	O
priority	O
to	O
be	O
selected	O
.	O

Train	O
and	O
update	O
classifier	O
M	O
based	O
on	O
P	O
6	O
:	O
until	O
The	O
annotation	O
budget	O
is	O
exhausted	O
With	O
the	O
same	O
amount	O
of	O
labeled	O
data	O
P	O
,	O
criteria	O
for	O
instance	O
selection	O
in	O
active	O
learning	O
determine	O
the	O
classifier	O
performance	O
.	O

At	O
every	O
round	O
,	O
there	O
are	O
n	O
instances	O
to	O
be	O
selected	O
and	O
labeled	O
.	O

The	O
instance	O
selection	O
process	O
is	O
iterative	O
,	O
and	O
the	O
process	O
will	O
repeat	O
until	O
a	O
fixed	O
annotation	O
budget	O
is	O
reached	O
.	O

The	O
process	O
is	O
illustrated	O
in	O
Algorithm	O
1	O
.	O

In	O
the	O
selection	O
criteria	O
,	O
a	O
measure	O
is	O
used	O
to	O
score	O
all	O
candidate	O
instances	O
in	O
Q	O
,	O
and	O
instances	O
maximizing	O
this	O
measure	O
are	O
selected	O
into	O
P	O
.	O

The	O
task	O
for	O
the	O
active	O
learning	O
is	O
to	O
select	O
instances	O
in	O
Q	O
based	O
on	O
some	O
criteria	O
,	O
and	O
then	O
label	O
them	O
and	O
add	O
them	O
into	O
P	O
,	O
so	O
as	O
to	O
maximize	O
classifier	O
performance	O
and	O
minimize	O
annotation	O
cost	O
.	O

P	O
is	O
for	O
training	O
a	O
classifier	O
and	O
can	O
absorb	O
new	O
instances	O
from	O
Q.	O

Standard	O
Active	O
Learning	O
:	O
In	O
a	O
general	O
active	O
learning	O
scenario	O
,	O
there	O
exists	O
a	O
small	O
set	O
of	O
labeled	O
data	O
P	O
and	O
a	O
large	O
pool	O
of	O
available	O
unlabeled	O
data	O
Q.	O

When	O
training	O
,	O
the	O
model	O
M	O
is	O
optimized	O
by	O
minimizing	O
cross	O
entropy	O
:	O
Loss	O
=	O
−P	O
(	O
y|a	O
,	O
b	O
;	O
θ	O
M	O
)	O
log	O
P	O
(	O
y|a	O
,	O
b	O
;	O
θ	O
M	O
)	O
(	O
8)	O
where	O
y	O
denotes	O
the	O
golden	O
label	O
.	O

When	O
testing	O
,	O
we	O
choose	O
the	O
label	O
with	O
the	O
highest	O
probability	O
in	O
prediction	O
distribution	O
P	O
(	O
y	O
i	O
|a	O
,	O
b	O
;	O
θ	O
M	O
)	O
as	O
output	O
,	O
where	O
θ	O
M	O
denotes	O
parameters	O
of	O
the	O
model	O
M	O
and	O
y	O
i	O
denotes	O
a	O
possible	O
label	O
.	O

And	O
there	O
is	O
a	O
sentence	O
matching	O
model	O
M	O
to	O
predict	O
a	O
label	O
ŷ	O
based	O
on	O
a	O
and	O
b.	O

,	O
e(b	O
l	O
B	O
)	O
]	O
,	O
where	O
n	O
e	O
denotes	O
the	O
vocabulary	O
size	O
,	O
d	B-HyperparameterName
denotes	O
the	O
embedding	B-HyperparameterName
size	I-HyperparameterName
and	O
e(a	O
i	O
)	O
and	O
e(b	O
j	O
)	O
denote	O
the	O
word	O
embedding	O
of	O
the	O
i	O
-	O
th	O
and	O
j	O
-	O
th	O
word	O
respectively	O
in	O
corresponding	O
sentences	O
.	O

,	O
e(a	O
l	O
A	O
)	O
]	O
and	O
b=[e(b	O
1	O
)	O
,	O
e(b	O
2	O
)	O
,	O
.	O

Through	O
a	O
shared	O
word	O
embedding	O
matrix	O
W	O
e	O
∈	O
R	O
ne×d	O
,	O
we	O
can	O
obtain	O
word	O
embeddings	O
of	O
input	O
sentences	O
a=[e(a	O
1	O
)	O
,	O
e(a	O
2	O
)	O
,	O
.	O

,	O
b	O
l	O
B	O
]	O
,	O
where	O
a	O
i	O
and	O
b	O
j	O
denote	O
the	O
i	O
-	O
th	O
and	O
j	O
-	O
th	O
word	O
respectively	O
in	O
corresponding	O
sentences	O
,	O
and	O
l	O
A	O
and	O
l	O
B	O
denote	O
the	O
length	O
of	O
corresponding	O
sentences	O
.	O

,	O
a	O
l	O
A	O
]	O
and	O
B=[b	O
1	O
,	O
b	O
2	O
,	O
.	O

In	O
formal	O
,	O
we	O
have	O
two	O
sentences	O
A=[a	O
1	O
,	O
a	O
2	O
,	O
.	O

Appendix	O
A	O
:	O
More	O
Details	O
and	O
Discussions	O
Sentence	B-TaskName
Matching	I-TaskName
Task	O
:	O
Given	O
a	O
pair	O
of	O
sentences	O
as	O
input	O
,	O
the	O
goal	O
of	O
the	O
task	O
is	O
to	O
judge	O
the	O
relation	O
between	O
them	O
,	O
such	O
as	O
whether	O
they	O
express	O
the	O
same	O
meaning	O
.	O

Experiments	O
show	O
that	O
our	O
proposed	O
active	O
learning	O
approach	O
obtains	O
better	O
performance	O
.	O

We	O
devise	O
extra	O
linguistic	O
criteria	O
from	O
a	O
pre	O
-	O
trained	O
language	O
model	O
,	O
which	O
can	O
capture	O
language	O
characteristics	O
and	O
enhance	O
active	O
learning	O
.	O

In	O
this	O
paper	O
,	O
we	O
combine	B-MethodName
active	I-MethodName
learning	I-MethodName
with	I-MethodName
a	I-MethodName
pre	I-MethodName
-	I-MethodName
trained	I-MethodName
language	I-MethodName
model	I-MethodName
.	O

Conclusion	O
.	O

More	O
ablation	O
discussions	O
are	O
shown	O
in	O
the	O
Appendix	O
.	O

It	O
demonstrates	O
that	O
each	O
linguistic	O
criterion	O
from	O
a	O
pre	O
-	O
trained	O
language	O
model	O
helps	O
capture	O
language	O
characteristics	O
and	O
enhances	O
selection	O
of	O
instances	O
.	O

We	O
can	O
see	O
each	O
combined	O
criterion	O
performs	O
better	O
than	O
a	O
single	O
uncertainty	O
criterion	O
.	O

Curves	O
are	O
also	O
illustrated	O
in	O
the	O
Appendix	O
.	O

Table	O
1	O
reports	O
the	O
accuracy	B-MetricName
.	O

"	O
Ent	O
"	O
denotes	O
the	O
standard	O
uncertainty	O
criterion	O
,	O
"	O
E+Noi	O
/	O
E+Cov	O
/	O
E+Div	O
/	O
E+All	O
"	O
denotes	O
combining	O
uncertainty	O
with	O
noise	O
/	O
coverage	O
/	O
diversity	O
/	O
all	O
criteria	O
.	O

To	O
validate	O
the	O
effectiveness	O
of	O
extra	O
linguistic	O
criteria	O
,	O
we	O
separately	O
combining	O
them	O
with	O
standard	O
uncertainty	O
criterion	O
.	O

Ablation	O
Study	O
.	O

Moreover	O
,	O
we	O
show	O
the	O
relation	O
between	O
the	O
size	O
of	O
unlabeled	O
data	O
and	O
accuracy	B-MetricName
in	O
Figure	O
2	O
(	O
6	O
)	O
,	O
we	O
can	O
see	O
the	O
superiority	O
of	O
the	O
pre	O
-	O
trained	O
model	O
based	O
approach	O
is	O
more	O
significant	O
for	O
larger	O
data	O
size	O
.	O

In	O
fact	O
,	O
sentence	B-TaskName
matching	I-TaskName
needs	O
to	O
capture	O
the	O
difference	O
between	O
sentences	O
and	O
gradients	O
of	O
a	O
single	O
token	O
ca	O
n't	O
reflect	O
the	O
relation	O
.	O

And	O
EGL	B-MethodName
performs	O
worse	O
than	O
the	O
standard	O
approach	O
active	B-MethodName
learning	I-MethodName
,	O
maybe	O
gradient	O
based	O
active	O
learning	O
is	O
not	O
suitable	O
for	O
sentence	O
matching	O
.	O

It	O
demonstrates	O
that	O
the	O
amount	O
of	O
labeled	O
data	O
for	O
sentence	O
matching	O
can	O
be	O
substantially	O
reduced	O
by	O
active	O
learning	O
.	O

Besides	O
,	O
active	B-MethodName
learning	I-MethodName
approaches	O
always	O
obtain	O
better	O
performance	O
than	O
random	B-MethodName
sampling	I-MethodName
.	O

We	O
can	O
know	O
that	O
extra	O
linguistic	O
criteria	O
are	O
effective	O
,	O
demonstrating	O
that	O
a	O
pre	O
-	O
trained	O
language	O
model	O
can	O
substantially	O
capture	O
language	O
characteristics	O
and	O
provide	O
more	O
efficient	O
instances	O
for	O
training	O
.	O

Overall	O
,	O
our	O
approach	O
obtains	O
better	O
performance	O
on	O
both	O
English	O
and	O
Chinese	O
datasets	O
.	O

Table	O
1	O
and	O
Figure	O
2	O
(	O
1	O
-	O
5	O
)	O
report	O
accuracy	B-MetricName
and	O
learning	O
curves	O
of	O
each	O
approach	O
on	O
the	O
five	O
datasets	O
.	O

Results	O
.	O

(	O
4)Pre	B-MethodName
-	I-MethodName
trained	I-MethodName
language	I-MethodName
model	I-MethodName
(	O
LM	O
)	O
is	O
our	O
proposed	O
active	O
learning	O
approach	O
.	O

(	O
3)Expected	B-MethodName
Gradient	I-MethodName
Length	I-MethodName
(	O
EGL	B-MethodName
)	O
aims	O
to	O
select	O
instances	O
expected	O
to	O
result	O
in	O
the	O
greatest	O
change	O
to	O
the	O
gradients	O
of	O
tokens	O
(	O
Settles	O
and	O
Craven	O
,	O
2008;Zhang	O
et	O
al	O
.	O
,	O
2017	O
)	O
.	O

(	O
2)Uncertainty	B-MethodName
sampling	I-MethodName
(	O
Entropy	B-MethodName
)	O
is	O
the	O
standard	O
entropy	O
criterion	O
(	O
Tong	O
and	O
Koller	O
,	O
2001;Zhu	O
et	O
al	O
.	O
,	O
2008	O
)	O
.	O

We	O
compare	O
the	O
following	O
active	O
learning	O
approaches	O
:	O
(	O
1)Random	B-MethodName
sampling	I-MethodName
(	O
Random	B-MethodName
)	O
randomly	O
selects	O
instances	O
for	O
annotation	O
and	O
training	O
at	O
each	O
round	O
.	O

There	O
is	O
a	O
held	O
-	O
out	O
test	O
set	O
for	O
evaluation	O
after	O
all	O
rounds	O
.	O

We	O
choose	O
(	O
Devlin	O
et	O
al	O
.	O
,	O
2018	O
)	O
as	O
classifier	O
M	O
and	O
perform	O
25	B-HyperparameterValue
rounds	B-HyperparameterName
of	O
active	O
learning	O
.	O

The	O
number	O
of	O
instances	O
to	O
select	O
at	O
every	O
round	O
is	O
n	B-HyperparameterName
=	O
100	B-HyperparameterValue
.	O

In	O
practice	O
,	O
according	O
to	O
different	O
effectiveness	O
of	O
criteria	O
,	O
we	O
combine	O
ranks	O
of	O
criteria	O
and	O
select	O
the	O
top	O
n	B-HyperparameterName
candidate	O
instances	O
in	O
unlabeled	O
data	O
Q.	O

We	O
conduct	O
experiments	O
on	O
Both	O
English	O
and	O
Chinese	O
datasets	O
,	O
including	O
SNLI	B-DatasetName
(	O
Bowman	O
et	O
al	O
.	O
,	O
2015	O
)	O
,	O
MultiNLI	B-DatasetName
(	O
Williams	O
et	O
al	O
.	O
,	O
2017	O
)	O
,	O
Quora	B-DatasetName
(	O
Iyer	O
et	O
al	O
.	O
,	O
2017	O
)	O
,	O
LCQMC	B-DatasetName
(	O
Liu	O
et	O
al	O
.	O
,	O
2018	O
)	O
,	O
BQ	B-DatasetName
(	O
Chen	O
et	O
al	O
.	O
,	O
2018	O
)	O
.	O

Settings	O
and	O
Comparisons	O
.	O

3	O
Experiments	O
.	O

Specifically	O
,	O
we	O
sequentially	O
use	O
rank	O
uncer	O
,	O
rank	O
diver	O
,	O
rank	O
cover	O
,	O
rank	O
noise	O
to	O
select	O
top	O
8n	O
,	O
4n	O
,	O
2n	O
,	O
n	O
candidate	O
instances	O
,	O
and	O
add	O
the	O
final	O
n	O
instances	O
into	O
labeled	O
data	O
P	O
for	O
training	O
at	O
every	O
round	O
.	O

Instance	O
Selection	O
.	O

•	O
denotes	O
multiplication	O
on	O
element	O
.	O

Specifically	O
,	O
we	O
employ	O
k	O
-	O
means	O
clustering	O
algorithm	O
for	O
diversity	O
rank	O
as	O
follows	O
:	O
rank	O
diver	O
(	O
x	O
i	O
)	O
=	O
0	O
if	O
v	O
i	O
•	O
v	O
i	O
∈	O
O	O
diver	O
n	O
others(7	O
)	O
where	O
O	O
diver	O
are	O
the	O
centers	O
of	O
n	O
clusters	O
of	O
{	O
v	O
i	O
•	O
v	O
i	O
}	O
.	O

With	O
instance	O
representation	O
,	O
we	O
want	O
to	O
select	O
diverse	O
ones	O
that	O
are	O
representative	O
and	O
different	O
from	O
each	O
other	O
.	O

w	O
a	O
i	O
/w	O
b	O
j	O
denotes	O
the	O
weight	O
for	O
tokens	O
.	O

e(a	O
j	O
)	O
/e(b	O
j	O
)	O
denotes	O
word	O
embdeddings	O
.	O

Formally	O
,	O
v	O
i	O
=	O
j∈L	O
I	O
w	O
b	O
j	O
e(b	O
j	O
)	O
−	O
j∈L	O
D	O
w	O
a	O
j	O
e(a	O
j	O
)	O
(	O
5	O
)	O
w	O
a	O
j	O
=	O
s	O
a	O
j	O
k∈l	O
A	O
s	O
a	O
k	O
,	O
w	O
b	O
j	O
=	O
s	O
b	O
j	O
k∈l	O
B	O
s	O
b	O
k	O
(	O
6	O
)	O
where	O
s	O
a	O
i	O
/s	O
b	O
j	O
is	O
the	O
reconstruction	O
loss	O
of	O
the	O
i	O
/	O
j	O
-	O
th	O
word	O
of	O
sentence	O
A	O
/	O
B.	O

Intuitively	O
,	O
meaningless	O
tokens	O
such	O
as	O
preposition	O
should	O
have	O
less	O
weight	O
,	O
and	O
they	O
are	O
usually	O
easier	O
to	O
predict	O
with	O
lower	O
reconstruction	O
losses	O
.	O

Besides	O
,	O
the	O
word	O
embeddings	O
in	O
the	O
subtraction	O
are	O
weighted	O
by	O
reconstruction	O
losses	O
.	O

It	O
is	O
illustrated	O
in	O
the	O
Appendix	O
.	O

To	O
model	O
the	O
difference	O
between	O
two	O
sentences	O
,	O
we	O
employ	O
the	O
subtraction	O
of	O
word	O
embeddings	O
between	O
"	O
Delete	O
Sequence	O
"	O
L	O
D	O
and	O
"	O
Insert	O
Sequence	O
"	O
L	O
I	O
from	O
Levenshtein	O
Distance	O
(	O
when	O
we	O
transform	O
sentence	O
A	O
to	O
sentence	O
B	O
by	O
deleting	O
and	O
inserting	O
tokens	O
,	O
these	O
tokens	O
are	O
added	O
into	O
L	O
D	O
and	O
L	O
I	O
respectively	O
)	O
.	O

First	O
,	O
we	O
use	O
a	O
vector	O
v	O
i	O
for	O
instance	O
representation	O
of	O
a	O
sentence	O
pair	O
instance	O
x	O
i	O
.	O

In	O
contrast	O
,	O
diverse	O
ones	O
can	O
help	O
learn	O
more	O
various	O
language	O
expressions	O
and	O
matching	O
patterns	O
.	O

Redundant	O
instances	O
are	O
inefficient	O
and	O
waste	O
annotation	O
resources	O
.	O

Thus	O
,	O
we	O
can	O
employ	O
reconstruction	O
losses	O
to	O
capture	O
the	O
low	O
coverage	O
ones	O
as	O
follows	O
:	O
rank	O
cover	O
(	O
x	O
i	O
)	O
∝	O
−	O
j∈l	O
A	O
c	O
a	O
j	O
s	O
a	O
j	O
j∈l	O
A	O
c	O
a	O
j	O
−	O
j∈l	O
B	O
c	O
b	O
j	O
s	O
b	O
j	O
j∈l	O
B	O
c	O
b	O
j	O
(	O
3	O
)	O
c	O
a	O
j	O
=	O
0	O
if	O
s	O
a	O
j	O
>	O
β	O
1	O
others	O
,	O
c	O
b	O
j	O
=	O
0	O
if	O
s	O
b	O
j	O
>	O
β	O
1	O
others	O
(	O
4	O
)	O
where	O
β	O
denotes	O
a	O
hyperparameter	O
to	O
distinguish	O
noise	O
and	O
is	O
set	O
as	O
10.0	O
.	O
(	O
4	O
)	O
Diversity	O
:	O
The	O
diversity	O
criterion	O
indicates	O
the	O
diversity	O
of	O
instances	O
.	O

These	O
fresh	O
instances	O
like	O
relatively	O
low	O
-	O
frequency	O
professional	O
expressions	O
usually	O
have	O
lower	O
generating	O
probabilities	O
than	O
common	O
ones	O
.	O

On	O
the	O
other	O
hand	O
,	O
the	O
classifier	O
needs	O
fresh	O
instances	O
(	O
low	O
coverage	O
)	O
to	O
enrich	O
representation	O
learning	O
.	O

On	O
the	O
one	O
hand	O
,	O
some	O
tokens	O
like	O
stop	O
words	O
are	O
meaningless	O
and	O
easy	O
to	O
model	O
(	O
high	O
coverage	O
)	O
.	O

(	O
3	O
)	O
Coverage	O
:	O
The	O
coverage	O
criterion	O
indicates	O
whether	O
the	O
language	O
expression	O
of	O
the	O
current	O
instance	O
can	O
enrich	O
representation	O
learning	O
.	O

rank	O
noise	O
(	O
x	O
i	O
)	O
denotes	O
noise	O
rank	O
of	O
the	O
i	O
-	O
th	O
instance	O
in	O
Q	O
,	O
s	O
a	O
i	O
/s	O
b	O
i	O
is	O
the	O
reconstruction	O
loss	O
of	O
the	O
i	O
-	O
th	O
word	O
a	O
i	O
/b	O
i	O
in	O
sentence	O
A	O
/	O
B	O
from	O
the	O
pre	O
-	O
trained	O
language	O
model	O
.	O

P	O
(	O
B	O
)	O
is	O
similar	O
.	O

a	O
l	O
A	O
)	O
∝	O
l	O
A	O
i∈l	O
A	O
sa	O
i	O
.	O

Based	O
on	O
this	O
assumption	O
,	O
noise	O
criterion	O
is	O
formulated	O
about	O
losses	O
of	O
reconstructing	O
masked	O
tokens	O
:	O
rank	O
noise	O
(	O
x	O
i	O
)	O
∝	O
−P	O
(	O
A	O
)	O
−	O
P	O
(	O
B)(2	O
)	O
where	O
P	O
(	O
A	O
)	O
=	O
P	O
(	O
a	O
1	O
a	O
2	O
.	O

Thus	O
,	O
tokens	O
in	O
noisy	O
instances	O
may	O
be	O
hard	O
to	O
be	O
reconstructed	O
with	O
context	O
by	O
the	O
pre	O
-	O
trained	O
language	O
model	O
.	O

Noisy	O
instances	O
usually	O
have	O
rare	O
expression	O
with	O
low	O
generating	O
probability	O
.	O

Intuitively	O
,	O
instances	O
with	O
noise	O
may	O
degrade	O
the	O
labeled	O
data	O
P	O
,	O
and	O
we	O
want	O
to	O
select	O
noiseless	O
instances	O
.	O

(	O
2	O
)	O
Noise	O
:	O
The	O
noise	O
criterion	O
indicates	O
how	O
much	O
potential	O
noise	O
there	O
is	O
in	O
an	O
instance	O
.	O

Formally	O
,	O
rank	O
uncer	O
(	O
x	O
i	O
)	O
∝	O
−Ent(x	O
i	O
)	O
(	O
1	O
)	O
where	O
Ent(x	O
i	O
)	O
=	O
−	O
k	O
P	O
(	O
y	O
i	O
=	O
k|x	O
i	O
)	O
log	O
P	O
(	O
y	O
i	O
=	O
k|x	O
i	O
)	O
.	O

The	O
uncertainty	O
is	O
computed	O
as	O
the	O
entropy	O
,	O
and	O
we	O
can	O
obtain	O
uncertainty	O
rank	O
rank	O
uncer	O
(	O
x	O
i	O
)	O
for	O
the	O
i	O
-	O
th	O
instance	O
in	O
Q	O
based	O
on	O
the	O
entropy	O
.	O

Instances	O
with	O
high	O
uncertainty	O
are	O
more	O
helpful	O
to	O
optimize	O
the	O
classifier	O
and	O
thus	O
are	O
worthier	O
to	O
be	O
selected	O
.	O

(	O
1	O
)	O
Uncertainty	O
:	O
The	O
uncertainty	O
criterion	O
indicates	O
classification	O
uncertainty	O
of	O
an	O
instance	O
and	O
is	O
the	O
standard	O
criterion	O
in	O
active	O
learning	O
.	O

Criteria	O
for	O
Instance	O
Selection	O
.	O

,	O
e(a	O
l	O
A	O
)	O
]	O
in	O
the	O
sentence	O
,	O
where	O
l	O
A	O
is	O
the	O
length	O
of	O
sentence	O
A.	O

The	O
other	O
is	O
word	O
embeddings	O
(	O
contextual	O
representations	O
of	O
the	O
last	O
layer	O
)	O
a=[e(a	O
1	O
)	O
,	O
e(a	O
2	O
)	O
,	O
.	O

One	O
is	O
the	O
cross	O
entropy	O
loss	O
s	O
a	O
i	O
of	O
reconstructing	O
of	O
the	O
i	O
-	O
th	O
word	O
a	O
i	O
in	O
sentence	O
A	O
(	O
the	O
same	O
with	O
another	O
B	O
)	O
by	O
masking	O
only	O
a	O
i	O
and	O
predicting	O
a	O
i	O
again	O
.	O

From	O
BERT	O
,	O
we	O
can	O
obtain	O
two	O
kinds	O
of	O
information	O
to	O
provide	O
linguistic	O
criteria	O
.	O

We	O
choose	O
the	O
widely	O
used	O
language	O
model	O
BERT	O
(	O
Devlin	O
et	O
al	O
.	O
,	O
2018	O
)	O
as	O
the	O
pre	O
-	O
trained	O
language	O
model	O
.	O

Pre	O
-	O
trained	O
Language	O
Model	O
.	O

More	O
details	O
of	O
preliminaries	O
about	O
sentence	O
matching	O
and	O
active	O
learning	O
are	O
in	O
the	O
Appendix	O
.	O

Active	O
learning	O
is	O
to	O
select	O
instances	O
in	O
Q	O
according	O
to	O
some	O
criteria	O
,	O
and	O
then	O
label	O
them	O
and	O
add	O
them	O
into	O
P	O
,	O
so	O
as	O
to	O
maximize	O
classifier	O
M	O
performance	O
and	O
minimize	O
annotation	O
cost	O
.	O

In	O
a	O
general	O
active	O
learning	O
scenario	O
,	O
there	O
is	O
a	O
small	O
set	O
of	O
labeled	O
training	O
data	O
P	O
and	O
a	O
large	O
pool	O
of	O
available	O
unlabeled	O
data	O
Q.	O

Methodology	O
.	O

Experiments	O
on	O
both	O
English	O
and	O
Chinese	O
sentence	O
matching	O
datasets	O
demonstrate	O
the	O
pre	O
-	O
trained	O
language	O
model	O
can	O
enhance	O
active	O
learning	O
.	O

It	O
is	O
shown	O
in	O
Figure	O
1	O
.	O

In	O
this	O
paper	O
,	O
we	O
devise	O
linguistic	O
criteria	O
from	O
a	O
pre	O
-	O
trained	O
language	O
model	O
to	O
capture	O
language	O
characteristics	O
,	O
and	O
then	O
utilize	O
these	O
extra	O
linguistic	O
criteria	O
(	O
noise	O
,	O
coverage	O
and	O
diversity	O
)	O
to	O
enhance	O
active	O
learning	O
.	O

Accordingly	O
,	O
pre	O
-	O
trained	O
language	O
models	O
may	O
provide	O
a	O
reliable	O
way	O
to	O
help	O
capture	O
language	O
characteristics	O
.	O

Recently	O
,	O
pre	O
-	O
trained	O
language	O
models	O
(	O
Peters	O
et	O
al	O
.	O
,	O
2018;Radford	O
et	O
al	O
.	O
,	O
2018;Devlin	O
et	O
al	O
.	O
,	O
2018;Yang	O
et	O
al	O
.	O
,	O
2019	O
)	O
have	O
been	O
shown	O
to	O
be	O
powerful	O
for	O
learning	O
language	O
representation	O
.	O

Thus	O
,	O
how	O
to	O
devise	O
linguistic	O
criteria	O
to	O
measure	O
candidate	O
instances	O
is	O
an	O
important	O
challenge	O
.	O

To	O
be	O
more	O
specific	O
,	O
if	O
we	O
ignore	O
the	O
linguistic	O
similarity	O
,	O
we	O
may	O
select	O
redundant	O
instances	O
and	O
waste	O
many	O
annotation	O
resources	O
.	O

However	O
,	O
previous	O
active	O
learning	O
approaches	O
in	O
natural	O
language	O
processing	O
mainly	O
depend	O
on	O
the	O
entropy	O
-	O
based	O
uncertainty	O
criterion	O
(	O
Settles	O
,	O
2009	O
)	O
,	O
and	O
ignore	O
the	O
characteristics	O
of	O
natural	O
language	O
.	O

Instead	O
of	O
randomly	O
selecting	O
instances	O
,	O
active	O
learning	O
can	O
measure	O
the	O
whole	O
candidate	O
instances	O
according	O
to	O
some	O
criteria	O
,	O
and	O
then	O
select	O
more	O
efficient	O
instances	O
for	O
annotation	O
(	O
Zhang	O
et	O
al	O
.	O
,	O
2017;Shen	O
et	O
al	O
.	O
,	O
2017;Erdmann	O
et	O
al	O
.	O
,	O
;	O
Kasai	O
et	O
al	O
.	O
,	O
2019;Xu	O
et	O
al	O
.	O
,	O
2018	O
)	O
.	O

To	O
alleviate	O
this	O
problem	O
,	O
active	O
learning	O
is	O
proposed	O
to	O
achieve	O
better	O
performance	O
with	O
fewer	O
labeled	O
training	O
instances	O
(	O
Settles	O
,	O
2009	O
)	O
.	O

If	O
large	O
labeled	O
data	O
ca	O
n't	O
be	O
obtained	O
,	O
the	O
advantages	O
of	O
deep	O
learning	O
will	O
significantly	O
diminish	O
.	O

However	O
,	O
this	O
data	O
-	O
driven	O
technique	O
typically	O
requires	O
large	O
amounts	O
of	O
manual	O
annotation	O
and	O
brings	O
much	O
cost	O
.	O

Over	O
the	O
past	O
few	O
years	O
,	O
deep	O
learning	O
as	O
a	O
data	O
-	O
driven	O
technique	O
has	O
yielded	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
results	O
on	O
sentence	B-TaskName
matching	I-TaskName
(	O
Wang	O
et	O
al	O
.	O
,	O
2017;Chen	O
et	O
al	O
.	O
,	O
2016;Gong	O
et	O
al	O
.	O
,	O
2017;Yang	O
et	O
al	O
.	O
,	O
2016;Parikh	O
et	O
al	O
.	O
,	O
2016;Gong	O
et	O
al	O
.	O
,	O
2017;Kim	O
et	O
al	O
.	O
,	O
2019	O
)	O
.	O

Sentence	B-TaskName
matching	I-TaskName
is	O
a	O
fundamental	O
technology	O
in	O
natural	O
language	O
processing	O
.	O

Introduction	O
.	O

Experiments	O
demonstrate	O
our	O
approach	O
can	O
achieve	O
greater	O
accuracy	O
with	O
fewer	O
labeled	O
training	O
instances	O
.	O

Differing	O
from	O
previous	O
active	O
learning	O
,	O
it	O
can	O
provide	O
linguistic	O
criteria	O
from	O
the	O
pre	O
-	O
trained	O
language	O
model	O
to	O
measure	O
instances	O
and	O
help	O
select	O
more	O
effective	O
instances	O
for	O
annotation	O
.	O

In	O
this	O
paper	O
,	O
we	O
propose	O
a	O
pre	B-MethodName
-	I-MethodName
trained	I-MethodName
language	I-MethodName
model	I-MethodName
based	I-MethodName
active	I-MethodName
learning	I-MethodName
approach	I-MethodName
for	O
sentence	O
matching	O
.	O

However	O
,	O
previous	O
active	O
learning	O
approaches	O
for	O
natural	O
language	O
processing	O
mainly	O
depend	O
on	O
the	O
entropy	O
-	O
based	O
uncertainty	O
criterion	O
,	O
and	O
ignore	O
the	O
characteristics	O
of	O
natural	O
language	O
.	O

Active	O
learning	O
is	O
able	O
to	O
significantly	O
reduce	O
the	O
annotation	O
cost	O
for	O
data	O
-	O
driven	O
techniques	O
.	O

Pre	B-MethodName
-	I-MethodName
trained	I-MethodName
Language	I-MethodName
Model	I-MethodName
Based	I-MethodName
Active	I-MethodName
Learning	I-MethodName
for	O
Sentence	B-TaskName
Matching	I-TaskName
.	O

Next	O
,	O
we	O
find	O
our	O
proposed	O
method	O
outperforms	O
sentence	O
vector	O
based	O
methods	O
(	O
Topic	O
,	O
AE	O
,	O
and	O
Skip	O
)	O
.	O

