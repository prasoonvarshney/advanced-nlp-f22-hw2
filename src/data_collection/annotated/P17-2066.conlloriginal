-DOCSTART- -X- O
Since -X- _ O
most -X- _ O
available -X- _ O
caption -X- _ O
datasets -X- _ O
have -X- _ O
been -X- _ O
constructed -X- _ O
for -X- _ O
English -X- _ O
language -X- _ O
, -X- _ O
there -X- _ O
are -X- _ O
few -X- _ O
datasets -X- _ O
for -X- _ O
Japanese -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
particularly -X- _ O
consider -X- _ O
generating -X- _ O
Japanese -X- _ O
captions -X- _ O
for -X- _ O
images -X- _ O
. -X- _ O

As -X- _ O
a -X- _ O
result -X- _ O
, -X- _ O
we -X- _ O
showed -X- _ O
the -X- _ O
necessity -X- _ O
of -X- _ O
STAIR -X- _ B-DatasetName
Captions -X- _ I-DatasetName
. -X- _ O

In -X- _ O
addition -X- _ O
, -X- _ O
we -X- _ O
confirmed -X- _ O
that -X- _ O
Japanese -X- _ O
captions -X- _ O
can -X- _ O
be -X- _ O
generated -X- _ O
simply -X- _ O
by -X- _ O
adapting -X- _ O
the -X- _ O
existing -X- _ O
caption -X- _ B-TaskName
generation -X- _ I-TaskName
method -X- _ O
. -X- _ O

Moreover -X- _ O
, -X- _ O
by -X- _ O
using -X- _ O
both -X- _ O
Japanese -X- _ O
and -X- _ O
English -X- _ O
captions -X- _ O
, -X- _ O
we -X- _ O
will -X- _ O
develop -X- _ O
multi -X- _ O
- -X- _ O
lingual -X- _ O
caption -X- _ B-TaskName
generation -X- _ I-TaskName
models -X- _ O
. -X- _ O

In -X- _ O
our -X- _ O
experiment -X- _ O
, -X- _ O
we -X- _ O
compared -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
Japanese -X- _ O
caption -X- _ O
generation -X- _ O
by -X- _ O
a -X- _ O
neural -X- _ O
network -X- _ O
- -X- _ O
based -X- _ O
model -X- _ O
with -X- _ O
and -X- _ O
without -X- _ O
STAIR -X- _ B-DatasetName
Captions -X- _ I-DatasetName
to -X- _ O
highlight -X- _ O
the -X- _ O
necessity -X- _ O
of -X- _ O
Japanese -X- _ O
captions -X- _ O
. -X- _ O

To -X- _ O
the -X- _ O
best -X- _ O
of -X- _ O
our -X- _ O
knowledge -X- _ O
, -X- _ O
STAIR -X- _ B-DatasetName
Captions -X- _ I-DatasetName
is -X- _ O
currently -X- _ O
the -X- _ O
largest -X- _ O
Japanese -X- _ O
image -X- _ O
caption -X- _ O
dataset -X- _ O
. -X- _ O

In -X- _ O
STAIR -X- _ B-DatasetName
Captions -X- _ I-DatasetName
, -X- _ O
Japanese -X- _ O
captions -X- _ O
are -X- _ O
provided -X- _ O
for -X- _ O
all -X- _ O
the -X- _ O
images -X- _ O
of -X- _ O
MS -X- _ B-DatasetName
- -X- _ I-DatasetName
COCO -X- _ I-DatasetName
. -X- _ O

In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
constructed -X- _ O
a -X- _ O
new -X- _ O
Japanese -X- _ O
image -X- _ O
caption -X- _ O
dataset -X- _ O
called -X- _ O
STAIR -X- _ B-DatasetName
Captions -X- _ I-DatasetName
. -X- _ O

In -X- _ O
the -X- _ O
example -X- _ O
at -X- _ O
the -X- _ O
bottom -X- _ O
of -X- _ O
the -X- _ O
table -X- _ O
, -X- _ O
En -X- _ B-MethodName
- -X- _ I-MethodName
generator -X- _ I-MethodName
→ -X- _ I-MethodName
MT -X- _ I-MethodName
yielded -X- _ O
the -X- _ O
incorrect -X- _ O
caption -X- _ O
by -X- _ O
translating -X- _ O
" -X- _ O
A -X- _ O
bunch -X- _ O
of -X- _ O
food -X- _ O
" -X- _ O
as -X- _ O
" -X- _ O
食べ物の束 -X- _ O
( -X- _ O
A -X- _ O
bundle -X- _ O
of -X- _ O
food -X- _ O
) -X- _ O
. -X- _ O
" -X- _ O
By -X- _ O
contrast -X- _ O
, -X- _ O
Ja -X- _ B-MethodName
- -X- _ I-MethodName
generator -X- _ I-MethodName
correctly -X- _ O
recognized -X- _ O
that -X- _ O
the -X- _ O
food -X- _ O
pictured -X- _ O
in -X- _ O
the -X- _ O
image -X- _ O
is -X- _ O
a -X- _ O
donut -X- _ O
, -X- _ O
and -X- _ O
expressed -X- _ O
it -X- _ O
as -X- _ O
" -X- _ O
ドーナツがたくさん -X- _ O
( -X- _ O
A -X- _ O
bunch -X- _ O
of -X- _ O
donuts -X- _ O
) -X- _ O
. -X- _ O
" -X- _ O
. -X- _ O

By -X- _ O
contrast -X- _ O
, -X- _ O
Jagenerator -X- _ B-MethodName
generated -X- _ O
" -X- _ O
二階建てのバス -X- _ O
( -X- _ O
two -X- _ O
- -X- _ O
story -X- _ O
bus -X- _ O
) -X- _ O
, -X- _ O
" -X- _ O
which -X- _ O
is -X- _ O
appropriate -X- _ O
as -X- _ O
the -X- _ O
Japanese -X- _ O
translation -X- _ O
of -X- _ O
A -X- _ O
double -X- _ O
decker -X- _ O
bus -X- _ O
. -X- _ O

In -X- _ O
the -X- _ O
example -X- _ O
at -X- _ O
the -X- _ O
top -X- _ O
in -X- _ O
Table -X- _ O
3 -X- _ O
, -X- _ O
En -X- _ B-MethodName
- -X- _ I-MethodName
generator -X- _ I-MethodName
first -X- _ O
generated -X- _ O
the -X- _ O
term -X- _ O
, -X- _ O
" -X- _ O
A -X- _ O
double -X- _ O
decker -X- _ O
bus -X- _ O
. -X- _ O
" -X- _ O
MT -X- _ O
translated -X- _ O
the -X- _ O
term -X- _ O
into -X- _ O
as -X- _ O
" -X- _ O
二重デッカーバ -X- _ O
ス -X- _ O
" -X- _ O
, -X- _ O
but -X- _ O
the -X- _ O
translation -X- _ O
is -X- _ O
word -X- _ O
- -X- _ O
by -X- _ O
- -X- _ O
word -X- _ O
and -X- _ O
inappropriate -X- _ O
as -X- _ O
a -X- _ O
Japanese -X- _ O
term -X- _ O
. -X- _ O

Table -X- _ O
3 -X- _ O
shows -X- _ O
two -X- _ O
examples -X- _ O
where -X- _ O
Ja -X- _ B-MethodName
- -X- _ I-MethodName
generator -X- _ I-MethodName
generated -X- _ O
appropriate -X- _ O
captions -X- _ O
, -X- _ O
whereas -X- _ O
Engenerator -X- _ B-MethodName
→ -X- _ I-MethodName
MT -X- _ I-MethodName
generated -X- _ O
unnatural -X- _ O
ones -X- _ O
. -X- _ O

The -X- _ O
results -X- _ O
show -X- _ O
that -X- _ O
Ja -X- _ B-MethodName
- -X- _ I-MethodName
generator -X- _ I-MethodName
, -X- _ O
that -X- _ O
is -X- _ O
, -X- _ O
the -X- _ O
approach -X- _ O
in -X- _ O
which -X- _ O
Japanese -X- _ O
captions -X- _ O
were -X- _ O
used -X- _ O
as -X- _ O
training -X- _ O
data -X- _ O
, -X- _ O
outperformed -X- _ O
En -X- _ B-MethodName
- -X- _ I-MethodName
generator -X- _ I-MethodName
→ -X- _ I-MethodName
MT -X- _ I-MethodName
, -X- _ O
which -X- _ O
was -X- _ O
trained -X- _ O
without -X- _ O
Japanese -X- _ O
captions -X- _ O
. -X- _ O

The -X- _ O
hyper -X- _ O
- -X- _ O
parameters -X- _ O
of -X- _ O
the -X- _ O
neural -X- _ O
network -X- _ O
were -X- _ O
tuned -X- _ O
based -X- _ O
on -X- _ O
CIDEr -X- _ B-MetricName
scores -X- _ O
by -X- _ O
using -X- _ O
the -X- _ O
validation -X- _ O
set -X- _ O
. -X- _ O

With -X- _ O
the -X- _ O
optimization -X- _ B-HyperparameterName
of -X- _ O
LSTM -X- _ B-MethodName
, -X- _ O
we -X- _ O
used -X- _ O
mini -X- _ B-HyperparameterValue
- -X- _ I-HyperparameterValue
batch -X- _ I-HyperparameterValue
RMSProp -X- _ I-HyperparameterValue
, -X- _ O
and -X- _ O
the -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
was -X- _ O
set -X- _ O
to -X- _ O
20 -X- _ B-HyperparameterValue
. -X- _ O

We -X- _ O
used -X- _ O
VGG -X- _ B-MethodName
with -X- _ O
16 -X- _ B-HyperparameterValue
layers -X- _ B-HyperparameterName
as -X- _ O
CNN -X- _ B-MethodName
, -X- _ O
where -X- _ O
the -X- _ O
VGG -X- _ B-MethodName
parameters -X- _ O
were -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
ones5 -X- _ O
. -X- _ O

In -X- _ O
both -X- _ O
the -X- _ O
methods -X- _ O
, -X- _ O
following -X- _ O
Karpathy -X- _ O
and -X- _ O
Fei -X- _ O
- -X- _ O
Fei -X- _ O
, -X- _ O
we -X- _ O
only -X- _ O
trained -X- _ O
LSTM -X- _ B-MethodName
parameters -X- _ O
, -X- _ O
while -X- _ O
CNN -X- _ B-MethodName
parameters -X- _ O
were -X- _ O
fixed -X- _ O
. -X- _ O

En -X- _ B-MethodName
- -X- _ I-MethodName
generator -X- _ I-MethodName
→ -X- _ I-MethodName
MT -X- _ I-MethodName
: -X- _ O
テーブルの上にある食べ物の束 -X- _ O
。 -X- _ O
Ja -X- _ B-MethodName
- -X- _ I-MethodName
generator -X- _ I-MethodName
: -X- _ O
. -X- _ O

En -X- _ B-MethodName
- -X- _ I-MethodName
generator -X- _ I-MethodName
: -X- _ O
. -X- _ O

ストリートを運転する二重デッカーバス -X- _ O
。 -X- _ O
Ja -X- _ B-MethodName
- -X- _ I-MethodName
generator -X- _ I-MethodName
: -X- _ O
. -X- _ O

En -X- _ B-MethodName
- -X- _ I-MethodName
generator -X- _ I-MethodName
→ -X- _ I-MethodName
MT -X- _ I-MethodName
: -X- _ O
. -X- _ O

En -X- _ B-MethodName
- -X- _ I-MethodName
generator -X- _ I-MethodName
: -X- _ O
. -X- _ O

Ja -X- _ B-MethodName
- -X- _ I-MethodName
generator -X- _ I-MethodName
was -X- _ O
trained -X- _ O
with -X- _ O
Japanese -X- _ O
captions -X- _ O
. -X- _ O

En -X- _ B-MethodName
- -X- _ I-MethodName
generator -X- _ I-MethodName
→ -X- _ I-MethodName
MT -X- _ I-MethodName
is -X- _ O
the -X- _ O
pipeline -X- _ O
method -X- _ O
: -X- _ O
it -X- _ O
first -X- _ O
generates -X- _ O
English -X- _ O
caption -X- _ O
and -X- _ O
performs -X- _ O
machine -X- _ O
translation -X- _ O
subsequently -X- _ O
. -X- _ O

En -X- _ B-MethodName
- -X- _ I-MethodName
generator -X- _ I-MethodName
denotes -X- _ O
the -X- _ O
caption -X- _ O
generator -X- _ O
trained -X- _ O
with -X- _ O
MS -X- _ B-DatasetName
- -X- _ I-DatasetName
COCO -X- _ I-DatasetName
. -X- _ O

As -X- _ O
mentioned -X- _ O
in -X- _ O
Section -X- _ O
4 -X- _ O
, -X- _ O
we -X- _ O
used -X- _ O
the -X- _ O
method -X- _ O
proposed -X- _ O
by -X- _ O
Karpathy -X- _ O
and -X- _ O
Fei -X- _ O
- -X- _ O
Fei -X- _ O
( -X- _ O
2015 -X- _ O
) -X- _ O
as -X- _ O
caption -X- _ B-TaskName
generation -X- _ I-TaskName
models -X- _ O
for -X- _ O
both -X- _ O
En -X- _ B-MethodName
- -X- _ I-MethodName
generator -X- _ I-MethodName
→ -X- _ I-MethodName
MT -X- _ I-MethodName
and -X- _ O
Ja -X- _ B-MethodName
- -X- _ I-MethodName
generator -X- _ I-MethodName
. -X- _ O

Unlike -X- _ O
MS -X- _ B-DatasetName
- -X- _ I-DatasetName
COCO -X- _ I-DatasetName
→ -X- _ O
MT -X- _ O
, -X- _ O
this -X- _ O
method -X- _ O
directly -X- _ O
generate -X- _ O
a -X- _ O
Japanese -X- _ O
caption -X- _ O
from -X- _ O
a -X- _ O
given -X- _ O
image -X- _ O
. -X- _ O

• -X- _ O
Ja -X- _ O
- -X- _ O
generator -X- _ O
: -X- _ O
This -X- _ O
method -X- _ O
trains -X- _ O
a -X- _ O
neural -X- _ O
network -X- _ O
using -X- _ O
STAIR -X- _ B-DatasetName
Captions -X- _ I-DatasetName
. -X- _ O

In -X- _ O
the -X- _ O
test -X- _ O
phase -X- _ O
, -X- _ O
given -X- _ O
an -X- _ O
image -X- _ O
, -X- _ O
we -X- _ O
first -X- _ O
generate -X- _ O
an -X- _ O
English -X- _ O
caption -X- _ O
to -X- _ O
the -X- _ O
image -X- _ O
by -X- _ O
the -X- _ O
trained -X- _ O
neural -X- _ O
network -X- _ O
, -X- _ O
and -X- _ O
then -X- _ O
translate -X- _ O
the -X- _ O
generated -X- _ O
caption -X- _ O
into -X- _ O
Japanese -X- _ O
one -X- _ O
by -X- _ O
machine -X- _ B-TaskName
translation -X- _ I-TaskName
. -X- _ O

This -X- _ O
method -X- _ O
trains -X- _ O
a -X- _ O
neural -X- _ O
network -X- _ O
, -X- _ O
which -X- _ O
generates -X- _ O
English -X- _ O
captions -X- _ O
, -X- _ O
with -X- _ O
MS -X- _ B-DatasetName
- -X- _ I-DatasetName
COCO -X- _ I-DatasetName
. -X- _ O

• -X- _ O
En -X- _ O
- -X- _ O
generator -X- _ O
→ -X- _ O
MT -X- _ O
: -X- _ O
A -X- _ O
pipeline -X- _ O
method -X- _ O
of -X- _ O
English -X- _ O
caption -X- _ B-TaskName
generation -X- _ I-TaskName
and -X- _ O
English -X- _ O
- -X- _ O
Japanese -X- _ O
machine -X- _ B-TaskName
translation -X- _ I-TaskName
. -X- _ O

Although -X- _ O
BLEU -X- _ B-MetricName
and -X- _ O
ROUGE -X- _ B-MetricName
were -X- _ O
developed -X- _ O
originally -X- _ O
for -X- _ O
evaluating -X- _ O
machine -X- _ O
translation -X- _ O
and -X- _ O
text -X- _ O
summarization -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
them -X- _ O
here -X- _ O
because -X- _ O
they -X- _ O
are -X- _ O
often -X- _ O
used -X- _ O
for -X- _ O
measuring -X- _ O
the -X- _ O
quality -X- _ O
of -X- _ O
caption -X- _ B-TaskName
generation -X- _ I-TaskName
. -X- _ O

Following -X- _ O
the -X- _ O
literature -X- _ O
( -X- _ O
Chen -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015;Karpathy -X- _ O
and -X- _ O
Fei -X- _ O
- -X- _ O
Fei -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
BLEU -X- _ B-MetricName
( -X- _ O
Papineni -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2002 -X- _ O
) -X- _ O
, -X- _ O
ROUGE -X- _ B-MetricName
( -X- _ O
Lin -X- _ O
, -X- _ O
2004 -X- _ O
) -X- _ O
, -X- _ O
andCIDEr -X- _ B-MetricName
( -X- _ O
Vedantam -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
as -X- _ O
evaluation -X- _ O
measures -X- _ O
. -X- _ O

In -X- _ O
particular -X- _ O
, -X- _ O
we -X- _ O
evaluate -X- _ O
quantitatively -X- _ O
and -X- _ O
qualitatively -X- _ O
how -X- _ O
fluent -X- _ O
Japanese -X- _ O
captions -X- _ O
can -X- _ O
be -X- _ O
generated -X- _ O
by -X- _ O
using -X- _ O
a -X- _ O
neural -X- _ O
network -X- _ O
- -X- _ O
based -X- _ O
caption -X- _ B-TaskName
generation -X- _ I-TaskName
model -X- _ O
trained -X- _ O
on -X- _ O
STAIR -X- _ O
Captions -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
section -X- _ O
, -X- _ O
we -X- _ O
perform -X- _ O
an -X- _ O
experiment -X- _ O
which -X- _ O
generates -X- _ O
Japanese -X- _ O
captions -X- _ O
using -X- _ O
STAIR -X- _ B-DatasetName
Captions -X- _ I-DatasetName
. -X- _ O

In -X- _ O
the -X- _ O
training -X- _ O
phase -X- _ O
, -X- _ O
given -X- _ O
the -X- _ O
training -X- _ O
data -X- _ O
, -X- _ O
we -X- _ O
train -X- _ O
W -X- _ O
( -X- _ O
i -X- _ O
m -X- _ O
) -X- _ O
, -X- _ O
b -X- _ O
( -X- _ O
i -X- _ O
m -X- _ O
) -X- _ O
, -X- _ O
W -X- _ O
* -X- _ O
, -X- _ O
b -X- _ O
* -X- _ O
, -X- _ O
CNN -X- _ B-MethodName
, -X- _ O
and -X- _ O
LSTM -X- _ B-MethodName
parameters -X- _ O
, -X- _ O
where -X- _ O
* -X- _ O
represents -X- _ O
wild -X- _ O
card -X- _ O
. -X- _ O

The -X- _ O
generation -X- _ O
process -X- _ O
is -X- _ O
repeated -X- _ O
until -X- _ O
LSTM -X- _ B-MethodName
outputs -X- _ O
the -X- _ O
symbol -X- _ O
that -X- _ O
indicates -X- _ O
the -X- _ O
end -X- _ O
of -X- _ O
sentence -X- _ O
. -X- _ O

Then -X- _ O
, -X- _ O
caption -X- _ O
generation -X- _ O
is -X- _ O
defined -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O
x -X- _ O
( -X- _ O
i -X- _ O
m -X- _ O
) -X- _ O
= -X- _ O
CNN(I -X- _ B-MethodName
) -X- _ O
, -X- _ O
h -X- _ O
0 -X- _ O
= -X- _ O
tanh -X- _ O
( -X- _ O
W -X- _ O
( -X- _ O
i -X- _ O
m -X- _ O
) -X- _ O
x -X- _ O
( -X- _ O
i -X- _ O
m -X- _ O
) -X- _ O
+ -X- _ O
b -X- _ O
( -X- _ O
i -X- _ O
m -X- _ O
) -X- _ O
) -X- _ O
, -X- _ O
c -X- _ O
0 -X- _ O
= -X- _ O
0 -X- _ O
, -X- _ O
h -X- _ O
t -X- _ O
, -X- _ O
c -X- _ O
t -X- _ O
= -X- _ O
LSTM -X- _ B-MethodName
( -X- _ O
x -X- _ O
t -X- _ O
, -X- _ O
h -X- _ O
t−1 -X- _ O
, -X- _ O
c -X- _ O
t−1 -X- _ O
) -X- _ O
( -X- _ O
t -X- _ O
≥ -X- _ O
1 -X- _ O
) -X- _ O
, -X- _ O
y -X- _ O
t -X- _ O
= -X- _ O
softmax -X- _ O
( -X- _ O
W -X- _ O
o -X- _ O
h -X- _ O
t -X- _ O
+ -X- _ O
b -X- _ O
o -X- _ O
) -X- _ O
, -X- _ O
where -X- _ O
CNN(• -X- _ B-MethodName
) -X- _ O
is -X- _ O
a -X- _ O
function -X- _ O
that -X- _ O
outputs -X- _ O
the -X- _ O
image -X- _ O
features -X- _ O
extracted -X- _ O
by -X- _ O
CNN -X- _ B-MethodName
, -X- _ O
that -X- _ O
is -X- _ O
, -X- _ O
the -X- _ O
final -X- _ O
layer -X- _ O
of -X- _ O
CNN -X- _ B-MethodName
, -X- _ O
and -X- _ O
y -X- _ O
t -X- _ O
is -X- _ O
the -X- _ O
tth -X- _ O
output -X- _ O
word -X- _ O
. -X- _ O

Specifically -X- _ O
, -X- _ O
CNN -X- _ B-MethodName
first -X- _ O
extracts -X- _ O
features -X- _ O
from -X- _ O
a -X- _ O
given -X- _ O
image -X- _ O
, -X- _ O
and -X- _ O
then -X- _ O
, -X- _ O
LSTM -X- _ B-MethodName
generates -X- _ O
a -X- _ O
caption -X- _ O
from -X- _ O
the -X- _ O
extracted -X- _ O
features -X- _ O
. -X- _ O

This -X- _ O
method -X- _ O
consists -X- _ O
of -X- _ O
a -X- _ O
convolutional -X- _ B-MethodName
neural -X- _ I-MethodName
network -X- _ I-MethodName
( -X- _ O
CNN -X- _ B-MethodName
) -X- _ O
and -X- _ O
long -X- _ B-MethodName
short -X- _ I-MethodName
- -X- _ I-MethodName
term -X- _ I-MethodName
memory -X- _ I-MethodName
( -X- _ O
LSTM)3 -X- _ B-MethodName
. -X- _ O

In -X- _ O
this -X- _ O
section -X- _ O
, -X- _ O
we -X- _ O
briefly -X- _ O
review -X- _ O
the -X- _ O
caption -X- _ B-TaskName
generation -X- _ I-TaskName
method -X- _ O
proposed -X- _ O
by -X- _ O
Karpathy -X- _ O
and -X- _ O
Fei -X- _ O
- -X- _ O
Fei -X- _ O
( -X- _ O
2015 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
used -X- _ O
in -X- _ O
our -X- _ O
experiments -X- _ O
( -X- _ O
Section -X- _ O
5 -X- _ O
) -X- _ O
. -X- _ O

Image -X- _ B-TaskName
Caption -X- _ I-TaskName
Generation -X- _ I-TaskName
. -X- _ O

That -X- _ O
the -X- _ O
numbers -X- _ O
of -X- _ O
images -X- _ O
and -X- _ O
captions -X- _ O
are -X- _ O
large -X- _ O
in -X- _ O
STAIR -X- _ B-DatasetName
Captions -X- _ I-DatasetName
is -X- _ O
an -X- _ O
important -X- _ O
point -X- _ O
in -X- _ O
image -X- _ O
caption -X- _ O
. -X- _ O

In -X- _ O
the -X- _ O
public -X- _ O
part -X- _ O
of -X- _ O
STAIR -X- _ B-DatasetName
Captions -X- _ I-DatasetName
, -X- _ O
the -X- _ O
numbers -X- _ O
of -X- _ O
images -X- _ O
and -X- _ O
Japanese -X- _ O
captions -X- _ O
are -X- _ O
4.65x -X- _ O
and -X- _ O
4.67x -X- _ O
greater -X- _ O
than -X- _ O
those -X- _ O
in -X- _ O
YJ -X- _ B-DatasetName
Captions -X- _ I-DatasetName
, -X- _ O
respectively -X- _ O
. -X- _ O

Compared -X- _ O
with -X- _ O
YJ -X- _ B-DatasetName
Captions -X- _ I-DatasetName
, -X- _ O
overall -X- _ O
, -X- _ O
the -X- _ O
numbers -X- _ O
of -X- _ O
Japanese -X- _ O
captions -X- _ O
and -X- _ O
images -X- _ O
in -X- _ O
STAIR -X- _ B-DatasetName
Captions -X- _ I-DatasetName
are -X- _ O
6.23x -X- _ O
and -X- _ O
6.19x -X- _ O
, -X- _ O
respectively -X- _ O
. -X- _ O

In -X- _ O
addition -X- _ O
, -X- _ O
we -X- _ O
compare -X- _ O
it -X- _ O
to -X- _ O
YJ -X- _ B-DatasetName
Captions -X- _ I-DatasetName
( -X- _ O
Miyazaki -X- _ O
and -X- _ O
Shimizu -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
, -X- _ O
a -X- _ O
dataset -X- _ O
with -X- _ O
Japanese -X- _ O
captions -X- _ O
for -X- _ O
the -X- _ O
images -X- _ O
in -X- _ O
MS -X- _ B-DatasetName
- -X- _ I-DatasetName
COCO -X- _ I-DatasetName
like -X- _ O
in -X- _ O
STAIR -X- _ B-DatasetName
Captions -X- _ I-DatasetName
. -X- _ O

This -X- _ O
section -X- _ O
introduces -X- _ O
the -X- _ O
quantitative -X- _ O
characteristics -X- _ O
of -X- _ O
STAIR -X- _ B-DatasetName
Captions -X- _ I-DatasetName
. -X- _ O

To -X- _ O
concurrently -X- _ O
and -X- _ O
inexpensively -X- _ O
annotate -X- _ O
captions -X- _ O
by -X- _ O
using -X- _ O
the -X- _ O
above -X- _ O
web -X- _ O
system -X- _ O
, -X- _ O
we -X- _ O
asked -X- _ O
part -X- _ O
- -X- _ O
time -X- _ O
job -X- _ O
workers -X- _ O
and -X- _ O
crowd -X- _ O
- -X- _ O
sourcing -X- _ O
workers -X- _ O
to -X- _ O
perform -X- _ O
the -X- _ O
caption -X- _ O
annotation -X- _ O
. -X- _ O

Following -X- _ O
the -X- _ O
rules -X- _ O
for -X- _ O
publishing -X- _ O
datasets -X- _ O
created -X- _ O
based -X- _ O
on -X- _ O
MS -X- _ B-DatasetName
- -X- _ I-DatasetName
COCO -X- _ I-DatasetName
, -X- _ O
the -X- _ O
Japanese -X- _ O
captions -X- _ O
we -X- _ O
created -X- _ O
for -X- _ O
the -X- _ O
test -X- _ O
images -X- _ O
are -X- _ O
excluded -X- _ O
from -X- _ O
the -X- _ O
public -X- _ O
part -X- _ O
of -X- _ O
STAIR -X- _ B-DatasetName
Captions -X- _ I-DatasetName
. -X- _ O

We -X- _ O
annotated -X- _ O
all -X- _ O
images -X- _ O
( -X- _ O
164,062 -X- _ O
images -X- _ O
) -X- _ O
in -X- _ O
the -X- _ O
2014 -X- _ O
edition -X- _ O
of -X- _ O
MS -X- _ B-DatasetName
- -X- _ I-DatasetName
COCO -X- _ I-DatasetName
. -X- _ O

This -X- _ O
section -X- _ O
explains -X- _ O
how -X- _ O
we -X- _ O
constructed -X- _ O
STAIR -X- _ B-DatasetName
Captions -X- _ I-DatasetName
. -X- _ O

STAIR -X- _ B-DatasetName
Captions -X- _ I-DatasetName
. -X- _ O

In -X- _ O
Section -X- _ O
3 -X- _ O
, -X- _ O
we -X- _ O
highlight -X- _ O
this -X- _ O
difference -X- _ O
by -X- _ O
comparing -X- _ O
the -X- _ O
statistics -X- _ O
of -X- _ O
STAIR -X- _ B-DatasetName
Captions -X- _ I-DatasetName
and -X- _ O
YJ -X- _ B-DatasetName
Captions -X- _ I-DatasetName
. -X- _ O

The -X- _ O
main -X- _ O
difference -X- _ O
between -X- _ O
STAIR -X- _ B-DatasetName
Captions -X- _ I-DatasetName
and -X- _ O
YJ -X- _ B-DatasetName
Captions -X- _ I-DatasetName
is -X- _ O
that -X- _ O
STAIR -X- _ B-DatasetName
Captions -X- _ I-DatasetName
provides -X- _ O
Japanese -X- _ O
captions -X- _ O
for -X- _ O
a -X- _ O
greater -X- _ O
number -X- _ O
of -X- _ O
images -X- _ O
. -X- _ O

As -X- _ O
in -X- _ O
our -X- _ O
study -X- _ O
, -X- _ O
they -X- _ O
constructed -X- _ O
a -X- _ O
Japanese -X- _ O
caption -X- _ O
dataset -X- _ O
called -X- _ O
YJ -X- _ B-DatasetName
Captions -X- _ I-DatasetName
. -X- _ O

In -X- _ O
addition -X- _ O
, -X- _ O
many -X- _ O
studies -X- _ O
have -X- _ O
extended -X- _ O
MS -X- _ B-DatasetName
- -X- _ I-DatasetName
COCO -X- _ I-DatasetName
by -X- _ O
annotating -X- _ O
additional -X- _ O
information -X- _ O
about -X- _ O
the -X- _ O
images -X- _ O
in -X- _ O
MS -X- _ B-DatasetName
- -X- _ I-DatasetName
COCO2 -X- _ I-DatasetName
. -X- _ O

Since -X- _ O
its -X- _ O
release -X- _ O
, -X- _ O
MS -X- _ B-DatasetName
- -X- _ I-DatasetName
COCO -X- _ I-DatasetName
has -X- _ O
been -X- _ O
used -X- _ O
as -X- _ O
a -X- _ O
benchmark -X- _ O
dataset -X- _ O
for -X- _ O
image -X- _ B-TaskName
classification -X- _ I-TaskName
and -X- _ O
caption -X- _ B-TaskName
generation -X- _ I-TaskName
. -X- _ O

MS -X- _ B-DatasetName
- -X- _ I-DatasetName
COCO -X- _ I-DatasetName
is -X- _ O
a -X- _ O
dataset -X- _ O
constructed -X- _ O
for -X- _ O
research -X- _ O
on -X- _ O
image -X- _ B-TaskName
classification -X- _ I-TaskName
, -X- _ O
object -X- _ B-TaskName
recognition -X- _ I-TaskName
, -X- _ O
and -X- _ O
English -X- _ O
caption -X- _ B-TaskName
generation -X- _ I-TaskName
. -X- _ O

Note -X- _ O
that -X- _ O
when -X- _ O
annotating -X- _ O
the -X- _ O
Japanese -X- _ O
captions -X- _ O
, -X- _ O
we -X- _ O
did -X- _ O
not -X- _ O
refer -X- _ O
to -X- _ O
the -X- _ O
original -X- _ O
English -X- _ O
captions -X- _ O
in -X- _ O
MS -X- _ B-DatasetName
- -X- _ I-DatasetName
COCO -X- _ I-DatasetName
. -X- _ O

As -X- _ O
detailed -X- _ O
in -X- _ O
Section -X- _ O
3 -X- _ O
, -X- _ O
we -X- _ O
annotate -X- _ O
Japanese -X- _ O
captions -X- _ O
for -X- _ O
the -X- _ O
images -X- _ O
in -X- _ O
MS -X- _ B-DatasetName
- -X- _ I-DatasetName
COCO -X- _ I-DatasetName
. -X- _ O

STAIR -X- _ B-DatasetName
Captions -X- _ I-DatasetName
is -X- _ O
available -X- _ O
for -X- _ O
download -X- _ O
from -X- _ O
http://captions.stair.center -X- _ O
. -X- _ O

• -X- _ O
We -X- _ O
confirmed -X- _ O
that -X- _ O
quantitatively -X- _ O
and -X- _ O
qualitatively -X- _ O
better -X- _ O
Japanese -X- _ O
captions -X- _ O
than -X- _ O
the -X- _ O
ones -X- _ O
translated -X- _ O
from -X- _ O
English -X- _ O
captions -X- _ O
can -X- _ O
be -X- _ O
generated -X- _ O
by -X- _ O
applying -X- _ O
a -X- _ O
neural -X- _ O
network -X- _ O
- -X- _ O
based -X- _ O
image -X- _ O
caption -X- _ O
generation -X- _ O
model -X- _ O
learned -X- _ O
on -X- _ O
STAIR -X- _ B-DatasetName
Captions -X- _ I-DatasetName
( -X- _ O
Section -X- _ O
5 -X- _ O
) -X- _ O
. -X- _ O

The -X- _ O
contributions -X- _ O
of -X- _ O
this -X- _ O
paper -X- _ O
are -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O
• -X- _ O
We -X- _ O
constructed -X- _ O
a -X- _ O
large -X- _ O
- -X- _ O
scale -X- _ O
Japanese -X- _ O
image -X- _ O
caption -X- _ O
dataset -X- _ O
, -X- _ O
STAIR -X- _ B-DatasetName
Captions -X- _ I-DatasetName
, -X- _ O
which -X- _ O
consists -X- _ O
of -X- _ O
Japanese -X- _ O
captions -X- _ O
for -X- _ O
all -X- _ O
the -X- _ O
images -X- _ O
in -X- _ O
MS -X- _ B-DatasetName
- -X- _ I-DatasetName
COCO -X- _ I-DatasetName
( -X- _ O
Lin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
( -X- _ O
Section -X- _ O
3 -X- _ O
) -X- _ O
. -X- _ O

By -X- _ O
improving -X- _ O
the -X- _ O
quality -X- _ O
of -X- _ O
image -X- _ B-TaskName
captioning -X- _ I-TaskName
, -X- _ O
image -X- _ B-TaskName
search -X- _ I-TaskName
using -X- _ O
natural -X- _ O
sentences -X- _ O
and -X- _ O
image -X- _ B-TaskName
recognition -X- _ I-TaskName
support -X- _ O
for -X- _ O
1In -X- _ O
recent -X- _ O
years -X- _ O
it -X- _ O
has -X- _ O
been -X- _ O
held -X- _ O
as -X- _ O
a -X- _ O
joint -X- _ O
workshop -X- _ O
such -X- _ O
as -X- _ O
EMNLP -X- _ O
and -X- _ O
ACL -X- _ O
; -X- _ O
https://vision.cs.hacettepe -X- _ O
. -X- _ O

Image -X- _ B-TaskName
captioning -X- _ I-TaskName
is -X- _ O
to -X- _ O
automatically -X- _ O
generate -X- _ O
a -X- _ O
caption -X- _ O
for -X- _ O
a -X- _ O
given -X- _ O
image -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
research -X- _ O
area -X- _ O
, -X- _ O
methods -X- _ O
to -X- _ O
automatically -X- _ O
generate -X- _ O
image -X- _ O
descriptions -X- _ O
( -X- _ O
captions -X- _ O
) -X- _ O
, -X- _ O
that -X- _ O
is -X- _ O
, -X- _ O
image -X- _ B-TaskName
captioning -X- _ I-TaskName
, -X- _ O
have -X- _ O
attracted -X- _ O
a -X- _ O
great -X- _ O
deal -X- _ O
of -X- _ O
attention -X- _ O
( -X- _ O
Karpathy -X- _ O
and -X- _ O
Fei -X- _ O
- -X- _ O
Fei -X- _ O
, -X- _ O
2015;Donahue -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015;Vinyals -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015;Mao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
. -X- _ O

In -X- _ O
the -X- _ O
experiment -X- _ O
, -X- _ O
we -X- _ O
show -X- _ O
that -X- _ O
a -X- _ O
neural -X- _ O
network -X- _ O
trained -X- _ O
using -X- _ O
STAIR -X- _ B-DatasetName
Captions -X- _ I-DatasetName
can -X- _ O
generate -X- _ O
more -X- _ O
natural -X- _ O
and -X- _ O
better -X- _ O
Japanese -X- _ O
captions -X- _ O
, -X- _ O
compared -X- _ O
to -X- _ O
those -X- _ O
generated -X- _ O
using -X- _ O
English -X- _ O
- -X- _ O
Japanese -X- _ O
machine -X- _ B-TaskName
translation -X- _ I-TaskName
after -X- _ O
generating -X- _ O
English -X- _ O
captions -X- _ O
. -X- _ O

STAIR -X- _ B-DatasetName
Captions -X- _ I-DatasetName
consists -X- _ O
of -X- _ O
820,310 -X- _ O
Japanese -X- _ O
captions -X- _ O
for -X- _ O
164,062 -X- _ O
images -X- _ O
. -X- _ O

To -X- _ O
tackle -X- _ O
this -X- _ O
problem -X- _ O
, -X- _ O
we -X- _ O
construct -X- _ O
a -X- _ O
large -X- _ O
- -X- _ O
scale -X- _ O
Japanese -X- _ O
image -X- _ O
caption -X- _ O
dataset -X- _ O
based -X- _ O
on -X- _ O
images -X- _ O
from -X- _ O
MS -X- _ B-DatasetName
- -X- _ I-DatasetName
COCO -X- _ I-DatasetName
, -X- _ O
which -X- _ O
is -X- _ O
called -X- _ O
STAIR -X- _ B-DatasetName
Captions -X- _ I-DatasetName
. -X- _ O

In -X- _ O
recent -X- _ O
years -X- _ O
, -X- _ O
automatic -X- _ O
generation -X- _ O
of -X- _ O
image -X- _ O
descriptions -X- _ O
( -X- _ O
captions -X- _ O
) -X- _ O
, -X- _ O
that -X- _ O
is -X- _ O
, -X- _ O
image -X- _ B-TaskName
captioning -X- _ I-TaskName
, -X- _ O
has -X- _ O
attracted -X- _ O
a -X- _ O
great -X- _ O
deal -X- _ O
of -X- _ O
attention -X- _ O
. -X- _ O

STAIR -X- _ B-DatasetName
Captions -X- _ I-DatasetName
: -X- _ O
Constructing -X- _ O
a -X- _ O
Large -X- _ O
- -X- _ O
Scale -X- _ O
Japanese -X- _ O
Image -X- _ O
Caption -X- _ O
Dataset -X- _ O
. -X- _ O

In -X- _ O
future -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
will -X- _ O
analyze -X- _ O
the -X- _ O
experimental -X- _ O
results -X- _ O
in -X- _ O
greater -X- _ O
detail -X- _ O
. -X- _ O

The -X- _ O
total -X- _ O
number -X- _ O
of -X- _ O
Japanese -X- _ O
captions -X- _ O
is -X- _ O
820,310 -X- _ O
. -X- _ O

Conclusion -X- _ O
. -X- _ O

Table -X- _ O
2 -X- _ O
summarizes -X- _ O
the -X- _ O
experimental -X- _ O
results -X- _ O
. -X- _ O

Results -X- _ O
. -X- _ O

As -X- _ O
preprocessing -X- _ O
, -X- _ O
we -X- _ O
applied -X- _ O
morphological -X- _ O
analysis -X- _ O
to -X- _ O
the -X- _ O
Japanese -X- _ O
captions -X- _ O
using -X- _ O
MeCab6 -X- _ O
. -X- _ O

We -X- _ O
divided -X- _ O
the -X- _ O
dataset -X- _ O
into -X- _ O
three -X- _ O
parts -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
113,287 -X- _ O
images -X- _ O
for -X- _ O
the -X- _ O
training -X- _ O
set -X- _ O
, -X- _ O
5,000 -X- _ O
images -X- _ O
for -X- _ O
the -X- _ O
validation -X- _ O
set -X- _ O
, -X- _ O
and -X- _ O
5,000 -X- _ O
images -X- _ O
for -X- _ O
the -X- _ O
test -X- _ O
set -X- _ O
. -X- _ O

Following -X- _ O
the -X- _ O
experimental -X- _ O
setting -X- _ O
in -X- _ O
the -X- _ O
previous -X- _ O
studies -X- _ O
( -X- _ O
Chen -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015;Karpathy -X- _ O
and -X- _ O
Fei -X- _ O
- -X- _ O
Fei -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
used -X- _ O
123,287 -X- _ O
images -X- _ O
included -X- _ O
in -X- _ O
the -X- _ O
MS -X- _ O
- -X- _ O
COCO -X- _ O
training -X- _ O
and -X- _ O
validation -X- _ O
sets -X- _ O
and -X- _ O
their -X- _ O
corresponding -X- _ O
Japanese -X- _ O
captions -X- _ O
. -X- _ O

Dataset -X- _ O
Separation -X- _ O
. -X- _ O

ドーナツがたくさん並んでいる -X- _ O
。 -X- _ O
. -X- _ O

A -X- _ O
bunch -X- _ O
of -X- _ O
food -X- _ O
that -X- _ O
are -X- _ O
on -X- _ O
a -X- _ O
table -X- _ O
. -X- _ O

二階建てのバスが道路を走っている -X- _ O
。 -X- _ O
. -X- _ O

A -X- _ O
double -X- _ O
decker -X- _ O
bus -X- _ O
driving -X- _ O
down -X- _ O
a -X- _ O
street -X- _ O
. -X- _ O

Examples -X- _ O
of -X- _ O
generated -X- _ O
image -X- _ O
captions -X- _ O
. -X- _ O

This -X- _ O
method -X- _ O
is -X- _ O
the -X- _ O
baseline -X- _ O
. -X- _ O

Here -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
Google -X- _ O
translate4 -X- _ O
for -X- _ O
machine -X- _ O
translation -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
experiment -X- _ O
, -X- _ O
we -X- _ O
evaluate -X- _ O
the -X- _ O
following -X- _ O
caption -X- _ O
generation -X- _ O
methods -X- _ O
. -X- _ O

Comparison -X- _ O
Methods -X- _ O
. -X- _ O

Evaluation -X- _ O
Measure -X- _ O
. -X- _ O

Experimental -X- _ O
Setup -X- _ O
. -X- _ O

The -X- _ O
aim -X- _ O
of -X- _ O
this -X- _ O
experiment -X- _ O
is -X- _ O
to -X- _ O
show -X- _ O
the -X- _ O
necessity -X- _ O
of -X- _ O
a -X- _ O
Japanese -X- _ O
caption -X- _ O
dataset -X- _ O
. -X- _ O

Experiments -X- _ O
. -X- _ O

The -X- _ O
input -X- _ O
x -X- _ O
t -X- _ O
at -X- _ O
time -X- _ O
t -X- _ O
is -X- _ O
substituted -X- _ O
by -X- _ O
a -X- _ O
word -X- _ O
embedding -X- _ O
vector -X- _ O
corresponding -X- _ O
to -X- _ O
the -X- _ O
previous -X- _ O
output -X- _ O
, -X- _ O
that -X- _ O
is -X- _ O
, -X- _ O
y -X- _ O
t−1 -X- _ O
. -X- _ O

Let -X- _ O
I -X- _ O
be -X- _ O
an -X- _ O
image -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
corresponding -X- _ O
caption -X- _ O
be -X- _ O
Y -X- _ O
= -X- _ O
( -X- _ O
y -X- _ O
1 -X- _ O
, -X- _ O
y -X- _ O
2 -X- _ O
, -X- _ O
• -X- _ O
• -X- _ O
• -X- _ O
, -X- _ O
y -X- _ O
n -X- _ O
) -X- _ O
. -X- _ O

Table -X- _ O
1 -X- _ O
summarizes -X- _ O
the -X- _ O
statistics -X- _ O
of -X- _ O
the -X- _ O
datasets -X- _ O
. -X- _ O

Statistics -X- _ O
. -X- _ O

The -X- _ O
entire -X- _ O
annotation -X- _ O
work -X- _ O
was -X- _ O
completed -X- _ O
by -X- _ O
about -X- _ O
2,100 -X- _ O
workers -X- _ O
in -X- _ O
about -X- _ O
half -X- _ O
a -X- _ O
year -X- _ O
. -X- _ O

To -X- _ O
guarantee -X- _ O
the -X- _ O
quality -X- _ O
of -X- _ O
the -X- _ O
captions -X- _ O
created -X- _ O
in -X- _ O
this -X- _ O
manner -X- _ O
, -X- _ O
we -X- _ O
conducted -X- _ O
sampling -X- _ O
inspection -X- _ O
of -X- _ O
the -X- _ O
annotated -X- _ O
captions -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
captions -X- _ O
not -X- _ O
in -X- _ O
line -X- _ O
with -X- _ O
the -X- _ O
guidelines -X- _ O
were -X- _ O
removed -X- _ O
. -X- _ O

( -X- _ O
5 -X- _ O
) -X- _ O
A -X- _ O
caption -X- _ O
must -X- _ O
not -X- _ O
include -X- _ O
emotions -X- _ O
or -X- _ O
opinions -X- _ O
about -X- _ O
the -X- _ O
image -X- _ O
. -X- _ O

( -X- _ O
4 -X- _ O
) -X- _ O
A -X- _ O
caption -X- _ O
must -X- _ O
be -X- _ O
a -X- _ O
single -X- _ O
sentence -X- _ O
. -X- _ O

( -X- _ O
3 -X- _ O
) -X- _ O
A -X- _ O
caption -X- _ O
must -X- _ O
describe -X- _ O
only -X- _ O
what -X- _ O
is -X- _ O
happening -X- _ O
in -X- _ O
an -X- _ O
image -X- _ O
and -X- _ O
the -X- _ O
things -X- _ O
displayed -X- _ O
therein -X- _ O
. -X- _ O

( -X- _ O
2 -X- _ O
) -X- _ O
A -X- _ O
caption -X- _ O
must -X- _ O
follow -X- _ O
the -X- _ O
da -X- _ O
/ -X- _ O
dearu -X- _ O
style -X- _ O
( -X- _ O
one -X- _ O
of -X- _ O
writing -X- _ O
styles -X- _ O
in -X- _ O
Japanese -X- _ O
) -X- _ O
. -X- _ O

( -X- _ O
1 -X- _ O
) -X- _ O
A -X- _ O
caption -X- _ O
must -X- _ O
contain -X- _ O
more -X- _ O
than -X- _ O
15 -X- _ O
letters -X- _ O
. -X- _ O

The -X- _ O
workers -X- _ O
annotated -X- _ O
the -X- _ O
images -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
following -X- _ O
guidelines -X- _ O
. -X- _ O

By -X- _ O
pressing -X- _ O
the -X- _ O
send -X- _ O
( -X- _ O
送信 -X- _ O
) -X- _ O
button -X- _ O
, -X- _ O
a -X- _ O
single -X- _ O
task -X- _ O
is -X- _ O
completed -X- _ O
and -X- _ O
the -X- _ O
next -X- _ O
task -X- _ O
is -X- _ O
started -X- _ O
. -X- _ O

Each -X- _ O
annotator -X- _ O
looks -X- _ O
at -X- _ O
the -X- _ O
displayed -X- _ O
image -X- _ O
and -X- _ O
writes -X- _ O
the -X- _ O
corresponding -X- _ O
Japanese -X- _ O
description -X- _ O
in -X- _ O
the -X- _ O
text -X- _ O
box -X- _ O
under -X- _ O
the -X- _ O
image -X- _ O
. -X- _ O

Figure -X- _ O
1 -X- _ O
shows -X- _ O
the -X- _ O
example -X- _ O
of -X- _ O
the -X- _ O
annotation -X- _ O
screen -X- _ O
in -X- _ O
the -X- _ O
web -X- _ O
system -X- _ O
. -X- _ O

To -X- _ O
annotate -X- _ O
captions -X- _ O
efficiently -X- _ O
, -X- _ O
we -X- _ O
first -X- _ O
developed -X- _ O
a -X- _ O
web -X- _ O
system -X- _ O
for -X- _ O
caption -X- _ O
annotation -X- _ O
. -X- _ O

Therefore -X- _ O
, -X- _ O
the -X- _ O
total -X- _ O
number -X- _ O
of -X- _ O
captions -X- _ O
was -X- _ O
820,310 -X- _ O
. -X- _ O

For -X- _ O
each -X- _ O
image -X- _ O
, -X- _ O
we -X- _ O
provided -X- _ O
five -X- _ O
Japanese -X- _ O
captions -X- _ O
. -X- _ O

Annotation -X- _ O
Procedure -X- _ O
. -X- _ O

In -X- _ O
particular -X- _ O
, -X- _ O
the -X- _ O
study -X- _ O
of -X- _ O
Miyazaki -X- _ O
and -X- _ O
Shimizu -X- _ O
( -X- _ O
2016 -X- _ O
) -X- _ O
is -X- _ O
closest -X- _ O
to -X- _ O
the -X- _ O
present -X- _ O
study -X- _ O
. -X- _ O

Recently -X- _ O
, -X- _ O
a -X- _ O
few -X- _ O
caption -X- _ O
datasets -X- _ O
in -X- _ O
languages -X- _ O
other -X- _ O
than -X- _ O
English -X- _ O
have -X- _ O
been -X- _ O
constructed -X- _ O
( -X- _ O
Miyazaki -X- _ O
and -X- _ O
Shimizu -X- _ O
, -X- _ O
2016;Grubinger -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2006;Elliott -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
. -X- _ O

Representative -X- _ O
examples -X- _ O
are -X- _ O
PASCAL -X- _ O
( -X- _ O
Rashtchian -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2010 -X- _ O
) -X- _ O
, -X- _ O
Flickr3k -X- _ O
( -X- _ O
Rashtchian -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2010;Hodosh -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2013 -X- _ O
) -X- _ O
, -X- _ O
Flickr30k -X- _ O
( -X- _ O
Young -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
-an -X- _ O
extension -X- _ O
of -X- _ O
Flickr3k- -X- _ O
, -X- _ O
and -X- _ O
MS -X- _ O
- -X- _ O
COCO -X- _ O
( -X- _ O
Microsoft -X- _ O
Common -X- _ O
Objects -X- _ O
in -X- _ O
Context -X- _ O
) -X- _ O
( -X- _ O
Lin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
. -X- _ O

Some -X- _ O
English -X- _ O
image -X- _ O
caption -X- _ O
datasets -X- _ O
have -X- _ O
been -X- _ O
proposed -X- _ O
( -X- _ O
Krishna -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016;Kuznetsova -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2013;Ordonez -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2011;Vedantam -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015;Isola -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
. -X- _ O

Related -X- _ O
Work -X- _ O
. -X- _ O

Therefore -X- _ O
, -X- _ O
in -X- _ O
this -X- _ O
study -X- _ O
, -X- _ O
we -X- _ O
construct -X- _ O
a -X- _ O
Japanese -X- _ O
image -X- _ O
caption -X- _ O
dataset -X- _ O
, -X- _ O
and -X- _ O
for -X- _ O
given -X- _ O
images -X- _ O
, -X- _ O
we -X- _ O
aim -X- _ O
to -X- _ O
generate -X- _ O
more -X- _ O
natural -X- _ O
Japanese -X- _ O
captions -X- _ O
than -X- _ O
translating -X- _ O
the -X- _ O
generated -X- _ O
English -X- _ O
captions -X- _ O
into -X- _ O
the -X- _ O
Japanese -X- _ O
ones -X- _ O
. -X- _ O

However -X- _ O
, -X- _ O
the -X- _ O
translated -X- _ O
captions -X- _ O
may -X- _ O
be -X- _ O
literal -X- _ O
and -X- _ O
unnatural -X- _ O
because -X- _ O
image -X- _ O
information -X- _ O
can -X- _ O
not -X- _ O
be -X- _ O
reflected -X- _ O
in -X- _ O
the -X- _ O
translation -X- _ O
. -X- _ O

A -X- _ O
straightforward -X- _ O
solution -X- _ O
is -X- _ O
to -X- _ O
translate -X- _ O
English -X- _ O
captions -X- _ O
into -X- _ O
Japanese -X- _ O
ones -X- _ O
by -X- _ O
using -X- _ O
machine -X- _ O
translation -X- _ O
such -X- _ O
as -X- _ O
Google -X- _ O
Translate -X- _ O
. -X- _ O

Since -X- _ O
most -X- _ O
available -X- _ O
caption -X- _ O
datasets -X- _ O
have -X- _ O
been -X- _ O
constructed -X- _ O
for -X- _ O
English -X- _ O
language -X- _ O
, -X- _ O
there -X- _ O
are -X- _ O
few -X- _ O
datasets -X- _ O
for -X- _ O
Japanese -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
study -X- _ O
, -X- _ O
we -X- _ O
consider -X- _ O
generating -X- _ O
image -X- _ O
captions -X- _ O
in -X- _ O
Japanese -X- _ O
. -X- _ O

Recognizing -X- _ O
various -X- _ O
images -X- _ O
and -X- _ O
generating -X- _ O
appropriate -X- _ O
captions -X- _ O
for -X- _ O
the -X- _ O
images -X- _ O
necessitates -X- _ O
the -X- _ O
compilation -X- _ O
of -X- _ O
a -X- _ O
large -X- _ O
number -X- _ O
of -X- _ O
image -X- _ O
and -X- _ O
caption -X- _ O
pairs -X- _ O
. -X- _ O

edu.tr/vl2017/ -X- _ O
visually -X- _ O
impaired -X- _ O
people -X- _ O
by -X- _ O
outputting -X- _ O
captions -X- _ O
as -X- _ O
sounds -X- _ O
can -X- _ O
be -X- _ O
made -X- _ O
available -X- _ O
. -X- _ O

The -X- _ O
Workshop -X- _ O
on -X- _ O
Vision -X- _ O
and -X- _ O
Language -X- _ O
held -X- _ O
in -X- _ O
2011 -X- _ O
has -X- _ O
since -X- _ O
become -X- _ O
an -X- _ O
annual -X- _ O
event1 -X- _ O
. -X- _ O

Integrated -X- _ O
processing -X- _ O
of -X- _ O
natural -X- _ O
language -X- _ O
and -X- _ O
images -X- _ O
has -X- _ O
attracted -X- _ O
attention -X- _ O
in -X- _ O
recent -X- _ O
years -X- _ O
. -X- _ O

Introduction -X- _ O
. -X- _ O

