Not	O
matched	O
(	O
threats	O
,	O
ridicule	O
,	O
mockery	O
,	O
attacks	O
,	O
threat	O
)	O
(	O
backlash	O
,	O
ridicule	O
,	O
mockery	O
,	O
condemnation	O
,	O
criticism	O
)	O
.	O

Matched	O
.	O

The	O
politician	O
received	O
a	O
lot	O
of	O
public	O
criticism	O
or	O
--for	O
his	O
controversial	O
stance	O
on	O
the	O
issue	O
.	O

Not	O
matched	O
(	O
something	O
,	O
leak	O
,	O
obstruction	O
,	O
defect	O
,	O
overflow	O
)	O
(	O
debris	O
,	O
obstruction	O
,	O
water	O
,	O
leak	O
,	O
crack	O
)	O
The	O
senator	O
received	O
severe	O
criticism	O
or	O
--from	O
his	O
opponent	O
.	O

Matched	O
.	O

We	O
had	O
to	O
call	O
a	O
plumber	O
to	O
clear	O
out	O
the	O
blockage	O
or	O
--in	O
the	O
drainpipe	O
.	O

Not	O
matched	O
(	O
anger	O
,	O
disgust	O
,	O
irritation	O
,	O
contempt	O
,	O
frustration	O
)	O
(	O
anger	O
,	O
rage	O
,	O
frustration	O
,	O
aggression	O
,	O
disgust	O
)	O
There	O
was	O
a	O
blockage	O
or	O
--in	O
the	O
sewer	O
,	O
so	O
we	O
called	O
out	O
the	O
plumber	O
.	O

Matched	O
.	O

He	O
could	O
no	O
longer	O
contain	O
his	O
hostility	O
or	O
--	O
.	O

Not	O
matched	O
(	O
river	O
,	O
bay	O
,	O
sea	O
,	O
ocean	O
,	O
channel	O
)	O
(	O
voices	O
,	O
footsteps	O
,	O
whispers	O
,	O
conversations	O
,	O
cries	O
)	O
He	O
could	O
not	O
conceal	O
his	O
hostility	O
or	O
--	O
.	O

Not	O
matched	O
.	O

He	O
strained	O
to	O
hear	O
the	O
faint	O
sounds	O
or	O
--	O
.	O

Not	O
matched	O
Not	O
matched	O
(	O
trunk	O
,	O
roof	O
,	O
chassis	O
,	O
frame	O
,	O
grill	O
)	O
(	O
agency	O
,	O
institution	O
,	O
government	O
,	O
commission	O
,	O
equivalent	O
)	O
The	O
main	O
body	O
of	O
the	O
sound	O
or	O
-ran	O
parallel	O
to	O
the	O
coast	O
.	O

Administrative	O
body	O
or	O
--	O
.	O

Not	O
matched	O
(	O
use	O
,	O
extraction	O
,	O
taking	O
,	O
pumping	O
,	O
consumption	O
)	O
(	O
paintings	O
,	O
sculptures	O
,	O
something	O
,	O
more	O
,	O
looked	O
)	O
The	O
body	O
or	O
--of	O
the	O
car	O
was	O
badly	O
rusted	O
.	O

Not	O
matched	O
.	O

He	O
did	O
complicated	O
pen	O
-	O
and	O
-	O
ink	O
drawings	O
or	O
--like	O
medieval	O
miniatures	O
.	O

The	O
drawing	O
or	O
--of	O
water	O
from	O
the	O
well	O
.	O

Prompt2	O
(	O
Top-5	O
words	O
)	O
Prediction	O
Ground	O
Truth	O
.	O

Prompt1	O
(	O
Top-5	O
words	O
)	O
.	O

For	O
the	O
bottom	O
three	O
where	O
the	O
model	O
fails	O
,	O
we	O
can	O
observe	O
that	O
the	O
target	O
words	O
have	O
very	O
similar	O
or	O
close	O
senses	O
,	O
making	O
them	O
really	O
hard	O
to	O
distinguish	O
.	O

The	O
most	O
probable	O
predicted	O
words	O
for	O
the	O
top	O
three	O
examples	O
indicate	O
that	O
the	O
PLM	O
has	O
spotted	O
the	O
correct	O
senses	O
in	O
both	O
contexts	O
.	O

The	O
top	O
three	O
examples	O
are	O
correctly	O
predicted	O
as	O
negative	O
with	O
high	O
confidence	O
(	O
high	O
similarity	O
score	O
)	O
,	O
while	O
the	O
bottom	O
three	O
are	O
predicted	O
positive	O
again	O
with	O
high	O
confidence	O
.	O

The	O
table	O
presents	O
our	O
generated	O
prompts	O
,	O
top-5	O
most	O
probable	O
words	O
predicted	O
by	O
RoBERTa	O
-	O
Large	O
for	O
each	O
prompt	O
and	O
the	O
final	O
prediction	O
of	O
SP	O
.	O

We	O
did	O
not	O
include	O
the	O
positive	O
examples	O
,	O
since	O
the	O
observation	O
that	O
the	O
same	O
words	O
with	O
the	O
same	O
senses	O
are	O
treated	O
similarly	O
,	O
might	O
not	O
provide	O
a	O
useful	O
insight	O
.	O

The	O
examples	O
are	O
those	O
from	O
WiC	O
dev	O
set	O
which	O
had	O
negative	O
labels	O
.	O

We	O
include	O
some	O
examples	O
of	O
how	O
SP	O
works	O
on	O
WiC	O
in	O
Table	O
4	O
for	O
qualitative	O
analysis	O
.	O

B	O
Qualitative	O
Analysis	O
.	O

The	O
results	O
in	O
.	O

Since	O
our	O
cloze	O
-	O
style	O
prompt	O
template	O
is	O
not	O
applicable	O
to	O
GPT2	O
,	O
we	O
use	O
a	O
different	O
template	O
for	O
it	O
:	O
sentence	O
+	O
targetword	O
+	O
"	O
means	O
--	O
"	O
.	O

Table	O
3	O
shows	O
full	O
test	O
set	O
results	O
of	O
SP	O
for	O
different	O
PLMs	O
and	O
similarity	O
measures	O
to	O
compare	O
the	O
performance	O
of	O
SP	O
in	O
different	O
scenarios	O
.	O

A	O
Experiments	O
with	O
other	O
PLMs	O
.	O
This	O
appendix	O
contains	O
more	O
details	O
on	O
WiC	O
experiments	O
.	O

We	O
hope	O
that	O
our	O
positive	O
results	O
inspire	O
other	O
prompting	O
strategies	O
to	O
better	O
exploit	O
the	O
encoded	O
knowledge	O
in	O
PLMs	O
.	O
As	O
future	O
work	O
,	O
one	O
interesting	O
direction	O
could	O
be	O
to	O
perform	O
further	O
analysis	O
on	O
the	O
behaviour	O
of	O
Spearman	O
's	O
correlation	O
compared	O
to	O
cosine	O
similarity	O
anywhere	O
it	O
is	O
applicable	O
as	O
a	O
similarity	O
measure	O
.	O

We	O
also	O
showed	O
that	O
Spearman	O
's	O
ranking	O
correlation	O
is	O
a	O
more	O
robust	O
choice	O
of	O
similarity	O
measure	O
compared	O
to	O
cosine	O
similarity	O
in	O
this	O
setting	O
.	O

In	O
this	O
work	O
we	O
showed	O
that	O
similarity	O
based	O
approach	O
to	O
promptbased	O
learning	O
is	O
capable	O
of	O
achieving	O
comparable	O
results	O
to	O
purely	O
fine	O
-	O
tuning	O
based	O
methods	O
on	O
Word	O
-	O
in	O
-	O
Context	O
task	O
,	O
in	O
which	O
previous	O
few	O
-	O
shot	O
attempts	O
have	O
failed	O
.	O

We	O
proposed	O
an	O
adaptation	O
of	O
prompt	O
-	O
based	O
learning	O
which	O
addresses	O
the	O
common	O
failure	O
of	O
existing	O
techniques	O
on	O
the	O
WiC	O
dataset	O
.	O

Conclusion	O
.	O

This	O
further	O
supports	O
the	O
sensitivity	O
of	O
cosine	O
similarity	O
for	O
WiC	O
to	O
the	O
noisy	O
variations	O
along	O
the	O
most	O
dominant	O
dimension	O
compared	O
to	O
the	O
other	O
two	O
tasks	O
.	O

The	O
ratio	O
of	O
variance	O
is	O
6.5	O
times	O
for	O
WiC	O
compared	O
to	O
SST	O
and	O
27.3	O
times	O
compared	O
to	O
SICK	O
.	O

Figure	O
2	O
illustrates	O
the	O
distribution	O
of	O
values	O
for	O
the	O
most	O
dominant	O
dimension	O
.	O

To	O
verify	O
our	O
hypothesis	O
,	O
we	O
ran	O
an	O
experiment	O
using	O
1200	O
sample	O
MASK	O
embeddings	O
for	O
each	O
of	O
our	O
three	O
tasks	O
.	O

It	O
is	O
known	O
that	O
the	O
most	O
dominant	O
dimensions	O
in	O
PLMs	O
often	O
encode	O
irrelevant	O
information	O
,	O
such	O
as	O
word	O
frequency	O
(	O
Gao	O
et	O
al	O
.	O
,	O
2019	O
)	O
,	O
therefore	O
hampering	O
performance	O
for	O
sensitive	O
metrics	O
such	O
as	O
cosine	O
similarity	O
.	O

This	O
results	O
in	O
a	O
higher	O
spread	O
on	O
the	O
most	O
dominant	O
dimension	O
in	O
the	O
case	O
of	O
WiC.	O

However	O
,	O
in	O
SST	O
and	O
SICK	O
the	O
MASK	O
template	O
embedding	O
is	O
more	O
restricted	O
,	O
often	O
representing	O
a	O
closely	O
related	O
word	O
to	O
one	O
of	O
the	O
class	O
centroid	O
embeddings	O
(	O
e.g.	O
,	O
in	O
SST	O
the	O
MASK	O
embedding	O
almost	O
always	O
represents	O
a	O
positive	O
or	O
negative	O
adjective	O
)	O
.	O

In	O
WiC	O
,	O
the	O
MASK	O
embeddings	O
can	O
potentially	O
refer	O
to	O
any	O
word	O
,	O
varying	O
from	O
sample	O
to	O
sample	O
.	O

The	O
difference	O
in	O
the	O
gain	O
across	O
tasks	O
can	O
be	O
explained	O
by	O
the	O
difference	O
in	O
their	O
underlying	O
nature	O
.	O

However	O
,	O
the	O
gain	O
in	O
the	O
other	O
two	O
tasks	O
is	O
negligible	O
.	O

The	O
results	O
approve	O
the	O
assumption	O
:	O
pruned	O
cosine	O
similarity	O
gains	O
around	O
10	O
%	O
absolute	O
performance	O
boost	O
on	O
WiC	O
,	O
filling	O
the	O
gap	O
to	O
Spearman	O
correlation	O
.	O

To	O
evaluate	O
this	O
hypothesis	O
,	O
we	O
performed	O
an	O
experiment	O
in	O
which	O
the	O
most	O
dominant	O
dimension	O
was	O
set	O
to	O
zero	O
for	O
all	O
the	O
embeddings	O
(	O
the	O
dominant	O
dimension	O
is	O
identical	O
across	O
all	O
vectors	O
)	O
.	O

This	O
superiority	O
can	O
be	O
explained	O
by	O
the	O
assumption	O
that	O
cosine	O
similarity	O
is	O
more	O
susceptible	O
to	O
variations	O
in	O
the	O
dominant	O
dimensions	O
.	O

Notably	O
,	O
the	O
Spearman	O
correlation	O
score	O
,	O
which	O
is	O
less	O
commonly	O
used	O
for	O
comparing	O
embeddings	O
,	O
outperforms	O
the	O
cosine	O
similarity	O
on	O
WiC	O
by	O
a	O
large	O
margin	O
while	O
maintaining	O
the	O
same	O
level	O
of	O
performance	O
on	O
other	O
tasks	O
.	O

Similarity	O
Measures	O
Comparison	O
.	O

In	O
fact	O
,	O
one	O
could	O
argue	O
that	O
the	O
auto	O
-	O
generated	O
prompt	O
of	O
Auto	O
-	O
Prompt	O
is	O
sub	O
-	O
optimal	O
for	O
our	O
model	O
,	O
which	O
results	O
in	O
dropped	O
performance	O
on	O
the	O
SICK	O
-	O
E	O
dataset	O
.	O

We	O
note	O
that	O
the	O
goal	O
of	O
this	O
experiment	O
was	O
to	O
showcase	O
that	O
our	O
simple	O
adaptation	O
is	O
also	O
applicable	O
to	O
scenarios	O
other	O
than	O
the	O
setting	O
of	O
WiC.	O

SP	O
retains	O
an	O
acceptable	O
level	O
of	O
performance	O
,	O
particularly	O
with	O
the	O
manual	O
prompt	O
,	O
but	O
lags	O
behind	O
with	O
the	O
auto	O
-	O
generated	O
prompt	O
.	O

To	O
compare	O
our	O
results	O
with	O
AutoPrompt	O
on	O
the	O
SICK	O
-	O
E	O
task	O
,	O
we	O
report	O
accuracy	O
score	O
of	O
SP	O
for	O
the	O
standard	O
test	O
set	O
(	O
with	O
neutral	O
majority	O
)	O
and	O
its	O
balanced	O
variant	O
.	O

This	O
suggests	O
that	O
it	O
is	O
possible	O
to	O
gain	O
significant	O
improvement	O
by	O
simply	O
exploiting	O
a	O
non	O
-	O
optimized	O
manual	O
prompt	O
template	O
.	O

For	O
SST-2	O
,	O
we	O
observe	O
that	O
SP	O
can	O
exploit	O
a	O
manual	O
prompt	O
template	O
significantly	O
better	O
than	O
Auto	O
-	O
Prompt	O
,	O
while	O
being	O
competitive	O
using	O
the	O
best	O
template	O
optimized	O
by	O
AutoPrompt	O
(	O
auto	O
-	O
generated	O
)	O
.	O

We	O
compare	O
SP	O
with	O
AutoPrompt	O
which	O
searches	O
for	O
the	O
best	O
template	O
for	O
each	O
task	O
.	O

The	O
results	O
on	O
SST-2	O
and	O
SICK	O
-	O
E	O
are	O
shown	O
in	O
Table	O
2	O
.	O

SICK	O
and	O
SST-2	O
.	O

We	O
also	O
include	O
some	O
detailed	O
examples	O
of	O
how	O
SP	O
works	O
for	O
WiC	O
in	O
the	O
Appendix	O
.	O

We	O
report	O
SP	O
's	O
performance	O
on	O
WiC	O
for	O
other	O
PLMs	O
in	O
the	O
Appendix	O
which	O
shows	O
our	O
method	O
/	O
observation	O
does	O
not	O
depend	O
on	O
a	O
specific	O
PLM	O
.	O

Therefore	O
,	O
using	O
limited	O
examples	O
in	O
the	O
fewshot	O
setting	O
they	O
are	O
able	O
to	O
reach	O
their	O
maximum	O
fine	O
-	O
tuning	O
potential	O
on	O
WiC.	O

This	O
observation	O
suggests	O
that	O
PLMs	O
already	O
encode	O
a	O
certain	O
amount	O
of	O
task	O
-	O
related	O
knowledge	O
and	O
the	O
supervised	O
fine	O
-	O
tuning	O
mainly	O
updates	O
their	O
task	O
description	O
(	O
i.e.	O
,	O
what	O
the	O
task	O
is	O
,	O
not	O
how	O
to	O
solve	O
it	O
)	O
.	O

The	O
performance	O
of	O
SP	O
in	O
the	O
few	O
-	O
shot	O
setting	O
is	O
in	O
the	O
same	O
ballpark	O
as	O
supervised	O
fine	O
-	O
tuning	O
(	O
with	O
nearly	O
170	O
times	O
the	O
data	O
,	O
i.e.	O
,	O
2,714	O
instances	O
per	O
class	O
)	O
.	O

Table	O
1	O
summarizes	O
the	O
results	O
on	O
WiC	O
with	O
RoBERTa	O
-	O
Large	O
as	O
SP	O
's	O
PLM	O
.	O

WiC.	O

Given	O
that	O
our	O
experiments	O
are	O
mainly	O
focused	O
on	O
the	O
WiC	O
dataset	O
,	O
we	O
first	O
report	O
our	O
results	O
on	O
this	O
benchmark	O
,	O
and	O
then	O
provide	O
additional	O
results	O
for	O
the	O
other	O
two	O
tasks	O
.	O

Results	O
.	O

As	O
for	O
PLM	O
,	O
we	O
opted	O
for	O
RoBERTA	O
-	O
large	O
to	O
be	O
able	O
to	O
benchmark	O
our	O
results	O
against	O
Auto	O
-	O
Prompt	O
's	O
(	O
Shin	O
et	O
al	O
.	O
,	O
2020	O
)	O
For	O
each	O
experiment	O
,	O
we	O
report	O
the	O
average	O
performance	O
along	O
with	O
the	O
standard	O
deviation	O
.	O

To	O
train	O
our	O
models	O
,	O
we	O
only	O
used	O
16	O
examples	O
per	O
class	O
.	O

Setup	O
.	O

Answer	O
:	O
--	O
,	O
"	O
+	O
hyp	O
,	O
where	O
pre	O
is	O
the	O
premise	O
and	O
hyp	O
is	O
the	O
hypothesis	O
of	O
an	O
input	O
example	O
.	O

Thus	O
we	O
define	O
our	O
own	O
manual	O
template	O
function	O
as	O
:	O
T	O
(	O
pre	O
,	O
hyp	O
)	O
=	O
pre	O
+	O
"	O
?	O

In	O
our	O
experiments	O
,	O
we	O
only	O
use	O
the	O
former	O
annotations	O
(	O
SICK	O
-	O
E	O
)	O
to	O
compare	O
our	O
results	O
with	O
AutoPrompt	O
,	O
which	O
only	O
reports	O
results	O
for	O
its	O
optimized	O
prompt	O
.	O

Knowledge	O
(	O
Marelli	O
et	O
al	O
.	O
,	O
2014	O
)	O
is	O
a	O
collection	O
of	O
sentence	O
pairs	O
annotated	O
with	O
their	O
entailment	O
relationship	O
as	O
well	O
as	O
a	O
quantified	O
measurement	O
of	O
their	O
semantic	O
similarity	O
.	O

Sentences	O
Involving	O
Compositional	O
.	O

SICK	O
.	O

This	O
is	O
the	O
same	O
manual	O
prompt	O
used	O
in	O
AutoPrompt	O
.	O

For	O
this	O
task	O
we	O
used	O
the	O
automatically	O
-	O
generated	O
template	O
of	O
Auto	O
-	O
Prompt	O
,	O
along	O
with	O
the	O
following	O
manual	O
template	O
:	O
T	O
(	O
sent	O
)	O
=	O
sent	O
+	O
"	O
this	O
movie	O
was	O
--	O
.	O
"	O
,	O
where	O
sent	O
is	O
the	O
input	O
sentence	O
and	O
"	O
+	O
"	O
is	O
concatenation	O
operator	O
.	O

We	O
follow	O
the	O
latter	O
(	O
SST-2	O
)	O
in	O
our	O
experiments	O
.	O

Systems	O
are	O
evaluated	O
either	O
on	O
a	O
five	O
-	O
way	O
fine	O
-	O
grained	O
or	O
binary	O
classification	O
task	O
.	O

Stanford	O
Sentiment	O
Treebank	O
(	O
Socher	O
et	O
al	O
.	O
,	O
2013	O
)	O
contains	O
fine	O
-	O
grained	O
sentiment	O
labeled	O
parse	O
trees	O
of	O
sentences	O
from	O
movie	O
reviews	O
.	O

Following	O
AutoPrompt	O
,	O
we	O
report	O
results	O
for	O
the	O
following	O
two	O
task	O
:	O
SST	O
.	O

The	O
approach	O
makes	O
use	O
of	O
full	O
training	O
set	O
to	O
optimize	O
discrete	O
prompts	O
for	O
each	O
specific	O
target	O
task	O
.	O

For	O
this	O
experiment	O
,	O
we	O
compare	O
against	O
AutoPrompt	O
(	O
Shin	O
et	O
al	O
.	O
,	O
2020	O
)	O
.	O

The	O
goal	O
of	O
this	O
additional	O
experiment	O
is	O
twofold	O
:	O
first	O
,	O
to	O
show	O
the	O
applicability	O
of	O
SP	O
to	O
other	O
settings	O
,	O
including	O
tasks	O
with	O
single	O
input	O
sequence	O
;	O
and	O
second	O
,	O
to	O
evaluate	O
if	O
SP	O
is	O
effective	O
when	O
using	O
prompt	O
templates	O
from	O
other	O
techniques	O
,	O
including	O
those	O
optimized	O
for	O
specific	O
tasks	O
.	O

In	O
addition	O
to	O
WiC	O
,	O
we	O
also	O
carried	O
out	O
experiments	O
on	O
two	O
more	O
tasks	O
.	O

Tasks	O
.	O

GPT3	O
(	O
Brown	O
et	O
al	O
.	O
,	O
2020	O
)	O
is	O
different	O
in	O
that	O
it	O
employs	O
the	O
so	O
-	O
called	O
in	O
-	O
context	O
learning	O
which	O
involves	O
no	O
parameter	O
tuning	O
.	O

P	O
-	O
tuning	O
(	O
Liu	O
et	O
al	O
.	O
,	O
2021	O
)	O
uses	O
the	O
same	O
PLM	O
as	O
PET	O
,	O
but	O
optimizes	O
a	O
continuous	O
prompt	O
instead	O
of	O
tuning	O
PLM	O
parameters	O
.	O

PET	O
(	O
Schick	O
and	O
Schütze	O
,	O
2021b	O
)	O
prefers	O
ALBERT	O
-	O
xxlarge	O
-	O
v2	O
(	O
Lan	O
et	O
al	O
.	O
,	O
2019	O
)	O
over	O
RoBERTa	O
(	O
with	O
an	O
average	O
gain	O
of	O
8	O
points	O
on	O
a	O
subset	O
of	O
SuperGLUE	O
tasks	O
)	O
and	O
fine	O
-	O
tunes	O
it	O
with	O
manually	O
engineered	O
cloze	O
-	O
style	O
prompts	O
.	O

We	O
compare	O
our	O
results	O
on	O
WiC	O
with	O
three	O
other	O
methods	O
,	O
all	O
of	O
which	O
use	O
32	O
examples	O
for	O
their	O
training	O
.	O

Comparison	O
Systems	O
.	O

Experiments	O
.	O

The	O
latter	O
is	O
a	O
rank	O
-	O
based	O
comparison	O
measure	O
which	O
is	O
insensitive	O
to	O
the	O
absolute	O
values	O
of	O
individual	O
dimensions	O
(	O
rather	O
checks	O
for	O
their	O
relative	O
rankings	O
)	O
.	O

We	O
opted	O
for	O
two	O
similarity	O
metrics	O
:	O
cosine	O
similarity	O
and	O
Spearman	O
's	O
rank	O
correlation	O
.	O

Similarity	O
Measures	O
.	O

We	O
then	O
train	O
the	O
same	O
linear	O
model	O
as	O
before	O
on	O
the	O
similarity	O
scores	O
of	O
the	O
training	O
set	O
examples	O
to	O
find	O
the	O
best	O
discriminating	O
threshold	O
.	O

Finally	O
,	O
our	O
classification	O
step	O
reduces	O
to	O
that	O
of	O
directly	O
comparing	O
our	O
pair	O
of	O
embedding	O
vectors	O
using	O
a	O
similarity	O
function	O
,	O
to	O
produce	O
a	O
single	O
similarity	O
score	O
for	O
each	O
instance	O
.	O

Next	O
the	O
prompts	O
are	O
separately	O
fed	O
to	O
PLM	O
,	O
resulting	O
in	O
a	O
pair	O
of	O
mask	O
embeddings	O
as	O
PLM	O
's	O
response	O
.	O

In	O
the	O
first	O
step	O
of	O
SP	O
,	O
we	O
apply	O
this	O
template	O
function	O
to	O
both	O
input	O
sentences	O
which	O
generates	O
a	O
pair	O
of	O
prompts	O
.	O

Having	O
an	O
input	O
sentence	O
and	O
the	O
target	O
word	O
index	O
,	O
we	O
insert	O
"	O
or	O
--	O
"	O
after	O
the	O
target	O
word	O
,	O
where	O
"	O
--	O
"	O
indicates	O
the	O
MASK	O
token	O
.	O

Therefore	O
,	O
we	O
ask	O
PLM	O
about	O
the	O
triggered	O
meaning	O
of	O
the	O
target	O
word	O
,	O
separately	O
for	O
each	O
context	O
,	O
and	O
leave	O
the	O
comparison	O
to	O
similarity	O
measures	O
.	O

Previous	O
work	O
has	O
fallen	O
short	O
of	O
designing	O
a	O
single	O
prompt	O
template	O
which	O
make	O
the	O
PLM	O
answer	O
about	O
the	O
target	O
word	O
having	O
the	O
same	O
meaning	O
or	O
not	O
(	O
e.g.	O
,	O
with	O
"	O
yes	O
"	O
or	O
"	O
no	O
"	O
)	O
.	O

Given	O
an	O
ambiguous	O
target	O
word	O
in	O
two	O
different	O
contexts	O
,	O
the	O
task	O
in	O
WiC	O
is	O
defined	O
as	O
a	O
simple	O
binary	O
classification	O
problem	O
to	O
identify	O
if	O
the	O
triggered	O
meaning	O
of	O
the	O
target	O
word	O
differs	O
in	O
the	O
two	O
contexts	O
or	O
not	O
.	O

The	O
surprising	O
failure	O
of	O
existing	O
prompt	O
-	O
based	O
techniques	O
on	O
the	O
Word	O
-	O
in	O
-	O
Context	O
task	O
(	O
Pilehvar	O
and	O
Camacho	O
-	O
Collados	O
,	O
2019	O
,	O
WiC	O
)	O
,	O
motivated	O
us	O
to	O
focus	O
on	O
filling	O
this	O
gap	O
.	O

Similarity	O
Prompting	O
for	O
WiC.	O

This	O
linear	O
model	O
is	O
then	O
used	O
at	O
inference	O
time	O
to	O
evaluate	O
SP	O
on	O
test	O
set	O
.	O

To	O
alleviate	O
the	O
problem	O
,	O
we	O
perform	O
a	O
class	O
centroid	O
-	O
based	O
dimension	O
reduction	O
(	O
i.e.	O
by	O
taking	O
the	O
similarity	O
to	O
each	O
centroid	O
as	O
a	O
feature	O
)	O
,	O
and	O
train	O
a	O
simple	O
linear	O
classifier	O
.	O

However	O
,	O
this	O
assumes	O
the	O
variance	O
of	O
different	O
classes	O
to	O
be	O
equal	O
in	O
the	O
embedding	O
space	O
.	O

To	O
classify	O
a	O
new	O
sample	O
at	O
inference	O
time	O
,	O
a	O
simple	O
approach	O
would	O
be	O
to	O
employ	O
a	O
nearest	O
centroid	O
classifier	O
.	O

Here	O
,	O
we	O
first	O
obtain	O
class	O
-	O
specific	O
centroids	O
by	O
taking	O
the	O
average	O
of	O
the	O
MASK	O
embeddings	O
of	O
our	O
few	O
training	O
examples	O
.	O

The	O
third	O
step	O
is	O
where	O
SP	O
differs	O
from	O
existing	O
prompt	O
-	O
based	O
approaches	O
.	O

This	O
is	O
done	O
by	O
giving	O
the	O
generated	O
prompts	O
to	O
the	O
PLM	O
as	O
input	O
and	O
obtaining	O
its	O
contextualized	O
embedding	O
at	O
the	O
MASK	O
index	O
.	O

The	O
next	O
step	O
is	O
feature	O
extraction	O
from	O
a	O
PLM	O
.	O

this	O
movie	O
was	O
--	O
.	O
"	O
.	O

For	O
instance	O
,	O
in	O
sentiment	O
analysis	O
,	O
for	O
the	O
movie	O
review	O
"	O
Just	O
give	O
it	O
a	O
chance	O
.	O
"	O
,	O
a	O
valid	O
template	O
function	O
would	O
generate	O
as	O
output	O
prompt	O
:	O
"	O
Just	O
give	O
it	O
a	O
chance	O
.	O

Given	O
a	O
task	O
-	O
specific	O
input	O
consisting	O
of	O
one	O
or	O
more	O
text	O
sequences	O
,	O
we	O
first	O
use	O
a	O
template	O
function	O
to	O
generate	O
a	O
prompt	O
-	O
a	O
sequence	O
of	O
tokens	O
containing	O
one	O
[	O
MASK	O
]	O
token	O
-	O
per	O
input	O
sequence	O
.	O

As	O
shown	O
in	O
Figure	O
1	O
,	O
SP	O
consists	O
of	O
three	O
main	O
steps	O
:	O
(	O
1	O
)	O
prompt	O
generation	O
,	O
(	O
2	O
)	O
feature	O
extraction	O
,	O
and	O
(	O
3	O
)	O
prediction	O
.	O

In	O
what	O
follows	O
in	O
this	O
section	O
,	O
we	O
describe	O
our	O
similarity	O
-	O
based	O
prompting	O
approach	O
which	O
we	O
will	O
refer	O
to	O
as	O
SP	O
(	O
Similarity	O
Prompting	O
)	O
.	O

We	O
propose	O
a	O
similarity	O
-	O
based	O
method	O
that	O
not	O
only	O
better	O
exploits	O
the	O
response	O
,	O
but	O
also	O
allows	O
using	O
multiple	O
prompts	O
which	O
paves	O
the	O
way	O
for	O
comparisonbased	O
tasks	O
,	O
such	O
as	O
WiC.	O

Existing	O
methods	O
often	O
pick	O
a	O
set	O
of	O
one	O
or	O
few	O
word	O
predictions	O
as	O
a	O
representative	O
for	O
each	O
class	O
,	O
utilizing	O
the	O
language	O
model	O
's	O
response	O
in	O
a	O
sub	O
-	O
optimal	O
manner	O
.	O

For	O
instance	O
,	O
to	O
ask	O
about	O
the	O
sentiment	O
of	O
a	O
movie	O
review	O
,	O
one	O
can	O
augment	O
the	O
review	O
with	O
a	O
cloze	O
question	O
like	O
"	O
this	O
movie	O
was	O
--	O
.	O
"	O
.	O

The	O
common	O
approach	O
in	O
prompt	O
-	O
based	O
learning	O
is	O
to	O
reformulate	O
the	O
task	O
as	O
a	O
cloze	O
-	O
style	O
question	O
.	O

Assuming	O
that	O
PLMs	O
know	O
how	O
to	O
solve	O
some	O
tasks	O
(	O
to	O
some	O
extent	O
)	O
,	O
prompt	O
-	O
based	O
learning	O
focuses	O
on	O
the	O
former	O
,	O
i.e.	O
,	O
teaching	O
the	O
model	O
what	O
the	O
task	O
is	O
,	O
without	O
needing	O
to	O
resort	O
to	O
large	O
amounts	O
of	O
data	O
or	O
additional	O
parameters	O
.	O

Fine	O
-	O
tuning	O
on	O
a	O
specific	O
task	O
can	O
potentially	O
update	O
PLMs	O
on	O
what	O
the	O
task	O
is	O
and	O
how	O
to	O
solve	O
it	O
.	O

Methodology	O
.	O

Moreover	O
,	O
we	O
show	O
that	O
with	O
few	O
adjustments	O
,	O
this	O
simple	O
approach	O
can	O
be	O
effectively	O
used	O
for	O
other	O
downstream	O
tasks	O
.	O

The	O
experimental	O
results	O
on	O
the	O
WiC	O
dataset	O
shows	O
that	O
,	O
with	O
only	O
16	O
instances	O
per	O
class	O
,	O
our	O
proposed	O
prompt	O
-	O
based	O
technique	O
can	O
achieve	O
comparable	O
results	O
to	O
the	O
fine	O
-	O
tuned	O
models	O
(	O
with	O
access	O
to	O
full	O
training	O
data	O
of	O
2700	O
+	O
instances	O
per	O
class	O
)	O
.	O

Hence	O
,	O
instead	O
of	O
relying	O
on	O
a	O
single	O
response	O
,	O
we	O
make	O
use	O
of	O
the	O
similarity	O
of	O
PLM	O
's	O
response	O
to	O
the	O
combination	O
of	O
a	O
pair	O
of	O
prompts	O
.	O

Given	O
the	O
comparison	O
-	O
based	O
nature	O
of	O
WiC	O
,	O
we	O
hypothesize	O
that	O
conventional	O
prompting	O
methods	O
fall	O
short	O
since	O
they	O
only	O
utilize	O
a	O
single	O
prompt	O
response	O
.	O

In	O
this	O
work	O
we	O
investigate	O
the	O
latter	O
issue	O
by	O
introducing	O
a	O
new	O
configuration	O
for	O
prompting	O
.	O

However	O
,	O
none	O
of	O
these	O
have	O
shown	O
success	O
on	O
the	O
WiC	O
task	O
.	O

To	O
address	O
the	O
first	O
issue	O
,	O
there	O
have	O
been	O
proposals	O
to	O
automatically	O
find	O
a	O
suitable	O
prompt	O
template	O
using	O
a	O
search	O
in	O
the	O
discrete	O
token	O
space	O
(	O
Shin	O
et	O
al	O
.	O
,	O
2020	O
)	O
or	O
in	O
the	O
continuous	O
embedding	O
space	O
(	O
Liu	O
et	O
al	O
.	O
,	O
2021	O
)	O
.	O

Two	O
issues	O
could	O
be	O
responsible	O
for	O
the	O
latter	O
case	O
:	O
(	O
1	O
)	O
improper	O
prompt	O
,	O
or	O
(	O
2	O
)	O
inefficient	O
utilization	O
of	O
PLM	O
's	O
response	O
.	O

The	O
natural	O
question	O
that	O
arises	O
here	O
is	O
if	O
the	O
failure	O
of	O
few	O
-	O
shot	O
techniques	O
on	O
WiC	O
is	O
due	O
to	O
lack	O
of	O
relevant	O
encoded	O
knowledge	O
in	O
PLMs	O
or	O
the	O
inefficiency	O
of	O
the	O
employed	O
prompt	O
-	O
based	O
methods	O
.	O

The	O
same	O
pattern	O
of	O
failure	O
is	O
also	O
observed	O
in	O
the	O
more	O
recent	O
prompt	O
based	O
attempts	O
(	O
Liu	O
et	O
al	O
.	O
,	O
2021;Schick	O
and	O
Schütze	O
,	O
2021a	O
)	O
.	O

‡	O
While	O
a	O
simple	O
fine	O
-	O
tuned	O
BERT	O
-	O
base	O
model	O
achieves	O
around	O
69	O
%	O
accuracy	O
on	O
this	O
task	O
(	O
Wang	O
et	O
al	O
.	O
,	O
2019	O
)	O
,	O
GPT-3	O
,	O
with	O
more	O
than	O
100	O
times	O
the	O
number	O
of	O
parameters	O
,	O
performs	O
no	O
better	O
than	O
a	O
random	O
baseline	O
by	O
employing	O
a	O
promptbased	O
approach	O
(	O
Brown	O
et	O
al	O
.	O
,	O
2020	O
)	O
.	O

However	O
,	O
surprisingly	O
,	O
the	O
Word	O
-	O
in	O
-	O
Context	O
task	O
(	O
Pilehvar	O
and	O
Camacho	O
-	O
Collados	O
,	O
2019	O
)	O
-one	O
of	O
the	O
tasks	O
in	O
the	O
SuperGLUE	O
benchmark	O
(	O
Wang	O
et	O
al	O
.	O
,	O
2019)-is	O
one	O
exception	O
on	O
which	O
these	O
methods	O
fail	O
to	O
stay	O
on	O
par	O
with	O
their	O
fine	O
-	O
tuned	O
counterparts	O
.	O

Prompt	O
-	O
based	O
techniques	O
have	O
shown	O
impressive	O
performance	O
in	O
the	O
few	O
-	O
shot	O
setting	O
,	O
especially	O
when	O
compared	O
to	O
standard	O
fine	O
-	O
tuning	O
on	O
datasets	O
of	O
hundreds	O
of	O
data	O
points	O
(	O
Le	O
Scao	O
and	O
Rush	O
,	O
2021	O
)	O
.	O

From	O
the	O
practical	O
point	O
of	O
view	O
,	O
prompt	O
-	O
based	O
learning	O
is	O
particularly	O
well	O
-	O
suited	O
for	O
massive	O
models	O
,	O
such	O
as	O
GPT-3	O
,	O
since	O
it	O
does	O
not	O
involve	O
parameter	O
tuning	O
.	O

This	O
paradigm	O
has	O
proven	O
its	O
effectiveness	O
in	O
the	O
few	O
-	O
shot	O
setting	O
,	O
even	O
for	O
relatively	O
smaller	O
models	O
,	O
such	O
as	O
BERT	O
(	O
Devlin	O
et	O
al	O
.	O
,	O
2019	O
)	O
and	O
RoBERTA	O
(	O
Liu	O
et	O
al	O
.	O
,	O
2019	O
)	O
,	O
when	O
combined	O
with	O
ensembling	O
and	O
fine	O
-	O
tuning	O
(	O
Schick	O
and	O
Schütze	O
,	O
2021a	O
)	O
.	O

The	O
core	O
idea	O
is	O
to	O
extract	O
knowledge	O
by	O
asking	O
the	O
right	O
question	O
from	O
the	O
pre	O
-	O
trained	O
language	O
model	O
(	O
PLM	O
)	O
using	O
a	O
task	O
-	O
specific	O
prompting	O
template	O
which	O
directs	O
the	O
PLM	O
to	O
generate	O
a	O
textual	O
output	O
corresponding	O
to	O
a	O
target	O
class	O
.	O

The	O
current	O
dominant	O
few	O
-	O
shot	O
approach	O
is	O
the	O
so	O
-	O
called	O
promptbased	O
learning	O
which	O
involves	O
a	O
simple	O
reformulation	O
of	O
the	O
target	O
task	O
as	O
a	O
cloze	O
-	O
style	O
(	O
Taylor	O
,	O
1953	O
)	O
fill	O
-	O
in	O
-	O
the	O
-	O
blank	O
objective	O
.	O

Recently	O
,	O
there	O
has	O
been	O
a	O
resurgence	O
of	O
interest	O
in	O
few	O
-	O
shot	O
learning	O
,	O
especially	O
after	O
the	O
introduction	O
of	O
GPT-3	O
(	O
Brown	O
et	O
al	O
.	O
,	O
2020	O
)	O
.	O

Introduction	O
.	O

†	O
*	O
Work	O
done	O
as	O
a	O
Master	O
's	O
student	O
at	O
IUST	O
.	O

We	O
also	O
show	O
that	O
this	O
approach	O
can	O
be	O
effectively	O
extended	O
to	O
other	O
downstream	O
tasks	O
for	O
which	O
a	O
single	O
prompt	O
is	O
sufficient	O
.	O

Our	O
simple	O
adaptation	O
shows	O
that	O
the	O
failure	O
of	O
existing	O
prompt	O
-	O
based	O
techniques	O
in	O
semantic	O
distinction	O
is	O
due	O
to	O
their	O
improper	O
configuration	O
,	O
rather	O
than	O
lack	O
of	O
relevant	O
knowledge	O
in	O
the	O
representations	O
.	O

Trying	O
to	O
fill	O
this	O
gap	O
,	O
we	O
propose	O
a	O
new	O
prompting	O
technique	O
,	O
based	O
on	O
similarity	O
metrics	O
,	O
which	O
boosts	O
few	O
-	O
shot	O
performance	O
to	O
the	O
level	O
of	O
fully	O
supervised	O
methods	O
.	O

Specifically	O
,	O
none	O
of	O
the	O
existing	O
few	O
-	O
shot	O
approaches	O
(	O
including	O
the	O
incontext	O
learning	O
of	O
GPT-3	O
)	O
can	O
attain	O
a	O
performance	O
that	O
is	O
meaningfully	O
different	O
from	O
the	O
random	O
baseline	O
.	O

However	O
,	O
despite	O
proving	O
competitive	O
on	O
most	O
tasks	O
in	O
the	O
GLUE	O
and	O
SuperGLUE	O
benchmarks	O
,	O
existing	O
prompt	O
-	O
based	O
techniques	O
fail	O
on	O
the	O
semantic	O
distinction	O
task	O
of	O
the	O
Word	O
-	O
in	O
-	O
Context	O
(	O
WiC	O
)	O
dataset	O
.	O

As	O
a	O
recent	O
development	O
in	O
few	O
-	O
shot	O
learning	O
,	O
prompt	O
-	O
based	O
techniques	O
have	O
demonstrated	O
promising	O
potential	O
in	O
a	O
variety	O
of	O
natural	O
language	O
processing	O
tasks	O
.	O

Exploiting	O
Language	O
Model	O
Prompts	O
Using	O
Similarity	O
Measures	O
:	O
A	O
Case	O
Study	O
on	O
the	O
Word	O
-	O
in	O
-	O
Context	O
Task	O
.	O

