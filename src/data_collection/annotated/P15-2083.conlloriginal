-DOCSTART- -X- O
For -X- _ O
example -X- _ O
, -X- _ O
word -X- _ O
" -X- _ O
allocation -X- _ O
" -X- _ O
has -X- _ O
a -X- _ O
new -X- _ O
distance-2 -X- _ O
word -X- _ O
" -X- _ O
topics -X- _ O
" -X- _ O
after -X- _ O
merging -X- _ O
. -X- _ O

Experiments -X- _ O
on -X- _ O
two -X- _ O
datasets -X- _ O
show -X- _ O
EGTRF -X- _ B-MethodName
achieves -X- _ O
better -X- _ O
performance -X- _ O
than -X- _ O
GTRF -X- _ B-MethodName
and -X- _ O
LDA -X- _ B-MethodName
, -X- _ O
which -X- _ O
confirm -X- _ O
our -X- _ O
assumption -X- _ O
that -X- _ O
adding -X- _ O
topical -X- _ O
dependency -X- _ O
of -X- _ O
distance-2 -X- _ B-HyperparameterName
words -X- _ O
and -X- _ O
incorporating -X- _ O
word -X- _ O
similarity -X- _ O
information -X- _ O
can -X- _ O
improve -X- _ O
model -X- _ O
performance -X- _ O
. -X- _ O

Word -X- _ O
topics -X- _ O
are -X- _ O
drawed -X- _ O
by -X- _ O
Extended -X- _ B-MethodName
Global -X- _ I-MethodName
Random -X- _ I-MethodName
Field(EGRF -X- _ I-MethodName
) -X- _ O
instead -X- _ O
of -X- _ O
Multinomial -X- _ O
, -X- _ O
the -X- _ O
conditional -X- _ O
independence -X- _ O
of -X- _ O
word -X- _ O
topic -X- _ O
assignment -X- _ O
is -X- _ O
thus -X- _ O
relaxed -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
extended -X- _ O
Global -X- _ B-MethodName
Topic -X- _ I-MethodName
Random -X- _ I-MethodName
Field(GTRF -X- _ I-MethodName
) -X- _ O
and -X- _ O
proposed -X- _ O
a -X- _ O
novel -X- _ O
topic -X- _ O
model -X- _ O
Extended -X- _ B-MethodName
Global -X- _ I-MethodName
Topic -X- _ I-MethodName
Random -X- _ I-MethodName
Field(EGTRF -X- _ I-MethodName
) -X- _ O
which -X- _ O
can -X- _ O
model -X- _ O
dependency -X- _ O
relation -X- _ O
between -X- _ O
adjacent -X- _ O
words -X- _ O
and -X- _ O
distance-2 -X- _ B-HyperparameterName
words -X- _ O
. -X- _ O

And -X- _ O
we -X- _ O
define -X- _ O
the -X- _ O
topic -X- _ B-TaskName
model -X- _ I-TaskName
based -X- _ O
on -X- _ O
EGRF -X- _ B-MethodName
as -X- _ O
Extended -X- _ B-MethodName
Global -X- _ I-MethodName
Topic -X- _ I-MethodName
Random -X- _ I-MethodName
Field(EGTRF -X- _ I-MethodName
) -X- _ O
. -X- _ O

We -X- _ O
define -X- _ O
the -X- _ O
random -X- _ O
field -X- _ O
as -X- _ O
in -X- _ O
Equation -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
a -X- _ O
Extended -X- _ B-MethodName
Global -X- _ I-MethodName
Random -X- _ I-MethodName
Field -X- _ I-MethodName
( -X- _ O
EGRF -X- _ B-MethodName
) -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
section -X- _ O
, -X- _ O
we -X- _ O
first -X- _ O
present -X- _ O
Extended -X- _ B-MethodName
Global -X- _ I-MethodName
Random -X- _ I-MethodName
Field(EGRF -X- _ I-MethodName
) -X- _ O
in -X- _ O
section -X- _ O
2.1 -X- _ O
, -X- _ O
then -X- _ O
show -X- _ O
how -X- _ O
to -X- _ O
model -X- _ O
topical -X- _ O
dependencies -X- _ O
using -X- _ O
EGRF -X- _ B-MethodName
in -X- _ O
section -X- _ O
2.2 -X- _ O
. -X- _ O
We -X- _ O
incorporate -X- _ O
word -X- _ O
similarity -X- _ O
information -X- _ O
into -X- _ O
model -X- _ O
in -X- _ O
section -X- _ O
2.3 -X- _ O
. -X- _ O
1 -X- _ O
https://code.google.com/p/word2vec/. -X- _ O

In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
extend -X- _ O
GTRF -X- _ B-MethodName
model -X- _ O
and -X- _ O
present -X- _ O
a -X- _ O
novel -X- _ O
model -X- _ O
Extended -X- _ B-MethodName
Global -X- _ I-MethodName
Topic -X- _ I-MethodName
Random -X- _ I-MethodName
Field -X- _ I-MethodName
( -X- _ O
EGTRF -X- _ B-MethodName
) -X- _ O
to -X- _ O
exploit -X- _ O
topical -X- _ O
dependency -X- _ O
between -X- _ O
words -X- _ O
. -X- _ O

In -X- _ O
Global -X- _ B-MethodName
Topic -X- _ I-MethodName
Random -X- _ I-MethodName
Field(GTRF -X- _ I-MethodName
) -X- _ O
model -X- _ O
( -X- _ O
Li -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
, -X- _ O
sentences -X- _ O
of -X- _ O
a -X- _ O
document -X- _ O
are -X- _ O
parsed -X- _ O
into -X- _ O
dependency -X- _ O
trees -X- _ O
( -X- _ O
Marneffe -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2008 -X- _ O
) -X- _ O
( -X- _ O
Manning -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
( -X- _ O
Marneffe -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2006 -X- _ O
) -X- _ O
. -X- _ O

Probabilistic -X- _ O
topic -X- _ O
model -X- _ O
such -X- _ O
as -X- _ O
Latent -X- _ B-MethodName
Dirichlet -X- _ I-MethodName
Allocation(LDA -X- _ I-MethodName
) -X- _ O
( -X- _ O
Blei -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2003 -X- _ O
) -X- _ O
has -X- _ O
been -X- _ O
widely -X- _ O
used -X- _ O
for -X- _ O
discovering -X- _ B-TaskName
latent -X- _ I-TaskName
topics -X- _ I-TaskName
from -X- _ O
document -X- _ O
collections -X- _ O
by -X- _ O
capturing -X- _ O
words -X- _ O
' -X- _ O
cooccuring -X- _ O
relation -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
new -X- _ O
model -X- _ O
Extended -X- _ B-MethodName
Global -X- _ I-MethodName
Topic -X- _ I-MethodName
Random -X- _ I-MethodName
Field -X- _ I-MethodName
( -X- _ O
EGTRF -X- _ B-MethodName
) -X- _ O
to -X- _ O
model -X- _ O
non -X- _ O
- -X- _ O
linear -X- _ O
dependencies -X- _ O
between -X- _ O
words -X- _ O
. -X- _ O

Topic -X- _ O
Model -X- _ O
such -X- _ O
as -X- _ O
Latent -X- _ B-MethodName
Dirichlet -X- _ I-MethodName
Allocation(LDA -X- _ I-MethodName
) -X- _ O
makes -X- _ O
assumption -X- _ O
that -X- _ O
topic -X- _ O
assignment -X- _ O
of -X- _ O
different -X- _ O
words -X- _ O
are -X- _ O
conditionally -X- _ O
independent -X- _ O
. -X- _ O

As -X- _ O
we -X- _ O
discussed -X- _ O
in -X- _ O
section -X- _ O
1 -X- _ O
, -X- _ O
word -X- _ O
similarity -X- _ O
information -X- _ O
S -X- _ O
w -X- _ O
1 -X- _ O
, -X- _ O
w -X- _ O
2 -X- _ O
works -X- _ O
as -X- _ O
a -X- _ O
confidence -X- _ O
score -X- _ O
to -X- _ O
model -X- _ O
how -X- _ O
likely -X- _ O
two -X- _ O
words -X- _ O
on -X- _ O
an -X- _ O
edge -X- _ O
have -X- _ O
same -X- _ O
topic -X- _ O
. -X- _ O

S -X- _ O
w -X- _ O
1 -X- _ O
, -X- _ O
w -X- _ O
2 -X- _ O
is -X- _ O
the -X- _ O
similarity -X- _ O
measure -X- _ O
between -X- _ O
word -X- _ O
w -X- _ O
1 -X- _ O
and -X- _ O
w -X- _ O
2 -X- _ O
. -X- _ O

And -X- _ O
we -X- _ O
make -X- _ O
assumption -X- _ O
that -X- _ O
two -X- _ O
words -X- _ O
are -X- _ O
more -X- _ O
likely -X- _ O
to -X- _ O
have -X- _ O
same -X- _ O
topic -X- _ O
if -X- _ O
they -X- _ O
have -X- _ O
a -X- _ O
higher -X- _ O
similarity -X- _ O
score -X- _ O
. -X- _ O

To -X- _ O
get -X- _ O
the -X- _ O
similarity -X- _ O
score -X- _ O
between -X- _ O
words -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
word2vec -X- _ O
tool -X- _ O
to -X- _ O
learn -X- _ O
the -X- _ O
word -X- _ O
representation -X- _ O
of -X- _ O
each -X- _ O
word -X- _ O
from -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
model -X- _ O
. -X- _ O

Normalized -X- _ O
similarity -X- _ O
between -X- _ O
word -X- _ O
vectors -X- _ O
can -X- _ O
be -X- _ O
regarded -X- _ O
as -X- _ O
the -X- _ O
confidence -X- _ O
score -X- _ O
of -X- _ O
how -X- _ O
possible -X- _ O
two -X- _ O
words -X- _ O
have -X- _ O
same -X- _ O
topic -X- _ O
. -X- _ O

E -X- _ O
2 -X- _ O
is -X- _ O
distance-2 -X- _ O
edge -X- _ O
set -X- _ O
, -X- _ O
E -X- _ O
2 -X- _ O
= -X- _ O
{ -X- _ O
( -X- _ O
w -X- _ O
i -X- _ O
, -X- _ O
w -X- _ O
j -X- _ O
) -X- _ O
|∃path -X- _ O
between -X- _ O
w -X- _ O
i -X- _ O
, -X- _ O
w -X- _ O
j -X- _ O
that -X- _ O
length -X- _ O
is -X- _ O
2 -X- _ O
} -X- _ O
. -X- _ O

E -X- _ O
1 -X- _ O
is -X- _ O
distance-1 -X- _ O
edge -X- _ O
set -X- _ O
, -X- _ O
E -X- _ O
1 -X- _ O
= -X- _ O
{ -X- _ O
( -X- _ O
w -X- _ O
i -X- _ O
, -X- _ O
w -X- _ O
j -X- _ O
) -X- _ O
|∃path -X- _ O
between -X- _ O
w -X- _ O
i -X- _ O
, -X- _ O
w -X- _ O
j -X- _ O
that -X- _ O
length -X- _ O
is -X- _ O
1 -X- _ O
} -X- _ O
. -X- _ O

After -X- _ O
representing -X- _ O
document -X- _ O
to -X- _ O
undirected -X- _ O
graph -X- _ O
on -X- _ O
previous -X- _ O
section -X- _ O
, -X- _ O
we -X- _ O
extend -X- _ O
Global -X- _ B-MethodName
Random -X- _ I-MethodName
Field -X- _ I-MethodName
and -X- _ O
give -X- _ O
the -X- _ O
definition -X- _ O
of -X- _ O
Extended -X- _ B-MethodName
Global -X- _ I-MethodName
Random -X- _ I-MethodName
Field -X- _ I-MethodName
to -X- _ O
model -X- _ O
the -X- _ O
graph -X- _ O
as -X- _ O
below -X- _ O
: -X- _ O
Given -X- _ O
an -X- _ O
undirected -X- _ O
graph -X- _ O
G -X- _ O
, -X- _ O
word -X- _ O
vertex -X- _ O
set -X- _ O
is -X- _ O
denoted -X- _ O
as -X- _ O
W -X- _ O
= -X- _ O
{ -X- _ O
w -X- _ O
i -X- _ O
|i -X- _ O
= -X- _ O
1 -X- _ O
, -X- _ O
2 -X- _ O
, -X- _ O
.. -X- _ O
n -X- _ O
} -X- _ O
, -X- _ O
where -X- _ O
w -X- _ O
i -X- _ O
is -X- _ O
a -X- _ O
word -X- _ O
vertex -X- _ O
, -X- _ O
and -X- _ O
n -X- _ O
is -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
unique -X- _ O
words -X- _ O
in -X- _ O
a -X- _ O
document -X- _ O
. -X- _ O

Extended -X- _ B-MethodName
Global -X- _ I-MethodName
Topic -X- _ I-MethodName
Random -X- _ I-MethodName
Field -X- _ I-MethodName
. -X- _ O

We -X- _ O
use -X- _ O
the -X- _ O
pretrained -X- _ O
model -X- _ O
from -X- _ O
Google -X- _ B-DatasetName
News -X- _ I-DatasetName
dataset(about -X- _ O
100 -X- _ O
billion -X- _ O
words -X- _ O
) -X- _ O
using -X- _ O
word2vec -X- _ O
1 -X- _ O
tool -X- _ O
to -X- _ O
represent -X- _ O
each -X- _ O
word -X- _ O
as -X- _ O
a -X- _ O
300 -X- _ O
- -X- _ O
dimensional -X- _ O
word -X- _ O
vector -X- _ O
, -X- _ O
and -X- _ O
apply -X- _ O
normalized -X- _ O
word -X- _ O
similarity -X- _ O
as -X- _ O
a -X- _ O
confidence -X- _ O
score -X- _ O
to -X- _ O
indicate -X- _ O
how -X- _ O
possible -X- _ O
two -X- _ O
word -X- _ O
vertices -X- _ O
share -X- _ O
same -X- _ O
topic -X- _ O
. -X- _ O

Theoretically -X- _ O
, -X- _ O
we -X- _ O
can -X- _ O
also -X- _ O
model -X- _ O
the -X- _ O
distance -X- _ O
further -X- _ O
than -X- _ O
2 -X- _ O
, -X- _ O
however -X- _ O
, -X- _ O
it -X- _ O
leads -X- _ O
to -X- _ O
more -X- _ O
complicated -X- _ O
computation -X- _ O
and -X- _ O
small -X- _ O
increase -X- _ O
of -X- _ O
performance -X- _ O
. -X- _ O

In -X- _ O
EGTRF -X- _ B-MethodName
, -X- _ O
the -X- _ O
topic -X- _ O
assignment -X- _ O
of -X- _ O
a -X- _ O
word -X- _ O
is -X- _ O
assumed -X- _ O
to -X- _ O
depend -X- _ O
on -X- _ O
both -X- _ O
distance-1 -X- _ O
and -X- _ O
distance-2 -X- _ O
word -X- _ O
vertices -X- _ O
. -X- _ O

However -X- _ O
, -X- _ O
GTRF -X- _ B-MethodName
assumes -X- _ O
topic -X- _ O
assignment -X- _ O
of -X- _ O
a -X- _ O
word -X- _ O
vertex -X- _ O
depends -X- _ O
on -X- _ O
the -X- _ O
topic -X- _ O
mixture -X- _ O
of -X- _ O
the -X- _ O
document -X- _ O
and -X- _ O
its -X- _ O
neighboring -X- _ O
word -X- _ O
vertices -X- _ O
, -X- _ O
ignoring -X- _ O
the -X- _ O
fact -X- _ O
that -X- _ O
word -X- _ O
vertex -X- _ O
can -X- _ O
also -X- _ O
be -X- _ O
influenced -X- _ O
by -X- _ O
the -X- _ O
distance-2 -X- _ O
or -X- _ O
further -X- _ O
word -X- _ O
vertices -X- _ O
. -X- _ O

Specifically -X- _ O
, -X- _ O
we -X- _ O
parse -X- _ O
sentences -X- _ O
into -X- _ O
dependency -X- _ O
trees -X- _ O
and -X- _ O
represent -X- _ O
them -X- _ O
as -X- _ O
a -X- _ O
graph -X- _ O
, -X- _ O
and -X- _ O
assume -X- _ O
the -X- _ O
topic -X- _ B-TaskName
assignment -X- _ I-TaskName
of -X- _ O
a -X- _ O
word -X- _ O
is -X- _ O
influenced -X- _ O
by -X- _ O
its -X- _ O
adjacent -X- _ O
words -X- _ O
and -X- _ O
distance-2 -X- _ O
words -X- _ O
. -X- _ O

Extended -X- _ B-MethodName
Topic -X- _ I-MethodName
Model -X- _ I-MethodName
for -X- _ O
Word -X- _ O
Dependency -X- _ O
. -X- _ O

We -X- _ O
believe -X- _ O
modeling -X- _ O
distance-2 -X- _ B-HyperparameterName
word -X- _ O
vertices -X- _ O
can -X- _ O
exploit -X- _ O
more -X- _ O
semantically -X- _ O
or -X- _ O
syntactically -X- _ O
word -X- _ O
dependencies -X- _ O
from -X- _ O
document -X- _ O
, -X- _ O
and -X- _ O
word -X- _ O
similarity -X- _ O
information -X- _ O
obtained -X- _ O
from -X- _ O
large -X- _ O
corpus -X- _ O
can -X- _ O
make -X- _ O
up -X- _ O
the -X- _ O
lack -X- _ O
of -X- _ O
sufficient -X- _ O
information -X- _ O
from -X- _ O
the -X- _ O
original -X- _ O
corpus -X- _ O
. -X- _ O

Therefore -X- _ O
, -X- _ O
adding -X- _ O
the -X- _ O
influence -X- _ O
of -X- _ O
distance-2 -X- _ B-HyperparameterName
word -X- _ O
vertices -X- _ O
and -X- _ O
word -X- _ O
similarity -X- _ O
information -X- _ O
can -X- _ O
improve -X- _ O
performance -X- _ O
of -X- _ O
topic -X- _ B-TaskName
modeling -X- _ I-TaskName
. -X- _ O

Figure -X- _ O
2 -X- _ O
shows -X- _ O
the -X- _ O
experimental -X- _ O
results -X- _ O
of -X- _ O
four -X- _ O
models -X- _ O
: -X- _ O
lda -X- _ B-MethodName
, -X- _ O
gtrf -X- _ B-MethodName
, -X- _ O
egtrf(EGTRF -X- _ B-MethodName
without -X- _ B-MethodName
word -X- _ I-MethodName
similarity -X- _ I-MethodName
information -X- _ I-MethodName
) -X- _ O
, -X- _ O
and -X- _ O
egtrf+s(EGTRF -X- _ B-MethodName
with -X- _ B-MethodName
word -X- _ I-MethodName
similarity -X- _ I-MethodName
information -X- _ I-MethodName
) -X- _ O
on -X- _ O
two -X- _ O
datasets -X- _ O
. -X- _ O

The -X- _ O
results -X- _ O
show -X- _ O
EGTRF -X- _ B-MethodName
outperforms -X- _ O
LDA -X- _ B-MethodName
and -X- _ O
GTRF -X- _ B-MethodName
in -X- _ O
general -X- _ O
, -X- _ O
and -X- _ O
EGTRF -X- _ B-MethodName
with -X- _ I-MethodName
word -X- _ I-MethodName
similarity -X- _ I-MethodName
information -X- _ I-MethodName
achieves -X- _ O
best -X- _ O
performance -X- _ O
. -X- _ O

We -X- _ O
choose -X- _ O
10 -X- _ B-HyperparameterValue
, -X- _ O
20 -X- _ B-HyperparameterValue
, -X- _ O
30 -X- _ B-HyperparameterValue
, -X- _ O
50 -X- _ B-HyperparameterValue
topics -X- _ B-HyperparameterName
for -X- _ O
20 -X- _ B-HyperparameterValue
news -X- _ B-DatasetName
dataset -X- _ I-DatasetName
, -X- _ O
10 -X- _ B-HyperparameterValue
, -X- _ O
15 -X- _ B-HyperparameterValue
, -X- _ O
20 -X- _ B-HyperparameterValue
, -X- _ O
25 -X- _ B-HyperparameterValue
topics -X- _ O
for -X- _ O
NIPS -X- _ B-DatasetName
dataset -X- _ O
. -X- _ O

Word -X- _ O
is -X- _ O
represented -X- _ O
as -X- _ O
vector -X- _ O
from -X- _ O
pretrained -X- _ O
Google -X- _ B-DatasetName
News -X- _ I-DatasetName
dataset -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
word -X- _ O
vector -X- _ O
learned -X- _ O
from -X- _ O
original -X- _ O
corpus -X- _ O
when -X- _ O
the -X- _ O
word -X- _ O
does -X- _ O
not -X- _ O
exist -X- _ O
in -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
Google -X- _ B-DatasetName
News -X- _ I-DatasetName
dataset -X- _ O
. -X- _ O

We -X- _ O
set -X- _ O
λ -X- _ B-HyperparameterName
4 -X- _ I-HyperparameterName
= -X- _ O
1.2 -X- _ B-HyperparameterValue
to -X- _ O
give -X- _ O
lower(even -X- _ O
negative -X- _ O
) -X- _ O
reward -X- _ O
to -X- _ O
edges -X- _ O
from -X- _ O
E -X- _ O
2 -X- _ O
that -X- _ O
the -X- _ O
two -X- _ O
word -X- _ O
vertices -X- _ O
have -X- _ O
same -X- _ O
topic -X- _ O
in -X- _ O
EGTRF -X- _ B-MethodName
, -X- _ O
since -X- _ O
the -X- _ O
distance-1 -X- _ B-HyperparameterName
words -X- _ O
are -X- _ O
expected -X- _ O
to -X- _ O
have -X- _ O
greater -X- _ O
topical -X- _ O
affects -X- _ O
than -X- _ O
distance-2 -X- _ B-HyperparameterName
words -X- _ O
. -X- _ O

We -X- _ O
implement -X- _ O
GTRF -X- _ B-MethodName
without -X- _ O
adding -X- _ O
self -X- _ O
defined -X- _ O
edges -X- _ O
from -X- _ O
the -X- _ O
original -X- _ O
paper -X- _ O
, -X- _ O
and -X- _ O
set -X- _ O
λ -X- _ B-HyperparameterName
2 -X- _ I-HyperparameterName
= -X- _ O
0.2 -X- _ B-HyperparameterValue
to -X- _ O
give -X- _ O
higher -X- _ O
reward -X- _ O
to -X- _ O
edges -X- _ O
from -X- _ O
E -X- _ O
1 -X- _ O
that -X- _ O
the -X- _ O
two -X- _ O
word -X- _ O
vertices -X- _ O
have -X- _ O
same -X- _ O
topic -X- _ O
. -X- _ O

Lower -X- _ O
perplexity -X- _ B-MetricName
, -X- _ O
higher -X- _ O
log -X- _ B-MetricName
predictive -X- _ I-MetricName
probability -X- _ I-MetricName
indicate -X- _ O
better -X- _ O
generalization -X- _ O
performance -X- _ O
. -X- _ O

We -X- _ O
evaluate -X- _ O
how -X- _ O
well -X- _ O
a -X- _ O
model -X- _ O
fits -X- _ O
the -X- _ O
data -X- _ O
with -X- _ O
held -X- _ B-MetricName
- -X- _ I-MetricName
out -X- _ I-MetricName
perplexity -X- _ I-MetricName
( -X- _ O
Blei -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2003 -X- _ O
) -X- _ O
and -X- _ O
predictive -X- _ B-MetricName
distribution -X- _ I-MetricName
( -X- _ O
Hoffman -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2013 -X- _ O
) -X- _ O
. -X- _ O

• -X- _ O
NIPS -X- _ B-DatasetName
data -X- _ I-DatasetName
( -X- _ O
Globerson -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2004 -X- _ O
): -X- _ O
Spanning -X- _ O
from -X- _ O
2000 -X- _ O
to -X- _ O
2005 -X- _ O
. -X- _ O

• -X- _ O
20 -X- _ B-DatasetName
News -X- _ I-DatasetName
Groups -X- _ I-DatasetName
: -X- _ O
After -X- _ O
processing -X- _ O
, -X- _ O
it -X- _ O
contains -X- _ O
13706 -X- _ O
documents -X- _ O
with -X- _ O
a -X- _ O
vocabulary -X- _ O
of -X- _ O
5164 -X- _ O
terms -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
section -X- _ O
we -X- _ O
study -X- _ O
the -X- _ O
empirical -X- _ O
performance -X- _ O
of -X- _ O
EGTRF -X- _ B-MethodName
on -X- _ O
two -X- _ O
datasets -X- _ O
. -X- _ O

The -X- _ O
updating -X- _ O
rule -X- _ O
of -X- _ O
α -X- _ O
and -X- _ O
β -X- _ O
are -X- _ O
same -X- _ O
to -X- _ O
LDA -X- _ B-MethodName
, -X- _ O
γ -X- _ O
is -X- _ O
updated -X- _ O
using -X- _ O
Newton -X- _ O
method -X- _ O
since -X- _ O
we -X- _ O
can -X- _ O
not -X- _ O
obtain -X- _ O
the -X- _ O
direct -X- _ O
updating -X- _ O
rule -X- _ O
for -X- _ O
γ -X- _ O
. -X- _ O

All -X- _ O
terms -X- _ O
except -X- _ O
P -X- _ O
( -X- _ O
z|θ -X- _ O
) -X- _ O
in -X- _ O
likelihood -X- _ O
function -X- _ O
are -X- _ O
also -X- _ O
same -X- _ O
to -X- _ O
LDA -X- _ B-MethodName
, -X- _ O
Based -X- _ O
on -X- _ O
Equation -X- _ O
( -X- _ O
9 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
obtain -X- _ O
: -X- _ O
Eq[log -X- _ O
P -X- _ O
egrf -X- _ O
( -X- _ O
z -X- _ O
| -X- _ O
θ -X- _ O
) -X- _ O
] -X- _ O
≈Eq[log -X- _ O
( -X- _ O
n -X- _ O
M -X- _ O
ulti(zw -X- _ O
n -X- _ O
| -X- _ O
θ))]+ -X- _ O
1 -X- _ O
− -X- _ O
λ2 -X- _ O
ζ1 -X- _ O
Eq(| -X- _ O
E -X- _ O
C -X- _ O
1 -X- _ O
| -X- _ O
) -X- _ O
+ -X- _ O
1 -X- _ O
− -X- _ O
λ4 -X- _ O
ζ1 -X- _ O
Eq(| -X- _ O
E -X- _ O
C -X- _ O
2 -X- _ O
|)+ -X- _ O
( -X- _ O
| -X- _ O
E1 -X- _ O
| -X- _ O
λ2 -X- _ O
+ -X- _ O
| -X- _ O
E2 -X- _ O
| -X- _ O
λ4 -X- _ O
ζ1 -X- _ O
− -X- _ O
| -X- _ O
E1 -X- _ O
| -X- _ O
+ -X- _ O
| -X- _ O
E2 -X- _ O
| -X- _ O
ζ2 -X- _ O
) -X- _ O
Eq(θ -X- _ O
T -X- _ O
θ)+ -X- _ O
log -X- _ O
ζ1 -X- _ O
− -X- _ O
log -X- _ O
ζ2(11 -X- _ O
) -X- _ O
We -X- _ O
get -X- _ O
the -X- _ O
approximation -X- _ O
in -X- _ O
Equation -X- _ O
( -X- _ O
11 -X- _ O
) -X- _ O
from -X- _ O
Taylor -X- _ O
series -X- _ O
, -X- _ O
where -X- _ O
ζ -X- _ O
1 -X- _ O
and -X- _ O
ζ -X- _ O
2 -X- _ O
are -X- _ O
Taylor -X- _ O
approximation -X- _ O
. -X- _ O

The -X- _ O
variational -X- _ O
function -X- _ O
q -X- _ O
is -X- _ O
same -X- _ O
to -X- _ O
the -X- _ O
original -X- _ O
LDA -X- _ B-MethodName
paper -X- _ O
( -X- _ O
Blei -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2003 -X- _ O
) -X- _ O
. -X- _ O

The -X- _ O
expectation -X- _ O
of -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
edges -X- _ O
in -X- _ O
E -X- _ O
c -X- _ O
i -X- _ O
can -X- _ O
be -X- _ O
computed -X- _ O
as -X- _ O
: -X- _ O
E(| -X- _ O
E -X- _ O
C -X- _ O
i -X- _ O
| -X- _ O
) -X- _ O
= -X- _ O
( -X- _ O
w -X- _ O
1 -X- _ O
, -X- _ O
w -X- _ O
2 -X- _ O
) -X- _ O
∈E -X- _ O
i -X- _ O
φ -X- _ O
T -X- _ O
w -X- _ O
1 -X- _ O
φw -X- _ O
2 -X- _ O
Sw -X- _ O
1 -X- _ O
, -X- _ O
w -X- _ O
2 -X- _ O
( -X- _ O
10 -X- _ O
) -X- _ O
φ -X- _ O
is -X- _ O
the -X- _ O
K -X- _ O
dimensional -X- _ O
variational -X- _ O
multinomial -X- _ O
parameters -X- _ O
and -X- _ O
can -X- _ O
be -X- _ O
thought -X- _ O
as -X- _ O
the -X- _ O
posterior -X- _ O
probability -X- _ O
of -X- _ O
a -X- _ O
word -X- _ O
given -X- _ O
the -X- _ O
topic -X- _ B-TaskName
assignment -X- _ I-TaskName
. -X- _ O

If -X- _ O
|E -X- _ O
2 -X- _ O
| -X- _ O
= -X- _ O
0 -X- _ O
, -X- _ O
|E -X- _ O
1 -X- _ O
| -X- _ O
= -X- _ O
0 -X- _ O
, -X- _ O
EGTRF -X- _ B-MethodName
is -X- _ O
equivalent -X- _ O
to -X- _ O
GTRF -X- _ B-MethodName
. -X- _ O

If -X- _ O
( -X- _ O
7 -X- _ O
) -X- _ O
and -X- _ O
( -X- _ O
8) -X- _ O
hold -X- _ O
true -X- _ O
, -X- _ O
Equation -X- _ O
( -X- _ O
3 -X- _ O
) -X- _ O
is -X- _ O
an -X- _ O
EGRF -X- _ B-MethodName
. -X- _ O

In -X- _ O
order -X- _ O
to -X- _ O
model -X- _ O
Equation -X- _ O
( -X- _ O
3 -X- _ O
) -X- _ O
as -X- _ O
an -X- _ O
EGRF -X- _ B-MethodName
, -X- _ O
it -X- _ O
must -X- _ O
satisfy -X- _ O
all -X- _ O
the -X- _ O
four -X- _ O
constraints -X- _ O
in -X- _ O
Equation -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
. -X- _ O

According -X- _ O
to -X- _ O
EGRF -X- _ B-MethodName
described -X- _ O
in -X- _ O
section -X- _ O
2.1 -X- _ O
, -X- _ O
we -X- _ O
define -X- _ O
the -X- _ O
probability -X- _ O
of -X- _ O
topic -X- _ O
sequence -X- _ O
z -X- _ O
as -X- _ O
below -X- _ O
: -X- _ O
P -X- _ O
egrf -X- _ O
( -X- _ O
z -X- _ O
| -X- _ O
θ -X- _ O
) -X- _ O
= -X- _ O
1 -X- _ O
| -X- _ O
E1 -X- _ O
| -X- _ O
+ -X- _ O
| -X- _ O
E2 -X- _ O
| -X- _ O
w∈V -X- _ O
f -X- _ O
( -X- _ O
zw)× -X- _ O
( -X- _ O
( -X- _ O
w -X- _ O
1 -X- _ O
, -X- _ O
w -X- _ O
1 -X- _ O
) -X- _ O
∈E -X- _ O
1 -X- _ O
f -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
( -X- _ O
z -X- _ O
w -X- _ O
1 -X- _ O
, -X- _ O
z -X- _ O
w -X- _ O
1 -X- _ O
) -X- _ O
+ -X- _ O
( -X- _ O
w -X- _ O
2 -X- _ O
, -X- _ O
w -X- _ O
2 -X- _ O
) -X- _ O
∈E -X- _ O
2 -X- _ O
f -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
( -X- _ O
z -X- _ O
w -X- _ O
2 -X- _ O
, -X- _ O
z -X- _ O
w -X- _ O
2 -X- _ O
) -X- _ O
) -X- _ O
( -X- _ O
3 -X- _ O
) -X- _ O
where -X- _ O
f -X- _ O
( -X- _ O
zw -X- _ O
) -X- _ O
= -X- _ O
M -X- _ O
ulti(zw|θ -X- _ O
) -X- _ O
( -X- _ O
4 -X- _ O
) -X- _ O
f -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
( -X- _ O
z -X- _ O
w -X- _ O
1 -X- _ O
, -X- _ O
z -X- _ O
w -X- _ O
1 -X- _ O
) -X- _ O
= -X- _ O
σz -X- _ O
w -X- _ O
1 -X- _ O
= -X- _ O
z -X- _ O
w -X- _ O
1 -X- _ O
λ1 -X- _ O
+ -X- _ O
σ -X- _ O
z -X- _ O
w -X- _ O
1 -X- _ O
= -X- _ O
z -X- _ O
w -X- _ O
1 -X- _ O
λ2 -X- _ O
( -X- _ O
5 -X- _ O
) -X- _ O
f -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
( -X- _ O
z -X- _ O
w -X- _ O
2 -X- _ O
, -X- _ O
z -X- _ O
w -X- _ O
2 -X- _ O
) -X- _ O
= -X- _ O
σz -X- _ O
w -X- _ O
2 -X- _ O
= -X- _ O
z -X- _ O
w -X- _ O
2 -X- _ O
λ3 -X- _ O
+ -X- _ O
σ -X- _ O
z -X- _ O
w -X- _ O
2 -X- _ O
= -X- _ O
z -X- _ O
w -X- _ O
2 -X- _ O
λ4 -X- _ O
( -X- _ O
6 -X- _ O
) -X- _ O
σ -X- _ O
is -X- _ O
an -X- _ O
indicator -X- _ O
function -X- _ O
and -X- _ O
equals -X- _ O
1 -X- _ O
if -X- _ O
the -X- _ O
topic -X- _ O
assignments -X- _ O
of -X- _ O
two -X- _ O
words -X- _ O
on -X- _ O
an -X- _ O
edge -X- _ O
are -X- _ O
same -X- _ O
. -X- _ O

So -X- _ O
the -X- _ O
word -X- _ B-TaskName
topic -X- _ I-TaskName
assignment -X- _ I-TaskName
is -X- _ O
no -X- _ O
longer -X- _ O
conditionally -X- _ O
independent -X- _ O
. -X- _ O

We -X- _ O
define -X- _ O
Extended -X- _ B-MethodName
Global -X- _ I-MethodName
Topic -X- _ I-MethodName
Random -X- _ I-MethodName
Field -X- _ I-MethodName
based -X- _ O
on -X- _ O
EGRF -X- _ B-MethodName
. -X- _ O

Topic -X- _ B-TaskName
Model -X- _ I-TaskName
Using -X- _ O
EGRF -X- _ B-MethodName
. -X- _ O

And -X- _ O
EGRF -X- _ B-MethodName
does -X- _ O
not -X- _ O
have -X- _ O
normalization -X- _ B-HyperparameterName
factor -X- _ I-HyperparameterName
, -X- _ O
which -X- _ O
is -X- _ O
much -X- _ O
simplier -X- _ O
than -X- _ O
models -X- _ O
with -X- _ O
intractable -X- _ O
normalizing -X- _ B-HyperparameterName
factor -X- _ I-HyperparameterName
. -X- _ O

The -X- _ O
state(topic -X- _ B-TaskName
assignment -X- _ I-TaskName
) -X- _ O
of -X- _ O
a -X- _ O
word -X- _ O
vertex -X- _ O
w -X- _ O
is -X- _ O
generated -X- _ O
from -X- _ O
Z -X- _ O
= -X- _ O
{ -X- _ O
z -X- _ O
i -X- _ O
|i -X- _ O
= -X- _ O
1 -X- _ O
, -X- _ O
2 -X- _ O
, -X- _ O
... -X- _ O
, -X- _ O
k -X- _ O
} -X- _ O
, -X- _ O
k -X- _ O
is -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
topics -X- _ O
. -X- _ O

Another -X- _ O
advantage -X- _ O
of -X- _ O
EGTRF -X- _ B-MethodName
is -X- _ O
it -X- _ O
incorporates -X- _ O
word -X- _ O
features -X- _ O
. -X- _ O

Word -X- _ O
similarity -X- _ O
information -X- _ O
learned -X- _ O
from -X- _ O
large -X- _ O
corpus -X- _ O
is -X- _ O
incorporated -X- _ O
into -X- _ O
the -X- _ O
model -X- _ O
. -X- _ O

Conclusion -X- _ O
. -X- _ O

After -X- _ O
processing -X- _ O
, -X- _ O
it -X- _ O
contains -X- _ O
843 -X- _ O
documents -X- _ O
with -X- _ O
a -X- _ O
vocabulary -X- _ O
of -X- _ O
6098 -X- _ O
terms -X- _ O
. -X- _ O

Eighty -X- _ O
percent -X- _ O
data -X- _ O
are -X- _ O
used -X- _ O
for -X- _ O
training -X- _ O
, -X- _ O
others -X- _ O
for -X- _ O
testing -X- _ O
. -X- _ O

For -X- _ O
each -X- _ O
dataset -X- _ O
, -X- _ O
we -X- _ O
remove -X- _ O
very -X- _ O
short -X- _ O
documents -X- _ O
, -X- _ O
and -X- _ O
compute -X- _ O
a -X- _ O
vocabulary -X- _ O
by -X- _ O
removing -X- _ O
stop -X- _ O
words -X- _ O
, -X- _ O
rare -X- _ O
words -X- _ O
, -X- _ O
frequent -X- _ O
words -X- _ O
. -X- _ O

Experiment -X- _ O
. -X- _ O

We -X- _ O
run -X- _ O
such -X- _ O
iterations -X- _ O
until -X- _ O
convergence -X- _ O
. -X- _ O

At -X- _ O
M -X- _ O
- -X- _ O
step -X- _ O
, -X- _ O
we -X- _ O
update -X- _ O
new -X- _ O
α -X- _ O
and -X- _ O
β -X- _ O
based -X- _ O
on -X- _ O
obtained -X- _ O
γ -X- _ O
and -X- _ O
φ -X- _ O
. -X- _ O

At -X- _ O
E -X- _ O
- -X- _ O
step -X- _ O
, -X- _ O
we -X- _ O
estimate -X- _ O
the -X- _ O
best -X- _ O
γ -X- _ O
and -X- _ O
φ -X- _ O
given -X- _ O
current -X- _ O
α -X- _ O
and -X- _ O
β -X- _ O
. -X- _ O

φ -X- _ O
can -X- _ O
be -X- _ O
approximated -X- _ O
as -X- _ O
: -X- _ O
φw -X- _ O
n -X- _ O
, -X- _ O
i -X- _ O
∝ -X- _ O
βi -X- _ O
, -X- _ O
vexp(Ψ(γi)+ -X- _ O
1 -X- _ O
− -X- _ O
λ2 -X- _ O
ζ1 -X- _ O
× -X- _ O
( -X- _ O
wn -X- _ O
, -X- _ O
wm)∈E -X- _ O
1 -X- _ O
φw -X- _ O
m -X- _ O
, -X- _ O
i -X- _ O
Sm -X- _ O
, -X- _ O
n+ -X- _ O
1 -X- _ O
− -X- _ O
λ4 -X- _ O
ζ1 -X- _ O
× -X- _ O
( -X- _ O
wn -X- _ O
, -X- _ O
wp)∈E -X- _ O
2 -X- _ O
φw -X- _ O
p -X- _ O
, -X- _ O
i -X- _ O
Sp -X- _ O
, -X- _ O
n -X- _ O
) -X- _ O
( -X- _ O
12 -X- _ O
) -X- _ O
EM -X- _ O
algorithm -X- _ O
is -X- _ O
applied -X- _ O
using -X- _ O
above -X- _ O
updating -X- _ O
rules -X- _ O
. -X- _ O

E -X- _ O
q -X- _ O
( -X- _ O
| -X- _ O
E -X- _ O
C -X- _ O
i -X- _ O
| -X- _ O
) -X- _ O
is -X- _ O
obtained -X- _ O
directly -X- _ O
from -X- _ O
( -X- _ O
10 -X- _ O
) -X- _ O
, -X- _ O
E -X- _ O
q -X- _ O
( -X- _ O
θ -X- _ O
T -X- _ O
θ -X- _ O
) -X- _ O
is -X- _ O
from -X- _ O
the -X- _ O
property -X- _ O
of -X- _ O
Dirichlet -X- _ O
distribution -X- _ O
. -X- _ O

We -X- _ O
derive -X- _ O
Variational -X- _ O
Inference -X- _ O
for -X- _ O
posterior -X- _ O
inference -X- _ O
. -X- _ O

Posterior -X- _ O
Inference -X- _ O
and -X- _ O
Parameter -X- _ O
Estimation -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
way -X- _ O
, -X- _ O
knowledge -X- _ O
from -X- _ O
large -X- _ O
corpus -X- _ O
other -X- _ O
than -X- _ O
current -X- _ O
document -X- _ O
collections -X- _ O
is -X- _ O
incorporated -X- _ O
to -X- _ O
guide -X- _ O
topic -X- _ O
modeling -X- _ O
. -X- _ O

The -X- _ O
word -X- _ O
representations -X- _ O
are -X- _ O
computed -X- _ O
using -X- _ O
neural -X- _ O
networks -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
learned -X- _ O
representations -X- _ O
explicitly -X- _ O
encode -X- _ O
many -X- _ O
linguistic -X- _ O
regularities -X- _ O
and -X- _ O
patterns -X- _ O
from -X- _ O
the -X- _ O
corpus -X- _ O
. -X- _ O

Then -X- _ O
equation -X- _ O
( -X- _ O
3 -X- _ O
) -X- _ O
can -X- _ O
be -X- _ O
represented -X- _ O
as -X- _ O
below -X- _ O
: -X- _ O
P -X- _ O
egrf -X- _ O
( -X- _ O
z -X- _ O
| -X- _ O
θ -X- _ O
) -X- _ O
= -X- _ O
1 -X- _ O
| -X- _ O
E1 -X- _ O
| -X- _ O
+ -X- _ O
| -X- _ O
E2 -X- _ O
| -X- _ O
w∈V -X- _ O
M -X- _ O
ulti(zw -X- _ O
| -X- _ O
θ)× -X- _ O
( -X- _ O
| -X- _ O
E -X- _ O
C -X- _ O
1 -X- _ O
| -X- _ O
λ1 -X- _ O
+ -X- _ O
| -X- _ O
E -X- _ O
N -X- _ O
C -X- _ O
1 -X- _ O
| -X- _ O
λ2 -X- _ O
+ -X- _ O
| -X- _ O
E -X- _ O
C -X- _ O
2 -X- _ O
| -X- _ O
λ3 -X- _ O
+ -X- _ O
| -X- _ O
E -X- _ O
N -X- _ O
C -X- _ O
2 -X- _ O
| -X- _ O
λ4 -X- _ O
) -X- _ O
= -X- _ O
w∈V -X- _ O
M -X- _ O
ulti(zw -X- _ O
| -X- _ O
θ -X- _ O
) -X- _ O
( -X- _ O
| -X- _ O
E1 -X- _ O
| -X- _ O
+ -X- _ O
| -X- _ O
E2 -X- _ O
|)θ -X- _ O
T -X- _ O
θ -X- _ O
× -X- _ O
( -X- _ O
| -X- _ O
E -X- _ O
C -X- _ O
1 -X- _ O
| -X- _ O
( -X- _ O
1 -X- _ O
− -X- _ O
λ2)+ -X- _ O
| -X- _ O
E1 -X- _ O
| -X- _ O
λ2θ -X- _ O
T -X- _ O
θ+ -X- _ O
| -X- _ O
E -X- _ O
C -X- _ O
2 -X- _ O
| -X- _ O
( -X- _ O
1 -X- _ O
− -X- _ O
λ4)+ -X- _ O
| -X- _ O
E2 -X- _ O
| -X- _ O
λ4θ -X- _ O
T -X- _ O
θ -X- _ O
) -X- _ O
( -X- _ O
9 -X- _ O
) -X- _ O
From -X- _ O
the -X- _ O
second -X- _ O
line -X- _ O
to -X- _ O
the -X- _ O
third -X- _ O
line -X- _ O
of -X- _ O
Equation -X- _ O
( -X- _ O
9 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
represent -X- _ O
λ -X- _ O
1 -X- _ O
, -X- _ O
λ -X- _ O
3 -X- _ O
as -X- _ O
the -X- _ O
function -X- _ O
of -X- _ O
λ -X- _ O
2 -X- _ O
, -X- _ O
λ -X- _ O
4 -X- _ O
based -X- _ O
on -X- _ O
( -X- _ O
7 -X- _ O
) -X- _ O
and -X- _ O
( -X- _ O
8) -X- _ O
. -X- _ O

E -X- _ O
C -X- _ O
i -X- _ O
includes -X- _ O
all -X- _ O
coherent -X- _ O
edges -X- _ O
, -X- _ O
E -X- _ O
N -X- _ O
C -X- _ O
i -X- _ O
contains -X- _ O
all -X- _ O
non -X- _ O
- -X- _ O
coherent -X- _ O
edges -X- _ O
. -X- _ O

In -X- _ O
distance -X- _ O
- -X- _ O
i -X- _ O
edge -X- _ O
set -X- _ O
, -X- _ O
i= -X- _ O
1 -X- _ O
, -X- _ O
2 -X- _ O
. -X- _ O

The -X- _ O
coherent -X- _ O
edge -X- _ O
is -X- _ O
the -X- _ O
edge -X- _ O
that -X- _ O
the -X- _ O
two -X- _ O
linked -X- _ O
words -X- _ O
have -X- _ O
same -X- _ O
topic -X- _ O
. -X- _ O

Word -X- _ O
Similarity -X- _ O
Information -X- _ O
. -X- _ O

If -X- _ O
|E -X- _ O
1 -X- _ O
| -X- _ O
= -X- _ O
0 -X- _ O
, -X- _ O
|E -X- _ O
2 -X- _ O
| -X- _ O
= -X- _ O
0 -X- _ O
, -X- _ O
EGTRF -X- _ O
is -X- _ O
equiva- -X- _ O
lent -X- _ O
to -X- _ O
LDA -X- _ O
. -X- _ O

Equation -X- _ O
( -X- _ O
4 -X- _ O
) -X- _ O
defines -X- _ O
word -X- _ O
vertex -X- _ O
as -X- _ O
multinomial -X- _ O
distribution -X- _ O
, -X- _ O
and -X- _ O
we -X- _ O
assign -X- _ O
λ -X- _ O
1 -X- _ O
, -X- _ O
λ -X- _ O
2 -X- _ O
, -X- _ O
λ -X- _ O
3 -X- _ O
and -X- _ O
λ -X- _ O
4 -X- _ O
nonzero -X- _ O
values -X- _ O
, -X- _ O
then -X- _ O
it -X- _ O
is -X- _ O
clear -X- _ O
to -X- _ O
verify -X- _ O
constraint -X- _ O
Lower -X- _ O
λ -X- _ O
2 -X- _ O
, -X- _ O
λ -X- _ O
4 -X- _ O
give -X- _ O
higher -X- _ O
reward -X- _ O
to -X- _ O
the -X- _ O
edge -X- _ O
that -X- _ O
connects -X- _ O
two -X- _ O
word -X- _ O
vertices -X- _ O
with -X- _ O
same -X- _ O
topic -X- _ O
. -X- _ O

We -X- _ O
obtain -X- _ O
the -X- _ O
marginal -X- _ O
distribution -X- _ O
of -X- _ O
a -X- _ O
document -X- _ O
: -X- _ O
p(w -X- _ O
| -X- _ O
α -X- _ O
, -X- _ O
β -X- _ O
) -X- _ O
= -X- _ O
P -X- _ O
( -X- _ O
θ -X- _ O
| -X- _ O
α -X- _ O
) -X- _ O
z -X- _ O
P -X- _ O
egrf -X- _ O
( -X- _ O
z -X- _ O
| -X- _ O
θ -X- _ O
) -X- _ O
n -X- _ O
P -X- _ O
( -X- _ O
wn -X- _ O
| -X- _ O
zw -X- _ O
n -X- _ O
, -X- _ O
β)dθ(2 -X- _ O
) -X- _ O
We -X- _ O
can -X- _ O
see -X- _ O
the -X- _ O
marginal -X- _ O
distribution -X- _ O
is -X- _ O
similar -X- _ O
to -X- _ O
LDA -X- _ O
except -X- _ O
topic -X- _ O
assignment -X- _ O
of -X- _ O
word -X- _ O
is -X- _ O
sampled -X- _ O
by -X- _ O
Extended -X- _ O
Global -X- _ O
Random -X- _ O
Field -X- _ O
instead -X- _ O
of -X- _ O
Multinomial -X- _ O
. -X- _ O

Given -X- _ O
Dirichlet -X- _ O
prior -X- _ O
α -X- _ O
, -X- _ O
word -X- _ O
distribution -X- _ O
of -X- _ O
topics -X- _ O
β -X- _ O
, -X- _ O
topic -X- _ O
mixture -X- _ O
of -X- _ O
document -X- _ O
θ -X- _ O
, -X- _ O
topic -X- _ O
assignments -X- _ O
z -X- _ O
and -X- _ O
words -X- _ O
w. -X- _ O

For -X- _ O
each -X- _ O
of -X- _ O
the -X- _ O
n -X- _ O
words -X- _ O
w -X- _ O
n -X- _ O
in -X- _ O
d -X- _ O
: -X- _ O
Choose -X- _ O
topic -X- _ O
z -X- _ O
n -X- _ O
∼ -X- _ O
P -X- _ O
egrf -X- _ O
( -X- _ O
z -X- _ O
| -X- _ O
θ -X- _ O
) -X- _ O
, -X- _ O
Choose -X- _ O
word -X- _ O
w -X- _ O
n -X- _ O
∼ -X- _ O
M -X- _ O
ulti(β -X- _ O
zn -X- _ O
, -X- _ O
wn -X- _ O
) -X- _ O
. -X- _ O

Choose -X- _ O
θ -X- _ O
∼ -X- _ O
Dir(α -X- _ O
) -X- _ O
. -X- _ O

The -X- _ O
generative -X- _ O
process -X- _ O
for -X- _ O
word -X- _ O
sequence -X- _ O
of -X- _ O
a -X- _ O
document -X- _ O
is -X- _ O
described -X- _ O
as -X- _ O
below -X- _ O
: -X- _ O
For -X- _ O
each -X- _ O
document -X- _ O
d -X- _ O
in -X- _ O
corpus -X- _ O
D -X- _ O
: -X- _ O
Transform -X- _ O
document -X- _ O
d -X- _ O
into -X- _ O
graph -X- _ O
. -X- _ O

EGTRF -X- _ O
is -X- _ O
a -X- _ O
generative -X- _ O
proba -X- _ O
- -X- _ O
bilistic -X- _ O
model -X- _ O
, -X- _ O
the -X- _ O
basic -X- _ O
idea -X- _ O
is -X- _ O
that -X- _ O
documents -X- _ O
are -X- _ O
represented -X- _ O
as -X- _ O
mixtures -X- _ O
of -X- _ O
topics -X- _ O
, -X- _ O
words -X- _ O
are -X- _ O
generated -X- _ O
depending -X- _ O
on -X- _ O
the -X- _ O
topic -X- _ O
mixtures -X- _ O
and -X- _ O
graph -X- _ O
structure -X- _ O
of -X- _ O
current -X- _ O
document -X- _ O
. -X- _ O

If -X- _ O
Equation -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
satisfies -X- _ O
all -X- _ O
the -X- _ O
four -X- _ O
constraints -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
easy -X- _ O
to -X- _ O
verify -X- _ O
P -X- _ O
( -X- _ O
G -X- _ O
) -X- _ O
is -X- _ O
also -X- _ O
a -X- _ O
probability -X- _ O
measure -X- _ O
since -X- _ O
summing -X- _ O
over -X- _ O
all -X- _ O
possible -X- _ O
samples -X- _ O
g -X- _ O
equals -X- _ O
to -X- _ O
1 -X- _ O
. -X- _ O

g -X- _ O
is -X- _ O
one -X- _ O
sample -X- _ O
of -X- _ O
word -X- _ O
topic -X- _ O
assignments -X- _ O
from -X- _ O
graph -X- _ O
G. -X- _ O

So -X- _ O
f -X- _ O
( -X- _ O
z -X- _ O
) -X- _ O
f -X- _ O
( -X- _ O
z -X- _ O
) -X- _ O
f -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
( -X- _ O
z -X- _ O
, -X- _ O
z -X- _ O
) -X- _ O
and -X- _ O
f -X- _ O
( -X- _ O
z -X- _ O
) -X- _ O
f -X- _ O
( -X- _ O
z -X- _ O
) -X- _ O
f -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
( -X- _ O
z -X- _ O
, -X- _ O
z -X- _ O
) -X- _ O
are -X- _ O
probability -X- _ O
measure -X- _ O
. -X- _ O

f -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
and -X- _ O
f -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
are -X- _ O
not -X- _ O
necessarily -X- _ O
probability -X- _ O
measure -X- _ O
, -X- _ O
however -X- _ O
, -X- _ O
summing -X- _ O
over -X- _ O
all -X- _ O
possible -X- _ O
states -X- _ O
of -X- _ O
the -X- _ O
product -X- _ O
of -X- _ O
the -X- _ O
edge -X- _ O
and -X- _ O
the -X- _ O
linked -X- _ O
word -X- _ O
pair -X- _ O
should -X- _ O
equal -X- _ O
to -X- _ O
1 -X- _ O
, -X- _ O
which -X- _ O
are -X- _ O
from -X- _ O
constraints -X- _ O
3 -X- _ O
and -X- _ O
4 -X- _ O
. -X- _ O

f -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
( -X- _ O
z -X- _ O
, -X- _ O
z -X- _ O
) -X- _ O
and -X- _ O
f -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
( -X- _ O
z -X- _ O
, -X- _ O
z -X- _ O
) -X- _ O
are -X- _ O
the -X- _ O
function -X- _ O
defined -X- _ O
on -X- _ O
edge -X- _ O
set -X- _ O
E -X- _ O
1 -X- _ O
and -X- _ O
E -X- _ O
2 -X- _ O
. -X- _ O

z -X- _ O
, -X- _ O
z -X- _ O
∈Z -X- _ O
f -X- _ O
( -X- _ O
z -X- _ O
) -X- _ O
f -X- _ O
( -X- _ O
z -X- _ O
) -X- _ O
f -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
( -X- _ O
z -X- _ O
, -X- _ O
z -X- _ O
) -X- _ O
= -X- _ O
1 -X- _ O
In -X- _ O
Equation -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
, -X- _ O
f -X- _ O
( -X- _ O
z -X- _ O
) -X- _ O
is -X- _ O
the -X- _ O
function -X- _ O
defined -X- _ O
on -X- _ O
word -X- _ O
vertex -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
a -X- _ O
probability -X- _ O
measure -X- _ O
because -X- _ O
of -X- _ O
the -X- _ O
constraints -X- _ O
1 -X- _ O
and -X- _ O
2 -X- _ O
. -X- _ O

z -X- _ O
, -X- _ O
z -X- _ O
∈Z -X- _ O
f -X- _ O
( -X- _ O
z -X- _ O
) -X- _ O
f -X- _ O
( -X- _ O
z -X- _ O
) -X- _ O
f -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
( -X- _ O
z -X- _ O
, -X- _ O
z -X- _ O
) -X- _ O
= -X- _ O
1 -X- _ O
4 -X- _ O
. -X- _ O

z∈Z -X- _ O
f -X- _ O
( -X- _ O
z -X- _ O
) -X- _ O
= -X- _ O
1 -X- _ O
3 -X- _ O
. -X- _ O

P -X- _ O
( -X- _ O
G -X- _ O
) -X- _ O
= -X- _ O
f -X- _ O
G -X- _ O
( -X- _ O
g -X- _ O
) -X- _ O
= -X- _ O
1 -X- _ O
| -X- _ O
E1 -X- _ O
| -X- _ O
+ -X- _ O
| -X- _ O
E2 -X- _ O
| -X- _ O
w∈W -X- _ O
f -X- _ O
( -X- _ O
zw)× -X- _ O
( -X- _ O
( -X- _ O
w -X- _ O
1 -X- _ O
, -X- _ O
w -X- _ O
1 -X- _ O
) -X- _ O
∈E -X- _ O
1 -X- _ O
f -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
( -X- _ O
z -X- _ O
w -X- _ O
1 -X- _ O
, -X- _ O
z -X- _ O
w -X- _ O
1 -X- _ O
) -X- _ O
+ -X- _ O
( -X- _ O
w -X- _ O
2 -X- _ O
, -X- _ O
w -X- _ O
2 -X- _ O
) -X- _ O
∈E -X- _ O
2 -X- _ O
f -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
( -X- _ O
z -X- _ O
w -X- _ O
2 -X- _ O
, -X- _ O
z -X- _ O
w -X- _ O
2 -X- _ O
) -X- _ O
) -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
s.t -X- _ O
. -X- _ O
1.f -X- _ O
( -X- _ O
z -X- _ O
) -X- _ O
> -X- _ O
0 -X- _ O
, -X- _ O
f -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
( -X- _ O
z -X- _ O
, -X- _ O
z -X- _ O
) -X- _ O
> -X- _ O
0 -X- _ O
, -X- _ O
f -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
( -X- _ O
z -X- _ O
, -X- _ O
z -X- _ O
) -X- _ O
> -X- _ O
0 -X- _ O
2 -X- _ O
. -X- _ O

Extended -X- _ O
Global -X- _ O
Random -X- _ O
Field -X- _ O
. -X- _ O

We -X- _ O
organized -X- _ O
the -X- _ O
paper -X- _ O
as -X- _ O
below -X- _ O
: -X- _ O
EGTRF -X- _ O
is -X- _ O
presented -X- _ O
in -X- _ O
Section -X- _ O
2 -X- _ O
, -X- _ O
variational -X- _ O
inference -X- _ O
and -X- _ O
parameter -X- _ O
estimation -X- _ O
are -X- _ O
derived -X- _ O
in -X- _ O
Section -X- _ O
3 -X- _ O
, -X- _ O
experiments -X- _ O
on -X- _ O
two -X- _ O
datasets -X- _ O
are -X- _ O
showed -X- _ O
in -X- _ O
Section -X- _ O
4 -X- _ O
, -X- _ O
we -X- _ O
conclude -X- _ O
the -X- _ O
paper -X- _ O
in -X- _ O
Section -X- _ O
5 -X- _ O
. -X- _ O

The -X- _ O
word -X- _ O
vector -X- _ O
representations -X- _ O
are -X- _ O
very -X- _ O
interesting -X- _ O
because -X- _ O
the -X- _ O
learned -X- _ O
vectors -X- _ O
explicitly -X- _ O
encode -X- _ O
many -X- _ O
linguistic -X- _ O
regularities -X- _ O
and -X- _ O
patterns -X- _ O
( -X- _ O
Mikolov -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2013 -X- _ O
) -X- _ O
. -X- _ O

Therefore -X- _ O
, -X- _ O
EGTRF -X- _ O
can -X- _ O
exploit -X- _ O
more -X- _ O
semantically -X- _ O
or -X- _ O
syntactically -X- _ O
word -X- _ O
dependencies -X- _ O
. -X- _ O

Some -X- _ O
hidden -X- _ O
dependency -X- _ O
relations -X- _ O
can -X- _ O
also -X- _ O
be -X- _ O
extracted -X- _ O
by -X- _ O
merging -X- _ O
dependency -X- _ O
trees -X- _ O
. -X- _ O

The -X- _ O
two -X- _ O
sentences -X- _ O
are -X- _ O
parsed -X- _ O
into -X- _ O
dependency -X- _ O
trees -X- _ O
respectively -X- _ O
, -X- _ O
and -X- _ O
then -X- _ O
merged -X- _ O
into -X- _ O
a -X- _ O
graph -X- _ O
. -X- _ O

An -X- _ O
example -X- _ O
of -X- _ O
a -X- _ O
simple -X- _ O
document -X- _ O
that -X- _ O
has -X- _ O
two -X- _ O
sentences -X- _ O
shows -X- _ O
in -X- _ O
Figure -X- _ O
1 -X- _ O
. -X- _ O

Then -X- _ O
they -X- _ O
propose -X- _ O
GTRF -X- _ O
to -X- _ O
model -X- _ O
non -X- _ O
- -X- _ O
linear -X- _ O
topical -X- _ O
dependencies -X- _ O
, -X- _ O
word -X- _ O
topics -X- _ O
are -X- _ O
sampled -X- _ O
based -X- _ O
on -X- _ O
graph -X- _ O
structure -X- _ O
instead -X- _ O
of -X- _ O
" -X- _ O
bag -X- _ O
of -X- _ O
words -X- _ O
" -X- _ O
representation -X- _ O
, -X- _ O
the -X- _ O
conditional -X- _ O
independence -X- _ O
of -X- _ O
word -X- _ O
topic -X- _ O
assignment -X- _ O
is -X- _ O
thus -X- _ O
relaxed -X- _ O
. -X- _ O

They -X- _ O
show -X- _ O
topics -X- _ O
of -X- _ O
semantically -X- _ O
or -X- _ O
syntactically -X- _ O
dependent -X- _ O
words -X- _ O
achieve -X- _ O
the -X- _ O
highest -X- _ O
similarity -X- _ O
and -X- _ O
are -X- _ O
able -X- _ O
to -X- _ O
provide -X- _ O
more -X- _ O
useful -X- _ O
information -X- _ O
in -X- _ O
topic -X- _ O
modeling -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
also -X- _ O
the -X- _ O
basic -X- _ O
assumption -X- _ O
of -X- _ O
our -X- _ O
model -X- _ O
. -X- _ O

In -X- _ O
Syntactic -X- _ O
topic -X- _ O
models -X- _ O
( -X- _ O
Boyd -X- _ O
- -X- _ O
Graber -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2009 -X- _ O
) -X- _ O
, -X- _ O
each -X- _ O
word -X- _ O
of -X- _ O
a -X- _ O
sentence -X- _ O
is -X- _ O
generated -X- _ O
by -X- _ O
a -X- _ O
distribution -X- _ O
that -X- _ O
combines -X- _ O
document -X- _ O
- -X- _ O
specific -X- _ O
topic -X- _ O
weights -X- _ O
and -X- _ O
parsetree -X- _ O
- -X- _ O
specific -X- _ O
syntactic -X- _ O
transitions -X- _ O
. -X- _ O

Most -X- _ O
of -X- _ O
the -X- _ O
models -X- _ O
above -X- _ O
are -X- _ O
limited -X- _ O
to -X- _ O
model -X- _ O
linear -X- _ O
topical -X- _ O
dependencies -X- _ O
between -X- _ O
words -X- _ O
, -X- _ O
word -X- _ O
topical -X- _ O
dependencies -X- _ O
can -X- _ O
also -X- _ O
be -X- _ O
modeled -X- _ O
by -X- _ O
a -X- _ O
non -X- _ O
- -X- _ O
linear -X- _ O
way -X- _ O
. -X- _ O

Zhu -X- _ O
( -X- _ O
Zhu -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2010 -X- _ O
) -X- _ O
incorporates -X- _ O
Markov -X- _ O
dependency -X- _ O
between -X- _ O
topic -X- _ O
assignments -X- _ O
of -X- _ O
neighboring -X- _ O
words -X- _ O
, -X- _ O
and -X- _ O
employs -X- _ O
a -X- _ O
general -X- _ O
structure -X- _ O
of -X- _ O
the -X- _ O
GLM -X- _ O
to -X- _ O
define -X- _ O
a -X- _ O
conditional -X- _ O
distribution -X- _ O
of -X- _ O
latent -X- _ O
topic -X- _ O
assignments -X- _ O
over -X- _ O
words -X- _ O
. -X- _ O

Gruber -X- _ O
( -X- _ O
Gruber -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2007 -X- _ O
) -X- _ O
models -X- _ O
the -X- _ O
topics -X- _ O
of -X- _ O
words -X- _ O
in -X- _ O
the -X- _ O
document -X- _ O
as -X- _ O
a -X- _ O
Markov -X- _ O
chain -X- _ O
, -X- _ O
and -X- _ O
assumes -X- _ O
all -X- _ O
words -X- _ O
in -X- _ O
the -X- _ O
same -X- _ O
sentence -X- _ O
are -X- _ O
more -X- _ O
likely -X- _ O
to -X- _ O
have -X- _ O
the -X- _ O
same -X- _ O
topic -X- _ O
. -X- _ O

Wallach -X- _ O
( -X- _ O
Wallach -X- _ O
, -X- _ O
2006 -X- _ O
) -X- _ O
explores -X- _ O
a -X- _ O
hierarchical -X- _ O
generative -X- _ O
probabilistic -X- _ O
model -X- _ O
that -X- _ O
incorporates -X- _ O
both -X- _ O
n -X- _ O
- -X- _ O
gram -X- _ O
statistics -X- _ O
and -X- _ O
latent -X- _ O
topic -X- _ O
variables -X- _ O
. -X- _ O

To -X- _ O
relax -X- _ O
the -X- _ O
" -X- _ O
bag -X- _ O
of -X- _ O
words -X- _ O
" -X- _ O
assumption -X- _ O
, -X- _ O
many -X- _ O
extended -X- _ O
topic -X- _ O
models -X- _ O
have -X- _ O
been -X- _ O
proposed -X- _ O
to -X- _ O
address -X- _ O
the -X- _ O
limitation -X- _ O
of -X- _ O
conditional -X- _ O
independence -X- _ O
. -X- _ O

However -X- _ O
, -X- _ O
the -X- _ O
" -X- _ O
bag -X- _ O
of -X- _ O
words -X- _ O
" -X- _ O
assumption -X- _ O
is -X- _ O
employed -X- _ O
in -X- _ O
most -X- _ O
existing -X- _ O
topic -X- _ O
models -X- _ O
, -X- _ O
it -X- _ O
assumes -X- _ O
the -X- _ O
order -X- _ O
of -X- _ O
words -X- _ O
can -X- _ O
be -X- _ O
ignored -X- _ O
and -X- _ O
topic -X- _ O
assignment -X- _ O
of -X- _ O
each -X- _ O
word -X- _ O
is -X- _ O
conditionally -X- _ O
independent -X- _ O
given -X- _ O
the -X- _ O
topic -X- _ O
mixture -X- _ O
of -X- _ O
a -X- _ O
document -X- _ O
. -X- _ O

Introduction -X- _ O
. -X- _ O

Parameters -X- _ O
are -X- _ O
estimated -X- _ O
efficiently -X- _ O
by -X- _ O
variational -X- _ O
inference -X- _ O
and -X- _ O
experimental -X- _ O
results -X- _ O
on -X- _ O
two -X- _ O
datasets -X- _ O
show -X- _ O
EGTRF -X- _ O
achieves -X- _ O
lower -X- _ O
perplexity -X- _ O
and -X- _ O
higher -X- _ O
log -X- _ O
predictive -X- _ O
probability -X- _ O
. -X- _ O

Word -X- _ O
similarity -X- _ O
information -X- _ O
learned -X- _ O
from -X- _ O
large -X- _ O
corpus -X- _ O
is -X- _ O
incorporated -X- _ O
to -X- _ O
enhance -X- _ O
word -X- _ O
topic -X- _ O
assignment -X- _ O
. -X- _ O

