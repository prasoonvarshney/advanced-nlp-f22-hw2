Acknowledgements	O
.	O

4	O
)	O
For	O
the	O
overall	O
performance	O
indicated	O
by	O
PR	B-MetricName
curves	I-MetricName
,	O
BGRU	B-MethodName
is	O
the	O
most	O
solid	O
relation	O
extractor	O
.	O

We	O
deduce	O
that	O
it	O
is	O
severely	O
affected	O
by	O
the	O
unbalanced	O
instance	O
numbers	O
of	O
different	O
relations	O
,	O
which	O
will	O
make	O
label	O
generator	O
over	O
-	O
fitting	O
to	O
frequent	O
labels	O
.	O

4	O
)	O
The	O
soft	O
-	O
label	O
method	O
greatly	O
improves	O
the	O
accuracy	O
at	O
high	O
confident	O
score	O
but	O
significantly	O
reduces	O
the	O
overall	O
performance	O
.	O

2	O
)	O
The	O
selective	O
attention	O
has	O
limited	O
help	O
in	O
improving	O
the	O
overall	O
performance	O
,	O
even	O
though	O
it	O
may	O
have	O
positive	O
effects	O
at	O
high	O
confident	O
score	O
.	O

From	O
both	O
Table	O
3	O
and	O
Figure	O
5	O
,	O
we	O
are	O
aware	O
of	O
that	O
:	O
1	O
)	O
The	O
relative	O
ranking	O
is	O
quite	O
different	O
from	O
that	O
on	O
held	B-MethodName
-	I-MethodName
out	I-MethodName
evaluation	I-MethodName
according	O
to	O
PR	B-MetricName
curve	I-MetricName
.	O

In	O
this	O
section	O
,	O
we	O
additionally	O
provide	O
PR	B-MetricName
curves	I-MetricName
to	O
show	O
the	O
performance	O
of	O
baselines	O
.	O

C.2	O
Discussion	O
.	O

In	O
.	O

However	O
,	O
part	O
of	O
them	O
are	O
false	O
negative	O
instances	O
in	O
fact	O
and	O
have	O
the	O
corresponding	O
relations	O
,	O
which	O
cause	O
considerable	O
biases	O
between	O
manual	O
and	O
held	B-MethodName
-	I-MethodName
out	I-MethodName
evaluation	I-MethodName
.	O

In	O
held	B-MethodName
-	I-MethodName
out	I-MethodName
evaluation	I-MethodName
,	O
relation	O
predictions	O
for	O
these	O
instances	O
are	O
judged	O
as	O
wrong	O
.	O

These	O
instances	O
are	O
all	O
negative	O
instances	O
and	O
has	O
the	O
automatic	O
label	O
N	O
A	O
in	O
NYT-10	B-DatasetName
.	O

In	O
Figure	O
6	O
,	O
all	O
cases	O
are	O
selected	O
from	O
Top	O
300	O
predictions	O
of	O
PCNN+ATT	B-MethodName
.	O

We	O
present	O
realistic	O
cases	O
in	O
NYT-10	B-DatasetName
to	O
show	O
the	O
effectiveness	O
of	O
our	O
method	O
.	O

B	O
Case	O
Study	O
.	O

When	O
the	O
number	O
is	O
more	O
than	O
100	O
,	O
the	O
distance	O
no	O
longer	O
drops	O
rapidly	O
but	O
begins	O
to	O
fluctuate	O
.	O

With	O
the	O
results	O
,	O
we	O
can	O
observe	O
that	O
the	O
evaluation	O
results	O
obtained	O
by	O
our	O
method	O
become	O
closer	O
to	O
human	O
evaluation	O
when	O
the	O
number	O
of	O
annotated	O
entity	O
pairs	O
is	O
less	O
than	O
100	O
.	O

We	O
have	O
recorded	O
the	O
distance	O
of	O
different	O
iterations	O
between	O
the	O
curves	O
obtained	O
by	O
our	O
method	O
and	O
manual	O
evaluation	O
in	O
Figure	O
4	O
.	O

A.4	O
The	O
result	O
of	O
different	O
iterations	O
.	O

Our	O
method	O
gets	O
the	O
distances	O
0.15	O
to	O
the	O
curve	O
of	O
human	B-MethodName
evaluation	I-MethodName
while	O
corresponding	O
distances	O
for	O
held	B-MethodName
-	I-MethodName
out	I-MethodName
evaluation	I-MethodName
is	O
0.55	O
.	O

The	O
results	O
are	O
shown	O
in	O
Table	O
4	O
,	O
and	O
Figure	O
3	O
.	O

We	O
also	O
evaluate	O
the	O
performance	O
of	O
BGRU+ATT	B-MethodName
with	O
held	B-MethodName
-	I-MethodName
out	I-MethodName
evaluation	I-MethodName
,	O
human	B-MethodName
evaluation	I-MethodName
and	O
our	O
method	O
.	O

A.3	O
Experimental	O
result	O
of	O
BGRU+ATT	B-MethodName
.	O

E	O
p(z	O
i	O
|V	O
)	O
[	O
∆i(z	O
i	O
)	O
]	O
=	O
pi	O
1	O
K	O
|1	O
−	O
pi|	O
+	O
(	O
1	O
−	O
pi	O
)	O
1	O
K	O
|0	O
−	O
pi|	O
=	O
2	O
K	O
pi(1	O
−	O
pi	O
)	O
.	O

Table	O
4	O
:	O
The	O
Precision	B-MetricName
at	O
top	O
K	O
predictions	O
(	O
%	O
)	O
of	O
BGRU+ATT	B-MethodName
upon	O
held	B-MethodName
-	I-MethodName
out	I-MethodName
evaluation	I-MethodName
,	O
our	O
method	O
and	O
human	B-MethodName
evaluation	I-MethodName
on	O
NYT-10	B-DatasetName
.	O

Here	O
we	O
provide	O
the	O
derivation	O
of	O
Equation.8	O
in	O
the	O
main	O
paper	O
.	O

A.2	O
Vetting	O
Strategy	O
.	O

The	O
expression	O
is	O
simplified	O
to	O
:	O
p(z	O
i	O
|y	O
i	O
,	O
s	O
k	O
)	O
=	O
p(y	O
jk	O
|z	O
jk	O
)	O
p(z	O
jk	O
|s	O
jk	O
)	O
v	O
p(y	O
jk	O
|z	O
jk	O
=	O
v)p(z	O
jk	O
=	O
v|s	O
jk	O
)	O
.	O

p(z	O
i	O
|y	O
i	O
,	O
s	O
i	O
)	O
=	O
p(z	O
i	O
,	O
y	O
i	O
,	O
s	O
i	O
)	O
v	O
p(z	O
i	O
=	O
v	O
,	O
y	O
i	O
,	O
s	O
i	O
)	O
=	O
p(z	O
jk	O
,	O
y	O
jk	O
,	O
s	O
jk	O
)	O
v	O
p(z	O
jk	O
=	O
v	O
,	O
y	O
jk	O
,	O
s	O
jk	O
)	O
=	O
p(y	O
jk	O
|z	O
jk	O
,	O
s	O
jk	O
)	O
p(z	O
jk	O
|s	O
jk	O
)	O
v	O
p(y	O
jk	O
|z	O
jk	O
=	O
v	O
,	O
s	O
jk	O
)	O
p(z	O
jk	O
=	O
v|s	O
jk	O
)	O
We	O
assume	O
that	O
given	O
z	O
jk	O
,	O
the	O
observed	O
label	O
y	O
jk	O
is	O
conditionally	O
independent	O
of	O
s	O
jk	O
,	O
which	O
means	O
p(y	O
jk	O
|z	O
jk	O
,	O
s	O
jk	O
)	O
=	O
p(y	O
jk	O
|z	O
jk	O
)	O
.	O

Here	O
we	O
provide	O
the	O
derivation	O
of	O
Equation.6	O
in	O
the	O
main	O
paper	O
.	O

A.1	O
Logistic	O
Regression	O
.	O

A	O
Appendices	O
.	O

Our	O
experiments	O
show	O
that	O
the	O
proposed	O
evaluation	O
method	O
is	O
appropriately	O
unbiased	O
and	O
significant	O
for	O
optimization	O
of	O
distantly	O
relation	B-TaskName
extraction	I-TaskName
in	O
future	O
.	O

In	O
this	O
paper	O
,	O
we	O
propose	O
a	O
novel	O
active	O
testing	O
approach	O
for	O
distantly	B-TaskName
supervised	I-TaskName
relation	I-TaskName
extraction	I-TaskName
,	O
which	O
evaluates	O
performance	O
of	O
relation	O
extractors	O
with	O
both	O
noisy	O
data	O
and	O
a	O
few	O
vetted	O
data	O
.	O

Conclusion	O
.	O

More	O
results	O
and	O
discussions	O
can	O
be	O
found	O
in	O
the	O
Appendix	O
.	O

2018	O
achieves	O
highest	O
precision	O
.	O

3	O
)	O
BGRU	B-MethodName
performs	O
better	O
than	O
any	O
other	O
models	O
,	O
while	O
BGRU	B-MethodName
based	O
method	O
Liu	O
et	O
al	O
.	O

2	O
)	O
Most	O
models	O
make	O
the	O
improvements	O
as	O
they	O
mentioned	O
within	O
papers	O
at	O
high	O
confident	O
score	O
interval	O
.	O

Although	O
GAN	O
and	O
reinforcement	O
learning	O
are	O
helpful	O
to	O
select	O
valuable	O
training	O
instances	O
,	O
they	O
are	O
tendentiously	O
to	O
be	O
overfitted	O
.	O

2018a	O
.	O

2018b	O
andQin	O
et	O
al	O
.	O

From	O
Table	O
3	O
,	O
we	O
can	O
observe	O
that	O
:	O
1	O
)	O
The	O
relative	O
ranking	O
of	O
the	O
models	O
according	O
to	O
precision	O
at	O
top	O
K	O
almost	O
remains	O
the	O
same	O
except	O
Qin	O
et	O
al	O
.	O

All	O
the	O
methods	O
are	O
implemented	O
with	O
the	O
same	O
framework	O
and	O
running	O
in	O
the	O
same	O
run	O
-	O
time	O
environment	O
.	O

With	O
the	O
proposed	O
performance	O
estimator	O
,	O
we	O
reevaluate	O
eight	O
up	O
-	O
to	O
-	O
date	O
distantly	O
supervised	O
rela-	O
Model	O
P@100(%	B-MetricName
)	O
P@200(%	B-MetricName
)	O
P@300(%	B-MetricName
)	O
Table	O
3	O
:	O
The	O
P@N	B-MetricName
precision	B-MetricName
of	O
distantly	O
supervised	O
relation	O
extractors	O
on	O
NYT-10	B-DatasetName
.	O

Re	O
-	O
evaluation	O
of	O
Relation	O
Extractors	O
.	O

With	O
the	O
same	O
vetting	O
budget	O
,	O
MEMC	O
gets	O
more	O
accurate	O
performance	O
estimation	O
at	O
most	O
parts	O
of	O
the	O
range	O
.	O

From	O
the	O
figure	O
,	O
we	O
can	O
conclude	O
that	O
the	O
proposed	O
vetting	O
strategy	O
is	O
much	O
more	O
effective	O
than	O
the	O
random	O
vetting	O
strategy	O
.	O

The	O
distance	O
from	O
curves	O
of	O
different	O
vetting	O
strategies	O
to	O
that	O
of	O
human	O
evaluation	O
is	O
0.176	O
and	O
0.284	O
.	O

We	O
compare	O
our	O
MEMC	O
strategy	O
with	O
a	O
random	O
vetting	O
strategy	O
as	O
shown	O
in	O
Figure	O
2	O
.	O

Effect	O
of	O
Vetting	O
Strategy	O
.	O

Our	O
method	O
obtains	O
at	O
least	O
8.2	B-MetricValue
%	I-MetricValue
closer	O
precision	B-MetricName
to	O
manual	B-MethodName
evaluation	I-MethodName
than	O
the	O
held	B-MethodName
-	I-MethodName
out	I-MethodName
evaluation	I-MethodName
.	O

2	O
)	O
The	O
huge	O
biases	O
caused	O
by	O
wrongly	O
labeled	O
instances	O
are	O
dramatically	O
alleviated	O
by	O
our	O
method	O
.	O

We	O
can	O
observe	O
that	O
1	O
)	O
The	O
performance	O
biases	O
between	O
manual	B-MethodName
evaluation	I-MethodName
and	O
held	B-MethodName
-	I-MethodName
out	I-MethodName
evaluation	I-MethodName
are	O
too	O
significant	O
to	O
be	O
neglected	O
.	O

In	O
this	O
way	O
,	O
our	O
method	O
gets	O
the	O
distances	O
0.17	O
to	O
the	O
curve	O
of	O
human	B-MethodName
evaluation	I-MethodName
while	O
corresponding	O
distances	O
for	O
held	B-MethodName
-	I-MethodName
out	I-MethodName
evaluation	I-MethodName
is	O
0.72	O
.	O

To	O
measure	O
the	O
distance	O
between	O
two	O
curves	O
,	O
we	O
sample	O
20	O
points	O
equidistant	O
on	O
each	O
curve	O
and	O
calculate	O
the	O
Euclidean	O
distance	O
of	O
the	O
two	O
vectors	O
.	O

The	O
results	O
are	O
shown	O
in	O
Table	O
2	O
:	O
The	O
Precision	O
at	O
top	O
K	O
predictions	O
(	O
%	O
)	O
of	O
PCNN+ATT	B-MethodName
upon	O
held	O
-	O
out	O
evaluation	O
,	O
our	O
method	O
and	O
human	O
evaluation	O
on	O
NYT-10	B-DatasetName
.	O

We	O
evaluate	O
the	O
performance	O
of	O
PCNN+ATT	B-MethodName
with	O
held	B-MethodName
-	I-MethodName
out	I-MethodName
evaluation	I-MethodName
,	O
human	B-MethodName
evaluation	I-MethodName
and	O
our	O
method	O
.	O

Effect	O
of	O
Active	B-MethodName
Testing	I-MethodName
.	O

The	O
batch	B-HyperparameterName
size	I-HyperparameterName
for	O
vetting	O
is	O
20	B-HyperparameterValue
and	O
the	O
vetting	B-HyperparameterName
budget	I-HyperparameterName
is	O
set	O
to	O
100	B-HyperparameterValue
entity	O
pairs	O
.	O

The	O
initial	O
state	O
of	O
vetted	O
set	O
includes	O
all	O
the	O
positive	O
entity	O
pairs	O
of	O
the	O
test	O
set	O
in	O
NYT-10	B-DatasetName
and	O
150	O
vetted	O
negative	O
entity	O
pairs	O
.	O

To	O
be	O
more	O
convincing	O
,	O
we	O
provide	O
the	O
experimental	O
results	O
of	O
BGRU+ATT	B-MethodName
in	O
the	O
appendix	O
.	O

We	O
use	O
PCNN+ATT	B-MethodName
(	O
Lin	O
et	O
al	O
.	O
,	O
2016	O
)	O
as	O
baseline	O
relation	O
extractors	O
.	O

Algorithm	O
1	O
Active	B-MethodName
Testing	I-MethodName
Algorithm	O
.	O

The	O
procedure	O
is	O
described	O
in	O
Algorithm	O
1	O
.	O

When	O
the	O
budget	O
is	O
used	O
up	O
,	O
the	O
vetting	O
stops	O
.	O

In	O
this	O
approach	O
,	O
we	O
take	O
it	O
as	O
a	O
hyper	O
parameter	O
.	O

Therefore	O
,	O
vetting	O
budget	O
is	O
the	O
only	O
factor	O
controlling	O
the	O
vetting	O
procedure	O
.	O

With	O
this	O
vetting	O
strategy	O
,	O
the	O
most	O
valuable	O
data	O
is	O
always	O
selected	O
first	O
.	O

Thus	O
,	O
this	O
vetting	O
strategy	O
is	O
also	O
useful	O
for	O
the	O
PR	O
curve	O
.	O

For	O
the	O
PR	O
curve	O
,	O
every	O
point	O
depends	O
on	O
P	O
@K	O
for	O
different	O
K.	O

The	O
change	O
caused	O
by	O
vetting	O
example	O
i	O
can	O
be	O
written	O
as	O
∆	O
i	O
(	O
z	O
i	O
)	O
=	O
|E	O
p(z	O
|V	O
)	O
Q	O
−	O
E	O
p(z	O
|V	O
,	O
z	O
i	O
)	O
Q|(7	O
)	O
For	O
precision	O
at	O
top	O
K	O
,	O
this	O
expected	O
change	O
can	O
be	O
written	O
as	O
E	O
p(z	O
i	O
|V	O
)	O
[	O
∆	O
i	O
(	O
z	O
i	O
)	O
]	O
=	O
2	O
K	O
p	O
i	O
(	O
1	O
−	O
p	O
i	O
)	O
(	O
8)	O
where	O
p	O
i	O
=	O
P	O
(	O
z	O
i	O
=	O
1|Θ	O
)	O
.	O

After	O
vetting	O
example	O
i	O
and	O
updating	O
that	O
estimator	O
,	O
it	O
will	O
become	O
E	O
p(z	O
|V	O
,	O
z	O
i	O
)	O
Q.	O

Let	O
E	O
p(z	O
|V	O
)	O
Q	O
be	O
the	O
expected	O
performance	O
based	O
on	O
the	O
distribution	O
p(z	O
|V	O
)	O
estimated	O
from	O
current	O
vetted	O
set	O
V	O
.	O

The	O
vetting	O
strategy	O
is	O
to	O
select	O
the	O
sample	O
which	O
can	O
yield	O
a	O
largest	O
expected	O
change	O
of	O
performance	O
estimation	O
.	O

In	O
this	O
work	O
,	O
we	O
apply	O
a	O
strategy	O
based	O
on	O
maximum	O
expected	O
model	O
change(MEMC	O
)	O
(	O
Settles	O
,	O
2009	O
)	O
.	O

Vetting	O
Strategy	O
.	O

For	O
each	O
relation	O
,	O
there	O
is	O
a	O
specific	O
logistic	O
regression	O
function	O
to	O
fit	O
.	O

p(z	O
jk	O
|s	O
jk	O
)	O
is	O
fitted	O
by	O
using	O
logistic	O
regression	O
.	O

Given	O
a	O
few	O
vetted	O
data	O
,	O
we	O
fit	O
p(y	O
jk	O
|z	O
jk	O
)	O
by	O
standard	O
maximum	O
likelihood	O
estimation	O
(	O
counting	O
frequencies	O
)	O
.	O

s	O
jk	O
,	O
y	O
jk	O
,	O
z	O
jk	O
are	O
the	O
corresponding	O
elements	O
of	O
s	O
i	O
,	O
y	O
i	O
,	O
z	O
i	O
before	O
sorting	O
confident	O
score	O
.	O

This	O
posterior	O
probability	O
can	O
be	O
derived	O
as	O
(	O
see	O
appendix	O
for	O
proof	O
)	O
p(z	O
i	O
|y	O
i	O
,	O
s	O
i	O
)	O
=	O
p(y	O
jk	O
|z	O
jk	O
)	O
p(z	O
jk	O
|s	O
jk	O
)	O
v	O
p(y	O
jk	O
|z	O
jk	O
=	O
v)p(z	O
jk	O
=	O
v|s	O
jk	O
)	O
(	O
6	O
)	O
where	O
v	O
∈	O
{	O
0	O
,	O
1	O
}	O
.	O

To	O
predict	O
the	O
true	O
latent	O
label	O
z	O
i	O
for	O
a	O
specific	O
relation	O
,	O
we	O
use	O
noisy	O
label	O
y	O
i	O
and	O
confident	O
score	O
s	O
i	O
.	O

Then	O
,	O
the	O
precision	O
and	O
recall	O
equations	O
can	O
be	O
rewritten	O
as	O
E[P	O
@K	O
]	O
=	O
1	O
K	O
(	O
i∈V	O
K	O
z	O
i	O
+	O
i∈U	O
K	O
p(z	O
i	O
=	O
1|Θ	O
)	O
)	O
(	O
4	O
)	O
E[R@K	O
]	O
=	O
i∈V	O
K	O
z	O
i	O
+	O
i∈U	O
K	O
p(z	O
i	O
=	O
1|Θ	O
)	O
i∈V	O
z	O
i	O
+	O
i∈U	O
p(z	O
i	O
=	O
1|Θ	O
)	O
(	O
5	O
)	O
where	O
U	O
K	O
and	O
V	O
K	O
denote	O
the	O
unvetted	O
and	O
vetted	O
subsets	O
of	O
K	O
highest	O
-	O
scoring	O
examples	O
in	O
the	O
total	O
set	O
U	O
∪	O
V	O
.	O

Given	O
posterior	O
estimates	O
p(z	O
i	O
|Θ	O
)	O
,	O
we	O
can	O
compute	O
the	O
expected	O
performance	O
by	O
replacing	O
the	O
true	O
latent	O
label	O
by	O
its	O
probability	O
.	O

We	O
make	O
the	O
assumption	O
that	O
the	O
distribution	O
of	O
true	O
latent	O
labels	O
is	O
conditioned	O
on	O
Θ.	O

In	O
our	O
work	O
,	O
we	O
estimate	O
the	O
probability	O
as	O
p(z	O
i	O
)	O
=	O
i∈U	O
p(z	O
i	O
|Θ	O
)	O
i∈V	O
δ(z	O
i	O
=	O
z	O
i	O
)	O
(	O
3	O
)	O
where	O
Θ	O
represents	O
all	O
available	O
elements	O
such	O
as	O
confident	O
score	O
,	O
noisy	O
labels	O
and	O
so	O
on	O
.	O

The	O
performance	O
evaluation	O
mainly	O
depends	O
on	O
the	O
estimation	O
of	O
z	O
i	O
.	O

We	O
treat	O
the	O
true	O
label	O
z	O
i	O
as	O
a	O
latent	O
variable	O
and	O
z	O
i	O
is	O
its	O
observed	O
value	O
.	O

Our	O
test	O
set	O
consists	O
of	O
two	O
parts	O
:	O
1	O
)	O
a	O
noisy	O
set	O
U	O
in	O
which	O
we	O
only	O
know	O
automatic	O
label	O
y	O
i	O
;	O
2	O
)	O
a	O
vetted	O
set	O
V	O
in	O
which	O
we	O
know	O
both	O
automatic	O
label	O
y	O
i	O
and	O
manual	O
label	O
z	O
i	O
.	O

Metric	O
Estimator	O
.	O

In	O
summary	O
,	O
our	O
method	O
consists	O
of	O
two	O
key	O
components	O
:	O
a	O
vetting	O
strategy	O
and	O
a	O
metric	O
estimator	O
.	O

After	O
a	O
few	O
vetting	O
-	O
evaluating	O
iterations	O
,	O
unbiased	O
performance	O
of	O
relation	B-TaskName
extraction	I-TaskName
is	O
appropriately	O
evaluated	O
.	O

In	O
each	O
iteration	O
there	O
are	O
two	O
steps	O
:	O
1	O
)	O
select	O
a	O
batch	O
of	O
entity	O
pairs	O
with	O
a	O
customized	O
vetting	O
strategy	O
,	O
label	O
them	O
manually	O
,	O
and	O
add	O
them	O
to	O
the	O
vetted	O
set	O
;	O
2	O
)	O
use	O
a	O
new	O
metric	O
estimator	O
to	O
evaluate	O
existing	O
models	O
by	O
the	O
noisy	O
set	O
and	O
the	O
vetted	O
set	O
jointly	O
.	O

A	O
small	O
random	O
sampled	O
set	O
is	O
vetted	O
in	O
the	O
initial	O
state	O
.	O

In	O
this	O
section	O
,	O
we	O
present	O
the	O
general	O
framework	O
of	O
our	O
method	O
.	O

Methodology	O
.	O

z	O
P	O
}	O
=	O
i≤K	O
z	O
i	O
i≤P	O
z	O
i	O
(	O
2	O
)	O
Held	O
-	O
out	O
evaluation	O
replaces	O
z	O
with	O
y	O
to	O
calculate	O
P	O
@K	O
and	O
R@K	O
,	O
which	O
leads	O
to	O
incorrect	O
results	O
obviously	O
.	O

z	O
P	O
}	O
=	O
1	O
K	O
i≤K	O
z	O
i	O
(	O
1	O
)	O
R@K{z	O
1	O
.	O

In	O
summary	O
,	O
P	O
@K	O
and	O
R@K	O
can	O
be	O
described	O
by	O
the	O
following	O
equations	O
,	O
P	O
@K{z	O
1	O
.	O

,	O
z	O
P	O
}	O
.	O

,	O
y	O
P	O
}	O
and	O
z	O
=	O
{	O
z	O
1	O
,	O
.	O

Automatic	O
labels	O
and	O
true	O
labels	O
are	O
denoted	O
as	O
y	O
=	O
{	O
y	O
1	O
,	O
.	O

s	O
P	O
}	O
where	O
P	O
=	O
N	O
p.	O

To	O
compute	O
both	O
metrics	O
,	O
confident	O
score	O
for	O
all	O
entity	O
pairs	O
are	O
sorted	O
in	O
descending	O
order	O
,	O
which	O
is	O
defined	O
as	O
s	O
=	O
{	O
s	O
1	O
,	O
s	O
2	O
.	O

(	O
PR	O
curve	O
)	O
.	O

3	O
An	O
entity	O
pair	O
may	O
have	O
more	O
than	O
one	O
relations	O
.	O

In	O
widely	O
used	O
held	O
-	O
out	O
evaluation	O
,	O
existing	O
methods	O
observe	O
two	O
key	O
metrics	O
which	O
are	O
precision	O
at	O
top	O
K	O
(	O
P	O
@K	O
)	O
and	O
Precision	O
-	O
Recall	O
curve	O
2	O
Confident	O
scores	O
are	O
estimated	O
probabilities	O
for	O
relations	O
.	O

z	O
ip	O
}	O
respectively	O
represent	O
automatic	O
labels	O
and	O
true	O
labels	O
for	O
entity	O
pair	O
i	O
,	O
where	O
y	O
ij	O
and	O
z	O
ij	O
are	O
both	O
in	O
{	O
0	O
,	O
1	O
}	O
3	O
.	O

y	O
ip	O
}	O
and	O
z	O
i	O
=	O
{	O
z	O
i1	O
,	O
z	O
i2	O
.	O

y	O
i	O
=	O
{	O
y	O
i1	O
,	O
y	O
i2	O
.	O

N	O
}	O
,	O
where	O
p	O
is	O
the	O
number	O
of	O
relations	O
,	O
N	O
is	O
the	O
number	O
of	O
entity	O
pairs	O
,	O
and	O
s	O
ij	O
∈	O
(	O
0	O
,	O
1	O
)	O
.	O

s	O
ip	O
}	O
for	O
entity	O
pair	O
i	O
∈	O
{	O
1	O
.	O

Suppose	O
that	O
a	O
distantly	O
supervised	O
model	O
returns	O
confident	O
score	O
2	O
s	O
i	O
=	O
{	O
s	O
i1	O
,	O
s	O
i2	O
.	O

Researchers	O
train	O
a	O
relation	O
extractor	O
based	O
on	O
bags	O
of	O
sentences	O
and	O
then	O
use	O
it	O
to	O
predict	O
relations	O
of	O
entity	O
pairs	O
.	O

In	O
distant	O
supervision	O
paradigm	O
,	O
all	O
sentences	O
containing	O
the	O
same	O
entity	O
pair	O
constitute	O
a	O
bag	O
.	O

Task	O
Definition	O
.	O

Though	O
human	B-MethodName
evaluation	I-MethodName
can	O
yield	O
accurate	O
evaluation	O
results	O
(	O
Zeng	O
et	O
al	O
.	O
,	O
2015;Alt	O
et	O
al	O
.	O
,	O
2019	O
)	O
,	O
labeling	O
all	O
the	O
instances	O
in	O
the	O
test	O
set	O
is	O
too	O
costly	O
.	O

However	O
,	O
none	O
of	O
the	O
above	O
methods	O
pay	O
attention	O
to	O
the	O
biased	O
and	O
inaccurate	O
test	O
set	O
.	O

Then	O
,	O
to	O
alleviate	O
the	O
influence	O
of	O
wrongly	O
labeled	O
instances	O
in	O
distant	O
supervision	O
,	O
those	O
neural	O
relation	O
extractors	O
integrated	O
techniques	O
such	O
as	O
attention	O
mechanism	O
(	O
Lin	O
et	O
al	O
.	O
,	O
2016;Han	O
et	O
al	O
.	O
,	O
2018;Huang	O
and	O
Du	O
,	O
2019	O
)	O
,	O
generative	O
adversarial	O
nets	O
(	O
Qin	O
et	O
al	O
.	O
,	O
2018a;Li	O
et	O
al	O
.	O
,	O
2019	O
)	O
,	O
and	O
reinforcement	O
learning	O
(	O
Feng	O
et	O
al	O
.	O
,	O
2018;Qin	O
et	O
al	O
.	O
,	O
2018b	O
)	O
.	O

In	O
recent	O
years	O
,	O
neural	O
models	O
were	O
widely	O
used	O
to	O
extract	O
semantic	O
meanings	O
accurately	O
without	O
hand	O
-	O
designed	O
features	O
(	O
Zeng	O
et	O
al	O
.	O
,	O
2015;Lin	O
et	O
al	O
.	O
,	O
2017;Zhang	O
et	O
al	O
.	O
,	O
2019	O
)	O
.	O

A	O
series	O
of	O
studies	O
have	O
been	O
conducted	O
with	O
human	O
-	O
designed	O
features	O
in	O
distantly	B-TaskName
supervised	I-TaskName
relation	I-TaskName
extraction	I-TaskName
(	O
Riedel	O
et	O
al	O
.	O
,	O
2010;Surdeanu	O
et	O
al	O
.	O
,	O
2012;Takamatsu	O
et	O
al	O
.	O
,	O
2012;Angeli	O
et	O
al	O
.	O
,	O
2014;Han	O
and	O
Sun	O
,	O
2016	O
)	O
.	O

Distant	O
supervision	O
(	O
Mintz	O
et	O
al	O
.	O
,	O
2009	O
)	O
was	O
proposed	O
to	O
deal	O
with	O
large	O
-	O
scale	O
relation	B-TaskName
extraction	I-TaskName
with	O
automatic	O
annotations	O
.	O

Related	O
Work	O
.	O

Experimental	O
results	O
demonstrate	O
that	O
the	O
proposed	O
evaluation	O
method	O
yields	O
approximately	O
unbiased	O
estimations	O
for	O
distantly	B-TaskName
supervised	I-TaskName
relation	I-TaskName
extraction	I-TaskName
.	O

With	O
a	O
few	O
vetting	O
-	O
estimating	O
iterations	O
,	O
evaluation	O
results	O
can	O
be	O
dramatically	O
close	O
to	O
that	O
of	O
human	O
evaluation	O
by	O
using	O
limited	O
vetted	O
data	O
and	O
all	O
noisy	O
data	O
.	O

In	O
the	O
estimating	O
stage	O
,	O
a	O
metric	O
estimator	O
is	O
proposed	O
to	O
obtain	O
a	O
more	O
accurate	O
evaluation	O
.	O

In	O
the	O
vetting	O
stage	O
,	O
we	O
adopt	O
an	O
active	O
strategy	O
to	O
select	O
batches	O
of	O
the	O
most	O
valuable	O
entity	O
pairs	O
from	O
the	O
noisy	O
test	O
set	O
for	O
annotating	O
.	O

In	O
our	O
approach	O
,	O
we	O
design	O
an	O
iterative	O
approach	O
,	O
with	O
two	O
stage	O
per	O
iteration	O
:	O
vetting	O
stage	O
and	O
estimating	O
stage	O
.	O

Active	B-MethodName
testing	I-MethodName
has	O
been	O
proved	O
effective	O
in	O
evaluating	O
vision	O
models	O
with	O
large	O
-	O
scale	O
noisy	O
datasets	O
(	O
Nguyen	O
et	O
al	O
.	O
,	O
2018	O
)	O
.	O

In	O
this	O
paper	O
,	O
we	O
propose	O
an	O
active	B-MethodName
testing	I-MethodName
approach	O
to	O
estimate	O
the	O
performance	O
of	O
distantly	O
supervised	O
relation	O
extraction	O
.	O

1	O
Clearly	O
,	O
these	O
mislabeled	O
entity	O
pairs	O
yield	O
biased	O
evaluations	O
and	O
lead	O
to	O
inappropriate	O
optimization	O
for	O
distantly	B-TaskName
supervised	I-TaskName
relation	I-TaskName
extraction	I-TaskName
.	O

From	O
a	O
random	O
sampling	O
,	O
we	O
deduce	O
that	O
about	O
8.75	O
%	O
entity	O
pairs	O
in	O
the	O
test	O
set	O
of	O
NYT-10	B-DatasetName
are	O
misclassified	O
as	O
non	O
-	O
relation	O
.	O

For	O
example	O
,	O
over	O
70	O
%	O
of	O
people	O
included	O
in	O
Freebase	O
have	O
no	O
place	O
of	O
birth	O
(	O
Dong	O
et	O
al	O
.	O
,	O
2014	O
)	O
.	O

This	O
problem	O
is	O
caused	O
by	O
the	O
incompleteness	O
of	O
existing	O
knowledge	O
bases	O
.	O

A	O
false	O
negative	O
instance	O
is	O
an	O
entity	O
pair	O
labeled	O
as	O
non	O
-	O
relation	O
,	O
even	O
if	O
it	O
has	O
at	O
least	O
one	O
relation	O
in	O
reality	O
.	O

Results	O
are	O
obtained	O
by	O
our	O
implementations	O
.	O

(	O
2016	O
)	O
upon	O
held	B-MethodName
-	I-MethodName
out	I-MethodName
evaluation	I-MethodName
and	O
human	B-MethodName
evaluation	I-MethodName
on	O
NYT-10	B-DatasetName
.	O

Evaluations	O
P@100	B-MetricName
P@200	B-MetricName
P@300	B-MetricName
Held	B-MethodName
-	I-MethodName
out	I-MethodName
Evaluation	I-MethodName
83	B-MetricValue
77	B-MetricValue
69	B-MetricValue
Human	B-MethodName
Evaluation	I-MethodName
93(+10	B-MetricValue
)	O
92.5(+15.5	B-MetricValue
)	O
91(+22	B-MetricValue
)	O
Table	O
1	O
:	O
The	O
Precision	B-MetricName
at	I-MetricName
top	I-MetricName
K	I-MetricName
predictions	I-MetricName
(	O
%	O
)	O
of	O
the	O
model	O
Lin	O
et	O
al	O
.	O

The	O
biases	O
between	O
human	B-MethodName
evaluation	I-MethodName
and	O
existing	O
held	B-MethodName
-	I-MethodName
out	I-MethodName
evaluation	I-MethodName
are	O
over	O
10	O
%	O
,	O
which	O
are	O
mainly	O
caused	O
by	O
wrongly	O
labeled	O
instances	O
in	O
the	O
test	O
set	O
,	O
especially	O
false	O
negative	O
instances	O
.	O

As	O
shown	O
in	O
Table	O
1	O
,	O
we	O
compare	O
the	O
results	O
of	O
held	B-MethodName
-	I-MethodName
out	I-MethodName
evaluation	I-MethodName
and	O
human	B-MethodName
evaluation	I-MethodName
for	O
the	O
same	O
model	O
on	O
a	O
widely	O
used	O
*	O
Corresponding	O
author	O
:	O
jiawj@bnu.edu.cn	O
.	O

benchmark	O
dataset	O
NYT-10	B-DatasetName
(	O
Riedel	O
et	O
al	O
.	O
,	O
2010	O
)	O
.	O

Most	O
of	O
them	O
estimate	O
their	O
performance	O
with	O
the	O
held	O
-	O
out	O
evaluation	O
on	O
noisy	O
test	O
sets	O
,	O
which	O
will	O
yield	O
inaccurate	O
evaluations	O
of	O
existing	O
models	O
and	O
seriously	O
mislead	O
the	O
model	O
optimization	O
.	O

However	O
,	O
previous	O
works	O
only	O
focus	O
on	O
wrongly	O
labeled	O
instances	O
in	O
training	O
sets	O
but	O
neglect	O
those	O
in	O
test	O
sets	O
.	O

Clearly	O
,	O
the	O
automatically	O
labeled	O
datasets	O
in	O
distant	O
supervision	O
contain	O
amounts	O
of	O
sentences	O
with	O
wrong	O
relation	O
labels	O
.	O

It	O
assumes	O
that	O
if	O
a	O
pair	O
of	O
entities	O
have	O
a	O
known	O
relation	O
in	O
a	O
knowledge	O
base	O
,	O
all	O
sentences	O
with	O
these	O
two	O
entities	O
may	O
express	O
the	O
same	O
relation	O
.	O

To	O
break	O
the	O
bottleneck	O
of	O
manual	O
labeling	O
,	O
distant	O
supervision	O
(	O
Mintz	O
et	O
al	O
.	O
,	O
2009	O
)	O
automatically	O
labels	O
raw	O
text	O
with	O
knowledge	O
bases	O
.	O

It	O
has	O
been	O
thoroughly	O
researched	O
by	O
supervised	O
methods	O
with	O
hand	O
-	O
labeled	O
data	O
.	O

Relation	B-TaskName
extraction	I-TaskName
aims	O
to	O
identify	O
relations	O
between	O
a	O
pair	O
of	O
entities	O
in	O
a	O
sentence	O
.	O

Introduction	O
.	O

Experiments	O
on	O
a	O
widely	O
used	O
benchmark	O
show	O
that	O
our	O
proposed	O
approach	O
can	O
yield	O
approximately	O
unbiased	O
evaluations	O
for	O
distantly	O
supervised	O
relation	O
extractors	O
.	O

To	O
mitigate	O
this	O
problem	O
,	O
we	O
propose	O
a	O
novel	O
evaluation	O
method	O
named	O
active	B-MethodName
testing	I-MethodName
through	O
utilizing	O
both	O
the	O
noisy	O
test	O
set	O
and	O
a	O
few	O
manual	O
annotations	O
.	O

These	O
biases	O
not	O
only	O
result	O
in	O
unfair	O
evaluations	O
but	O
also	O
mislead	O
the	O
optimization	O
of	O
neural	O
relation	B-TaskName
extraction	I-TaskName
.	O

However	O
,	O
existing	O
works	O
on	O
distantly	B-TaskName
supervised	I-TaskName
relation	I-TaskName
extraction	I-TaskName
suffer	O
from	O
the	O
low	O
quality	O
of	O
test	O
set	O
,	O
which	O
leads	O
to	O
considerable	O
biased	O
performance	O
evaluation	O
.	O

Distant	O
supervision	O
has	O
been	O
a	O
widely	O
used	O
method	O
for	O
neural	O
relation	B-TaskName
extraction	I-TaskName
for	O
its	O
convenience	O
of	O
automatically	O
labeling	O
datasets	O
.	O

Active	B-MethodName
Testing	I-MethodName
:	O
An	O
Unbiased	O
Evaluation	O
Method	O
for	O
Distantly	B-TaskName
Supervised	I-TaskName
Relation	I-TaskName
Extraction	I-TaskName
.	O

Require	O
:	O
unvetted	O
set	O
U	O
,	O
vetted	O
set	O
V	O
,	O
vetting	O
budget	O
T	O
,	O
vetting	O
strategy	O
VS	O
,	O
confident	O
score	O
S	O
,	O
estimator	O
p(z	O
)	O
1	O
:	O
while	O
T	O
>	O
0	O
do	O
Initialization	O
.	O

