-DOCSTART- -X- O
After -X- _ O
constructing -X- _ O
clusters -X- _ O
given -X- _ O
a -X- _ O
document -X- _ O
, -X- _ O
a -X- _ O
word -X- _ O
- -X- _ O
graph -X- _ O
is -X- _ O
created -X- _ O
for -X- _ O
each -X- _ O
cluster -X- _ O
to -X- _ O
get -X- _ O
abstractive -X- _ O
fusions -X- _ O
from -X- _ O
these -X- _ O
related -X- _ O
sentences -X- _ O
. -X- _ O

We -X- _ O
use -X- _ O
the -X- _ O
NLTK -X- _ O
4 -X- _ O
and -X- _ O
BNLP -X- _ O
5 -X- _ O
to -X- _ O
preprocess -X- _ O
each -X- _ O
sentence -X- _ O
and -X- _ O
obtain -X- _ O
a -X- _ O
more -X- _ O
accurate -X- _ O
representation -X- _ O
of -X- _ O
the -X- _ O
information -X- _ O
. -X- _ O

BenSumm -X- _ B-MethodName
Model -X- _ O
. -X- _ O

The -X- _ O
summary -X- _ O
of -X- _ O
our -X- _ O
contributions -X- _ O
: -X- _ O
• -X- _ O
To -X- _ O
the -X- _ O
best -X- _ O
of -X- _ O
our -X- _ O
knowledge -X- _ O
, -X- _ O
our -X- _ O
Bengali -X- _ O
Text -X- _ B-TaskName
Summarization -X- _ I-TaskName
model -X- _ O
( -X- _ O
BenSumm -X- _ O
) -X- _ O
is -X- _ O
the -X- _ O
very -X- _ O
first -X- _ O
unsupervised -X- _ O
model -X- _ O
to -X- _ O
generate -X- _ O
abstractive -X- _ O
summary -X- _ O
from -X- _ O
Bengali -X- _ O
text -X- _ O
documents -X- _ O
while -X- _ O
being -X- _ O
simple -X- _ O
yet -X- _ O
robust -X- _ O
. -X- _ O

A -X- _ O
cluster -X- _ O
of -X- _ O
sentences -X- _ O
uses -X- _ O
multi -X- _ O
- -X- _ O
sentence -X- _ O
compression -X- _ O
( -X- _ O
MSC -X- _ O
) -X- _ O
to -X- _ O
summarize -X- _ O
into -X- _ O
one -X- _ O
single -X- _ O
sentence -X- _ O
originally -X- _ O
called -X- _ O
sentence -X- _ O
fusion -X- _ O
( -X- _ O
Barzilay -X- _ O
and -X- _ O
McKeown -X- _ O
, -X- _ O
2005;Nayeem -X- _ O
and -X- _ O
Chali -X- _ O
, -X- _ O
2017b -X- _ O
) -X- _ O
. -X- _ O

A -X- _ O
detailed -X- _ O
illustration -X- _ O
of -X- _ O
our -X- _ O
BenSumm -X- _ B-MethodName
model -X- _ O
with -X- _ O
outputs -X- _ O
from -X- _ O
each -X- _ O
step -X- _ O
for -X- _ O
a -X- _ O
sample -X- _ O
input -X- _ O
document -X- _ O
is -X- _ O
presented -X- _ O
in -X- _ O
Figure -X- _ O
6 -X- _ O
. -X- _ O

We -X- _ O
have -X- _ O
implemented -X- _ O
a -X- _ O
graphbased -X- _ B-MethodName
model -X- _ I-MethodName
to -X- _ O
fuse -X- _ O
multiple -X- _ O
related -X- _ O
sentences -X- _ O
, -X- _ O
requiring -X- _ O
only -X- _ O
a -X- _ O
POS -X- _ O
tagger -X- _ O
and -X- _ O
a -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
language -X- _ O
model -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
have -X- _ O
developed -X- _ O
an -X- _ O
unsupervised -X- _ B-TaskName
abstractive -X- _ I-TaskName
text -X- _ I-TaskName
summarization -X- _ I-TaskName
system -X- _ O
for -X- _ O
Bengali -X- _ O
text -X- _ O
documents -X- _ O
. -X- _ O

We -X- _ O
get -X- _ O
an -X- _ O
average -X- _ O
score -X- _ O
of -X- _ O
4.41 -X- _ B-MetricValue
, -X- _ O
3.95 -X- _ B-MetricValue
, -X- _ O
and -X- _ O
4.2 -X- _ B-MetricValue
in -X- _ O
content -X- _ B-MetricName
, -X- _ O
readability -X- _ B-MetricName
, -X- _ O
and -X- _ O
overall -X- _ B-MetricName
quality -X- _ I-MetricName
respectively -X- _ O
. -X- _ O

Here -X- _ O
, -X- _ O
content -X- _ B-MetricName
means -X- _ O
how -X- _ O
well -X- _ O
the -X- _ O
summary -X- _ O
can -X- _ O
convey -X- _ O
the -X- _ O
original -X- _ O
input -X- _ O
document -X- _ O
's -X- _ O
meaning -X- _ O
, -X- _ O
and -X- _ O
readability -X- _ B-MetricName
represents -X- _ O
the -X- _ O
grammatical -X- _ O
correction -X- _ O
and -X- _ O
the -X- _ O
overall -X- _ O
summary -X- _ O
sentence -X- _ O
coherence -X- _ O
. -X- _ O

They -X- _ O
have -X- _ O
evaluated -X- _ O
each -X- _ O
system -X- _ O
generated -X- _ O
summary -X- _ O
with -X- _ O
scores -X- _ B-MetricName
ranges -X- _ O
from -X- _ O
1 -X- _ B-MetricValue
to -X- _ O
5 -X- _ B-MetricValue
, -X- _ O
where -X- _ O
1 -X- _ B-MetricValue
represents -X- _ O
very -X- _ O
poor -X- _ O
performance -X- _ O
, -X- _ O
and -X- _ O
5 -X- _ B-MetricValue
represents -X- _ O
very -X- _ O
good -X- _ O
performance -X- _ O
. -X- _ O

Therefore -X- _ O
, -X- _ O
we -X- _ O
assign -X- _ O
three -X- _ O
different -X- _ O
evaluators -X- _ O
to -X- _ O
each -X- _ O
summary -X- _ O
generated -X- _ O
from -X- _ O
our -X- _ O
abstractive -X- _ O
system -X- _ O
( -X- _ O
BenSumm -X- _ B-MethodName
[ -X- _ O
Abs -X- _ O
] -X- _ O
) -X- _ O
considering -X- _ O
three -X- _ O
different -X- _ O
aspects -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
Content -X- _ B-MetricName
, -X- _ O
Readability -X- _ B-MetricName
, -X- _ O
and -X- _ O
Overall -X- _ B-MetricName
Quality -X- _ I-MetricName
. -X- _ O

10 -X- _ O
Human -X- _ O
Evaluation -X- _ O
Though -X- _ O
ROUGE -X- _ B-MetricName
( -X- _ O
Lin -X- _ O
, -X- _ O
2004 -X- _ O
) -X- _ O
has -X- _ O
been -X- _ O
shown -X- _ O
to -X- _ O
correlate -X- _ O
well -X- _ O
with -X- _ O
human -X- _ O
judgments -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
biased -X- _ O
towards -X- _ O
surface -X- _ O
level -X- _ O
lexical -X- _ O
similarities -X- _ O
, -X- _ O
and -X- _ O
this -X- _ O
makes -X- _ O
it -X- _ O
inappropriate -X- _ O
for -X- _ O
the -X- _ O
evaluation -X- _ O
of -X- _ O
abstractive -X- _ O
summaries -X- _ O
. -X- _ O

We -X- _ O
get -X- _ O
better -X- _ O
scores -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
R1 -X- _ B-MetricName
and -X- _ O
RL -X- _ B-MetricName
compared -X- _ O
to -X- _ O
the -X- _ O
baselines -X- _ O
. -X- _ O

Moreover -X- _ O
, -X- _ O
we -X- _ O
compare -X- _ O
our -X- _ O
extractive -X- _ O
version -X- _ O
of -X- _ O
our -X- _ O
model -X- _ O
BenSumm -X- _ B-MethodName
without -X- _ O
the -X- _ O
sentence -X- _ O
fusion -X- _ O
component -X- _ O
. -X- _ O

According -X- _ O
to -X- _ O
Table -X- _ O
2 -X- _ O
, -X- _ O
our -X- _ O
abstractive -X- _ O
summarization -X- _ O
model -X- _ O
outperforms -X- _ O
all -X- _ O
the -X- _ O
extractive -X- _ O
baselines -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
all -X- _ O
the -X- _ O
ROUGE -X- _ B-MetricName
metrics -X- _ O
even -X- _ O
though -X- _ O
the -X- _ O
dataset -X- _ O
itself -X- _ O
is -X- _ O
highly -X- _ O
abstractive -X- _ B-MetricName
( -X- _ O
reference -X- _ O
summary -X- _ O
contains -X- _ O
almost -X- _ O
73 -X- _ B-MetricValue
% -X- _ I-MetricValue
new -X- _ O
words -X- _ O
) -X- _ O
. -X- _ O

Results -X- _ O
We -X- _ O
report -X- _ O
our -X- _ O
model -X- _ O
's -X- _ O
performance -X- _ O
compared -X- _ O
with -X- _ O
the -X- _ O
baselines -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
F1 -X- _ B-MetricName
scores -X- _ O
of -X- _ O
R-1 -X- _ B-MetricName
, -X- _ O
R-2 -X- _ B-MetricName
, -X- _ O
and -X- _ O
R -X- _ B-MetricName
- -X- _ I-MetricName
L -X- _ I-MetricName
in -X- _ O
Table -X- _ O
2 -X- _ O
. -X- _ O

Baseline -X- _ O
Systems -X- _ O
We -X- _ O
compare -X- _ O
our -X- _ O
system -X- _ O
with -X- _ O
various -X- _ O
well -X- _ O
established -X- _ O
baseline -X- _ O
systems -X- _ O
like -X- _ O
LexRank -X- _ B-MethodName
( -X- _ O
Erkan -X- _ O
and -X- _ O
Radev -X- _ O
, -X- _ O
2004 -X- _ O
) -X- _ O
, -X- _ O
TextRank -X- _ B-MethodName
( -X- _ O
Mihalcea -X- _ O
and -X- _ O
Tarau -X- _ O
, -X- _ O
2004 -X- _ O
) -X- _ O
, -X- _ O
GreedyKL -X- _ B-MethodName
( -X- _ O
Haghighi -X- _ O
and -X- _ O
Vanderwende -X- _ O
, -X- _ O
2009 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
SumBasic -X- _ B-MethodName
( -X- _ O
Nenkova -X- _ O
and -X- _ O
Vanderwende -X- _ O
, -X- _ O
2005 -X- _ O
) -X- _ O
. -X- _ O

Since -X- _ O
ROUGE -X- _ B-MetricName
computes -X- _ O
scores -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
lexical -X- _ O
overlap -X- _ O
at -X- _ O
the -X- _ O
surface -X- _ O
level -X- _ O
, -X- _ O
there -X- _ O
is -X- _ O
no -X- _ O
difference -X- _ O
in -X- _ O
implementation -X- _ O
for -X- _ O
summary -X- _ O
evaluation -X- _ O
of -X- _ O
the -X- _ O
Bengali -X- _ O
language -X- _ O
. -X- _ O

We -X- _ O
report -X- _ O
unigram -X- _ O
and -X- _ O
bigram -X- _ O
overlap -X- _ O
( -X- _ O
ROUGE-1 -X- _ B-MetricName
and -X- _ O
ROUGE-2 -X- _ B-MetricName
) -X- _ O
to -X- _ O
measure -X- _ O
informativeness -X- _ O
and -X- _ O
the -X- _ O
longest -X- _ O
common -X- _ O
subsequence -X- _ O
( -X- _ O
ROUGE -X- _ B-MetricName
- -X- _ I-MetricName
L -X- _ I-MetricName
) -X- _ O
to -X- _ O
measure -X- _ O
the -X- _ O
summaries -X- _ O
' -X- _ O
fluency -X- _ O
. -X- _ O

Automatic -X- _ O
Evaluation -X- _ O
We -X- _ O
evaluate -X- _ O
our -X- _ O
system -X- _ O
( -X- _ O
BenSumm -X- _ B-MethodName
) -X- _ O
using -X- _ O
an -X- _ O
automatic -X- _ O
evaluation -X- _ O
metric -X- _ O
ROUGE -X- _ B-TaskName
F1 -X- _ O
( -X- _ O
Lin -X- _ O
, -X- _ O
2004 -X- _ O
) -X- _ O
without -X- _ O
any -X- _ O
limit -X- _ O
of -X- _ O
words -X- _ O
. -X- _ O

We -X- _ O
remove -X- _ O
the -X- _ O
abstractive -X- _ B-MethodName
sentence -X- _ I-MethodName
fusion -X- _ I-MethodName
part -X- _ O
to -X- _ O
compare -X- _ O
with -X- _ O
the -X- _ O
baselines -X- _ O
for -X- _ O
the -X- _ O
extractive -X- _ O
evaluation -X- _ O
. -X- _ O

Moreover -X- _ O
, -X- _ O
to -X- _ O
provide -X- _ O
our -X- _ O
proposed -X- _ O
framework -X- _ O
's -X- _ O
effectiveness -X- _ O
, -X- _ O
we -X- _ O
also -X- _ O
experiment -X- _ O
with -X- _ O
an -X- _ O
extractive -X- _ O
dataset -X- _ O
BNLPC -X- _ B-DatasetName
7 -X- _ O
( -X- _ O
Haque -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
. -X- _ O

From -X- _ O
the -X- _ O
dataset -X- _ O
, -X- _ O
we -X- _ O
measure -X- _ O
the -X- _ O
copy -X- _ B-MetricName
rate -X- _ I-MetricName
between -X- _ O
the -X- _ O
source -X- _ O
document -X- _ O
and -X- _ O
the -X- _ O
human -X- _ O
summaries -X- _ O
. -X- _ O

6 -X- _ O
We -X- _ O
collected -X- _ O
the -X- _ O
human -X- _ O
written -X- _ O
document -X- _ O
- -X- _ O
summary -X- _ O
pairs -X- _ O
from -X- _ O
the -X- _ O
several -X- _ O
printed -X- _ O
copy -X- _ O
of -X- _ O
NCTB -X- _ B-DatasetName
books -X- _ I-DatasetName
. -X- _ O

We -X- _ O
conduct -X- _ O
experiments -X- _ O
on -X- _ O
our -X- _ O
dataset -X- _ O
which -X- _ O
consists -X- _ O
of -X- _ O
139 -X- _ O
samples -X- _ O
of -X- _ O
human -X- _ B-TaskName
- -X- _ I-TaskName
written -X- _ I-TaskName
abstractive -X- _ I-TaskName
document -X- _ I-TaskName
- -X- _ I-TaskName
summary -X- _ I-TaskName
pairs -X- _ I-TaskName
written -X- _ O
professional -X- _ O
summary -X- _ O
writers -X- _ O
of -X- _ O
the -X- _ O
National -X- _ O
Curriculum -X- _ O
and -X- _ O
Textbook -X- _ O
Board -X- _ O
( -X- _ O
NCTB -X- _ O
) -X- _ O
. -X- _ O

This -X- _ O
section -X- _ O
presents -X- _ O
our -X- _ O
experimental -X- _ O
details -X- _ O
for -X- _ O
assessing -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
the -X- _ O
proposed -X- _ O
Ben -X- _ B-MethodName
- -X- _ I-MethodName
Summ -X- _ I-MethodName
model -X- _ O
. -X- _ O

Word -X- _ B-MethodName
Graph -X- _ I-MethodName
Generation -X- _ O
Sentence -X- _ B-MethodName
Fusion -X- _ I-MethodName
. -X- _ O

Word -X- _ B-MethodName
Graph -X- _ I-MethodName
Generation -X- _ O
Sentence -X- _ B-MethodName
Fusion -X- _ I-MethodName
. -X- _ O

We -X- _ O
get -X- _ O
multiple -X- _ O
weighted -X- _ O
sentences -X- _ O
( -X- _ O
see -X- _ O
Figure -X- _ O
2 -X- _ O
) -X- _ O
form -X- _ O
the -X- _ O
clusters -X- _ O
using -X- _ O
the -X- _ O
ranking -X- _ B-MethodName
strategy -X- _ O
( -X- _ O
Boudin -X- _ O
and -X- _ O
Morin -X- _ O
, -X- _ O
2013 -X- _ O
) -X- _ O
. -X- _ O

Word -X- _ B-MethodName
Graph -X- _ I-MethodName
( -X- _ O
WG -X- _ B-MethodName
) -X- _ O
Construction -X- _ O
. -X- _ O

We -X- _ O
chose -X- _ O
to -X- _ O
build -X- _ O
an -X- _ O
abstractive -X- _ O
summarizer -X- _ O
with -X- _ O
a -X- _ O
sentence -X- _ B-MethodName
fusion -X- _ I-MethodName
technique -X- _ O
by -X- _ O
generating -X- _ O
word -X- _ O
graphs -X- _ O
( -X- _ O
Filippova -X- _ O
, -X- _ O
2010;Boudin -X- _ O
and -X- _ O
Morin -X- _ O
, -X- _ O
2013 -X- _ O
) -X- _ O
for -X- _ O
the -X- _ O
Bengali -X- _ O
Language -X- _ O
. -X- _ O

We -X- _ O
measure -X- _ O
the -X- _ O
number -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
clusters -X- _ I-HyperparameterName
for -X- _ O
a -X- _ O
given -X- _ O
document -X- _ O
using -X- _ O
the -X- _ O
silhouette -X- _ O
value -X- _ O
. -X- _ O

There -X- _ O
will -X- _ O
be -X- _ O
a -X- _ O
minimum -X- _ B-HyperparameterName
of -X- _ O
2 -X- _ B-HyperparameterValue
and -X- _ O
a -X- _ O
maximum -X- _ B-HyperparameterName
of -X- _ O
n -X- _ B-HyperparameterValue
− -X- _ I-HyperparameterValue
1 -X- _ I-HyperparameterValue
clusters -X- _ B-HyperparameterName
. -X- _ O

We -X- _ O
use -X- _ O
hierarchical -X- _ B-MethodName
agglomerative -X- _ I-MethodName
clustering -X- _ I-MethodName
with -X- _ O
the -X- _ O
ward -X- _ B-MethodName
's -X- _ I-MethodName
method -X- _ I-MethodName
( -X- _ O
Murtagh -X- _ O
and -X- _ O
Legendre -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
. -X- _ O

Therefore -X- _ O
, -X- _ O
we -X- _ O
calculate -X- _ O
the -X- _ O
cosine -X- _ O
similarity -X- _ O
between -X- _ O
the -X- _ O
sentence -X- _ O
vectors -X- _ O
obtained -X- _ O
from -X- _ O
ULMfit -X- _ B-MethodName
pre -X- _ O
- -X- _ O
trained -X- _ O
language -X- _ O
model -X- _ O
( -X- _ O
Howard -X- _ O
and -X- _ O
Ruder -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O

The -X- _ O
Term -X- _ B-MethodName
Frequency -X- _ I-MethodName
- -X- _ I-MethodName
Inverse -X- _ I-MethodName
Document -X- _ I-MethodName
Frequency -X- _ I-MethodName
( -X- _ O
TF -X- _ B-MethodName
- -X- _ I-MethodName
IDF -X- _ I-MethodName
) -X- _ O
measure -X- _ O
does -X- _ O
not -X- _ O
work -X- _ O
well -X- _ O
( -X- _ O
Aggarwal -X- _ O
and -X- _ O
Zhai -X- _ O
, -X- _ O
2012 -X- _ O
) -X- _ O
. -X- _ O

We -X- _ O
here -X- _ O
describe -X- _ O
each -X- _ O
of -X- _ O
the -X- _ O
steps -X- _ O
involved -X- _ O
in -X- _ O
our -X- _ O
Bengali -X- _ B-TaskName
Unsupervised -X- _ I-TaskName
Abstractive -X- _ I-TaskName
Text -X- _ I-TaskName
Summarization -X- _ I-TaskName
model -X- _ O
( -X- _ O
BenSumm -X- _ O
) -X- _ O
for -X- _ O
single -X- _ O
document -X- _ O
setting -X- _ O
. -X- _ O

( -X- _ O
2018 -X- _ O
) -X- _ O
developed -X- _ O
an -X- _ O
unsupervised -X- _ B-TaskName
abstractive -X- _ I-TaskName
summarization -X- _ I-TaskName
system -X- _ O
that -X- _ O
jointly -X- _ O
performs -X- _ O
sentence -X- _ O
fusion -X- _ O
and -X- _ O
paraphrasing -X- _ O
. -X- _ O

Clarke -X- _ O
and -X- _ O
Lapata -X- _ O
( -X- _ O
2008 -X- _ O
) -X- _ O
; -X- _ O
Filippova -X- _ O
( -X- _ O
2010 -X- _ O
) -X- _ O
showed -X- _ O
a -X- _ O
first -X- _ O
intermediate -X- _ O
step -X- _ O
towards -X- _ O
abstractive -X- _ B-TaskName
summarization -X- _ I-TaskName
, -X- _ O
which -X- _ O
compresses -X- _ O
original -X- _ O
sentences -X- _ O
for -X- _ O
a -X- _ O
summary -X- _ O
generation -X- _ O
. -X- _ O

Potential -X- _ O
utility -X- _ O
for -X- _ O
extractive -X- _ O
text -X- _ B-TaskName
summarization -X- _ I-TaskName
made -X- _ O
SC -X- _ O
very -X- _ O
popular -X- _ O
for -X- _ O
single -X- _ O
or -X- _ O
multi -X- _ O
- -X- _ O
document -X- _ O
summarization -X- _ O
( -X- _ O
Nenkova -X- _ O
and -X- _ O
McKeown -X- _ O
, -X- _ O
2012 -X- _ O
) -X- _ O
. -X- _ O

Moreover -X- _ O
, -X- _ O
there -X- _ O
is -X- _ O
no -X- _ O
human -X- _ O
- -X- _ O
annotated -X- _ O
dataset -X- _ O
to -X- _ O
compare -X- _ O
abstractive -X- _ B-TaskName
summarization -X- _ I-TaskName
methods -X- _ O
of -X- _ O
this -X- _ O
language -X- _ O
. -X- _ O

( -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
) -X- _ O
worked -X- _ O
on -X- _ O
extractive -X- _ O
Bengali -X- _ B-TaskName
text -X- _ I-TaskName
summarization -X- _ I-TaskName
using -X- _ O
pronoun -X- _ O
replacement -X- _ O
, -X- _ O
sentence -X- _ O
ranking -X- _ O
with -X- _ O
term -X- _ O
frequency -X- _ O
, -X- _ O
numerical -X- _ O
figures -X- _ O
, -X- _ O
and -X- _ O
overlapping -X- _ O
of -X- _ O
title -X- _ O
words -X- _ O
with -X- _ O
the -X- _ O
document -X- _ O
sentences -X- _ O
. -X- _ O

Nevertheless -X- _ O
, -X- _ O
very -X- _ O
few -X- _ O
attempts -X- _ O
have -X- _ O
been -X- _ O
made -X- _ O
for -X- _ O
Bengali -X- _ B-TaskName
Text -X- _ I-TaskName
summarization -X- _ I-TaskName
despite -X- _ O
Bangla -X- _ O
being -X- _ O
the -X- _ O
7 -X- _ O
th -X- _ O
most -X- _ O
spoken -X- _ O
language -X- _ O
. -X- _ O

Many -X- _ O
researchers -X- _ O
have -X- _ O
worked -X- _ O
on -X- _ O
text -X- _ B-TaskName
summarization -X- _ I-TaskName
and -X- _ O
introduced -X- _ O
different -X- _ O
extractive -X- _ O
and -X- _ O
abstractive -X- _ O
methods -X- _ O
. -X- _ O

Our -X- _ O
model -X- _ O
requires -X- _ O
only -X- _ O
POS -X- _ O
tagger -X- _ O
and -X- _ O
a -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
language -X- _ O
model -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
easily -X- _ O
reproducible -X- _ O
. -X- _ O

2 -X- _ O
• -X- _ O
We -X- _ O
design -X- _ O
an -X- _ O
unsupervised -X- _ B-TaskName
abstractive -X- _ I-TaskName
sentence -X- _ I-TaskName
generation -X- _ I-TaskName
model -X- _ O
that -X- _ O
performs -X- _ O
sentence -X- _ B-MethodName
fusion -X- _ I-MethodName
on -X- _ O
Bengali -X- _ B-DatasetName
texts -X- _ I-DatasetName
. -X- _ O

The -X- _ O
success -X- _ O
of -X- _ O
neural -X- _ O
sequence -X- _ O
- -X- _ O
tosequence -X- _ O
( -X- _ O
seq2seq -X- _ O
) -X- _ O
models -X- _ O
with -X- _ O
attention -X- _ O
( -X- _ O
Bahdanau -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015;Luong -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
provides -X- _ O
an -X- _ O
effective -X- _ O
way -X- _ O
for -X- _ O
text -X- _ O
generation -X- _ O
which -X- _ O
has -X- _ O
been -X- _ O
extensively -X- _ O
applied -X- _ O
in -X- _ O
the -X- _ O
case -X- _ O
of -X- _ O
abstractive -X- _ O
summarization -X- _ O
of -X- _ O
English -X- _ O
language -X- _ O
documents -X- _ O
( -X- _ O
Rush -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015;Chopra -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016;Nallapati -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016;Miao -X- _ O
and -X- _ O
Blunsom -X- _ O
, -X- _ O
2016;Paulus -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018;Nayeem -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O

Compared -X- _ O
to -X- _ O
extractive -X- _ O
, -X- _ O
abstractive -X- _ B-TaskName
summary -X- _ I-TaskName
generation -X- _ I-TaskName
is -X- _ O
indeed -X- _ O
a -X- _ O
challenging -X- _ O
task -X- _ O
. -X- _ O

Extractive -X- _ B-TaskName
summarization -X- _ I-TaskName
is -X- _ O
about -X- _ O
ranking -X- _ O
important -X- _ O
sentences -X- _ O
from -X- _ O
the -X- _ O
original -X- _ O
text -X- _ O
. -X- _ O

The -X- _ O
process -X- _ O
of -X- _ O
shortening -X- _ O
a -X- _ O
large -X- _ O
text -X- _ O
document -X- _ O
with -X- _ O
the -X- _ O
most -X- _ O
relevant -X- _ O
information -X- _ O
of -X- _ O
the -X- _ O
source -X- _ O
is -X- _ O
known -X- _ O
as -X- _ O
automatic -X- _ B-TaskName
text -X- _ I-TaskName
summarization -X- _ I-TaskName
. -X- _ O

Our -X- _ O
unsupervised -X- _ B-TaskName
abstractive -X- _ I-TaskName
summarization -X- _ I-TaskName
model -X- _ O
outperforms -X- _ O
the -X- _ O
baselines -X- _ O
without -X- _ O
being -X- _ O
exposed -X- _ O
to -X- _ O
any -X- _ O
human -X- _ O
- -X- _ O
annotated -X- _ O
reference -X- _ O
summaries -X- _ O
. -X- _ O

We -X- _ O
conduct -X- _ O
experiments -X- _ O
on -X- _ O
this -X- _ O
dataset -X- _ O
and -X- _ O
compare -X- _ O
our -X- _ O
system -X- _ O
with -X- _ O
several -X- _ O
well -X- _ O
- -X- _ O
established -X- _ O
unsupervised -X- _ B-TaskName
extractive -X- _ I-TaskName
summarization -X- _ I-TaskName
systems -X- _ O
. -X- _ O

We -X- _ O
also -X- _ O
provide -X- _ O
a -X- _ O
human -X- _ B-MetricName
- -X- _ I-MetricName
annotated -X- _ I-MetricName
dataset -X- _ I-MetricName
with -X- _ O
document -X- _ O
- -X- _ O
summary -X- _ O
pairs -X- _ O
to -X- _ O
evaluate -X- _ O
our -X- _ O
abstractive -X- _ O
model -X- _ O
and -X- _ O
to -X- _ O
support -X- _ O
the -X- _ O
comparison -X- _ O
of -X- _ O
future -X- _ O
abstractive -X- _ B-TaskName
summarization -X- _ I-TaskName
systems -X- _ O
of -X- _ O
the -X- _ O
Bengali -X- _ O
Language -X- _ O
. -X- _ O

To -X- _ O
overcome -X- _ O
this -X- _ O
problem -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
graph -X- _ O
- -X- _ O
based -X- _ O
unsupervised -X- _ B-TaskName
abstractive -X- _ I-TaskName
summarization -X- _ I-TaskName
system -X- _ O
in -X- _ O
the -X- _ O
single -X- _ O
- -X- _ O
document -X- _ O
setting -X- _ O
for -X- _ O
Bengali -X- _ O
text -X- _ O
documents -X- _ O
, -X- _ O
which -X- _ O
requires -X- _ O
only -X- _ O
a -X- _ O
Part -X- _ O
- -X- _ O
Of -X- _ O
- -X- _ O
Speech -X- _ O
( -X- _ O
POS -X- _ O
) -X- _ O
tagger -X- _ O
and -X- _ O
a -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
language -X- _ O
model -X- _ O
trained -X- _ O
on -X- _ O
Bengali -X- _ O
texts -X- _ O
. -X- _ O

Abstractive -X- _ B-TaskName
summarization -X- _ I-TaskName
systems -X- _ O
generally -X- _ O
rely -X- _ O
on -X- _ O
large -X- _ O
collections -X- _ O
of -X- _ O
documentsummary -X- _ O
pairs -X- _ O
. -X- _ O

Unsupervised -X- _ B-TaskName
Abstractive -X- _ I-TaskName
Summarization -X- _ I-TaskName
of -X- _ O
Bengali -X- _ O
Text -X- _ O
Documents -X- _ O
. -X- _ O

A -X- _ O
Appendix -X- _ O
. -X- _ O

We -X- _ O
want -X- _ O
to -X- _ O
thank -X- _ O
all -X- _ O
the -X- _ O
anonymous -X- _ O
reviewers -X- _ O
for -X- _ O
their -X- _ O
thoughtful -X- _ O
comments -X- _ O
and -X- _ O
constructive -X- _ O
suggestions -X- _ O
for -X- _ O
future -X- _ O
improvements -X- _ O
to -X- _ O
this -X- _ O
work -X- _ O
. -X- _ O

Acknowledgments -X- _ O
. -X- _ O

In -X- _ O
the -X- _ O
future -X- _ O
, -X- _ O
we -X- _ O
would -X- _ O
like -X- _ O
to -X- _ O
jointly -X- _ O
model -X- _ O
multi -X- _ O
- -X- _ O
sentence -X- _ O
compression -X- _ O
and -X- _ O
paraphrasing -X- _ O
in -X- _ O
our -X- _ O
system -X- _ O
. -X- _ O

One -X- _ O
of -X- _ O
the -X- _ O
limitations -X- _ O
of -X- _ O
our -X- _ O
model -X- _ O
is -X- _ O
that -X- _ O
it -X- _ O
can -X- _ O
not -X- _ O
generate -X- _ O
new -X- _ O
words -X- _ O
. -X- _ O

We -X- _ O
design -X- _ O
a -X- _ O
Bengali -X- _ O
Document -X- _ O
Summarization -X- _ O
tool -X- _ O
to -X- _ O
provide -X- _ O
both -X- _ O
extractive -X- _ O
and -X- _ O
abstractive -X- _ O
summary -X- _ O
of -X- _ O
a -X- _ O
given -X- _ O
document -X- _ O
. -X- _ O

Experimental -X- _ O
results -X- _ O
on -X- _ O
our -X- _ O
proposed -X- _ O
dataset -X- _ O
demonstrate -X- _ O
the -X- _ O
superiority -X- _ O
of -X- _ O
our -X- _ O
approach -X- _ O
against -X- _ O
strong -X- _ O
extractive -X- _ O
baselines -X- _ O
. -X- _ O

Conclusion -X- _ O
and -X- _ O
Future -X- _ O
Work -X- _ O
. -X- _ O

Moreover -X- _ O
, -X- _ O
We -X- _ O
design -X- _ O
a -X- _ O
Bengali -X- _ O
Document -X- _ O
Summarization -X- _ O
tool -X- _ O
( -X- _ O
see -X- _ O
Figure -X- _ O
5 -X- _ O
) -X- _ O
capable -X- _ O
of -X- _ O
providing -X- _ O
both -X- _ O
extractive -X- _ O
and -X- _ O
abtractive -X- _ O
summary -X- _ O
for -X- _ O
an -X- _ O
input -X- _ O
document -X- _ O
. -X- _ O

Finally -X- _ O
, -X- _ O
we -X- _ O
present -X- _ O
an -X- _ O
example -X- _ O
of -X- _ O
our -X- _ O
model -X- _ O
output -X- _ O
in -X- _ O
Figure -X- _ O
4 -X- _ O
. -X- _ O

On -X- _ O
the -X- _ O
other -X- _ O
hand -X- _ O
, -X- _ O
our -X- _ O
model -X- _ O
is -X- _ O
unsupervised -X- _ O
and -X- _ O
abstractive -X- _ O
. -X- _ O

It -X- _ O
is -X- _ O
important -X- _ O
to -X- _ O
note -X- _ O
that -X- _ O
these -X- _ O
summarizers -X- _ O
are -X- _ O
completely -X- _ O
extractive -X- _ O
and -X- _ O
designed -X- _ O
for -X- _ O
English -X- _ O
language -X- _ O
. -X- _ O

We -X- _ O
use -X- _ O
an -X- _ O
open -X- _ O
source -X- _ O
implementation -X- _ O
9 -X- _ O
of -X- _ O
these -X- _ O
summarizers -X- _ O
and -X- _ O
adapted -X- _ O
it -X- _ O
for -X- _ O
Bengali -X- _ O
language -X- _ O
. -X- _ O

8 -X- _ O
We -X- _ O
extract -X- _ O
3 -X- _ O
- -X- _ O
best -X- _ O
sentences -X- _ O
from -X- _ O
our -X- _ O
system -X- _ O
and -X- _ O
the -X- _ O
systems -X- _ O
we -X- _ O
compare -X- _ O
as -X- _ O
baselines -X- _ O
. -X- _ O

It -X- _ O
's -X- _ O
clearly -X- _ O
visible -X- _ O
from -X- _ O
the -X- _ O
table -X- _ O
that -X- _ O
our -X- _ O
dataset -X- _ O
is -X- _ O
highly -X- _ O
abstractive -X- _ O
and -X- _ O
will -X- _ O
serve -X- _ O
as -X- _ O
a -X- _ O
robust -X- _ O
benchmark -X- _ O
for -X- _ O
this -X- _ O
task -X- _ O
's -X- _ O
future -X- _ O
works -X- _ O
. -X- _ O

The -X- _ O
overall -X- _ O
statistics -X- _ O
of -X- _ O
the -X- _ O
datasets -X- _ O
are -X- _ O
presented -X- _ O
in -X- _ O
Table -X- _ O
1 -X- _ O
. -X- _ O

The -X- _ O
majority -X- _ O
of -X- _ O
Bangladeshi -X- _ O
schools -X- _ O
follow -X- _ O
these -X- _ O
books -X- _ O
. -X- _ O

The -X- _ O
NCTB -X- _ O
is -X- _ O
responsible -X- _ O
for -X- _ O
the -X- _ O
development -X- _ O
of -X- _ O
the -X- _ O
curriculum -X- _ O
and -X- _ O
distribution -X- _ O
of -X- _ O
textbooks -X- _ O
. -X- _ O

Dataset -X- _ O
. -X- _ O

Experiments -X- _ O
. -X- _ O

Do -X- _ O
n't -X- _ O
be -X- _ O
happy -X- _ O
to -X- _ O
see -X- _ O
the -X- _ O
beautiful -X- _ O
faces -X- _ O
. -X- _ O
] -X- _ O
Human -X- _ O
Reference -X- _ O
. -X- _ O

We -X- _ O
need -X- _ O
hard -X- _ O
work -X- _ O
and -X- _ O
pursuit -X- _ O
to -X- _ O
form -X- _ O
the -X- _ O
nature -X- _ O
, -X- _ O
otherwise -X- _ O
it -X- _ O
is -X- _ O
not -X- _ O
possible -X- _ O
to -X- _ O
defeat -X- _ O
the -X- _ O
devil -X- _ O
. -X- _ O

People -X- _ O
hate -X- _ O
his -X- _ O
nature -X- _ O
, -X- _ O
his -X- _ O
touch -X- _ O
, -X- _ O
his -X- _ O
customs -X- _ O
. -X- _ O

[ -X- _ O
Evil -X- _ O
people -X- _ O
are -X- _ O
fascinated -X- _ O
by -X- _ O
human -X- _ O
form -X- _ O
and -X- _ O
enjoy -X- _ O
its -X- _ O
fruits -X- _ O
. -X- _ O

দ -X- _ O
ুঃস্বভাবের -X- _ O
মান -X- _ O
ষ -X- _ O
মান -X- _ O
বষর -X- _ O
রূপ -X- _ O
দদবে -X- _ O
ম -X- _ O
গ্ধ -X- _ O
হয় -X- _ O
এেং -X- _ O
তার -X- _ O
ফল -X- _ O
দভাগ -X- _ O
কবর -X- _ O
। -X- _ O
যার -X- _ O
স্বভাে -X- _ O
, -X- _ O
তার -X- _ O
স্পর্ -X- _ O
শ -X- _ O
, -X- _ O
তার -X- _ O
রীততনীততবক -X- _ O
মান -X- _ O
ষ -X- _ O
ঘৃ -X- _ O
ণা -X- _ O
কবর -X- _ O
। -X- _ O
স্বভাে -X- _ O
গঠবন -X- _ O
কঠঠন -X- _ O
পতরশ্রম -X- _ O
ও -X- _ O
সাধনা -X- _ O
চাই -X- _ O
, -X- _ O
নইবল -X- _ O
র্য়তানবক -X- _ O
পরাজিত -X- _ O
করা -X- _ O
সম্ভে -X- _ O
নয় -X- _ O
। -X- _ O
তার -X- _ O
স -X- _ O
ন্দর -X- _ O
ম -X- _ O
ে -X- _ O
দদবে -X- _ O
আনজন্দত -X- _ O
হবয়া -X- _ O
না -X- _ O
। -X- _ O
. -X- _ O

System -X- _ O
Summary -X- _ O
. -X- _ O

Ranking -X- _ O
. -X- _ O

Ranking -X- _ O
. -X- _ O

Cluster -X- _ O
n -X- _ O
Cluster -X- _ O
1 -X- _ O
. -X- _ O

Clustering -X- _ O
. -X- _ O

Preprocessing -X- _ O
. -X- _ O

Single -X- _ O
Document -X- _ O
. -X- _ O

We -X- _ O
also -X- _ O
present -X- _ O
a -X- _ O
detailed -X- _ O
illustration -X- _ O
of -X- _ O
our -X- _ O
framework -X- _ O
with -X- _ O
an -X- _ O
example -X- _ O
source -X- _ O
document -X- _ O
in -X- _ O
the -X- _ O
Appendix -X- _ O
. -X- _ O

The -X- _ O
overall -X- _ O
process -X- _ O
is -X- _ O
presented -X- _ O
in -X- _ O
Figure -X- _ O
3 -X- _ O
. -X- _ O

We -X- _ O
generate -X- _ O
the -X- _ O
final -X- _ O
summary -X- _ O
by -X- _ O
merging -X- _ O
all -X- _ O
the -X- _ O
topranked -X- _ O
sentences -X- _ O
. -X- _ O

We -X- _ O
take -X- _ O
the -X- _ O
top -X- _ O
- -X- _ O
ranked -X- _ O
sentence -X- _ O
from -X- _ O
each -X- _ O
cluster -X- _ O
to -X- _ O
present -X- _ O
the -X- _ O
summary -X- _ O
. -X- _ O

Start -X- _ O
. -X- _ O

Figure -X- _ O
1 -X- _ O
illustrates -X- _ O
an -X- _ O
example -X- _ O
WG -X- _ O
for -X- _ O
these -X- _ O
two -X- _ O
sentences -X- _ O
. -X- _ O

Figure -X- _ O
2 -X- _ O
presents -X- _ O
two -X- _ O
sentences -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
one -X- _ O
of -X- _ O
the -X- _ O
source -X- _ O
document -X- _ O
clusters -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
possible -X- _ O
paths -X- _ O
with -X- _ O
their -X- _ O
weighted -X- _ O
values -X- _ O
are -X- _ O
generated -X- _ O
using -X- _ O
the -X- _ O
word -X- _ O
- -X- _ O
graph -X- _ O
approach -X- _ O
. -X- _ O

After -X- _ O
constructing -X- _ O
the -X- _ O
word -X- _ O
- -X- _ O
graph -X- _ O
, -X- _ O
we -X- _ O
can -X- _ O
generate -X- _ O
M -X- _ O
-shortest -X- _ O
paths -X- _ O
from -X- _ O
the -X- _ O
dummy -X- _ O
start -X- _ O
node -X- _ O
to -X- _ O
the -X- _ O
end -X- _ O
node -X- _ O
in -X- _ O
the -X- _ O
word -X- _ O
graph -X- _ O
( -X- _ O
see -X- _ O
Figure -X- _ O
1 -X- _ O
) -X- _ O
. -X- _ O

Each -X- _ O
sentence -X- _ O
of -X- _ O
the -X- _ O
cluster -X- _ O
is -X- _ O
connected -X- _ O
to -X- _ O
a -X- _ O
dummy -X- _ O
start -X- _ O
and -X- _ O
end -X- _ O
node -X- _ O
to -X- _ O
mark -X- _ O
the -X- _ O
beginning -X- _ O
and -X- _ O
ending -X- _ O
sentences -X- _ O
. -X- _ O

After -X- _ O
the -X- _ O
first -X- _ O
sentence -X- _ O
is -X- _ O
added -X- _ O
to -X- _ O
the -X- _ O
graph -X- _ O
as -X- _ O
word -X- _ O
nodes -X- _ O
( -X- _ O
punctuation -X- _ O
included -X- _ O
) -X- _ O
, -X- _ O
words -X- _ O
from -X- _ O
the -X- _ O
other -X- _ O
related -X- _ O
sentences -X- _ O
are -X- _ O
mapped -X- _ O
onto -X- _ O
a -X- _ O
node -X- _ O
in -X- _ O
the -X- _ O
graph -X- _ O
with -X- _ O
the -X- _ O
same -X- _ O
POS -X- _ O
tag -X- _ O
. -X- _ O

Directed -X- _ O
edges -X- _ O
are -X- _ O
formed -X- _ O
by -X- _ O
connecting -X- _ O
the -X- _ O
adjacent -X- _ O
words -X- _ O
from -X- _ O
the -X- _ O
sentences -X- _ O
. -X- _ O

The -X- _ O
words -X- _ O
are -X- _ O
represented -X- _ O
as -X- _ O
vertices -X- _ O
along -X- _ O
with -X- _ O
the -X- _ O
parts -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
speech -X- _ O
( -X- _ O
POS -X- _ O
) -X- _ O
tags -X- _ O
. -X- _ O

Let -X- _ O
, -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
related -X- _ O
sentences -X- _ O
S -X- _ O
= -X- _ O
{ -X- _ O
s -X- _ O
1 -X- _ O
, -X- _ O
s -X- _ O
2 -X- _ O
, -X- _ O
... -X- _ O
, -X- _ O
s -X- _ O
n -X- _ O
} -X- _ O
, -X- _ O
we -X- _ O
construct -X- _ O
a -X- _ O
graph -X- _ O
G -X- _ O
= -X- _ O
( -X- _ O
V -X- _ O
, -X- _ O
E -X- _ O
) -X- _ O
by -X- _ O
iteratively -X- _ O
adding -X- _ O
sentences -X- _ O
to -X- _ O
it -X- _ O
. -X- _ O

Given -X- _ O
a -X- _ O
cluster -X- _ O
of -X- _ O
related -X- _ O
sentences -X- _ O
, -X- _ O
we -X- _ O
construct -X- _ O
a -X- _ O
word -X- _ O
- -X- _ O
graph -X- _ O
following -X- _ O
( -X- _ O
Filippova -X- _ O
, -X- _ O
2010;Boudin -X- _ O
and -X- _ O
Morin -X- _ O
, -X- _ O
2013 -X- _ O
) -X- _ O
. -X- _ O

This -X- _ O
method -X- _ O
is -X- _ O
entirely -X- _ O
unsupervised -X- _ O
and -X- _ O
needs -X- _ O
only -X- _ O
a -X- _ O
POS -X- _ O
tagger -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
highly -X- _ O
suitable -X- _ O
for -X- _ O
the -X- _ O
low -X- _ O
- -X- _ O
resource -X- _ O
setting -X- _ O
. -X- _ O

Textual -X- _ O
graphs -X- _ O
to -X- _ O
generate -X- _ O
abstractive -X- _ O
summaries -X- _ O
provide -X- _ O
effective -X- _ O
results -X- _ O
( -X- _ O
Ganesan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2010 -X- _ O
) -X- _ O
. -X- _ O

The -X- _ O
following -X- _ O
formula -X- _ O
can -X- _ O
measure -X- _ O
silhouette -X- _ O
Score -X- _ O
: -X- _ O
Silhouette -X- _ O
Score -X- _ O
= -X- _ O
( -X- _ O
x -X- _ O
− -X- _ O
y -X- _ O
) -X- _ O
max(x -X- _ O
, -X- _ O
y)(1 -X- _ O
) -X- _ O
where -X- _ O
y -X- _ O
denotes -X- _ O
mean -X- _ O
distance -X- _ O
to -X- _ O
the -X- _ O
other -X- _ O
instances -X- _ O
of -X- _ O
intra -X- _ O
- -X- _ O
cluster -X- _ O
and -X- _ O
x -X- _ O
is -X- _ O
the -X- _ O
mean -X- _ O
distance -X- _ O
to -X- _ O
the -X- _ O
instances -X- _ O
of -X- _ O
the -X- _ O
next -X- _ O
closest -X- _ O
cluster -X- _ O
. -X- _ O

The -X- _ O
clusters -X- _ O
are -X- _ O
highly -X- _ O
coherent -X- _ O
as -X- _ O
it -X- _ O
has -X- _ O
to -X- _ O
contain -X- _ O
sentences -X- _ O
similar -X- _ O
to -X- _ O
every -X- _ O
other -X- _ O
sentence -X- _ O
in -X- _ O
the -X- _ O
same -X- _ O
cluster -X- _ O
even -X- _ O
if -X- _ O
the -X- _ O
clusters -X- _ O
are -X- _ O
small -X- _ O
. -X- _ O

Here -X- _ O
, -X- _ O
n -X- _ O
denotes -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
sentences -X- _ O
in -X- _ O
the -X- _ O
document -X- _ O
. -X- _ O

This -X- _ O
step -X- _ O
is -X- _ O
critical -X- _ O
to -X- _ O
ensure -X- _ O
good -X- _ O
coverage -X- _ O
of -X- _ O
the -X- _ O
whole -X- _ O
document -X- _ O
and -X- _ O
avoid -X- _ O
redundancy -X- _ O
by -X- _ O
selecting -X- _ O
at -X- _ O
most -X- _ O
one -X- _ O
sentence -X- _ O
from -X- _ O
each -X- _ O
cluster -X- _ O
( -X- _ O
Nayeem -X- _ O
and -X- _ O
Chali -X- _ O
, -X- _ O
2017a -X- _ O
) -X- _ O
. -X- _ O

The -X- _ O
clustering -X- _ O
step -X- _ O
allows -X- _ O
us -X- _ O
to -X- _ O
group -X- _ O
similar -X- _ O
sentences -X- _ O
from -X- _ O
a -X- _ O
given -X- _ O
document -X- _ O
. -X- _ O

Sentence -X- _ O
Clustering -X- _ O
. -X- _ O

Our -X- _ O
preprocessing -X- _ O
step -X- _ O
includes -X- _ O
tokenization -X- _ O
, -X- _ O
removal -X- _ O
of -X- _ O
stopwords -X- _ O
, -X- _ O
Part -X- _ O
- -X- _ O
Of -X- _ O
- -X- _ O
Speech -X- _ O
( -X- _ O
POS -X- _ O
) -X- _ O
tagging -X- _ O
, -X- _ O
and -X- _ O
filtering -X- _ O
of -X- _ O
punctuation -X- _ O
marks -X- _ O
. -X- _ O

Nayeem -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

Boudin -X- _ O
and -X- _ O
Morin -X- _ O
( -X- _ O
2013 -X- _ O
) -X- _ O
improved -X- _ O
Filippova -X- _ O
's -X- _ O
approach -X- _ O
by -X- _ O
re -X- _ O
- -X- _ O
ranking -X- _ O
the -X- _ O
compression -X- _ O
paths -X- _ O
according -X- _ O
to -X- _ O
keyphrases -X- _ O
, -X- _ O
which -X- _ O
resulted -X- _ O
in -X- _ O
more -X- _ O
informative -X- _ O
sentences -X- _ O
. -X- _ O

The -X- _ O
Word -X- _ O
- -X- _ O
Graph -X- _ O
based -X- _ O
approaches -X- _ O
were -X- _ O
first -X- _ O
proposed -X- _ O
by -X- _ O
( -X- _ O
Filippova -X- _ O
, -X- _ O
2010 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
require -X- _ O
only -X- _ O
a -X- _ O
POS -X- _ O
tagger -X- _ O
and -X- _ O
a -X- _ O
list -X- _ O
of -X- _ O
stopwords -X- _ O
. -X- _ O

Tex -X- _ O
- -X- _ O
tRank -X- _ O
( -X- _ O
Mihalcea -X- _ O
and -X- _ O
Tarau -X- _ O
, -X- _ O
2004 -X- _ O
) -X- _ O
and -X- _ O
LexRank -X- _ O
( -X- _ O
Erkan -X- _ O
and -X- _ O
Radev -X- _ O
, -X- _ O
2004 -X- _ O
) -X- _ O
are -X- _ O
graph -X- _ O
- -X- _ O
based -X- _ O
methods -X- _ O
for -X- _ O
extracting -X- _ O
important -X- _ O
sentences -X- _ O
from -X- _ O
a -X- _ O
document -X- _ O
. -X- _ O

Jing -X- _ O
and -X- _ O
McKeown -X- _ O
( -X- _ O
2000 -X- _ O
) -X- _ O
worked -X- _ O
on -X- _ O
Sentence -X- _ O
Compression -X- _ O
( -X- _ O
SC -X- _ O
) -X- _ O
which -X- _ O
has -X- _ O
received -X- _ O
considerable -X- _ O
attention -X- _ O
in -X- _ O
the -X- _ O
NLP -X- _ O
community -X- _ O
. -X- _ O

Unfortunately -X- _ O
, -X- _ O
the -X- _ O
methods -X- _ O
are -X- _ O
limited -X- _ O
to -X- _ O
extractive -X- _ O
summarization -X- _ O
, -X- _ O
which -X- _ O
ranks -X- _ O
some -X- _ O
important -X- _ O
sentences -X- _ O
from -X- _ O
the -X- _ O
document -X- _ O
instead -X- _ O
of -X- _ O
generating -X- _ O
new -X- _ O
sentences -X- _ O
which -X- _ O
is -X- _ O
challenging -X- _ O
for -X- _ O
an -X- _ O
extremely -X- _ O
low -X- _ O
resource -X- _ O
language -X- _ O
like -X- _ O
Bengali -X- _ O
. -X- _ O

( -X- _ O
2017Haque -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

Haque -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

3 -X- _ O
Das -X- _ O
and -X- _ O
Bandyopadhyay -X- _ O
( -X- _ O
2010 -X- _ O
) -X- _ O
developed -X- _ O
Bengali -X- _ O
opinion -X- _ O
based -X- _ O
text -X- _ O
summarizer -X- _ O
using -X- _ O
given -X- _ O
topic -X- _ O
which -X- _ O
can -X- _ O
determine -X- _ O
the -X- _ O
information -X- _ O
on -X- _ O
sentiments -X- _ O
of -X- _ O
the -X- _ O
original -X- _ O
texts -X- _ O
. -X- _ O

Related -X- _ O
works -X- _ O
. -X- _ O

• -X- _ O
We -X- _ O
also -X- _ O
introduce -X- _ O
a -X- _ O
highly -X- _ O
abstractive -X- _ O
dataset -X- _ O
with -X- _ O
document -X- _ O
- -X- _ O
summary -X- _ O
pairs -X- _ O
to -X- _ O
evaluate -X- _ O
our -X- _ O
model -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
written -X- _ O
by -X- _ O
professional -X- _ O
summary -X- _ O
writers -X- _ O
of -X- _ O
National -X- _ O
Curriculum -X- _ O
and -X- _ O
Textbook -X- _ O
Board -X- _ O
( -X- _ O
NCTB -X- _ O
) -X- _ O
. -X- _ O

Therefore -X- _ O
, -X- _ O
we -X- _ O
choose -X- _ O
to -X- _ O
create -X- _ O
an -X- _ O
effective -X- _ O
Bengali -X- _ O
Text -X- _ O
Summarizer -X- _ O
with -X- _ O
an -X- _ O
unsupervised -X- _ O
approach -X- _ O
. -X- _ O

In -X- _ O
contrast -X- _ O
, -X- _ O
the -X- _ O
unsupervised -X- _ O
approach -X- _ O
reduces -X- _ O
the -X- _ O
human -X- _ O
effort -X- _ O
and -X- _ O
cost -X- _ O
for -X- _ O
collecting -X- _ O
and -X- _ O
annotating -X- _ O
large -X- _ O
amount -X- _ O
of -X- _ O
paired -X- _ O
training -X- _ O
data -X- _ O
. -X- _ O

These -X- _ O
models -X- _ O
are -X- _ O
usually -X- _ O
trained -X- _ O
with -X- _ O
lots -X- _ O
of -X- _ O
gold -X- _ O
summaries -X- _ O
, -X- _ O
but -X- _ O
there -X- _ O
is -X- _ O
no -X- _ O
large -X- _ O
- -X- _ O
scale -X- _ O
human -X- _ O
- -X- _ O
annotated -X- _ O
abstractive -X- _ O
summaries -X- _ O
available -X- _ O
for -X- _ O
low -X- _ O
- -X- _ O
resource -X- _ O
language -X- _ O
like -X- _ O
Bengali -X- _ O
. -X- _ O

Traditionally -X- _ O
used -X- _ O
abstractive -X- _ O
techniques -X- _ O
are -X- _ O
sentence -X- _ O
compression -X- _ O
, -X- _ O
syntactic -X- _ O
reorganization -X- _ O
, -X- _ O
sentence -X- _ O
fusion -X- _ O
, -X- _ O
and -X- _ O
lexical -X- _ O
paraphrasing -X- _ O
( -X- _ O
Lin -X- _ O
and -X- _ O
Ng -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O

The -X- _ O
abstractive -X- _ O
method -X- _ O
generates -X- _ O
human -X- _ O
- -X- _ O
like -X- _ O
sentences -X- _ O
using -X- _ O
natural -X- _ O
language -X- _ O
generation -X- _ O
techniques -X- _ O
. -X- _ O

There -X- _ O
are -X- _ O
two -X- _ O
types -X- _ O
of -X- _ O
summarizations -X- _ O
: -X- _ O
extractive -X- _ O
and -X- _ O
abstractive -X- _ O
. -X- _ O

A -X- _ O
good -X- _ O
summary -X- _ O
should -X- _ O
be -X- _ O
coherent -X- _ O
, -X- _ O
non -X- _ O
- -X- _ O
redundant -X- _ O
, -X- _ O
and -X- _ O
grammatically -X- _ O
readable -X- _ O
while -X- _ O
retaining -X- _ O
the -X- _ O
original -X- _ O
document -X- _ O
's -X- _ O
most -X- _ O
important -X- _ O
contents -X- _ O
( -X- _ O
Nenkova -X- _ O
and -X- _ O
McKeown -X- _ O
, -X- _ O
2012;Nayeem -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O

Introduction -X- _ O
. -X- _ O

1 -X- _ O
We -X- _ O
make -X- _ O
our -X- _ O
code -X- _ O
& -X- _ O
dataset -X- _ O
publicly -X- _ O
available -X- _ O
at -X- _ O
https://github.com/tafseer-nayeem/ -X- _ O
BengaliSummarization -X- _ O
for -X- _ O
reproduciblity -X- _ O
. -X- _ O

Listed -X- _ O
by -X- _ O
alphabetical -X- _ O
order -X- _ O
. -X- _ O

1 -X- _ O
* -X- _ O
Equal -X- _ O
contribution -X- _ O
. -X- _ O

However -X- _ O
, -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
abstractive -X- _ O
systems -X- _ O
remains -X- _ O
a -X- _ O
challenge -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
unavailability -X- _ O
of -X- _ O
the -X- _ O
parallel -X- _ O
data -X- _ O
for -X- _ O
low -X- _ O
- -X- _ O
resource -X- _ O
languages -X- _ O
like -X- _ O
Bengali -X- _ O
. -X- _ O

