-DOCSTART- -X- O
We -X- _ O
have -X- _ O
used -X- _ O
unsupervised -X- _ B-TaskName
NMT -X- _ I-TaskName
approach -X- _ O
of -X- _ O
MASS -X- _ B-MethodName
( -X- _ O
Song -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
to -X- _ O
build -X- _ O
a -X- _ O
single -X- _ O
model -X- _ O
that -X- _ O
can -X- _ O
translate -X- _ O
in -X- _ O
both -X- _ O
the -X- _ O
directions -X- _ O
i.e. -X- _ O
Russian -X- _ O
to -X- _ O
Hindi -X- _ O
and -X- _ O
vice -X- _ O
- -X- _ O
versa -X- _ O
. -X- _ O

This -X- _ O
paper -X- _ O
presents -X- _ O
a -X- _ O
zero -X- _ B-TaskName
- -X- _ I-TaskName
shot -X- _ I-TaskName
NMT -X- _ I-TaskName
task -X- _ O
on -X- _ O
the -X- _ O
Russian -X- _ O
⇔ -X- _ O
Hindi -X- _ O
translation -X- _ O
, -X- _ O
this -X- _ O
system -X- _ O
was -X- _ O
used -X- _ O
to -X- _ O
participate -X- _ O
in -X- _ O
the -X- _ O
LoResMT -X- _ O
2020 -X- _ O
shared -X- _ O
task -X- _ O
. -X- _ O

In -X- _ O
future -X- _ O
, -X- _ O
we -X- _ O
will -X- _ O
use -X- _ O
IndicNLP -X- _ B-MethodName
tokenizer -X- _ I-MethodName
( -X- _ O
Kunchukuttan -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
have -X- _ O
used -X- _ O
the -X- _ O
default -X- _ O
tokenizer -X- _ O
i.e. -X- _ O
Moses -X- _ B-MethodName
. -X- _ O

Task -X- _ O
BLEU -X- _ B-MetricName
Precision -X- _ B-MetricName
Recall -X- _ B-MetricName
F -X- _ B-MetricName
- -X- _ I-MetricName
measure -X- _ I-MetricName
RIBES -X- _ B-MetricName
. -X- _ O

The -X- _ O
results -X- _ O
are -X- _ O
evaluated -X- _ O
using -X- _ O
automatic -X- _ O
evaluation -X- _ O
metrics -X- _ O
, -X- _ O
BLEU -X- _ B-MetricName
( -X- _ O
Papineni -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2002 -X- _ O
) -X- _ O
, -X- _ O
precision -X- _ B-MetricName
, -X- _ O
recall -X- _ B-MetricName
, -X- _ O
F -X- _ B-MetricName
- -X- _ I-MetricName
measure -X- _ I-MetricName
and -X- _ O
RIBES -X- _ B-MetricName
( -X- _ O
Isozaki -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2010 -X- _ O
) -X- _ O
. -X- _ O

The -X- _ O
LoResMT -X- _ O
2020 -X- _ O
shared -X- _ O
task -X- _ O
organizer -X- _ O
declared -X- _ O
the -X- _ O
evaluation -X- _ O
result -X- _ O
5 -X- _ O
of -X- _ O
zero -X- _ B-TaskName
- -X- _ I-TaskName
shot -X- _ I-TaskName
NMT -X- _ I-TaskName
on -X- _ O
the -X- _ O
language -X- _ O
pairs -X- _ O
namely -X- _ O
, -X- _ O
Hindi -X- _ O
- -X- _ O
Bhojpuri -X- _ O
, -X- _ O
Hindi -X- _ O
- -X- _ O
Magahi -X- _ O
, -X- _ O
and -X- _ O
Russian -X- _ O
- -X- _ O
Hindi -X- _ O
, -X- _ O
and -X- _ O
participated -X- _ O
by -X- _ O
two -X- _ O
teams -X- _ O
only -X- _ O
. -X- _ O

Due -X- _ O
to -X- _ O
limited -X- _ O
computational -X- _ O
resources -X- _ O
, -X- _ O
we -X- _ O
have -X- _ O
used -X- _ O
256 -X- _ B-HyperparameterValue
embedding -X- _ B-HyperparameterName
layers -X- _ I-HyperparameterName
with -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
32 -X- _ B-HyperparameterValue
, -X- _ O
tokens -X- _ B-HyperparameterName
per -X- _ I-HyperparameterName
batch -X- _ I-HyperparameterName
500 -X- _ B-HyperparameterValue
and -X- _ O
dropout -X- _ B-HyperparameterName
0.1 -X- _ B-HyperparameterValue
. -X- _ O
The -X- _ O
obtained -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
model -X- _ O
from -X- _ O
4.1 -X- _ O
are -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
with -X- _ O
pseudo -X- _ O
bilingual -X- _ O
corpus -X- _ O
through -X- _ O
self -X- _ O
- -X- _ O
generated -X- _ O
back -X- _ O
- -X- _ O
translation -X- _ O
data -X- _ O
following -X- _ O
default -X- _ O
settings -X- _ O
of -X- _ O
( -X- _ O
Song -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O

In -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
step -X- _ O
, -X- _ O
we -X- _ O
have -X- _ O
followed -X- _ O
the -X- _ O
default -X- _ O
settings -X- _ O
of -X- _ O
Transformer -X- _ O
model -X- _ O
- -X- _ O
based -X- _ O
Mass -X- _ B-MethodName
( -X- _ O
Song -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
where -X- _ O
6 -X- _ B-HyperparameterValue
layers -X- _ B-HyperparameterName
with -X- _ O
8 -X- _ B-HyperparameterValue
attention -X- _ B-HyperparameterName
heads -X- _ I-HyperparameterName
are -X- _ O
used -X- _ O
. -X- _ O

During -X- _ O
pre -X- _ O
- -X- _ O
processing -X- _ O
of -X- _ O
the -X- _ O
data -X- _ O
, -X- _ O
following -X- _ O
( -X- _ O
Song -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
and -X- _ O
using -X- _ O
the -X- _ O
code -X- _ O
provided -X- _ O
by -X- _ O
( -X- _ O
Lample -X- _ O
and -X- _ O
Conneau -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
used -X- _ O
fastBPE -X- _ B-MethodName
4 -X- _ O
to -X- _ O
learn -X- _ O
byte -X- _ O
pair -X- _ O
encoding -X- _ O
( -X- _ O
BPE -X- _ O
) -X- _ O
vocabulary -X- _ O
with -X- _ O
50,000 -X- _ O
codes -X- _ O
. -X- _ O

( -X- _ O
1 -X- _ O
) -X- _ O
Here -X- _ O
, -X- _ O
the -X- _ O
seq2seq -X- _ B-MethodName
model -X- _ O
learns -X- _ O
the -X- _ O
parameter -X- _ O
θ -X- _ O
to -X- _ O
compute -X- _ O
the -X- _ O
conditional -X- _ O
probability -X- _ O
. -X- _ O

For -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
step -X- _ O
, -X- _ O
following -X- _ O
( -X- _ O
Song -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
we -X- _ O
have -X- _ O
undertaken -X- _ O
the -X- _ O
log -X- _ B-HyperparameterValue
likelihood -X- _ I-HyperparameterValue
objective -X- _ B-HyperparameterName
function -X- _ I-HyperparameterName
( -X- _ O
LF -X- _ O
) -X- _ O
as -X- _ O
shown -X- _ O
in -X- _ O
Equation -X- _ O
1 -X- _ O
. -X- _ O

The -X- _ O
MASS -X- _ B-MethodName
( -X- _ O
Song -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
based -X- _ O
model -X- _ O
leverages -X- _ O
encode -X- _ O
- -X- _ O
decoder -X- _ O
framework -X- _ O
to -X- _ O
develop -X- _ O
complete -X- _ O
sentences -X- _ O
from -X- _ O
given -X- _ O
fractured -X- _ O
pieces -X- _ O
of -X- _ O
sentences -X- _ O
as -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
1 -X- _ O
. -X- _ O

Moses -X- _ B-MethodName
is -X- _ O
used -X- _ O
for -X- _ O
tokenization -X- _ O
( -X- _ O
Koehn -X- _ O
and -X- _ O
Hoang -X- _ O
, -X- _ O
2010 -X- _ O
) -X- _ O
. -X- _ O

Our -X- _ O
system -X- _ O
consists -X- _ O
of -X- _ O
two -X- _ O
major -X- _ O
steps -X- _ O
namely -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
and -X- _ O
then -X- _ O
the -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
step -X- _ O
which -X- _ O
are -X- _ O
discussed -X- _ O
in -X- _ O
the -X- _ O
sub -X- _ O
- -X- _ O
sections -X- _ O
4.1 -X- _ O
and -X- _ O
4.2 -X- _ O
. -X- _ O
For -X- _ O
BPE -X- _ O
( -X- _ O
Sennrich -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
and -X- _ O
vocabulary -X- _ O
creation -X- _ O
, -X- _ O
we -X- _ O
have -X- _ O
used -X- _ O
the -X- _ O
cross -X- _ B-MethodName
- -X- _ I-MethodName
language -X- _ I-MethodName
model -X- _ I-MethodName
( -X- _ O
XLM -X- _ O
) -X- _ O
( -X- _ O
Lample -X- _ O
and -X- _ O
Conneau -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
codebase -X- _ O
as -X- _ O
given -X- _ O
in -X- _ O
their -X- _ O
repository -X- _ O
3 -X- _ O
. -X- _ O

We -X- _ O
have -X- _ O
adopted -X- _ O
MASS -X- _ B-MethodName
based -X- _ I-MethodName
unsupervised -X- _ I-MethodName
NMT -X- _ I-MethodName
( -X- _ O
Song -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
to -X- _ O
build -X- _ O
our -X- _ O
system -X- _ O
on -X- _ O
a -X- _ O
single -X- _ O
GPU -X- _ O
. -X- _ O

Additionally -X- _ O
, -X- _ O
we -X- _ O
have -X- _ O
used -X- _ O
external -X- _ O
monolingual -X- _ O
data -X- _ O
set -X- _ O
of -X- _ O
Hindi -X- _ O
( -X- _ O
9 -X- _ O
GB -X- _ O
) -X- _ O
from -X- _ O
IITB -X- _ B-DatasetName
1 -X- _ O
( -X- _ O
Kunchukuttan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018;Bojar -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
and -X- _ O
Russian -X- _ O
( -X- _ O
9 -X- _ O
GB -X- _ O
) -X- _ O
from -X- _ O
WMT16 -X- _ B-DatasetName
2 -X- _ O
. -X- _ O

The -X- _ O
LoResMT -X- _ B-DatasetName
2020 -X- _ I-DatasetName
shared -X- _ I-DatasetName
task -X- _ I-DatasetName
organizer -X- _ O
( -X- _ O
Ojha -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
provided -X- _ O
the -X- _ O
Russian -X- _ B-DatasetName
- -X- _ I-DatasetName
Hindi -X- _ I-DatasetName
monolingual -X- _ I-DatasetName
dataset -X- _ O
of -X- _ O
train -X- _ O
, -X- _ O
valid -X- _ O
, -X- _ O
and -X- _ O
test -X- _ O
sets -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
summarized -X- _ O
in -X- _ O
Table -X- _ O
1 -X- _ O
. -X- _ O

Figure -X- _ O
1 -X- _ O
: -X- _ O
The -X- _ O
encoder -X- _ O
- -X- _ O
decoder -X- _ O
framework -X- _ O
of -X- _ O
the -X- _ O
MASS -X- _ B-MethodName
model -X- _ O
used -X- _ O
( -X- _ O
as -X- _ O
adopted -X- _ O
from -X- _ O
( -X- _ O
Song -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
) -X- _ O
. -X- _ O

However -X- _ O
, -X- _ O
the -X- _ O
literature -X- _ O
survey -X- _ O
finds -X- _ O
work -X- _ O
on -X- _ O
unsupervised -X- _ B-MethodName
NMT -X- _ I-MethodName
using -X- _ I-MethodName
MASS -X- _ I-MethodName
( -X- _ O
Song -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
which -X- _ O
outperform -X- _ O
previous -X- _ O
unsupervised -X- _ O
approaches -X- _ O
( -X- _ O
Lample -X- _ O
and -X- _ O
Conneau -X- _ O
, -X- _ O
2019;Lample -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O

The -X- _ O
reason -X- _ O
behind -X- _ O
choosing -X- _ O
MASS -X- _ B-MethodName
- -X- _ I-MethodName
based -X- _ I-MethodName
unsupervised -X- _ I-MethodName
NMT -X- _ I-MethodName
is -X- _ O
that -X- _ O
it -X- _ O
achieves -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
performance -X- _ O
on -X- _ O
the -X- _ O
unsupervised -X- _ O
English -X- _ O
- -X- _ O
French -X- _ O
pair -X- _ O
translation -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
have -X- _ O
participated -X- _ O
in -X- _ O
the -X- _ O
LoResMT -X- _ O
2020 -X- _ O
shared -X- _ O
task -X- _ O
of -X- _ O
zero -X- _ B-TaskName
- -X- _ I-TaskName
shot -X- _ I-TaskName
NMT -X- _ I-TaskName
approach -X- _ O
on -X- _ O
Russian -X- _ O
- -X- _ O
Hindi -X- _ O
pair -X- _ O
using -X- _ O
the -X- _ O
only -X- _ O
monolingual -X- _ O
corpus -X- _ O
and -X- _ O
the -X- _ O
same -X- _ O
has -X- _ O
been -X- _ O
implemented -X- _ O
using -X- _ O
MASS -X- _ B-MethodName
- -X- _ I-MethodName
based -X- _ I-MethodName
unsupervised -X- _ I-MethodName
NMT -X- _ I-MethodName
( -X- _ O
Song -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O

( -X- _ O
Johnson -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
introduced -X- _ O
a -X- _ O
zero -X- _ O
- -X- _ O
shot -X- _ O
approach -X- _ O
to -X- _ O
language -X- _ O
pair -X- _ O
translation -X- _ O
without -X- _ O
considering -X- _ O
the -X- _ O
parallel -X- _ O
data -X- _ O
using -X- _ O
multilingual -X- _ B-TaskName
- -X- _ I-TaskName
based -X- _ I-TaskName
NMT -X- _ I-TaskName
. -X- _ O

For -X- _ O
low -X- _ O
resource -X- _ O
language -X- _ O
pair -X- _ O
translation -X- _ O
, -X- _ O
pivot -X- _ B-MethodName
- -X- _ I-MethodName
based -X- _ I-MethodName
NMT -X- _ I-MethodName
( -X- _ O
Kim -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
is -X- _ O
an -X- _ O
effective -X- _ O
approach -X- _ O
where -X- _ O
an -X- _ O
intermediate -X- _ O
language -X- _ O
is -X- _ O
considered -X- _ O
as -X- _ O
a -X- _ O
pivot -X- _ O
language -X- _ O
( -X- _ O
source -X- _ O
to -X- _ O
pivot -X- _ O
and -X- _ O
pivot -X- _ O
to -X- _ O
target -X- _ O
) -X- _ O
. -X- _ O

The -X- _ O
RNN -X- _ B-MethodName
based -X- _ I-MethodName
NMT -X- _ I-MethodName
approach -X- _ O
is -X- _ O
not -X- _ O
able -X- _ O
to -X- _ O
process -X- _ O
all -X- _ O
the -X- _ O
input -X- _ O
words -X- _ O
parallelly -X- _ O
, -X- _ O
to -X- _ O
solve -X- _ O
parallelization -X- _ O
transformer -X- _ O
- -X- _ O
based -X- _ O
NMT -X- _ O
( -X- _ O
Vaswani -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
is -X- _ O
proposed -X- _ O
by -X- _ O
using -X- _ O
a -X- _ O
self -X- _ O
- -X- _ O
attention -X- _ O
mechanism -X- _ O
. -X- _ O

The -X- _ O
end -X- _ B-MethodName
- -X- _ I-MethodName
to -X- _ I-MethodName
- -X- _ I-MethodName
end -X- _ I-MethodName
recurrent -X- _ I-MethodName
neural -X- _ I-MethodName
network -X- _ I-MethodName
( -X- _ O
RNN -X- _ B-MethodName
) -X- _ O
based -X- _ O
NMT -X- _ O
( -X- _ O
Cho -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2014b -X- _ O
, -X- _ O
a -X- _ O
) -X- _ O
approach -X- _ O
attracts -X- _ O
attention -X- _ O
in -X- _ O
MT -X- _ B-TaskName
because -X- _ O
it -X- _ O
deals -X- _ O
with -X- _ O
many -X- _ O
challenges -X- _ O
like -X- _ O
variable -X- _ O
- -X- _ O
length -X- _ O
phrases -X- _ O
using -X- _ O
sequence -X- _ O
to -X- _ O
sequence -X- _ O
learning -X- _ O
concept -X- _ O
, -X- _ O
long -X- _ O
- -X- _ O
term -X- _ O
dependency -X- _ O
problem -X- _ O
adopting -X- _ O
long -X- _ O
short -X- _ O
term -X- _ O
memory -X- _ O
( -X- _ O
LSTM -X- _ O
) -X- _ O
( -X- _ O
Sutskever -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
, -X- _ O
attention -X- _ O
mechanism -X- _ O
( -X- _ O
Bahdanau -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015;Luong -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
which -X- _ O
pays -X- _ O
attention -X- _ O
globally -X- _ O
and -X- _ O
locally -X- _ O
to -X- _ O
all -X- _ O
source -X- _ O
words -X- _ O
. -X- _ O

And -X- _ O
for -X- _ O
Hindi -X- _ O
to -X- _ O
Russian -X- _ O
translation -X- _ O
, -X- _ O
we -X- _ O
have -X- _ O
achieved -X- _ O
BLEU -X- _ B-MetricName
, -X- _ O
precision -X- _ B-MetricName
, -X- _ O
recall -X- _ B-MetricName
, -X- _ O
F -X- _ B-MetricName
- -X- _ I-MetricName
measure -X- _ I-MetricName
, -X- _ O
and -X- _ O
RIBES -X- _ B-MetricName
score -X- _ O
of -X- _ O
1.11 -X- _ B-MetricValue
, -X- _ O
4.72 -X- _ B-MetricValue
, -X- _ O
4.41 -X- _ B-MetricValue
, -X- _ O
4.56 -X- _ B-MetricValue
, -X- _ O
and -X- _ O
0.026842 -X- _ B-MetricValue
respectively -X- _ O
. -X- _ O

The -X- _ O
evaluated -X- _ O
results -X- _ O
are -X- _ O
declared -X- _ O
at -X- _ O
the -X- _ O
LoResMT -X- _ O
2020 -X- _ O
shared -X- _ O
task -X- _ O
, -X- _ O
which -X- _ O
reports -X- _ O
that -X- _ O
our -X- _ O
system -X- _ O
achieves -X- _ O
the -X- _ O
bilingual -X- _ B-MetricName
evaluation -X- _ I-MetricName
understudy -X- _ I-MetricName
( -X- _ O
BLEU -X- _ B-MetricName
) -X- _ O
score -X- _ O
of -X- _ O
0.59 -X- _ B-MetricValue
, -X- _ O
precision -X- _ B-MetricName
score -X- _ O
of -X- _ O
3.43 -X- _ B-MetricValue
, -X- _ O
recall -X- _ B-MetricName
score -X- _ O
of -X- _ O
5.48 -X- _ B-MetricValue
, -X- _ O
F -X- _ B-MetricName
- -X- _ I-MetricName
measure -X- _ I-MetricName
score -X- _ O
of -X- _ O
4.22 -X- _ B-MetricValue
, -X- _ O
and -X- _ O
rank -X- _ B-MetricName
- -X- _ I-MetricName
based -X- _ I-MetricName
intuitive -X- _ I-MetricName
bilingual -X- _ I-MetricName
evaluation -X- _ I-MetricName
score -X- _ I-MetricName
( -X- _ O
RIBES -X- _ B-MetricName
) -X- _ O
of -X- _ O
0.180147 -X- _ B-MetricValue
in -X- _ O
Russian -X- _ O
to -X- _ O
Hindi -X- _ O
translation -X- _ O
. -X- _ O

We -X- _ O
have -X- _ O
used -X- _ O
masked -X- _ B-MethodName
sequence -X- _ I-MethodName
to -X- _ I-MethodName
sequence -X- _ I-MethodName
pre -X- _ I-MethodName
- -X- _ I-MethodName
training -X- _ I-MethodName
for -X- _ I-MethodName
language -X- _ I-MethodName
generation -X- _ I-MethodName
( -X- _ O
MASS -X- _ B-MethodName
) -X- _ O
with -X- _ O
only -X- _ O
monolingual -X- _ O
corpus -X- _ O
following -X- _ O
the -X- _ O
unsupervised -X- _ B-TaskName
NMT -X- _ I-TaskName
architecture -X- _ O
. -X- _ O

Workshop -X- _ O
on -X- _ O
Technologies -X- _ O
for -X- _ O
MT -X- _ B-TaskName
of -X- _ O
Low -X- _ O
Resource -X- _ O
Languages -X- _ O
( -X- _ O
LoResMT -X- _ O
2020 -X- _ O
) -X- _ O
organized -X- _ O
shared -X- _ O
tasks -X- _ O
of -X- _ O
low -X- _ O
resource -X- _ O
language -X- _ O
pair -X- _ O
translation -X- _ O
using -X- _ O
zero -X- _ B-TaskName
- -X- _ I-TaskName
shot -X- _ I-TaskName
NMT -X- _ I-TaskName
. -X- _ O

To -X- _ O
mitigate -X- _ O
this -X- _ O
issue -X- _ O
, -X- _ O
NMT -X- _ B-MethodName
attempts -X- _ O
to -X- _ O
utilize -X- _ O
a -X- _ O
monolingual -X- _ O
corpus -X- _ O
to -X- _ O
get -X- _ O
better -X- _ O
at -X- _ O
translation -X- _ O
for -X- _ O
low -X- _ O
resource -X- _ O
language -X- _ O
pairs -X- _ O
. -X- _ O

Neural -X- _ B-MethodName
machine -X- _ I-MethodName
translation -X- _ I-MethodName
( -X- _ O
NMT -X- _ B-MethodName
) -X- _ O
is -X- _ O
a -X- _ O
widely -X- _ O
accepted -X- _ O
approach -X- _ O
in -X- _ O
the -X- _ O
machine -X- _ B-TaskName
translation -X- _ I-TaskName
( -X- _ O
MT -X- _ B-TaskName
) -X- _ O
community -X- _ O
, -X- _ O
translating -X- _ O
from -X- _ O
one -X- _ O
natural -X- _ O
language -X- _ O
to -X- _ O
another -X- _ O
natural -X- _ O
language -X- _ O
. -X- _ O

Zero -X- _ B-TaskName
- -X- _ I-TaskName
Shot -X- _ I-TaskName
Neural -X- _ I-TaskName
Machine -X- _ I-TaskName
Translation -X- _ I-TaskName
: -X- _ O
Russian -X- _ O
- -X- _ O
Hindi -X- _ O
@LoResMT -X- _ O
2020 -X- _ O
. -X- _ O

Also -X- _ O
, -X- _ O
thank -X- _ O
to -X- _ O
LoResMT -X- _ O
2020 -X- _ O
shared -X- _ O
task -X- _ O
organizers -X- _ O
. -X- _ O

We -X- _ O
would -X- _ O
like -X- _ O
to -X- _ O
thank -X- _ O
Center -X- _ O
for -X- _ O
Natural -X- _ O
Language -X- _ O
Processing -X- _ O
( -X- _ O
CNLP -X- _ O
) -X- _ O
and -X- _ O
Department -X- _ O
of -X- _ O
Computer -X- _ O
Science -X- _ O
and -X- _ O
Engineering -X- _ O
at -X- _ O
National -X- _ O
Institute -X- _ O
of -X- _ O
Technology -X- _ O
, -X- _ O
Silchar -X- _ O
, -X- _ O
India -X- _ O
for -X- _ O
providing -X- _ O
the -X- _ O
requisite -X- _ O
support -X- _ O
and -X- _ O
infrastructure -X- _ O
to -X- _ O
execute -X- _ O
this -X- _ O
work -X- _ O
. -X- _ O

Acknowledgement -X- _ O
. -X- _ O

The -X- _ O
obtained -X- _ O
scores -X- _ O
and -X- _ O
closely -X- _ O
observed -X- _ O
predicted -X- _ O
output -X- _ O
remarks -X- _ O
that -X- _ O
our -X- _ O
future -X- _ O
works -X- _ O
require -X- _ O
significant -X- _ O
improvement -X- _ O
to -X- _ O
achieve -X- _ O
better -X- _ O
translation -X- _ O
accuracies -X- _ O
in -X- _ O
both -X- _ O
directions -X- _ O
. -X- _ O

Conclusion -X- _ O
and -X- _ O
Future -X- _ O
Work -X- _ O
. -X- _ O

This -X- _ O
tokenizer -X- _ O
is -X- _ O
specifically -X- _ O
designed -X- _ O
for -X- _ O
Indic -X- _ O
languages -X- _ O
, -X- _ O
in -X- _ O
order -X- _ O
to -X- _ O
improve -X- _ O
the -X- _ O
overall -X- _ O
performance -X- _ O
of -X- _ O
predictive -X- _ O
models -X- _ O
in -X- _ O
Hindi -X- _ O
languages -X- _ O
. -X- _ O

To -X- _ O
achieve -X- _ O
better -X- _ O
translation -X- _ O
accuracy -X- _ O
, -X- _ O
we -X- _ O
need -X- _ O
to -X- _ O
improve -X- _ O
both -X- _ O
adequacy -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
fluency -X- _ O
of -X- _ O
predicted -X- _ O
translations -X- _ O
. -X- _ O

Moreover -X- _ O
, -X- _ O
from -X- _ O
the -X- _ O
predicted -X- _ O
translation -X- _ O
as -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
2 -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
quite -X- _ O
clear -X- _ O
that -X- _ O
the -X- _ O
translation -X- _ O
accuracy -X- _ O
is -X- _ O
very -X- _ O
poor -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
adequacy -X- _ O
but -X- _ O
better -X- _ O
in -X- _ O
the -X- _ O
fluency -X- _ O
factor -X- _ O
of -X- _ O
translation -X- _ O
. -X- _ O

However -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
to -X- _ O
be -X- _ O
noted -X- _ O
that -X- _ O
with -X- _ O
increasing -X- _ O
monolingual -X- _ O
data -X- _ O
, -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
our -X- _ O
systems -X- _ O
improves -X- _ O
. -X- _ O

From -X- _ O
Table -X- _ O
2 -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
observed -X- _ O
that -X- _ O
our -X- _ O
scores -X- _ O
are -X- _ O
very -X- _ O
low -X- _ O
. -X- _ O

We -X- _ O
have -X- _ O
submitted -X- _ O
two -X- _ O
systems -X- _ O
result -X- _ O
, -X- _ O
one -X- _ O
only -X- _ O
using -X- _ O
provided -X- _ O
monolingual -X- _ O
data -X- _ O
( -X- _ O
extension -X- _ O
-a -X- _ O
) -X- _ O
and -X- _ O
another -X- _ O
with -X- _ O
external -X- _ O
monolingual -X- _ O
data -X- _ O
addition -X- _ O
of -X- _ O
provided -X- _ O
monolingual -X- _ O
data -X- _ O
( -X- _ O
extension -X- _ O
-c -X- _ O
) -X- _ O
and -X- _ O
the -X- _ O
same -X- _ O
have -X- _ O
been -X- _ O
reported -X- _ O
in -X- _ O
Table -X- _ O
2 -X- _ O
. -X- _ O

For -X- _ O
the -X- _ O
Russian -X- _ O
- -X- _ O
Hindi -X- _ O
language -X- _ O
pair -X- _ O
, -X- _ O
only -X- _ O
our -X- _ O
team -X- _ O
participated -X- _ O
and -X- _ O
our -X- _ O
team -X- _ O
name -X- _ O
is -X- _ O
CNLP -X- _ O
- -X- _ O
NITS -X- _ O
. -X- _ O

Result -X- _ O
and -X- _ O
Analysis -X- _ O
. -X- _ O

Also -X- _ O
, -X- _ O
for -X- _ O
leveraging -X- _ O
the -X- _ O
model -X- _ O
features -X- _ O
, -X- _ O
we -X- _ O
have -X- _ O
followed -X- _ O
the -X- _ O
settings -X- _ O
of -X- _ O
( -X- _ O
Song -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O

Experimental -X- _ O
Setup -X- _ O
. -X- _ O

Experiment -X- _ O
. -X- _ O

Here -X- _ O
simply -X- _ O
backtranslation -X- _ O
is -X- _ O
employed -X- _ O
to -X- _ O
generate -X- _ O
pseudo -X- _ O
bilin- -X- _ O
. -X- _ O

Only -X- _ O
the -X- _ O
monolingual -X- _ O
data -X- _ O
is -X- _ O
used -X- _ O
here -X- _ O
. -X- _ O

Since -X- _ O
, -X- _ O
the -X- _ O
parallel -X- _ O
data -X- _ O
is -X- _ O
not -X- _ O
made -X- _ O
available -X- _ O
by -X- _ O
the -X- _ O
LoResMT -X- _ O
2020 -X- _ O
organizers -X- _ O
for -X- _ O
this -X- _ O
specific -X- _ O
task -X- _ O
, -X- _ O
we -X- _ O
have -X- _ O
undertaken -X- _ O
the -X- _ O
unsupervised -X- _ O
approach -X- _ O
as -X- _ O
followed -X- _ O
by -X- _ O
( -X- _ O
Song -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O

Fine -X- _ O
Tuning -X- _ O
. -X- _ O

t -X- _ O
denotes -X- _ O
the -X- _ O
word -X- _ O
position -X- _ O
. -X- _ O

LF -X- _ O
( -X- _ O
θ -X- _ O
; -X- _ O
S -X- _ O
) -X- _ O
= -X- _ O
1 -X- _ O
|S| -X- _ O
Σ -X- _ O
s∈S -X- _ O
log -X- _ O
P -X- _ O
( -X- _ O
s -X- _ O
u -X- _ O
: -X- _ O
v -X- _ O
|s -X- _ O
\u -X- _ O
: -X- _ O
v -X- _ O
; -X- _ O
θ -X- _ O
) -X- _ O
= -X- _ O
1 -X- _ O
|S| -X- _ O
Σ -X- _ O
s∈S -X- _ O
log -X- _ O
v -X- _ O
t -X- _ O
= -X- _ O
u -X- _ O
P -X- _ O
( -X- _ O
s -X- _ O
u -X- _ O
: -X- _ O
v -X- _ O
t -X- _ O
|s -X- _ O
u -X- _ O
: -X- _ O
v -X- _ O
< -X- _ O
t -X- _ O
, -X- _ O
s -X- _ O
\u -X- _ O
: -X- _ O
v -X- _ O
; -X- _ O
θ -X- _ O
) -X- _ O
. -X- _ O

And -X- _ O
in -X- _ O
a -X- _ O
particular -X- _ O
sentence -X- _ O
s -X- _ O
, -X- _ O
the -X- _ O
region -X- _ O
from -X- _ O
u -X- _ O
to -X- _ O
v -X- _ O
is -X- _ O
masked -X- _ O
, -X- _ O
such -X- _ O
that -X- _ O
the -X- _ O
sentence -X- _ O
length -X- _ O
remains -X- _ O
constant -X- _ O
. -X- _ O

Here -X- _ O
, -X- _ O
s -X- _ O
belongs -X- _ O
to -X- _ O
the -X- _ O
source -X- _ O
sentence -X- _ O
corpus -X- _ O
S. -X- _ O

Pre -X- _ O
- -X- _ O
training -X- _ O
. -X- _ O

The -X- _ O
model -X- _ O
details -X- _ O
are -X- _ O
further -X- _ O
described -X- _ O
in -X- _ O
Section -X- _ O
4.1 -X- _ O
and -X- _ O
4.2 -X- _ O
, -X- _ O
where -X- _ O
we -X- _ O
have -X- _ O
shown -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
and -X- _ O
fine -X- _ O
tuning -X- _ O
step -X- _ O
respectively -X- _ O
. -X- _ O

System -X- _ O
Description -X- _ O
. -X- _ O

Dataset -X- _ O
Description -X- _ O
. -X- _ O

Attention -X- _ O
. -X- _ O

( -X- _ O
Song -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
without -X- _ O
us- -X- _ O
X -X- _ O
8 -X- _ O
X -X- _ O
4 -X- _ O
X -X- _ O
7 -X- _ O
X -X- _ O
1 -X- _ O
X -X- _ O
2 -X- _ O
X -X- _ O
3 -X- _ O
_ -X- _ O
X -X- _ O
6 -X- _ O
_ -X- _ O
_ -X- _ O
_ -X- _ O
_ -X- _ O
_ -X- _ O
Encoder -X- _ O
Decoder -X- _ O
_ -X- _ O
_ -X- _ O
X -X- _ O
5 -X- _ O
. -X- _ O

There -X- _ O
is -X- _ O
a -X- _ O
lack -X- _ O
of -X- _ O
background -X- _ O
work -X- _ O
on -X- _ O
Russian -X- _ O
- -X- _ O
Hindi -X- _ O
translation -X- _ O
. -X- _ O

Related -X- _ O
Work -X- _ O
. -X- _ O

Generally -X- _ O
, -X- _ O
language -X- _ O
pairs -X- _ O
can -X- _ O
be -X- _ O
considered -X- _ O
as -X- _ O
low -X- _ O
- -X- _ O
resource -X- _ O
when -X- _ O
training -X- _ O
data -X- _ O
is -X- _ O
less -X- _ O
than -X- _ O
a -X- _ O
million -X- _ O
( -X- _ O
Kocmi -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O

Despite -X- _ O
modifying -X- _ O
NMT -X- _ O
architecture -X- _ O
, -X- _ O
it -X- _ O
needs -X- _ O
reasonable -X- _ O
parallel -X- _ O
training -X- _ O
data -X- _ O
which -X- _ O
is -X- _ O
a -X- _ O
challenge -X- _ O
for -X- _ O
low -X- _ O
resource -X- _ O
language -X- _ O
pair -X- _ O
translation -X- _ O
. -X- _ O

Introduction -X- _ O
. -X- _ O

We -X- _ O
have -X- _ O
participated -X- _ O
in -X- _ O
the -X- _ O
same -X- _ O
shared -X- _ O
task -X- _ O
with -X- _ O
our -X- _ O
team -X- _ O
name -X- _ O
CNLP -X- _ O
- -X- _ O
NITS -X- _ O
for -X- _ O
the -X- _ O
Russian -X- _ O
- -X- _ O
Hindi -X- _ O
language -X- _ O
pair -X- _ O
. -X- _ O

Here -X- _ O
, -X- _ O
the -X- _ O
parallel -X- _ O
corpus -X- _ O
is -X- _ O
not -X- _ O
used -X- _ O
and -X- _ O
only -X- _ O
monolingual -X- _ O
corpora -X- _ O
is -X- _ O
allowed -X- _ O
. -X- _ O

The -X- _ O
availability -X- _ O
of -X- _ O
a -X- _ O
parallel -X- _ O
corpus -X- _ O
in -X- _ O
low -X- _ O
resource -X- _ O
language -X- _ O
pairs -X- _ O
is -X- _ O
one -X- _ O
of -X- _ O
the -X- _ O
challenging -X- _ O
tasks -X- _ O
in -X- _ O
MT -X- _ O
. -X- _ O

Although -X- _ O
, -X- _ O
NMT -X- _ O
shows -X- _ O
remarkable -X- _ O
performance -X- _ O
in -X- _ O
both -X- _ O
high -X- _ O
and -X- _ O
low -X- _ O
resource -X- _ O
languages -X- _ O
, -X- _ O
it -X- _ O
needs -X- _ O
sufficient -X- _ O
training -X- _ O
corpus -X- _ O
. -X- _ O

