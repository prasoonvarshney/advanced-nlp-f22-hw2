-DOCSTART- -X- O
The -X- _ O
authors -X- _ O
would -X- _ O
like -X- _ O
to -X- _ O
thank -X- _ O
Chuck -X- _ O
Rosenberg -X- _ O
, -X- _ O
Tom -X- _ O
Duerig -X- _ O
, -X- _ O
Neil -X- _ O
Alldrin -X- _ O
, -X- _ O
Zhen -X- _ O
Li -X- _ O
, -X- _ O
Filipe -X- _ O
Gonc -X- _ O
Â¸alves -X- _ O
, -X- _ O
Mia -X- _ O
Chen -X- _ O
, -X- _ O
Zhifeng -X- _ O
Chen -X- _ O
, -X- _ O
Samy -X- _ O
Bengio -X- _ O
, -X- _ O
Yu -X- _ O
Zhang -X- _ O
, -X- _ O
Kevin -X- _ O
Swersky -X- _ O
, -X- _ O
Felix -X- _ O
Hill -X- _ O
and -X- _ O
the -X- _ O
ACL -X- _ O
anonymous -X- _ O
reviewers -X- _ O
for -X- _ O
their -X- _ O
valuable -X- _ O
advice -X- _ O
and -X- _ O
feedback -X- _ O
. -X- _ O

Acknowledgments -X- _ O
. -X- _ O

We -X- _ O
expect -X- _ O
that -X- _ O
integrating -X- _ O
Picturebook -X- _ B-MethodName
with -X- _ O
these -X- _ O
embeddings -X- _ O
to -X- _ O
lead -X- _ O
to -X- _ O
further -X- _ O
performance -X- _ O
improvements -X- _ O
as -X- _ O
well -X- _ O
. -X- _ O

Recently -X- _ O
, -X- _ O
contextualized -X- _ O
word -X- _ O
representations -X- _ O
have -X- _ O
shown -X- _ O
promising -X- _ O
improvements -X- _ O
when -X- _ O
combined -X- _ O
with -X- _ O
existing -X- _ O
embeddings -X- _ O
( -X- _ O
Melamud -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016;Peters -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017;McCann -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017;Peters -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O

In -X- _ O
future -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
would -X- _ O
like -X- _ O
to -X- _ O
explore -X- _ O
other -X- _ O
aspects -X- _ O
of -X- _ O
search -X- _ O
engines -X- _ O
for -X- _ O
language -X- _ O
grounding -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
the -X- _ O
effect -X- _ O
these -X- _ O
embeddings -X- _ O
may -X- _ O
have -X- _ O
on -X- _ O
learning -X- _ O
generic -X- _ O
sentence -X- _ O
representations -X- _ O
( -X- _ O
Kiros -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015b;Hill -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016;Conneau -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017a;Logeswaran -X- _ O
and -X- _ O
Lee -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O

Through -X- _ O
the -X- _ O
use -X- _ O
of -X- _ O
multimodal -X- _ O
gating -X- _ O
, -X- _ O
our -X- _ O
models -X- _ O
lead -X- _ O
to -X- _ O
interpretable -X- _ O
weightings -X- _ O
of -X- _ O
abstract -X- _ O
vs -X- _ O
concrete -X- _ O
words -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
work -X- _ O
we -X- _ O
demonstrated -X- _ O
that -X- _ O
Picturebook -X- _ B-MethodName
complements -X- _ O
traditional -X- _ O
embeddings -X- _ O
on -X- _ O
a -X- _ O
wide -X- _ O
variety -X- _ O
of -X- _ O
tasks -X- _ O
. -X- _ O

Picturebook -X- _ B-MethodName
embeddings -X- _ O
offer -X- _ O
an -X- _ O
alternative -X- _ O
approach -X- _ O
to -X- _ O
constructing -X- _ O
word -X- _ O
representations -X- _ O
grounded -X- _ O
in -X- _ O
image -X- _ O
search -X- _ O
engines -X- _ O
. -X- _ O

Traditionally -X- _ O
, -X- _ O
word -X- _ O
representations -X- _ O
have -X- _ O
been -X- _ O
built -X- _ O
on -X- _ O
co -X- _ O
- -X- _ O
occurrences -X- _ O
of -X- _ O
neighbouring -X- _ O
words -X- _ O
; -X- _ O
and -X- _ O
such -X- _ O
representations -X- _ O
only -X- _ O
make -X- _ O
use -X- _ O
of -X- _ O
the -X- _ O
statistics -X- _ O
of -X- _ O
the -X- _ O
text -X- _ O
distribution -X- _ O
. -X- _ O

Conclusion -X- _ O
. -X- _ O

We -X- _ O
also -X- _ O
observe -X- _ O
tags -X- _ O
which -X- _ O
are -X- _ O
exclusively -X- _ O
Glove -X- _ B-MethodName
oriented -X- _ O
, -X- _ O
namely -X- _ O
adverbs -X- _ O
( -X- _ O
RB -X- _ O
) -X- _ O
, -X- _ O
prepositions -X- _ O
( -X- _ O
IN -X- _ O
) -X- _ O
and -X- _ O
determiners -X- _ O
( -X- _ O
DT -X- _ O
) -X- _ O
. -X- _ O

The -X- _ O
highest -X- _ O
scoring -X- _ O
Picturebook -X- _ B-MethodName
words -X- _ O
are -X- _ O
almost -X- _ O
all -X- _ O
singular -X- _ O
and -X- _ O
plural -X- _ O
nouns -X- _ O
( -X- _ O
NN -X- _ O
/ -X- _ O
NNS -X- _ O
) -X- _ O
. -X- _ O

These -X- _ O
results -X- _ O
are -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
1 -X- _ O
. -X- _ O

MIXER -X- _ O
( -X- _ O
Ranzato -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
21.8 -X- _ O
Beam -X- _ O
Search -X- _ O
Optimization -X- _ O
( -X- _ O
Wiseman -X- _ O
and -X- _ O
Rush -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
25.5 -X- _ O
Actor -X- _ O
- -X- _ O
Critic -X- _ O
+ -X- _ O
Log -X- _ O
Likelihood -X- _ O
( -X- _ O
Bahdanau -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
28.5 -X- _ O
Neural -X- _ O
Phrase -X- _ O
- -X- _ O
based -X- _ O
Machine -X- _ O
Translation -X- _ O
( -X- _ O
Huang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018a -X- _ O
) -X- _ O
29.9 -X- _ O
Finally -X- _ O
we -X- _ O
analyze -X- _ O
the -X- _ O
parts -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
speech -X- _ O
( -X- _ O
POS -X- _ O
) -X- _ O
of -X- _ O
the -X- _ O
highest -X- _ O
activated -X- _ O
words -X- _ O
. -X- _ O

Appendix -X- _ O
A -X- _ O
contains -X- _ O
examples -X- _ O
of -X- _ O
words -X- _ O
that -X- _ O
most -X- _ O
strongly -X- _ O
activate -X- _ O
Glove -X- _ B-MethodName
and -X- _ O
Picturebook -X- _ B-MethodName
gates -X- _ O
. -X- _ O

These -X- _ O
results -X- _ O
provide -X- _ O
evidence -X- _ O
that -X- _ O
our -X- _ O
gating -X- _ O
mechanism -X- _ O
actively -X- _ O
prefers -X- _ O
Glove -X- _ B-MethodName
embeddings -X- _ O
for -X- _ O
abstract -X- _ O
words -X- _ O
and -X- _ O
Picturebook -X- _ B-MethodName
embeddings -X- _ O
for -X- _ O
concrete -X- _ O
words -X- _ O
. -X- _ O

Moreover -X- _ O
, -X- _ O
this -X- _ O
result -X- _ O
holds -X- _ O
true -X- _ O
across -X- _ O
all -X- _ O
datasets -X- _ O
, -X- _ O
even -X- _ O
those -X- _ O
that -X- _ O
are -X- _ O
not -X- _ O
inherently -X- _ O
visual -X- _ O
. -X- _ O

We -X- _ O
observe -X- _ O
that -X- _ O
gates -X- _ O
have -X- _ O
high -X- _ O
correlations -X- _ O
with -X- _ O
concreteness -X- _ B-MetricName
ratings -X- _ I-MetricName
and -X- _ O
strong -X- _ O
negative -X- _ O
correlations -X- _ O
with -X- _ O
image -X- _ B-MetricName
dispersion -X- _ I-MetricName
scores -X- _ O
. -X- _ O

Table -X- _ O
10 -X- _ O
illustrates -X- _ O
the -X- _ O
result -X- _ O
of -X- _ O
this -X- _ O
analysis -X- _ O
. -X- _ O

We -X- _ O
then -X- _ O
compute -X- _ O
the -X- _ O
Spearman -X- _ B-MetricName
correlation -X- _ I-MetricName
of -X- _ O
mean -X- _ O
gate -X- _ O
activations -X- _ O
with -X- _ O
a -X- _ O
) -X- _ O
concreteness -X- _ B-MetricName
ratings -X- _ I-MetricName
and -X- _ O
b -X- _ O
) -X- _ O
image -X- _ B-MetricName
dispersion -X- _ I-MetricName
scores -X- _ O
. -X- _ O

4 -X- _ O
For -X- _ O
concreteness -X- _ O
ratings -X- _ O
, -X- _ O
we -X- _ O
take -X- _ O
the -X- _ O
intersection -X- _ O
of -X- _ O
words -X- _ O
that -X- _ O
have -X- _ O
ratings -X- _ O
with -X- _ O
the -X- _ O
dataset -X- _ O
vocabulary -X- _ O
. -X- _ O

For -X- _ O
each -X- _ O
word -X- _ O
, -X- _ O
we -X- _ O
compute -X- _ O
the -X- _ O
mean -X- _ O
gate -X- _ O
activation -X- _ O
value -X- _ O
for -X- _ O
Picturebook -X- _ B-MethodName
embeddings -X- _ O
. -X- _ O

On -X- _ O
the -X- _ O
other -X- _ O
hand -X- _ O
, -X- _ O
low -X- _ O
dispersion -X- _ O
ratings -X- _ O
were -X- _ O
more -X- _ O
associated -X- _ O
with -X- _ O
concrete -X- _ O
words -X- _ O
. -X- _ O

( -X- _ O
2014 -X- _ O
) -X- _ O
that -X- _ O
abstract -X- _ O
words -X- _ O
tend -X- _ O
to -X- _ O
have -X- _ O
higher -X- _ O
dispersion -X- _ O
ratings -X- _ O
, -X- _ O
due -X- _ O
to -X- _ O
having -X- _ O
much -X- _ O
higher -X- _ O
variety -X- _ O
in -X- _ O
the -X- _ O
types -X- _ O
of -X- _ O
images -X- _ O
returned -X- _ O
from -X- _ O
a -X- _ O
query -X- _ O
. -X- _ O

It -X- _ O
was -X- _ O
shown -X- _ O
in -X- _ O
Kiela -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

Image -X- _ O
dispersion -X- _ O
is -X- _ O
the -X- _ O
average -X- _ O
distance -X- _ O
between -X- _ O
all -X- _ O
pairs -X- _ O
of -X- _ O
images -X- _ O
returned -X- _ O
from -X- _ O
a -X- _ O
search -X- _ O
query -X- _ O
. -X- _ O

( -X- _ O
2013 -X- _ O
) -X- _ O
which -X- _ O
provides -X- _ O
ratings -X- _ O
for -X- _ O
40,000 -X- _ O
English -X- _ O
lemmas -X- _ O
. -X- _ O

For -X- _ O
concreteness -X- _ O
ratings -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
dataset -X- _ O
of -X- _ O
Brysbaert -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

In -X- _ O
our -X- _ O
first -X- _ O
experiment -X- _ O
, -X- _ O
we -X- _ O
aim -X- _ O
to -X- _ O
determine -X- _ O
how -X- _ O
well -X- _ O
gate -X- _ O
activations -X- _ O
correlate -X- _ O
to -X- _ O
a -X- _ O
) -X- _ O
human -X- _ O
judgments -X- _ O
of -X- _ O
concreteness -X- _ O
and -X- _ O
b -X- _ O
) -X- _ O
image -X- _ O
dispersion -X- _ O
( -X- _ O
Kiela -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
section -X- _ O
we -X- _ O
perform -X- _ O
an -X- _ O
extensive -X- _ O
analysis -X- _ O
of -X- _ O
the -X- _ O
gating -X- _ O
mechanism -X- _ O
for -X- _ O
models -X- _ O
trained -X- _ O
across -X- _ O
datasets -X- _ O
used -X- _ O
in -X- _ O
our -X- _ O
experiments -X- _ O
. -X- _ O

Gate -X- _ O
Analysis -X- _ O
. -X- _ O

This -X- _ O
indicates -X- _ O
that -X- _ O
while -X- _ O
our -X- _ O
embeddings -X- _ O
are -X- _ O
useful -X- _ O
for -X- _ O
smaller -X- _ O
MT -X- _ B-TaskName
experiments -X- _ O
, -X- _ O
further -X- _ O
research -X- _ O
is -X- _ O
needed -X- _ O
on -X- _ O
how -X- _ O
to -X- _ O
best -X- _ O
incorporate -X- _ O
grounded -X- _ O
representations -X- _ O
in -X- _ O
larger -X- _ O
translation -X- _ O
tasks -X- _ O
. -X- _ O

However -X- _ O
, -X- _ O
we -X- _ O
were -X- _ O
not -X- _ O
able -X- _ O
to -X- _ O
improve -X- _ O
upon -X- _ O
BLEU -X- _ B-MetricName
scores -X- _ O
from -X- _ O
equivalent -X- _ O
models -X- _ O
that -X- _ O
do -X- _ O
not -X- _ O
use -X- _ O
Picturebook -X- _ B-MethodName
. -X- _ O

For -X- _ O
these -X- _ O
tasks -X- _ O
, -X- _ O
we -X- _ O
found -X- _ O
that -X- _ O
models -X- _ O
that -X- _ O
incorporate -X- _ O
Picturebook -X- _ B-MethodName
led -X- _ O
to -X- _ O
faster -X- _ O
convergence -X- _ O
. -X- _ O

We -X- _ O
explored -X- _ O
the -X- _ O
use -X- _ O
of -X- _ O
Picturebook -X- _ B-MethodName
for -X- _ O
larger -X- _ O
machine -X- _ B-TaskName
translation -X- _ I-TaskName
tasks -X- _ O
, -X- _ O
including -X- _ O
the -X- _ O
popular -X- _ O
WMT14 -X- _ B-DatasetName
benchmarks -X- _ O
. -X- _ O

Limitations -X- _ O
. -X- _ O

We -X- _ O
also -X- _ O
note -X- _ O
that -X- _ O
our -X- _ O
models -X- _ O
may -X- _ O
not -X- _ O
be -X- _ O
directly -X- _ O
comparable -X- _ O
to -X- _ O
previously -X- _ O
published -X- _ O
seq2seq -X- _ O
models -X- _ O
from -X- _ O
( -X- _ O
Wiseman -X- _ O
and -X- _ O
Rush -X- _ O
, -X- _ O
2016;Bahdanau -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
since -X- _ O
we -X- _ O
used -X- _ O
a -X- _ O
deeper -X- _ O
encoder -X- _ O
and -X- _ O
decoder -X- _ O
. -X- _ O

We -X- _ O
note -X- _ O
that -X- _ O
the -X- _ O
NPMT -X- _ O
is -X- _ O
not -X- _ O
a -X- _ O
seq2seq -X- _ O
model -X- _ O
and -X- _ O
can -X- _ O
be -X- _ O
augmented -X- _ O
with -X- _ O
our -X- _ O
Picturebook -X- _ B-MethodName
embeddings -X- _ O
. -X- _ O

We -X- _ O
( -X- _ O
Huang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018a -X- _ O
) -X- _ O
. -X- _ O

We -X- _ O
also -X- _ O
report -X- _ O
results -X- _ O
for -X- _ O
the -X- _ O
IWSLT -X- _ B-DatasetName
2014 -X- _ I-DatasetName
German -X- _ I-DatasetName
- -X- _ I-DatasetName
English -X- _ I-DatasetName
task -X- _ O
( -X- _ O
Cettolo -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
in -X- _ O
Table -X- _ O
9 -X- _ O
. -X- _ O

Compared -X- _ O
to -X- _ O
our -X- _ O
baseline -X- _ O
, -X- _ O
we -X- _ O
report -X- _ O
a -X- _ O
gain -X- _ O
of -X- _ O
0.3 -X- _ B-MetricValue
and -X- _ O
1.1 -X- _ B-MetricValue
BLEU -X- _ B-MetricName
for -X- _ O
German -X- _ O
! -X- _ O
English -X- _ O
and -X- _ O
English -X- _ O
! -X- _ O
German -X- _ O
respectively -X- _ O
. -X- _ O

On -X- _ O
the -X- _ O
English -X- _ O
! -X- _ O
French -X- _ O
task -X- _ O
, -X- _ O
the -X- _ O
Picturebook -X- _ B-MethodName
models -X- _ O
do -X- _ O
on -X- _ O
average -X- _ O
1.2 -X- _ B-MetricValue
BLEU -X- _ B-MetricName
better -X- _ O
or -X- _ O
1.0 -X- _ B-MetricValue
METEOR -X- _ B-MetricName
over -X- _ O
our -X- _ O
baseline -X- _ O
. -X- _ O

We -X- _ O
suspect -X- _ O
this -X- _ O
is -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
fact -X- _ O
that -X- _ O
we -X- _ O
did -X- _ O
not -X- _ O
use -X- _ O
BPE -X- _ O
. -X- _ O

On -X- _ O
the -X- _ O
German -X- _ O
task -X- _ O
, -X- _ O
compared -X- _ O
to -X- _ O
the -X- _ O
previously -X- _ O
best -X- _ O
published -X- _ O
results -X- _ O
( -X- _ O
Caglayan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
we -X- _ O
do -X- _ O
better -X- _ O
in -X- _ O
BLEU -X- _ B-MetricName
but -X- _ O
slightly -X- _ O
worse -X- _ O
in -X- _ O
METEOR -X- _ B-MetricName
. -X- _ O

On -X- _ O
the -X- _ O
English -X- _ O
! -X- _ O
German -X- _ O
tasks -X- _ O
, -X- _ O
we -X- _ O
find -X- _ O
our -X- _ O
Picturebook -X- _ B-MethodName
model -X- _ O
to -X- _ O
perform -X- _ O
on -X- _ O
average -X- _ O
0.8 -X- _ B-MetricValue
BLEU -X- _ B-MetricName
or -X- _ O
0.7 -X- _ B-MetricValue
METEOR -X- _ B-MetricName
over -X- _ O
our -X- _ O
baseline -X- _ O
. -X- _ O

We -X- _ O
did -X- _ O
not -X- _ O
experiment -X- _ O
with -X- _ O
regularizing -X- _ O
the -X- _ O
norm -X- _ O
of -X- _ O
the -X- _ O
embeddings -X- _ O
. -X- _ O

We -X- _ O
find -X- _ O
the -X- _ O
gating -X- _ O
mechanism -X- _ O
not -X- _ O
to -X- _ O
help -X- _ O
much -X- _ O
with -X- _ O
the -X- _ O
MT -X- _ B-TaskName
task -X- _ O
since -X- _ O
the -X- _ O
trainable -X- _ O
embeddings -X- _ O
are -X- _ O
free -X- _ O
to -X- _ O
change -X- _ O
their -X- _ O
norm -X- _ O
magnitudes -X- _ O
. -X- _ O

Since -X- _ O
seq2seq -X- _ O
MT -X- _ B-TaskName
models -X- _ O
are -X- _ O
typically -X- _ O
trained -X- _ O
without -X- _ O
Glove -X- _ B-MethodName
embeddings -X- _ O
, -X- _ O
we -X- _ O
also -X- _ O
did -X- _ O
not -X- _ O
use -X- _ O
Glove -X- _ B-MethodName
embeddings -X- _ O
for -X- _ O
this -X- _ O
task -X- _ O
, -X- _ O
but -X- _ O
rather -X- _ O
we -X- _ O
combine -X- _ O
randomly -X- _ O
initialized -X- _ O
learnable -X- _ O
embeddings -X- _ O
with -X- _ O
the -X- _ O
fixed -X- _ O
Picturebook -X- _ B-MethodName
embeddings -X- _ O
. -X- _ O

This -X- _ O
is -X- _ O
also -X- _ O
highlighted -X- _ O
where -X- _ O
our -X- _ O
French -X- _ O
models -X- _ O
perform -X- _ O
better -X- _ O
than -X- _ O
our -X- _ O
German -X- _ O
models -X- _ O
relatively -X- _ O
, -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
compounding -X- _ O
nature -X- _ O
of -X- _ O
German -X- _ O
words -X- _ O
. -X- _ O

We -X- _ O
believe -X- _ O
this -X- _ O
is -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
fact -X- _ O
we -X- _ O
did -X- _ O
not -X- _ O
use -X- _ O
Byte -X- _ O
Pair -X- _ O
Encoding -X- _ O
( -X- _ O
BPE -X- _ O
) -X- _ O
( -X- _ O
Sennrich -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
ME -X- _ B-MetricName
- -X- _ I-MetricName
TEOR -X- _ I-MetricName
captures -X- _ O
word -X- _ O
stemming -X- _ O
( -X- _ O
Denkowski -X- _ O
and -X- _ O
Lavie -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
. -X- _ O

We -X- _ O
find -X- _ O
our -X- _ O
models -X- _ O
to -X- _ O
perform -X- _ O
better -X- _ O
in -X- _ O
BLEU -X- _ B-MetricName
than -X- _ O
METEOR -X- _ B-MetricName
relatively -X- _ O
com -X- _ O
- -X- _ O
pared -X- _ O
to -X- _ O
( -X- _ O
Caglayan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
. -X- _ O

Table -X- _ O
7 -X- _ O
summarizes -X- _ O
our -X- _ O
English -X- _ O
! -X- _ O
German -X- _ O
results -X- _ O
and -X- _ O
Table -X- _ O
8 -X- _ O
summarizes -X- _ O
our -X- _ O
English -X- _ O
! -X- _ O
French -X- _ O
results -X- _ O
. -X- _ O

We -X- _ O
use -X- _ O
the -X- _ O
standard -X- _ O
seq2seq -X- _ O
( -X- _ O
Sutskever -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
with -X- _ O
content -X- _ O
- -X- _ O
based -X- _ O
attention -X- _ O
( -X- _ O
Bahdanau -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
model -X- _ O
and -X- _ O
we -X- _ O
describe -X- _ O
our -X- _ O
hyperparmeters -X- _ O
in -X- _ O
Appendix -X- _ O
B. -X- _ O

( -X- _ O
2017 -X- _ O
) -X- _ O
, -X- _ O
the -X- _ O
winner -X- _ O
of -X- _ O
the -X- _ O
WMT -X- _ O
17 -X- _ O
Multimodal -X- _ O
Machine -X- _ O
Translation -X- _ O
competition -X- _ O
( -X- _ O
Elliott -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
. -X- _ O

We -X- _ O
compare -X- _ O
our -X- _ O
Picturebook -X- _ B-MethodName
models -X- _ O
with -X- _ O
other -X- _ O
text -X- _ O
- -X- _ O
only -X- _ O
nonensembled -X- _ O
models -X- _ O
on -X- _ O
the -X- _ O
Flickr -X- _ B-DatasetName
Test2016 -X- _ I-DatasetName
, -X- _ O
Flickr -X- _ B-DatasetName
Test2017 -X- _ I-DatasetName
and -X- _ O
MSCOCO -X- _ B-DatasetName
test -X- _ O
sets -X- _ O
from -X- _ O
Caglayan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

We -X- _ O
experiment -X- _ O
with -X- _ O
the -X- _ O
Multi30k -X- _ B-DatasetName
( -X- _ O
Elliott -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016(Elliott -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
) -X- _ O
dataset -X- _ O
for -X- _ O
MT -X- _ B-TaskName
. -X- _ O

Machine -X- _ B-TaskName
Translation -X- _ I-TaskName
. -X- _ O

( -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
are -X- _ O
more -X- _ O
sophisticated -X- _ O
methods -X- _ O
that -X- _ O
incorporate -X- _ O
generative -X- _ O
modelling -X- _ O
, -X- _ O
reinforcement -X- _ O
learning -X- _ O
and -X- _ O
attention -X- _ O
. -X- _ O

( -X- _ O
2018b -X- _ O
) -X- _ O
; -X- _ O
Lee -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

( -X- _ O
2018 -X- _ O
) -X- _ O
; -X- _ O
Huang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

Our -X- _ O
reported -X- _ O
results -X- _ O
have -X- _ O
been -X- _ O
recently -X- _ O
outperformed -X- _ O
by -X- _ O
Gu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

However -X- _ O
, -X- _ O
using -X- _ O
contextual -X- _ O
gating -X- _ O
results -X- _ O
in -X- _ O
improvements -X- _ O
over -X- _ O
the -X- _ O
baseline -X- _ O
on -X- _ O
all -X- _ O
metrics -X- _ O
except -X- _ O
R@1 -X- _ B-MetricName
for -X- _ O
image -X- _ O
annotation -X- _ O
. -X- _ O

Glove+Picturebook -X- _ B-MethodName
improves -X- _ O
over -X- _ O
the -X- _ O
Glove -X- _ B-MethodName
baseline -X- _ O
for -X- _ O
image -X- _ O
search -X- _ O
but -X- _ O
falls -X- _ O
short -X- _ O
on -X- _ O
image -X- _ O
annotation -X- _ O
. -X- _ O

( -X- _ O
2017 -X- _ O
) -X- _ O
with -X- _ O
the -X- _ O
exception -X- _ O
of -X- _ O
Recall@10 -X- _ B-MetricName
for -X- _ O
image -X- _ O
annotation -X- _ O
, -X- _ O
where -X- _ O
it -X- _ O
performs -X- _ O
slightly -X- _ O
worse -X- _ O
. -X- _ O

Our -X- _ O
Glove -X- _ B-MethodName
baseline -X- _ O
was -X- _ O
able -X- _ O
to -X- _ O
match -X- _ O
or -X- _ O
outperform -X- _ O
the -X- _ O
reported -X- _ O
results -X- _ O
in -X- _ O
Faghri -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

BoW -X- _ O
( -X- _ O
Zhang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
88.8 -X- _ O
96.6 -X- _ O
92.2 -X- _ O
58.0 -X- _ O
68.9 -X- _ O
54.6 -X- _ O
90.4 -X- _ O
ngrams -X- _ O
( -X- _ O
Zhang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
92.0 -X- _ O
98.6 -X- _ O
95.6 -X- _ O
56.3 -X- _ O
68.5 -X- _ O
54.3 -X- _ O
92.0 -X- _ O
ngrams -X- _ O
TFIDF -X- _ O
( -X- _ O
Zhang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
92.4 -X- _ O
98.7 -X- _ O
95.4 -X- _ O
54.8 -X- _ O
68.5 -X- _ O
52.4 -X- _ O
91.5 -X- _ O
fastText -X- _ O
( -X- _ O
Joulin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
91 -X- _ O
Image -X- _ O
Annotation -X- _ O
Image -X- _ O
Search -X- _ O
Model -X- _ O
R@1 -X- _ B-MetricName
R@5 -X- _ B-MetricName
R@10 -X- _ B-MetricName
Med -X- _ B-MetricName
r -X- _ I-MetricName
R@1 -X- _ B-MetricName
R@5 -X- _ B-MetricName
R@10 -X- _ B-MetricName
Med -X- _ B-MetricName
r -X- _ I-MetricName
VSE++ -X- _ B-MethodName
( -X- _ O
Faghri -X- _ O
et -X- _ O
Table -X- _ O
6 -X- _ O
: -X- _ O
COCO -X- _ O
test -X- _ O
- -X- _ O
set -X- _ O
results -X- _ O
for -X- _ O
image -X- _ O
- -X- _ O
sentence -X- _ O
retrieval -X- _ O
experiments -X- _ O
. -X- _ O

Med -X- _ B-MetricName
r -X- _ I-MetricName
is -X- _ O
the -X- _ O
median -X- _ B-MetricName
rank -X- _ I-MetricName
( -X- _ O
low -X- _ O
is -X- _ O
good -X- _ O
) -X- _ O
. -X- _ O

R@K -X- _ B-MetricName
is -X- _ O
Recall@K -X- _ B-MetricName
( -X- _ O
high -X- _ O
is -X- _ O
good -X- _ O
) -X- _ O
. -X- _ O

Our -X- _ O
models -X- _ O
use -X- _ O
VSE++ -X- _ B-MethodName
. -X- _ O

P. -X- _ O

Amz -X- _ O
. -X- _ O

F. -X- _ O

Amz -X- _ O
. -X- _ O

A. -X- _ O

Yah -X- _ O
. -X- _ O

Yelp -X- _ O
F. -X- _ O

Model -X- _ O
AG -X- _ O
DBP -X- _ O
Yelp -X- _ O
P. -X- _ O

Table -X- _ O
6 -X- _ O
displays -X- _ O
our -X- _ O
results -X- _ O
on -X- _ O
this -X- _ O
task -X- _ O
. -X- _ O

Full -X- _ O
details -X- _ O
of -X- _ O
the -X- _ O
hyperparameters -X- _ O
are -X- _ O
in -X- _ O
Appendix -X- _ O
B. -X- _ O

As -X- _ O
in -X- _ O
previous -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
report -X- _ O
the -X- _ O
mean -X- _ B-MetricName
Recall@K -X- _ I-MetricName
( -X- _ O
R@K -X- _ B-MetricName
) -X- _ O
and -X- _ O
the -X- _ O
median -X- _ B-MetricName
rank -X- _ I-MetricName
over -X- _ O
1000 -X- _ O
images -X- _ O
and -X- _ O
5000 -X- _ O
sentences -X- _ O
. -X- _ O

We -X- _ O
re -X- _ O
- -X- _ O
implement -X- _ O
their -X- _ O
model -X- _ O
with -X- _ O
2 -X- _ O
modifications -X- _ O
: -X- _ O
1 -X- _ O
) -X- _ O
we -X- _ O
replace -X- _ O
the -X- _ O
unidirectional -X- _ O
LSTM -X- _ O
encoder -X- _ O
with -X- _ O
a -X- _ O
BiLSTM -X- _ O
- -X- _ O
Max -X- _ O
sentence -X- _ O
encoder -X- _ O
and -X- _ O
2 -X- _ O
) -X- _ O
we -X- _ O
use -X- _ O
Inception -X- _ B-MethodName
- -X- _ I-MethodName
V3 -X- _ I-MethodName
( -X- _ O
Szegedy -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
as -X- _ O
our -X- _ O
CNN -X- _ O
instead -X- _ O
of -X- _ O
ResNet -X- _ O
152 -X- _ O
( -X- _ O
He -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
. -X- _ O

( -X- _ O
2015a -X- _ O
) -X- _ O
by -X- _ O
using -X- _ O
hard -X- _ O
negatives -X- _ O
instead -X- _ O
of -X- _ O
summing -X- _ O
over -X- _ O
contrastive -X- _ O
examples -X- _ O
. -X- _ O

VSE++ -X- _ B-MethodName
improves -X- _ O
over -X- _ O
the -X- _ O
original -X- _ O
CNN -X- _ O
- -X- _ O
LSTM -X- _ O
embedding -X- _ O
method -X- _ O
of -X- _ O
Kiros -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

Here -X- _ O
, -X- _ O
we -X- _ O
utilize -X- _ O
VSE++ -X- _ B-MethodName
( -X- _ O
Faghri -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
as -X- _ O
our -X- _ O
base -X- _ O
model -X- _ O
and -X- _ O
evaluate -X- _ O
on -X- _ O
the -X- _ O
COCO -X- _ B-DatasetName
dataset -X- _ O
( -X- _ O
Lin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
. -X- _ O

We -X- _ O
next -X- _ O
consider -X- _ O
experiments -X- _ O
that -X- _ O
map -X- _ O
images -X- _ O
and -X- _ O
sentences -X- _ O
into -X- _ O
a -X- _ O
common -X- _ O
vector -X- _ O
space -X- _ O
for -X- _ O
retrieval -X- _ O
. -X- _ O

Image -X- _ B-TaskName
- -X- _ I-TaskName
Sentence -X- _ I-TaskName
Ranking -X- _ I-TaskName
. -X- _ O

We -X- _ O
note -X- _ O
that -X- _ O
the -X- _ O
best -X- _ O
performing -X- _ O
methods -X- _ O
on -X- _ O
these -X- _ O
tasks -X- _ O
are -X- _ O
based -X- _ O
on -X- _ O
convolutional -X- _ O
neural -X- _ O
networks -X- _ O
( -X- _ O
Conneau -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017b -X- _ O
) -X- _ O
. -X- _ O

This -X- _ O
result -X- _ O
shows -X- _ O
that -X- _ O
our -X- _ O
embeddings -X- _ O
are -X- _ O
able -X- _ O
to -X- _ O
work -X- _ O
as -X- _ O
a -X- _ O
general -X- _ O
text -X- _ O
embedding -X- _ O
, -X- _ O
though -X- _ O
they -X- _ O
typically -X- _ O
lag -X- _ O
behind -X- _ O
Glove -X- _ B-MethodName
. -X- _ O

Our -X- _ O
results -X- _ O
show -X- _ O
that -X- _ O
Picturebook -X- _ B-MethodName
embeddings -X- _ O
, -X- _ O
while -X- _ O
minimally -X- _ O
aiding -X- _ O
in -X- _ O
performance -X- _ O
, -X- _ O
can -X- _ O
perform -X- _ O
reasonably -X- _ O
well -X- _ O
on -X- _ O
their -X- _ O
own -X- _ O
-outperforming -X- _ O
the -X- _ O
n -X- _ O
- -X- _ O
gram -X- _ O
baselines -X- _ O
of -X- _ O
( -X- _ O
Zhang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
on -X- _ O
5 -X- _ O
out -X- _ O
of -X- _ O
7 -X- _ O
tasks -X- _ O
and -X- _ O
the -X- _ O
unigram -X- _ O
fastText -X- _ O
baseline -X- _ O
on -X- _ O
all -X- _ O
7 -X- _ O
tasks -X- _ O
. -X- _ O

Perhaps -X- _ O
unsurprisingly -X- _ O
, -X- _ O
adding -X- _ O
Picturebook -X- _ B-MethodName
to -X- _ O
Glove -X- _ B-MethodName
matches -X- _ O
or -X- _ O
only -X- _ O
slightly -X- _ O
improves -X- _ O
on -X- _ O
5 -X- _ O
out -X- _ O
of -X- _ O
7 -X- _ O
tasks -X- _ O
and -X- _ O
obtains -X- _ O
a -X- _ O
lower -X- _ O
result -X- _ O
on -X- _ O
AG -X- _ O
News -X- _ O
and -X- _ O
Yahoo -X- _ O
. -X- _ O

Our -X- _ O
experimental -X- _ O
results -X- _ O
are -X- _ O
provided -X- _ O
in -X- _ O
Table -X- _ O
5 -X- _ O
. -X- _ O

Hyperparameter -X- _ O
details -X- _ O
are -X- _ O
reported -X- _ O
in -X- _ O
Appendix -X- _ O
B. -X- _ O

( -X- _ O
2015 -X- _ O
) -X- _ O
and -X- _ O
compare -X- _ O
bag -X- _ O
- -X- _ O
ofwords -X- _ O
models -X- _ O
against -X- _ O
n -X- _ O
- -X- _ O
gram -X- _ O
baselines -X- _ O
provided -X- _ O
by -X- _ O
the -X- _ O
authors -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
fastText -X- _ O
( -X- _ O
Joulin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
. -X- _ O

We -X- _ O
experiment -X- _ O
with -X- _ O
7 -X- _ O
datasets -X- _ O
provided -X- _ O
by -X- _ O
Zhang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

Our -X- _ O
next -X- _ O
set -X- _ O
of -X- _ O
experiments -X- _ O
aims -X- _ O
to -X- _ O
determine -X- _ O
how -X- _ O
well -X- _ O
Picturebook -X- _ B-MethodName
embeddings -X- _ O
do -X- _ O
on -X- _ O
tasks -X- _ O
that -X- _ O
are -X- _ O
primarily -X- _ O
non -X- _ O
- -X- _ O
visual -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
topic -X- _ B-TaskName
and -X- _ I-TaskName
sentiment -X- _ I-TaskName
classification -X- _ I-TaskName
. -X- _ O

Sentiment -X- _ B-TaskName
and -X- _ I-TaskName
Topic -X- _ I-TaskName
Classification -X- _ I-TaskName
. -X- _ O

3 -X- _ O
. -X- _ O

( -X- _ O
2017a -X- _ O
) -X- _ O
, -X- _ O
from -X- _ O
which -X- _ O
we -X- _ O
improve -X- _ O
on -X- _ O
their -X- _ O
accuracy -X- _ B-MetricName
from -X- _ O
85.0 -X- _ B-MetricValue
to -X- _ O
86.8 -X- _ B-MetricValue
on -X- _ O
the -X- _ O
development -X- _ O
set -X- _ O
. -X- _ O

Finally -X- _ O
we -X- _ O
note -X- _ O
the -X- _ O
strength -X- _ O
of -X- _ O
our -X- _ O
own -X- _ O
Glove -X- _ B-MethodName
baseline -X- _ O
over -X- _ O
the -X- _ O
reported -X- _ O
results -X- _ O
of -X- _ O
Conneau -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

Adding -X- _ O
contextual -X- _ O
gating -X- _ O
was -X- _ O
necessary -X- _ O
to -X- _ O
improve -X- _ O
over -X- _ O
the -X- _ O
Glove -X- _ B-MethodName
baseline -X- _ O
on -X- _ O
SNLI -X- _ B-DatasetName
. -X- _ O

While -X- _ O
non -X- _ O
- -X- _ O
contextual -X- _ O
gating -X- _ O
is -X- _ O
sufficient -X- _ O
to -X- _ O
improve -X- _ O
bag -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
words -X- _ O
methods -X- _ O
, -X- _ O
with -X- _ O
BiLSTM -X- _ O
- -X- _ O
Max -X- _ O
it -X- _ O
slightly -X- _ O
hurts -X- _ O
performance -X- _ O
over -X- _ O
the -X- _ O
Glove -X- _ B-MethodName
baseline -X- _ O
. -X- _ O

It -X- _ O
is -X- _ O
worth -X- _ O
noting -X- _ O
the -X- _ O
effect -X- _ O
that -X- _ O
different -X- _ O
encoders -X- _ O
have -X- _ O
when -X- _ O
using -X- _ O
our -X- _ O
embeddings -X- _ O
. -X- _ O

( -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O

For -X- _ O
BiLSTM -X- _ O
- -X- _ O
Max -X- _ O
, -X- _ O
our -X- _ O
contextual -X- _ O
gating -X- _ O
sets -X- _ O
a -X- _ O
new -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
on -X- _ O
SNLI -X- _ B-DatasetName
sentence -X- _ O
encoding -X- _ O
methods -X- _ O
( -X- _ O
methods -X- _ O
without -X- _ O
interaction -X- _ O
layers -X- _ O
) -X- _ O
, -X- _ O
outperforming -X- _ O
the -X- _ O
recently -X- _ O
proposed -X- _ O
methods -X- _ O
of -X- _ O
I -X- _ O
m -X- _ O
and -X- _ O
Cho -X- _ O
( -X- _ O
2017 -X- _ O
) -X- _ O
; -X- _ O
Shen -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

For -X- _ O
BoW -X- _ O
models -X- _ O
, -X- _ O
adding -X- _ O
Picturebook -X- _ B-MethodName
embeddings -X- _ O
to -X- _ O
Glove -X- _ B-MethodName
results -X- _ O
in -X- _ O
significant -X- _ O
gains -X- _ O
across -X- _ O
all -X- _ O
three -X- _ O
tasks -X- _ O
. -X- _ O

Table -X- _ O
4 -X- _ O
displays -X- _ O
our -X- _ O
results -X- _ O
. -X- _ O

The -X- _ O
full -X- _ O
details -X- _ O
of -X- _ O
hyperparameters -X- _ O
are -X- _ O
discussed -X- _ O
in -X- _ O
Appendix -X- _ O
B. -X- _ O

Due -X- _ O
to -X- _ O
the -X- _ O
small -X- _ O
size -X- _ O
of -X- _ O
the -X- _ O
dataset -X- _ O
, -X- _ O
we -X- _ O
only -X- _ O
experiment -X- _ O
with -X- _ O
BoW -X- _ O
on -X- _ O
SICK -X- _ B-DatasetName
. -X- _ O

We -X- _ O
explore -X- _ O
the -X- _ O
use -X- _ O
of -X- _ O
two -X- _ O
types -X- _ O
of -X- _ O
sentential -X- _ O
encoders -X- _ O
: -X- _ O
Bag -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
Words -X- _ O
( -X- _ O
BoW -X- _ O
) -X- _ O
and -X- _ O
BiLSTM -X- _ O
- -X- _ O
Max -X- _ O
( -X- _ O
Conneau -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017a -X- _ O
For -X- _ O
SICK -X- _ O
, -X- _ O
we -X- _ O
follow -X- _ O
previous -X- _ O
work -X- _ O
and -X- _ O
report -X- _ O
average -X- _ O
results -X- _ O
across -X- _ O
5 -X- _ O
runs -X- _ O
( -X- _ O
Tai -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
. -X- _ O

The -X- _ O
first -X- _ O
two -X- _ O
are -X- _ O
natural -X- _ O
language -X- _ O
inference -X- _ O
tasks -X- _ O
and -X- _ O
the -X- _ O
third -X- _ O
is -X- _ O
a -X- _ O
sentence -X- _ O
semantic -X- _ O
relatedness -X- _ O
task -X- _ O
. -X- _ O

We -X- _ O
next -X- _ O
consider -X- _ O
experiments -X- _ O
on -X- _ O
3 -X- _ O
pairwise -X- _ O
prediction -X- _ O
datasets -X- _ O
: -X- _ O
SNLI -X- _ B-DatasetName
( -X- _ O
Bowman -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
, -X- _ O
MultiNLI -X- _ B-DatasetName
( -X- _ O
Williams -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
and -X- _ O
SICK -X- _ B-DatasetName
( -X- _ O
Marelli -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
. -X- _ O

Sentential -X- _ O
Inference -X- _ O
and -X- _ O
Relatedness -X- _ O
. -X- _ O

All -X- _ O
subsequent -X- _ O
experiments -X- _ O
use -X- _ O
10 -X- _ O
images -X- _ O
with -X- _ O
semantic -X- _ O
Picturebook -X- _ B-MethodName
. -X- _ O

( -X- _ O
2016 -X- _ O
) -X- _ O
showed -X- _ O
that -X- _ O
after -X- _ O
10 -X- _ O
- -X- _ O
20 -X- _ O
images -X- _ O
, -X- _ O
performance -X- _ O
tends -X- _ O
to -X- _ O
saturate -X- _ O
. -X- _ O

Kiela -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

Finally -X- _ O
we -X- _ O
note -X- _ O
that -X- _ O
adding -X- _ O
more -X- _ O
images -X- _ O
nearly -X- _ O
consistently -X- _ O
improves -X- _ O
similarity -X- _ O
scores -X- _ O
across -X- _ O
categories -X- _ O
. -X- _ O

This -X- _ O
indicates -X- _ O
the -X- _ O
importance -X- _ O
of -X- _ O
the -X- _ O
type -X- _ O
of -X- _ O
similarity -X- _ O
used -X- _ O
for -X- _ O
training -X- _ O
the -X- _ O
model -X- _ O
. -X- _ O

We -X- _ O
observe -X- _ O
a -X- _ O
performance -X- _ O
difference -X- _ O
between -X- _ O
our -X- _ O
visual -X- _ O
and -X- _ O
semantic -X- _ O
embeddings -X- _ O
: -X- _ O
on -X- _ O
all -X- _ O
categories -X- _ O
except -X- _ O
verbs -X- _ O
, -X- _ O
the -X- _ O
semantic -X- _ O
embeddings -X- _ O
outperform -X- _ O
visual -X- _ O
ones -X- _ O
, -X- _ O
even -X- _ O
on -X- _ O
the -X- _ O
most -X- _ O
concrete -X- _ O
categories -X- _ O
. -X- _ O

We -X- _ O
also -X- _ O
compare -X- _ O
to -X- _ O
a -X- _ O
convolutional -X- _ O
network -X- _ O
trained -X- _ O
with -X- _ O
visual -X- _ O
similarity -X- _ O
. -X- _ O

For -X- _ O
the -X- _ O
hardest -X- _ O
subset -X- _ O
of -X- _ O
words -X- _ O
, -X- _ O
Picturebook -X- _ B-MethodName
performs -X- _ O
slightly -X- _ O
better -X- _ O
than -X- _ O
Glove -X- _ B-MethodName
while -X- _ O
Glove -X- _ B-MethodName
performs -X- _ O
better -X- _ O
across -X- _ O
all -X- _ O
pairs -X- _ O
. -X- _ O

Next -X- _ O
we -X- _ O
observe -X- _ O
that -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
Picturebook -X- _ B-MethodName
gets -X- _ O
progressively -X- _ O
better -X- _ O
across -X- _ O
each -X- _ O
concreteness -X- _ O
quartile -X- _ O
rating -X- _ O
, -X- _ O
with -X- _ O
a -X- _ O
20 -X- _ O
point -X- _ O
improvement -X- _ O
over -X- _ O
Glove -X- _ B-MethodName
for -X- _ O
the -X- _ O
most -X- _ O
concrete -X- _ O
category -X- _ O
. -X- _ O

This -X- _ O
result -X- _ O
confirms -X- _ O
that -X- _ O
Glove -X- _ B-MethodName
and -X- _ O
Picturebook -X- _ B-MethodName
capture -X- _ O
very -X- _ O
different -X- _ O
properties -X- _ O
of -X- _ O
words -X- _ O
. -X- _ O

For -X- _ O
adjectives -X- _ O
and -X- _ O
the -X- _ O
most -X- _ O
abstract -X- _ O
category -X- _ O
, -X- _ O
Glove -X- _ B-MethodName
performs -X- _ O
significantly -X- _ O
better -X- _ O
, -X- _ O
while -X- _ O
for -X- _ O
the -X- _ O
most -X- _ O
concrete -X- _ O
category -X- _ O
Picturebook -X- _ B-MethodName
is -X- _ O
significantly -X- _ O
better -X- _ O
. -X- _ O

First -X- _ O
, -X- _ O
we -X- _ O
observe -X- _ O
that -X- _ O
combining -X- _ O
Glove -X- _ B-MethodName
and -X- _ O
Picturebook -X- _ B-MethodName
leads -X- _ O
to -X- _ O
improved -X- _ O
similarity -X- _ O
across -X- _ O
most -X- _ O
categories -X- _ O
. -X- _ O

Table -X- _ O
3 -X- _ O
displays -X- _ O
our -X- _ O
results -X- _ O
, -X- _ O
from -X- _ O
which -X- _ O
several -X- _ O
observations -X- _ O
can -X- _ O
be -X- _ O
made -X- _ O
. -X- _ O

By -X- _ O
default -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
10 -X- _ O
images -X- _ O
for -X- _ O
each -X- _ O
embedding -X- _ O
using -X- _ O
the -X- _ O
semantic -X- _ O
convolutional -X- _ O
network -X- _ O
. -X- _ O

We -X- _ O
also -X- _ O
report -X- _ O
results -X- _ O
combining -X- _ O
Glove -X- _ B-MethodName
and -X- _ O
Picturebook -X- _ B-MethodName
by -X- _ O
summing -X- _ O
their -X- _ O
two -X- _ O
independent -X- _ O
similarity -X- _ O
scores -X- _ O
. -X- _ O

Note -X- _ O
that -X- _ O
this -X- _ O
reduces -X- _ O
to -X- _ O
negative -X- _ O
cosine -X- _ O
distance -X- _ O
when -X- _ O
using -X- _ O
only -X- _ O
1 -X- _ O
image -X- _ O
per -X- _ O
word -X- _ O
. -X- _ O

2 -X- _ O
That -X- _ O
is -X- _ O
, -X- _ O
the -X- _ O
score -X- _ O
is -X- _ O
minus -X- _ O
the -X- _ O
smallest -X- _ O
cosine -X- _ O
distance -X- _ O
between -X- _ O
all -X- _ O
pairs -X- _ O
of -X- _ O
images -X- _ O
of -X- _ O
the -X- _ O
two -X- _ O
words -X- _ O
. -X- _ O

For -X- _ O
computing -X- _ O
a -X- _ O
score -X- _ O
between -X- _ O
2 -X- _ O
word -X- _ O
pairs -X- _ O
with -X- _ O
Picturebook -X- _ O
, -X- _ O
we -X- _ O
set -X- _ O
s(w -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
, -X- _ O
w -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
) -X- _ O
= -X- _ O
min -X- _ O
i -X- _ O
, -X- _ O
j -X- _ O
d(e -X- _ O
i -X- _ O
, -X- _ O
e -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
j -X- _ O
) -X- _ O
. -X- _ O

are -X- _ O
computed -X- _ O
via -X- _ O
cosine -X- _ O
similarity -X- _ O
. -X- _ O

Some -X- _ O
rows -X- _ O
are -X- _ O
copied -X- _ O
across -X- _ O
sections -X- _ O
for -X- _ O
ease -X- _ O
of -X- _ O
reading -X- _ O
. -X- _ O

Bracketed -X- _ O
numbers -X- _ O
signify -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
images -X- _ O
used -X- _ O
. -X- _ O

Best -X- _ O
results -X- _ O
per -X- _ O
section -X- _ O
are -X- _ O
underlined -X- _ O
. -X- _ O

Best -X- _ O
results -X- _ O
overall -X- _ O
are -X- _ O
bolded -X- _ O
. -X- _ O

For -X- _ O
Glove -X- _ O
, -X- _ O
scores -X- _ O
Table -X- _ O
3 -X- _ O
: -X- _ O
SimLex-999 -X- _ B-DatasetName
results -X- _ O
( -X- _ O
Spearman -X- _ O
's -X- _ O
â¢ -X- _ O
) -X- _ O
. -X- _ O

This -X- _ O
is -X- _ O
an -X- _ O
interesting -X- _ O
category -X- _ O
since -X- _ O
image -X- _ O
- -X- _ O
based -X- _ O
word -X- _ O
embeddings -X- _ O
are -X- _ O
perhaps -X- _ O
less -X- _ O
likely -X- _ O
to -X- _ O
confuse -X- _ O
similarity -X- _ O
with -X- _ O
relatedness -X- _ O
than -X- _ O
distributional -X- _ O
- -X- _ O
based -X- _ O
methods -X- _ O
. -X- _ O

The -X- _ O
hardest -X- _ O
pairs -X- _ O
are -X- _ O
those -X- _ O
for -X- _ O
which -X- _ O
similarity -X- _ O
is -X- _ O
difficult -X- _ O
to -X- _ O
distinguish -X- _ O
from -X- _ O
relatedness -X- _ O
. -X- _ O

For -X- _ O
the -X- _ O
concreteness -X- _ O
quartiles -X- _ O
, -X- _ O
the -X- _ O
first -X- _ O
quartile -X- _ O
corresponds -X- _ O
to -X- _ O
the -X- _ O
most -X- _ O
abstract -X- _ O
words -X- _ O
, -X- _ O
while -X- _ O
the -X- _ O
last -X- _ O
corresponds -X- _ O
to -X- _ O
the -X- _ O
most -X- _ O
concrete -X- _ O
words -X- _ O
. -X- _ O

We -X- _ O
use -X- _ O
the -X- _ O
SimLex-999 -X- _ B-DatasetName
dataset -X- _ O
( -X- _ O
Hill -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
and -X- _ O
report -X- _ O
results -X- _ O
across -X- _ O
9 -X- _ O
categories -X- _ O
: -X- _ O
all -X- _ O
( -X- _ O
the -X- _ O
whole -X- _ O
evaluation -X- _ O
) -X- _ O
, -X- _ O
adjectives -X- _ O
, -X- _ O
nouns -X- _ O
, -X- _ O
verbs -X- _ O
, -X- _ O
concreteness -X- _ O
quartiles -X- _ O
and -X- _ O
the -X- _ O
hardest -X- _ O
333 -X- _ O
pairs -X- _ O
. -X- _ O

Our -X- _ O
first -X- _ O
quantitative -X- _ O
experiment -X- _ O
aims -X- _ O
to -X- _ O
determine -X- _ O
how -X- _ O
well -X- _ O
Picturebook -X- _ B-MethodName
embeddings -X- _ O
capture -X- _ O
word -X- _ O
similarity -X- _ O
. -X- _ O

We -X- _ O
also -X- _ O
report -X- _ O
nearest -X- _ O
neighbour -X- _ O
examples -X- _ O
across -X- _ O
languages -X- _ O
in -X- _ O
Appendix -X- _ O
A.1 -X- _ O
. -X- _ O
Word -X- _ B-TaskName
similarity -X- _ I-TaskName
. -X- _ O

For -X- _ O
example -X- _ O
, -X- _ O
the -X- _ O
word -X- _ O
' -X- _ O
is -X- _ O
' -X- _ O
returns -X- _ O
words -X- _ O
related -X- _ O
to -X- _ O
terrorists -X- _ O
and -X- _ O
ISIS -X- _ O
and -X- _ O
' -X- _ O
it -X- _ O
' -X- _ O
returns -X- _ O
words -X- _ O
related -X- _ O
to -X- _ O
scary -X- _ O
and -X- _ O
clowns -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
2017 -X- _ O
film -X- _ O
of -X- _ O
the -X- _ O
same -X- _ O
name -X- _ O
. -X- _ O

Finally -X- _ O
, -X- _ O
it -X- _ O
's -X- _ O
worth -X- _ O
highlighting -X- _ O
that -X- _ O
the -X- _ O
most -X- _ O
frequent -X- _ O
association -X- _ O
of -X- _ O
a -X- _ O
word -X- _ O
may -X- _ O
not -X- _ O
be -X- _ O
what -X- _ O
is -X- _ O
represented -X- _ O
in -X- _ O
image -X- _ O
search -X- _ O
results -X- _ O
. -X- _ O

Words -X- _ O
like -X- _ O
' -X- _ O
sun -X- _ O
' -X- _ O
also -X- _ O
return -X- _ O
the -X- _ O
corresponding -X- _ O
word -X- _ O
in -X- _ O
different -X- _ O
languages -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
' -X- _ O
Sol -X- _ O
' -X- _ O
in -X- _ O
Spanish -X- _ O
and -X- _ O
' -X- _ O
Soleil -X- _ O
' -X- _ O
in -X- _ O
French -X- _ O
. -X- _ O

Searching -X- _ O
for -X- _ O
cities -X- _ O
returns -X- _ O
cities -X- _ O
which -X- _ O
have -X- _ O
visually -X- _ O
similar -X- _ O
characteristics -X- _ O
. -X- _ O

Some -X- _ O
words -X- _ O
capture -X- _ O
multimodality -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
' -X- _ O
deep -X- _ O
' -X- _ O
referring -X- _ O
both -X- _ O
to -X- _ O
deep -X- _ O
sea -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
to -X- _ O
AI -X- _ O
. -X- _ O

Often -X- _ O
this -X- _ O
captures -X- _ O
visual -X- _ O
similarity -X- _ O
as -X- _ O
well -X- _ O
. -X- _ O

These -X- _ O
results -X- _ O
can -X- _ O
be -X- _ O
interpreted -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O
the -X- _ O
words -X- _ O
that -X- _ O
appear -X- _ O
as -X- _ O
neighbours -X- _ O
are -X- _ O
those -X- _ O
which -X- _ O
have -X- _ O
semantically -X- _ O
similar -X- _ O
images -X- _ O
to -X- _ O
that -X- _ O
of -X- _ O
the -X- _ O
query -X- _ O
. -X- _ O

In -X- _ O
order -X- _ O
to -X- _ O
get -X- _ O
a -X- _ O
sense -X- _ O
of -X- _ O
the -X- _ O
representations -X- _ O
our -X- _ O
model -X- _ O
learns -X- _ O
, -X- _ O
we -X- _ O
first -X- _ O
compute -X- _ O
nearest -X- _ O
neighbour -X- _ O
results -X- _ O
of -X- _ O
several -X- _ O
words -X- _ O
, -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
2 -X- _ O
. -X- _ O

Nearest -X- _ O
neighbours -X- _ O
. -X- _ O

In -X- _ O
most -X- _ O
experiments -X- _ O
, -X- _ O
we -X- _ O
end -X- _ O
up -X- _ O
with -X- _ O
baselines -X- _ O
that -X- _ O
are -X- _ O
stronger -X- _ O
than -X- _ O
what -X- _ O
has -X- _ O
previously -X- _ O
been -X- _ O
reported -X- _ O
. -X- _ O

Since -X- _ O
the -X- _ O
use -X- _ O
of -X- _ O
Picturebook -X- _ B-MethodName
embeddings -X- _ O
adds -X- _ O
extra -X- _ O
parameters -X- _ O
to -X- _ O
our -X- _ O
models -X- _ O
, -X- _ O
we -X- _ O
include -X- _ O
a -X- _ O
baseline -X- _ O
for -X- _ O
each -X- _ O
experiment -X- _ O
( -X- _ O
either -X- _ O
based -X- _ O
on -X- _ O
Glove -X- _ O
or -X- _ O
learned -X- _ O
embeddings -X- _ O
) -X- _ O
that -X- _ O
we -X- _ O
extensively -X- _ O
tune -X- _ O
. -X- _ O

Hyperparameter -X- _ O
details -X- _ O
of -X- _ O
each -X- _ O
experiment -X- _ O
are -X- _ O
included -X- _ O
in -X- _ O
the -X- _ O
appendix -X- _ O
. -X- _ O

To -X- _ O
evaluate -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
our -X- _ O
embeddings -X- _ O
, -X- _ O
we -X- _ O
perform -X- _ O
both -X- _ O
quantitative -X- _ O
and -X- _ O
qualitative -X- _ O
evaluation -X- _ O
across -X- _ O
a -X- _ O
wide -X- _ O
range -X- _ O
of -X- _ O
natural -X- _ O
language -X- _ O
processing -X- _ O
tasks -X- _ O
. -X- _ O

Experiments -X- _ O
. -X- _ O

A -X- _ O
similar -X- _ O
technique -X- _ O
to -X- _ O
tie -X- _ O
the -X- _ O
softmax -X- _ O
matrix -X- _ O
as -X- _ O
the -X- _ O
transpose -X- _ O
of -X- _ O
the -X- _ O
embedding -X- _ O
matrix -X- _ O
can -X- _ O
be -X- _ O
found -X- _ O
in -X- _ O
language -X- _ O
modelling -X- _ O
( -X- _ O
Press -X- _ O
and -X- _ O
Wolf -X- _ O
, -X- _ O
2017;Inan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
. -X- _ O

In -X- _ O
practice -X- _ O
, -X- _ O
we -X- _ O
find -X- _ O
adding -X- _ O
additional -X- _ O
parameters -X- _ O
helps -X- _ O
with -X- _ O
learning -X- _ O
: -X- _ O
p(y -X- _ O
i -X- _ O
|h -X- _ O
) -X- _ O
= -X- _ O
exp(hh -X- _ O
, -X- _ O
e -X- _ O
i -X- _ O
+ -X- _ O
e -X- _ O
0 -X- _ O
i -X- _ O
i -X- _ O
+ -X- _ O
b -X- _ O
i -X- _ O
) -X- _ O
P -X- _ O
j -X- _ O
exp(hh -X- _ O
, -X- _ O
e -X- _ O
j -X- _ O
+ -X- _ O
e -X- _ O
0 -X- _ O
j -X- _ O
i -X- _ O
+ -X- _ O
b -X- _ O
j -X- _ O
) -X- _ O
( -X- _ O
7 -X- _ O
) -X- _ O
where -X- _ O
e -X- _ O
0 -X- _ O
i -X- _ O
is -X- _ O
a -X- _ O
trainable -X- _ O
weight -X- _ O
vector -X- _ O
per -X- _ O
word -X- _ O
and -X- _ O
b -X- _ O
i -X- _ O
is -X- _ O
a -X- _ O
trainable -X- _ O
bias -X- _ O
per -X- _ O
word -X- _ O
. -X- _ O

This -X- _ O
can -X- _ O
be -X- _ O
easily -X- _ O
implemented -X- _ O
by -X- _ O
setting -X- _ O
the -X- _ O
output -X- _ O
softmax -X- _ O
matrix -X- _ O
as -X- _ O
the -X- _ O
transpose -X- _ O
of -X- _ O
the -X- _ O
Picturebook -X- _ B-MethodName
embedding -X- _ O
matrix -X- _ O
E -X- _ O
p -X- _ O
. -X- _ O

Let -X- _ O
h -X- _ O
be -X- _ O
our -X- _ O
internal -X- _ O
representation -X- _ O
of -X- _ O
our -X- _ O
model -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
seq2seq -X- _ O
decoder -X- _ O
state -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
e -X- _ O
i -X- _ O
be -X- _ O
the -X- _ O
i -X- _ O
- -X- _ O
th -X- _ O
word -X- _ O
embedding -X- _ O
from -X- _ O
our -X- _ O
Picturebook -X- _ B-MethodName
embedding -X- _ O
matrix -X- _ O
E -X- _ O
p -X- _ O
: -X- _ O
p(y -X- _ O
i -X- _ O
|h -X- _ O
) -X- _ O
= -X- _ O
exp(hh -X- _ O
, -X- _ O
e -X- _ O
i -X- _ O
i -X- _ O
) -X- _ O
P -X- _ O
j -X- _ O
exp(hh -X- _ O
, -X- _ O
e -X- _ O
j -X- _ O
i)(6 -X- _ O
) -X- _ O
Given -X- _ O
a -X- _ O
representation -X- _ O
h -X- _ O
, -X- _ O
Equation -X- _ O
6 -X- _ O
simply -X- _ O
finds -X- _ O
the -X- _ O
most -X- _ O
similar -X- _ O
word -X- _ O
in -X- _ O
the -X- _ O
embedding -X- _ O
space -X- _ O
. -X- _ O

We -X- _ O
introduce -X- _ O
a -X- _ O
differentiable -X- _ O
mechanism -X- _ O
which -X- _ O
allows -X- _ O
us -X- _ O
to -X- _ O
align -X- _ O
words -X- _ O
across -X- _ O
source -X- _ O
and -X- _ O
target -X- _ O
languages -X- _ O
in -X- _ O
the -X- _ O
Picturebook -X- _ B-MethodName
embedding -X- _ O
domain -X- _ O
. -X- _ O

We -X- _ O
want -X- _ O
to -X- _ O
perform -X- _ O
this -X- _ O
inverse -X- _ O
image -X- _ O
search -X- _ O
operation -X- _ O
given -X- _ O
its -X- _ O
Picturebook -X- _ B-MethodName
embedding -X- _ O
. -X- _ O

For -X- _ O
example -X- _ O
, -X- _ O
given -X- _ O
the -X- _ O
word -X- _ O
' -X- _ O
bicycle -X- _ O
' -X- _ O
in -X- _ O
English -X- _ O
and -X- _ O
its -X- _ O
Picturebook -X- _ B-MethodName
embedding -X- _ O
, -X- _ O
we -X- _ O
want -X- _ O
to -X- _ O
find -X- _ O
the -X- _ O
closest -X- _ O
French -X- _ O
word -X- _ O
that -X- _ O
would -X- _ O
generate -X- _ O
this -X- _ O
representation -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
' -X- _ O
vÃ©lo -X- _ O
' -X- _ O
) -X- _ O
. -X- _ O

Given -X- _ O
a -X- _ O
Picturebook -X- _ B-MethodName
embedding -X- _ O
, -X- _ O
we -X- _ O
want -X- _ O
to -X- _ O
find -X- _ O
the -X- _ O
closest -X- _ O
word -X- _ O
or -X- _ O
phrase -X- _ O
aligned -X- _ O
to -X- _ O
the -X- _ O
representation -X- _ O
. -X- _ O

In -X- _ O
generative -X- _ O
modelling -X- _ O
problems -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
MT -X- _ B-TaskName
) -X- _ O
, -X- _ O
we -X- _ O
want -X- _ O
to -X- _ O
perform -X- _ O
the -X- _ O
opposite -X- _ O
operation -X- _ O
. -X- _ O

Up -X- _ O
until -X- _ O
now -X- _ O
, -X- _ O
we -X- _ O
have -X- _ O
only -X- _ O
discussed -X- _ O
scenarios -X- _ O
where -X- _ O
we -X- _ O
have -X- _ O
a -X- _ O
word -X- _ O
and -X- _ O
we -X- _ O
want -X- _ O
to -X- _ O
perform -X- _ O
this -X- _ O
implicit -X- _ O
search -X- _ O
operation -X- _ O
. -X- _ O

Picturebook -X- _ B-MethodName
embeddings -X- _ O
can -X- _ O
be -X- _ O
seen -X- _ O
as -X- _ O
a -X- _ O
form -X- _ O
of -X- _ O
implicit -X- _ O
image -X- _ O
search -X- _ O
: -X- _ O
given -X- _ O
a -X- _ O
word -X- _ O
( -X- _ O
or -X- _ O
phrase -X- _ O
) -X- _ O
, -X- _ O
image -X- _ O
search -X- _ O
the -X- _ O
word -X- _ O
query -X- _ O
and -X- _ O
concatenate -X- _ O
the -X- _ O
embeddings -X- _ O
of -X- _ O
the -X- _ O
images -X- _ O
produced -X- _ O
by -X- _ O
a -X- _ O
CNN -X- _ O
. -X- _ O

Inverse -X- _ B-MethodName
Picturebook -X- _ I-MethodName
. -X- _ O

We -X- _ O
experiment -X- _ O
with -X- _ O
contextual -X- _ O
gating -X- _ O
for -X- _ O
all -X- _ O
experiments -X- _ O
that -X- _ O
use -X- _ O
a -X- _ O
bidirectional -X- _ O
- -X- _ O
LSTM -X- _ O
encoder -X- _ O
. -X- _ O

For -X- _ O
contextual -X- _ O
gates -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
same -X- _ O
approach -X- _ O
as -X- _ O
above -X- _ O
except -X- _ O
we -X- _ O
replace -X- _ O
the -X- _ O
controller -X- _ O
( -X- _ O
e -X- _ O
g -X- _ O
, -X- _ O
e -X- _ O
p -X- _ O
) -X- _ O
with -X- _ O
inputs -X- _ O
that -X- _ O
have -X- _ O
been -X- _ O
fed -X- _ O
through -X- _ O
a -X- _ O
bidirectional -X- _ O
- -X- _ O
LSTM -X- _ O
, -X- _ O
e.g. -X- _ O
( -X- _ O
BiLSTM(e -X- _ O
g -X- _ O
) -X- _ O
, -X- _ O
BiLSTM(e -X- _ O
p -X- _ O
) -X- _ O
) -X- _ O
. -X- _ O

In -X- _ O
some -X- _ O
cases -X- _ O
it -X- _ O
may -X- _ O
be -X- _ O
beneficial -X- _ O
to -X- _ O
use -X- _ O
contextual -X- _ O
gates -X- _ O
that -X- _ O
are -X- _ O
aware -X- _ O
of -X- _ O
the -X- _ O
sentence -X- _ O
that -X- _ O
words -X- _ O
appear -X- _ O
in -X- _ O
to -X- _ O
decide -X- _ O
how -X- _ O
to -X- _ O
weight -X- _ O
Glove -X- _ O
and -X- _ O
Picturebook -X- _ O
embeddings -X- _ O
. -X- _ O

The -X- _ O
gating -X- _ O
described -X- _ O
above -X- _ O
is -X- _ O
non -X- _ O
- -X- _ O
contextual -X- _ O
, -X- _ O
in -X- _ O
the -X- _ O
sense -X- _ O
that -X- _ O
each -X- _ O
embedding -X- _ O
computes -X- _ O
a -X- _ O
gate -X- _ O
value -X- _ O
independent -X- _ O
of -X- _ O
the -X- _ O
context -X- _ O
the -X- _ O
words -X- _ O
occur -X- _ O
in -X- _ O
. -X- _ O

Contextual -X- _ O
Gating -X- _ O
. -X- _ O

We -X- _ O
leave -X- _ O
comparison -X- _ O
of -X- _ O
alternative -X- _ O
fusion -X- _ O
strategies -X- _ O
for -X- _ O
future -X- _ O
work -X- _ O
. -X- _ O

We -X- _ O
chose -X- _ O
this -X- _ O
form -X- _ O
of -X- _ O
fusion -X- _ O
over -X- _ O
other -X- _ O
approaches -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
CCA -X- _ O
variants -X- _ O
and -X- _ O
metric -X- _ O
learning -X- _ O
methods -X- _ O
, -X- _ O
to -X- _ O
allow -X- _ O
for -X- _ O
easier -X- _ O
interpretability -X- _ O
and -X- _ O
analysis -X- _ O
. -X- _ O

On -X- _ O
some -X- _ O
experiments -X- _ O
we -X- _ O
found -X- _ O
it -X- _ O
beneficial -X- _ O
to -X- _ O
include -X- _ O
a -X- _ O
skip -X- _ O
connection -X- _ O
from -X- _ O
the -X- _ O
hidden -X- _ O
layer -X- _ O
of -X- _ O
. -X- _ O

Similar -X- _ O
gating -X- _ O
mechanisms -X- _ O
can -X- _ O
be -X- _ O
found -X- _ O
in -X- _ O
LSTMs -X- _ O
( -X- _ O
Hochreiter -X- _ O
and -X- _ O
Schmidhuber -X- _ O
, -X- _ O
1997 -X- _ O
) -X- _ O
and -X- _ O
other -X- _ O
multimodal -X- _ O
models -X- _ O
( -X- _ O
Arevalo -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017;Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018;Kiela -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O

The -X- _ O
gating -X- _ O
DNN -X- _ O
allows -X- _ O
the -X- _ O
model -X- _ O
to -X- _ O
learn -X- _ O
how -X- _ O
visual -X- _ O
a -X- _ O
word -X- _ O
is -X- _ O
as -X- _ O
a -X- _ O
function -X- _ O
of -X- _ O
its -X- _ O
input -X- _ O
e -X- _ O
p -X- _ O
and -X- _ O
e -X- _ O
g -X- _ O
. -X- _ O

We -X- _ O
fuse -X- _ O
our -X- _ O
embeddings -X- _ O
using -X- _ O
a -X- _ O
multimodal -X- _ O
gating -X- _ O
mechanism -X- _ O
: -X- _ O
g -X- _ O
= -X- _ O
( -X- _ O
e -X- _ O
g -X- _ O
, -X- _ O
e -X- _ O
p -X- _ O
) -X- _ O
( -X- _ O
4 -X- _ O
) -X- _ O
e -X- _ O
= -X- _ O
g -X- _ O
( -X- _ O
e -X- _ O
g -X- _ O
) -X- _ O
+ -X- _ O
( -X- _ O
1 -X- _ O
g -X- _ O
) -X- _ O
( -X- _ O
e -X- _ O
p -X- _ O
) -X- _ O
( -X- _ O
5 -X- _ O
) -X- _ O
where -X- _ O
is -X- _ O
a -X- _ O
1 -X- _ O
hidden -X- _ O
layer -X- _ O
DNN -X- _ O
with -X- _ O
ReLU -X- _ O
activations -X- _ O
and -X- _ O
sigmoid -X- _ O
outputs -X- _ O
, -X- _ O
and -X- _ O
are -X- _ O
1 -X- _ O
hidden -X- _ O
layer -X- _ O
DNNs -X- _ O
with -X- _ O
ReLU -X- _ O
activations -X- _ O
and -X- _ O
tanh -X- _ O
outputs -X- _ O
. -X- _ O

Let -X- _ O
e -X- _ O
g -X- _ O
= -X- _ O
e -X- _ O
g -X- _ O
( -X- _ O
w -X- _ O
) -X- _ O
be -X- _ O
our -X- _ O
other -X- _ O
embedding -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
Glove -X- _ O
) -X- _ O
for -X- _ O
a -X- _ O
word -X- _ O
w -X- _ O
and -X- _ O
e -X- _ O
p -X- _ O
= -X- _ O
e -X- _ O
p -X- _ O
( -X- _ O
w -X- _ O
) -X- _ O
be -X- _ O
our -X- _ O
Picturebook -X- _ B-MethodName
embedding -X- _ O
. -X- _ O

Consequently -X- _ O
, -X- _ O
we -X- _ O
would -X- _ O
like -X- _ O
to -X- _ O
fuse -X- _ O
our -X- _ O
Picturebook -X- _ B-MethodName
embeddings -X- _ O
with -X- _ O
other -X- _ O
sources -X- _ O
of -X- _ O
information -X- _ O
, -X- _ O
for -X- _ O
example -X- _ O
Glove -X- _ O
embeddings -X- _ O
( -X- _ O
Pennington -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
or -X- _ O
randomly -X- _ O
initialized -X- _ O
embeddings -X- _ O
that -X- _ O
will -X- _ O
be -X- _ O
trained -X- _ O
. -X- _ O

Picturebook -X- _ B-MethodName
embeddings -X- _ O
on -X- _ O
their -X- _ O
own -X- _ O
are -X- _ O
likely -X- _ O
to -X- _ O
be -X- _ O
useful -X- _ O
for -X- _ O
representing -X- _ O
concrete -X- _ O
words -X- _ O
but -X- _ O
it -X- _ O
is -X- _ O
not -X- _ O
clear -X- _ O
whether -X- _ O
they -X- _ O
will -X- _ O
be -X- _ O
of -X- _ O
benefit -X- _ O
for -X- _ O
abstract -X- _ O
words -X- _ O
. -X- _ O

Multimodal -X- _ O
Fusion -X- _ O
Gating -X- _ O
. -X- _ O

As -X- _ O
we -X- _ O
will -X- _ O
show -X- _ O
in -X- _ O
our -X- _ O
experiments -X- _ O
, -X- _ O
the -X- _ O
semantic -X- _ O
Picturebook -X- _ B-MethodName
embeddings -X- _ O
result -X- _ O
in -X- _ O
representations -X- _ O
that -X- _ O
are -X- _ O
more -X- _ O
useful -X- _ O
for -X- _ O
natural -X- _ O
language -X- _ O
processing -X- _ O
tasks -X- _ O
than -X- _ O
the -X- _ O
visual -X- _ O
embeddings -X- _ O
. -X- _ O

In -X- _ O
our -X- _ O
experiments -X- _ O
we -X- _ O
consider -X- _ O
two -X- _ O
types -X- _ O
of -X- _ O
Picturebook -X- _ B-MethodName
embedding -X- _ O
: -X- _ O
one -X- _ O
trained -X- _ O
through -X- _ O
optimizing -X- _ O
for -X- _ O
visual -X- _ O
similarity -X- _ O
and -X- _ O
another -X- _ O
for -X- _ O
semantic -X- _ O
similarity -X- _ O
. -X- _ O

As -X- _ O
an -X- _ O
example -X- _ O
, -X- _ O
an -X- _ O
image -X- _ O
of -X- _ O
a -X- _ O
blue -X- _ O
car -X- _ O
would -X- _ O
have -X- _ O
high -X- _ O
visual -X- _ O
similarity -X- _ O
to -X- _ O
other -X- _ O
blue -X- _ O
cars -X- _ O
but -X- _ O
would -X- _ O
have -X- _ O
higher -X- _ O
semantic -X- _ O
similarity -X- _ O
to -X- _ O
cars -X- _ O
of -X- _ O
the -X- _ O
same -X- _ O
make -X- _ O
, -X- _ O
independent -X- _ O
of -X- _ O
color -X- _ O
. -X- _ O

We -X- _ O
consider -X- _ O
two -X- _ O
types -X- _ O
of -X- _ O
image -X- _ O
similarity -X- _ O
: -X- _ O
visual -X- _ O
and -X- _ O
semantic -X- _ O
. -X- _ O

The -X- _ O
training -X- _ O
procedure -X- _ O
is -X- _ O
heavily -X- _ O
influenced -X- _ O
by -X- _ O
the -X- _ O
choice -X- _ O
of -X- _ O
similarity -X- _ O
function -X- _ O
r -X- _ O
i -X- _ O
, -X- _ O
j -X- _ O
. -X- _ O

Visual -X- _ O
vs -X- _ O
Semantic -X- _ O
Similarity -X- _ O
. -X- _ O

To -X- _ O
obtain -X- _ O
the -X- _ O
full -X- _ O
collection -X- _ O
of -X- _ O
embeddings -X- _ O
, -X- _ O
we -X- _ O
run -X- _ O
the -X- _ O
full -X- _ O
Glove -X- _ O
vocabulary -X- _ O
( -X- _ O
2.2 -X- _ O
M -X- _ O
words -X- _ O
) -X- _ O
through -X- _ O
image -X- _ O
search -X- _ O
to -X- _ O
obtain -X- _ O
a -X- _ O
corresponding -X- _ O
Picturebook -X- _ B-MethodName
embedding -X- _ O
to -X- _ O
each -X- _ O
word -X- _ O
in -X- _ O
the -X- _ O
Glove -X- _ O
vocabulary -X- _ O
. -X- _ O

Most -X- _ O
of -X- _ O
our -X- _ O
experiments -X- _ O
use -X- _ O
k -X- _ O
= -X- _ O
10 -X- _ O
images -X- _ O
resulting -X- _ O
in -X- _ O
a -X- _ O
word -X- _ O
embedding -X- _ O
size -X- _ O
of -X- _ O
640 -X- _ O
. -X- _ O

In -X- _ O
our -X- _ O
model -X- _ O
, -X- _ O
each -X- _ O
embedding -X- _ O
results -X- _ O
in -X- _ O
a -X- _ O
64 -X- _ O
- -X- _ O
dimensional -X- _ O
vector -X- _ O
with -X- _ O
the -X- _ O
final -X- _ O
Picturebook -X- _ O
embedding -X- _ O
being -X- _ O
64 -X- _ O
â¤ -X- _ O
k -X- _ O
dimensions -X- _ O
. -X- _ O

; -X- _ O
f -X- _ O
( -X- _ O
p -X- _ O
w -X- _ O
k -X- _ O
) -X- _ O
] -X- _ O
( -X- _ O
3 -X- _ O
) -X- _ O
namely -X- _ O
, -X- _ O
the -X- _ O
concatenation -X- _ O
of -X- _ O
the -X- _ O
feature -X- _ O
vectors -X- _ O
in -X- _ O
ranked -X- _ O
order -X- _ O
. -X- _ O

The -X- _ O
Picturebook -X- _ B-MethodName
embedding -X- _ O
for -X- _ O
a -X- _ O
word -X- _ O
w -X- _ O
is -X- _ O
then -X- _ O
represented -X- _ O
as -X- _ O
: -X- _ O
e -X- _ O
p -X- _ O
( -X- _ O
w -X- _ O
) -X- _ O
= -X- _ O
[ -X- _ O
f -X- _ O
( -X- _ O
p -X- _ O
w -X- _ O
1 -X- _ O
) -X- _ O
; -X- _ O
f -X- _ O
( -X- _ O
p -X- _ O
w -X- _ O
2 -X- _ O
) -X- _ O
; -X- _ O
. -X- _ O

, -X- _ O
p -X- _ O
w -X- _ O
k -X- _ O
. -X- _ O

We -X- _ O
first -X- _ O
perform -X- _ O
an -X- _ O
image -X- _ O
search -X- _ O
with -X- _ O
query -X- _ O
w -X- _ O
to -X- _ O
obtain -X- _ O
a -X- _ O
ranked -X- _ O
list -X- _ O
of -X- _ O
images -X- _ O
p -X- _ O
w -X- _ O
1 -X- _ O
, -X- _ O
. -X- _ O

Suppose -X- _ O
we -X- _ O
would -X- _ O
like -X- _ O
to -X- _ O
obtain -X- _ O
a -X- _ O
Picturebook -X- _ B-MethodName
embedding -X- _ O
for -X- _ O
a -X- _ O
given -X- _ O
word -X- _ O
w. -X- _ O

After -X- _ O
the -X- _ O
model -X- _ O
is -X- _ O
trained -X- _ O
, -X- _ O
we -X- _ O
can -X- _ O
use -X- _ O
the -X- _ O
convolutional -X- _ O
network -X- _ O
as -X- _ O
a -X- _ O
feature -X- _ O
extractor -X- _ O
for -X- _ O
images -X- _ O
by -X- _ O
computing -X- _ O
an -X- _ O
embedding -X- _ O
vector -X- _ O
f -X- _ O
( -X- _ O
p -X- _ O
) -X- _ O
for -X- _ O
an -X- _ O
image -X- _ O
p. -X- _ O

( -X- _ O
2014 -X- _ O
) -X- _ O
for -X- _ O
additional -X- _ O
details -X- _ O
of -X- _ O
training -X- _ O
, -X- _ O
including -X- _ O
the -X- _ O
specifics -X- _ O
of -X- _ O
the -X- _ O
architecture -X- _ O
used -X- _ O
. -X- _ O

We -X- _ O
refer -X- _ O
the -X- _ O
reader -X- _ O
to -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

The -X- _ O
model -X- _ O
is -X- _ O
trained -X- _ O
end -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
end -X- _ O
using -X- _ O
a -X- _ O
proprietary -X- _ O
dataset -X- _ O
with -X- _ O
100 -X- _ O
+ -X- _ O
million -X- _ O
images -X- _ O
. -X- _ O

The -X- _ O
objective -X- _ O
function -X- _ O
that -X- _ O
is -X- _ O
optimized -X- _ O
is -X- _ O
given -X- _ O
by -X- _ O
: -X- _ O
min -X- _ O
X -X- _ O
i -X- _ O
â  -X- _ O
i -X- _ O
+ -X- _ O
kW -X- _ O
k -X- _ O
2 -X- _ O
2 -X- _ O
s.t -X- _ O
. -X- _ O
: -X- _ O
l(p -X- _ O
i -X- _ O
, -X- _ O
p -X- _ O
+ -X- _ O
i -X- _ O
, -X- _ O
p -X- _ O
i -X- _ O
) -X- _ O
ï£¿ -X- _ O
â  -X- _ O
i -X- _ O
8p -X- _ O
i -X- _ O
, -X- _ O
p -X- _ O
+ -X- _ O
i -X- _ O
, -X- _ O
p -X- _ O
i -X- _ O
such -X- _ O
that -X- _ O
r(p -X- _ O
i -X- _ O
, -X- _ O
p -X- _ O
+ -X- _ O
i -X- _ O
) -X- _ O
> -X- _ O
r(p -X- _ O
i -X- _ O
, -X- _ O
p -X- _ O
i -X- _ O
) -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
where -X- _ O
â  -X- _ O
i -X- _ O
are -X- _ O
slack -X- _ O
variables -X- _ O
and -X- _ O
W -X- _ O
is -X- _ O
a -X- _ O
vector -X- _ O
of -X- _ O
the -X- _ O
network -X- _ O
's -X- _ O
model -X- _ O
parameters -X- _ O
. -X- _ O

Suppose -X- _ O
we -X- _ O
have -X- _ O
available -X- _ O
pairwise -X- _ O
relevance -X- _ O
scores -X- _ O
r -X- _ O
i -X- _ O
, -X- _ O
j -X- _ O
= -X- _ O
r(p -X- _ O
i -X- _ O
, -X- _ O
p -X- _ O
j -X- _ O
) -X- _ O
indicating -X- _ O
the -X- _ O
similarity -X- _ O
of -X- _ O
images -X- _ O
p -X- _ O
i -X- _ O
and -X- _ O
p -X- _ O
j -X- _ O
. -X- _ O

We -X- _ O
define -X- _ O
the -X- _ O
following -X- _ O
hinge -X- _ O
loss -X- _ O
for -X- _ O
a -X- _ O
given -X- _ O
triplet -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O
l(p -X- _ O
i -X- _ O
, -X- _ O
p -X- _ O
+ -X- _ O
i -X- _ O
, -X- _ O
p -X- _ O
i -X- _ O
) -X- _ O
= -X- _ O
max{0 -X- _ O
, -X- _ O
g -X- _ O
+ -X- _ O
D(f -X- _ O
( -X- _ O
p -X- _ O
i -X- _ O
) -X- _ O
, -X- _ O
f(p -X- _ O
+ -X- _ O
i -X- _ O
) -X- _ O
) -X- _ O
D(f -X- _ O
( -X- _ O
p -X- _ O
i -X- _ O
) -X- _ O
, -X- _ O
f(p -X- _ O
i -X- _ O
) -X- _ O
) -X- _ O
} -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
where -X- _ O
f -X- _ O
( -X- _ O
p -X- _ O
i -X- _ O
) -X- _ O
represents -X- _ O
the -X- _ O
embedding -X- _ O
of -X- _ O
image -X- _ O
p -X- _ O
i -X- _ O
, -X- _ O
D(â¢ -X- _ O
, -X- _ O
â¢ -X- _ O
) -X- _ O
is -X- _ O
the -X- _ O
Euclidean -X- _ O
distance -X- _ O
and -X- _ O
g -X- _ O
is -X- _ O
a -X- _ O
margin -X- _ O
( -X- _ O
gap -X- _ O
) -X- _ O
hyperparameter -X- _ O
. -X- _ O

Let -X- _ O
p -X- _ O
i -X- _ O
, -X- _ O
p -X- _ O
+ -X- _ O
i -X- _ O
, -X- _ O
p -X- _ O
i -X- _ O
denote -X- _ O
a -X- _ O
triplet -X- _ O
of -X- _ O
query -X- _ O
, -X- _ O
positive -X- _ O
and -X- _ O
negative -X- _ O
images -X- _ O
, -X- _ O
respectively -X- _ O
. -X- _ O

( -X- _ O
2014 -X- _ O
) -X- _ O
. -X- _ O

The -X- _ O
convolutional -X- _ O
network -X- _ O
used -X- _ O
to -X- _ O
obtain -X- _ O
Picturebook -X- _ B-MethodName
embeddings -X- _ O
is -X- _ O
based -X- _ O
off -X- _ O
of -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

Inducing -X- _ O
Picturebook -X- _ B-MethodName
Embeddings -X- _ O
. -X- _ O

We -X- _ O
can -X- _ O
perform -X- _ O
all -X- _ O
of -X- _ O
these -X- _ O
operations -X- _ O
offline -X- _ O
to -X- _ O
construct -X- _ O
a -X- _ O
matrix -X- _ O
E -X- _ O
p -X- _ O
representing -X- _ O
the -X- _ O
Picturebook -X- _ B-MethodName
embeddings -X- _ O
over -X- _ O
a -X- _ O
vocabulary -X- _ O
. -X- _ O

Our -X- _ O
Picturebook -X- _ B-MethodName
embeddings -X- _ O
reflect -X- _ O
the -X- _ O
search -X- _ O
rankings -X- _ O
by -X- _ O
concatenating -X- _ O
the -X- _ O
individual -X- _ O
embeddings -X- _ O
in -X- _ O
the -X- _ O
order -X- _ O
of -X- _ O
the -X- _ O
search -X- _ O
results -X- _ O
. -X- _ O

We -X- _ O
then -X- _ O
pass -X- _ O
each -X- _ O
image -X- _ O
through -X- _ O
a -X- _ O
CNN -X- _ O
trained -X- _ O
with -X- _ O
a -X- _ O
semantic -X- _ O
ranking -X- _ O
objective -X- _ O
to -X- _ O
extract -X- _ O
its -X- _ O
embedding -X- _ O
. -X- _ O

Given -X- _ O
a -X- _ O
word -X- _ O
( -X- _ O
or -X- _ O
phrase -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
image -X- _ O
search -X- _ O
for -X- _ O
the -X- _ O
top -X- _ O
- -X- _ O
k -X- _ O
images -X- _ O
and -X- _ O
extract -X- _ O
the -X- _ O
images -X- _ O
. -X- _ O

Our -X- _ O
Picturebook -X- _ B-MethodName
embeddings -X- _ O
ground -X- _ O
language -X- _ O
using -X- _ O
the -X- _ O
' -X- _ O
snapshots -X- _ O
' -X- _ O
returned -X- _ O
by -X- _ O
an -X- _ O
image -X- _ O
search -X- _ O
engine -X- _ O
. -X- _ O

Picturebook -X- _ B-MethodName
Embeddings -X- _ O
. -X- _ O

The -X- _ O
use -X- _ O
of -X- _ O
image -X- _ O
search -X- _ O
allows -X- _ O
us -X- _ O
to -X- _ O
obtain -X- _ O
visual -X- _ O
embeddings -X- _ O
for -X- _ O
a -X- _ O
virtually -X- _ O
unlimited -X- _ O
vocabulary -X- _ O
without -X- _ O
needing -X- _ O
a -X- _ O
mapping -X- _ O
function -X- _ O
. -X- _ O

However -X- _ O
, -X- _ O
their -X- _ O
analysis -X- _ O
is -X- _ O
restricted -X- _ O
to -X- _ O
word -X- _ O
similarity -X- _ O
tasks -X- _ O
and -X- _ O
they -X- _ O
require -X- _ O
text -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
image -X- _ O
regression -X- _ O
to -X- _ O
obtain -X- _ O
visual -X- _ O
embeddings -X- _ O
for -X- _ O
unseen -X- _ O
words -X- _ O
, -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
use -X- _ O
of -X- _ O
ImageNet -X- _ O
. -X- _ O

( -X- _ O
2018 -X- _ O
) -X- _ O
who -X- _ O
also -X- _ O
consider -X- _ O
fusing -X- _ O
Glove -X- _ O
embeddings -X- _ O
with -X- _ O
visual -X- _ O
features -X- _ O
. -X- _ O

The -X- _ O
work -X- _ O
that -X- _ O
most -X- _ O
closely -X- _ O
matches -X- _ O
ours -X- _ O
is -X- _ O
that -X- _ O
of -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

( -X- _ O
2018 -X- _ O
) -X- _ O
describe -X- _ O
an -X- _ O
asymmetric -X- _ O
gate -X- _ O
that -X- _ O
allows -X- _ O
one -X- _ O
modality -X- _ O
to -X- _ O
' -X- _ O
attend -X- _ O
' -X- _ O
to -X- _ O
the -X- _ O
other -X- _ O
. -X- _ O

( -X- _ O
2017 -X- _ O
) -X- _ O
introduce -X- _ O
a -X- _ O
gating -X- _ O
mechanism -X- _ O
inspired -X- _ O
by -X- _ O
the -X- _ O
LSTM -X- _ O
while -X- _ O
Kiela -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

Arevalo -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

More -X- _ O
recently -X- _ O
, -X- _ O
gating -X- _ O
- -X- _ O
based -X- _ O
approaches -X- _ O
have -X- _ O
been -X- _ O
developed -X- _ O
for -X- _ O
fusing -X- _ O
traditional -X- _ O
word -X- _ O
embeddings -X- _ O
with -X- _ O
visual -X- _ O
representations -X- _ O
. -X- _ O

also -X- _ O
fused -X- _ O
text -X- _ O
- -X- _ O
based -X- _ O
representations -X- _ O
with -X- _ O
imagebased -X- _ O
representations -X- _ O
( -X- _ O
Bruni -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2014;Lazaridou -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015;Chrupala -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015;Mao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016;Silberer -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017;Kiela -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017;Collell -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017;Zablocki -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
and -X- _ O
representations -X- _ O
derived -X- _ O
from -X- _ O
a -X- _ O
knowledge -X- _ O
- -X- _ O
graph -X- _ O
( -X- _ O
Thoma -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
. -X- _ O

Various -X- _ O
work -X- _ O
has -X- _ O
Method -X- _ O
tasks -X- _ O
( -X- _ O
Bergsma -X- _ O
and -X- _ O
Durme -X- _ O
, -X- _ O
2011 -X- _ O
) -X- _ O
bilingual -X- _ O
lexicons -X- _ O
( -X- _ O
Bergsma -X- _ O
and -X- _ O
Goebel -X- _ O
, -X- _ O
2011 -X- _ O
) -X- _ O
lexical -X- _ O
preference -X- _ O
( -X- _ O
Kiela -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
word -X- _ O
similarity -X- _ O
( -X- _ O
Kiela -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015a -X- _ O
) -X- _ O
lexical -X- _ O
entailment -X- _ O
detection -X- _ O
( -X- _ O
Kiela -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015b -X- _ O
) -X- _ O
bilingual -X- _ O
lexicons -X- _ O
( -X- _ O
Shutova -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
metaphor -X- _ O
identification -X- _ O
( -X- _ O
Bulat -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
predicting -X- _ O
property -X- _ O
norms -X- _ O
( -X- _ O
Kiela -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
toolbox -X- _ O
( -X- _ O
Vulic -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
bilingual -X- _ O
lexicons -X- _ O
( -X- _ O
Kiela -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
word -X- _ O
similarity -X- _ O
( -X- _ O
Anderson -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
decoding -X- _ O
brain -X- _ O
activity -X- _ O
( -X- _ O
Glavas -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
semantic -X- _ O
text -X- _ O
similarity -X- _ O
( -X- _ O
Bhaskar -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
abstract -X- _ O
vs -X- _ O
concrete -X- _ O
nouns -X- _ O
( -X- _ O
Hartmann -X- _ O
and -X- _ O
Sogaard -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
bilingual -X- _ O
lexicons -X- _ O
( -X- _ O
Bulat -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
decoding -X- _ O
brain -X- _ O
activity -X- _ O
Table -X- _ O
1 -X- _ O
: -X- _ O
Existing -X- _ O
methods -X- _ O
that -X- _ O
use -X- _ O
image -X- _ O
search -X- _ O
for -X- _ O
grounding -X- _ O
and -X- _ O
their -X- _ O
corresponding -X- _ O
tasks -X- _ O
. -X- _ O

Our -X- _ O
work -X- _ O
also -X- _ O
relates -X- _ O
to -X- _ O
existing -X- _ O
multimodal -X- _ O
models -X- _ O
combining -X- _ O
different -X- _ O
representations -X- _ O
of -X- _ O
the -X- _ O
data -X- _ O
( -X- _ O
Hill -X- _ O
and -X- _ O
Korhonen -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
. -X- _ O

Our -X- _ O
approach -X- _ O
differs -X- _ O
from -X- _ O
the -X- _ O
above -X- _ O
methods -X- _ O
in -X- _ O
three -X- _ O
main -X- _ O
ways -X- _ O
: -X- _ O
a -X- _ O
) -X- _ O
we -X- _ O
obtain -X- _ O
searchgrounded -X- _ O
representations -X- _ O
for -X- _ O
over -X- _ O
2 -X- _ O
million -X- _ O
words -X- _ O
as -X- _ O
opposed -X- _ O
to -X- _ O
a -X- _ O
few -X- _ O
thousand -X- _ O
, -X- _ O
b -X- _ O
) -X- _ O
we -X- _ O
apply -X- _ O
our -X- _ O
representations -X- _ O
to -X- _ O
a -X- _ O
higher -X- _ O
diversity -X- _ O
of -X- _ O
tasks -X- _ O
than -X- _ O
previously -X- _ O
considered -X- _ O
, -X- _ O
and -X- _ O
c -X- _ O
) -X- _ O
we -X- _ O
introduce -X- _ O
a -X- _ O
multimodal -X- _ O
gating -X- _ O
mechanism -X- _ O
that -X- _ O
allows -X- _ O
for -X- _ O
a -X- _ O
more -X- _ O
flexible -X- _ O
integration -X- _ O
of -X- _ O
features -X- _ O
than -X- _ O
mere -X- _ O
concatenation -X- _ O
. -X- _ O

There -X- _ O
has -X- _ O
also -X- _ O
been -X- _ O
other -X- _ O
work -X- _ O
using -X- _ O
other -X- _ O
image -X- _ O
sources -X- _ O
such -X- _ O
as -X- _ O
ImageNet -X- _ O
( -X- _ O
Kiela -X- _ O
and -X- _ O
Bottou -X- _ O
, -X- _ O
2014;Collell -X- _ O
and -X- _ O
Moens -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
over -X- _ O
the -X- _ O
WordNet -X- _ O
synset -X- _ O
vocabulary -X- _ O
, -X- _ O
and -X- _ O
using -X- _ O
Flickr -X- _ O
photos -X- _ O
and -X- _ O
captions -X- _ O
( -X- _ O
Joulin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
. -X- _ O

Table -X- _ O
1 -X- _ O
illustrates -X- _ O
existing -X- _ O
methods -X- _ O
that -X- _ O
utilize -X- _ O
image -X- _ O
search -X- _ O
and -X- _ O
the -X- _ O
tasks -X- _ O
considered -X- _ O
in -X- _ O
their -X- _ O
work -X- _ O
. -X- _ O

The -X- _ O
use -X- _ O
of -X- _ O
image -X- _ O
search -X- _ O
for -X- _ O
obtaining -X- _ O
word -X- _ O
representations -X- _ O
is -X- _ O
not -X- _ O
new -X- _ O
. -X- _ O

Related -X- _ O
Work -X- _ O
. -X- _ O

In -X- _ O
particular -X- _ O
, -X- _ O
networks -X- _ O
trained -X- _ O
with -X- _ O
semantic -X- _ O
labels -X- _ O
result -X- _ O
in -X- _ O
better -X- _ O
embeddings -X- _ O
than -X- _ O
those -X- _ O
trained -X- _ O
with -X- _ O
visual -X- _ O
labels -X- _ O
, -X- _ O
even -X- _ O
when -X- _ O
evaluating -X- _ O
similarity -X- _ O
on -X- _ O
concrete -X- _ O
words -X- _ O
. -X- _ O

â¢ -X- _ O
We -X- _ O
highlight -X- _ O
the -X- _ O
importance -X- _ O
of -X- _ O
the -X- _ O
convolutional -X- _ O
network -X- _ O
used -X- _ O
to -X- _ O
extract -X- _ O
embeddings -X- _ O
. -X- _ O

We -X- _ O
also -X- _ O
show -X- _ O
that -X- _ O
Picturebook -X- _ B-MethodName
gate -X- _ O
activations -X- _ O
are -X- _ O
negatively -X- _ O
correlated -X- _ O
with -X- _ O
image -X- _ O
dispersion -X- _ O
( -X- _ O
Kiela -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
, -X- _ O
indicating -X- _ O
that -X- _ O
our -X- _ O
model -X- _ O
selectively -X- _ O
chooses -X- _ O
between -X- _ O
word -X- _ O
embeddings -X- _ O
based -X- _ O
on -X- _ O
their -X- _ O
abstraction -X- _ O
level -X- _ O
. -X- _ O

â¢ -X- _ O
We -X- _ O
perform -X- _ O
an -X- _ O
extensive -X- _ O
analysis -X- _ O
of -X- _ O
our -X- _ O
gating -X- _ O
mechanism -X- _ O
, -X- _ O
showing -X- _ O
that -X- _ O
the -X- _ O
gate -X- _ O
activations -X- _ O
for -X- _ O
Picturebook -X- _ B-MethodName
embeddings -X- _ O
are -X- _ O
highly -X- _ O
correlated -X- _ O
with -X- _ O
human -X- _ O
judgments -X- _ O
of -X- _ O
concreteness -X- _ O
. -X- _ O

This -X- _ O
is -X- _ O
useful -X- _ O
for -X- _ O
generative -X- _ O
modelling -X- _ O
tasks -X- _ O
. -X- _ O

Given -X- _ O
a -X- _ O
Picturebook -X- _ B-MethodName
embedding -X- _ O
, -X- _ O
we -X- _ O
find -X- _ O
the -X- _ O
closest -X- _ O
words -X- _ O
which -X- _ O
would -X- _ O
generate -X- _ O
the -X- _ O
embedding -X- _ O
. -X- _ O

â¢ -X- _ O
We -X- _ O
introduce -X- _ O
Inverse -X- _ O
Picturebook -X- _ B-MethodName
to -X- _ O
perform -X- _ O
the -X- _ O
inverse -X- _ O
lookup -X- _ O
operation -X- _ O
. -X- _ O

We -X- _ O
apply -X- _ O
our -X- _ O
approach -X- _ O
to -X- _ O
over -X- _ O
a -X- _ O
dozen -X- _ O
datasets -X- _ O
and -X- _ O
several -X- _ O
different -X- _ O
tasks -X- _ O
: -X- _ O
word -X- _ B-TaskName
similarity -X- _ I-TaskName
, -X- _ O
sentence -X- _ B-TaskName
relatedness -X- _ I-TaskName
, -X- _ O
natural -X- _ B-TaskName
language -X- _ I-TaskName
inference -X- _ I-TaskName
, -X- _ O
topic -X- _ B-TaskName
/ -X- _ I-TaskName
sentiment -X- _ I-TaskName
classification -X- _ I-TaskName
, -X- _ O
image -X- _ B-TaskName
sentence -X- _ I-TaskName
ranking -X- _ I-TaskName
and -X- _ O
Machine -X- _ B-TaskName
Translation -X- _ I-TaskName
( -X- _ O
MT -X- _ B-TaskName
) -X- _ O
. -X- _ O

â¢ -X- _ O
We -X- _ O
introduce -X- _ O
a -X- _ O
multimodal -X- _ O
gating -X- _ O
mechanism -X- _ O
to -X- _ O
selectively -X- _ O
choose -X- _ O
between -X- _ O
Glove -X- _ B-MethodName
and -X- _ O
Picturebook -X- _ B-MethodName
embeddings -X- _ O
in -X- _ O
a -X- _ O
task -X- _ O
- -X- _ O
dependent -X- _ O
way -X- _ O
. -X- _ O

The -X- _ O
main -X- _ O
contributions -X- _ O
of -X- _ O
our -X- _ O
work -X- _ O
are -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O
â¢ -X- _ O
We -X- _ O
obtain -X- _ O
Picturebook -X- _ B-MethodName
embeddings -X- _ O
for -X- _ O
the -X- _ O
2.2 -X- _ O
million -X- _ O
words -X- _ O
that -X- _ O
occur -X- _ O
in -X- _ O
the -X- _ O
Glove -X- _ O
vocabulary -X- _ O
( -X- _ O
Pennington -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
1 -X- _ O
, -X- _ O
allowing -X- _ O
each -X- _ O
word -X- _ O
to -X- _ O
have -X- _ O
a -X- _ O
Glove -X- _ B-MethodName
embedding -X- _ O
and -X- _ O
a -X- _ O
parallel -X- _ O
grounded -X- _ O
word -X- _ O
representation -X- _ O
. -X- _ O

This -X- _ O
collection -X- _ O
of -X- _ O
word -X- _ O
representations -X- _ O
that -X- _ O
we -X- _ O
visually -X- _ O
1 -X- _ O
Common -X- _ B-DatasetName
Crawl -X- _ I-DatasetName
, -X- _ O
840B -X- _ O
tokens -X- _ O
ground -X- _ O
via -X- _ O
image -X- _ O
search -X- _ O
is -X- _ O
2 -X- _ O
- -X- _ O
3 -X- _ O
orders -X- _ O
of -X- _ O
magnitude -X- _ O
larger -X- _ O
than -X- _ O
prior -X- _ O
work -X- _ O
. -X- _ O

Using -X- _ O
Google -X- _ O
image -X- _ O
search -X- _ O
, -X- _ O
a -X- _ O
Picturebook -X- _ B-MethodName
embedding -X- _ O
for -X- _ O
a -X- _ O
word -X- _ O
is -X- _ O
obtained -X- _ O
by -X- _ O
concatenating -X- _ O
the -X- _ O
k -X- _ O
- -X- _ O
feature -X- _ O
vectors -X- _ O
of -X- _ O
our -X- _ O
convolutional -X- _ O
network -X- _ O
on -X- _ O
the -X- _ O
top -X- _ O
- -X- _ O
k -X- _ O
retrieved -X- _ O
search -X- _ O
results -X- _ O
. -X- _ O

Picturebook -X- _ B-MethodName
embeddings -X- _ O
are -X- _ O
obtained -X- _ O
through -X- _ O
a -X- _ O
convolutional -X- _ O
network -X- _ O
trained -X- _ O
with -X- _ O
a -X- _ O
semantic -X- _ O
ranking -X- _ O
objective -X- _ O
on -X- _ O
a -X- _ O
proprietary -X- _ O
image -X- _ O
dataset -X- _ O
with -X- _ O
over -X- _ O
100 -X- _ O
+ -X- _ O
million -X- _ O
images -X- _ O
( -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
paper -X- _ O
we -X- _ O
introduce -X- _ O
Picturebook -X- _ B-MethodName
embeddings -X- _ O
produced -X- _ O
by -X- _ O
image -X- _ O
search -X- _ O
using -X- _ O
words -X- _ O
as -X- _ O
queries -X- _ O
. -X- _ O

While -X- _ O
several -X- _ O
authors -X- _ O
have -X- _ O
considered -X- _ O
this -X- _ O
approach -X- _ O
, -X- _ O
it -X- _ O
has -X- _ O
been -X- _ O
largely -X- _ O
limited -X- _ O
to -X- _ O
a -X- _ O
few -X- _ O
thousand -X- _ O
queries -X- _ O
and -X- _ O
only -X- _ O
a -X- _ O
small -X- _ O
number -X- _ O
of -X- _ O
tasks -X- _ O
. -X- _ O

These -X- _ O
word -X- _ O
embeddings -X- _ O
are -X- _ O
grounded -X- _ O
via -X- _ O
the -X- _ O
retrieved -X- _ O
images -X- _ O
. -X- _ O

This -X- _ O
involves -X- _ O
retrieving -X- _ O
the -X- _ O
top -X- _ O
- -X- _ O
k -X- _ O
images -X- _ O
from -X- _ O
a -X- _ O
search -X- _ O
engine -X- _ O
, -X- _ O
running -X- _ O
those -X- _ O
through -X- _ O
a -X- _ O
convolutional -X- _ O
network -X- _ O
and -X- _ O
aggregating -X- _ O
the -X- _ O
results -X- _ O
. -X- _ O

A -X- _ O
very -X- _ O
different -X- _ O
way -X- _ O
to -X- _ O
obtain -X- _ O
word -X- _ O
embeddings -X- _ O
is -X- _ O
to -X- _ O
aggregate -X- _ O
features -X- _ O
obtained -X- _ O
by -X- _ O
using -X- _ O
the -X- _ O
word -X- _ O
as -X- _ O
a -X- _ O
query -X- _ O
for -X- _ O
an -X- _ O
image -X- _ O
search -X- _ O
engine -X- _ O
. -X- _ O

While -X- _ O
immensely -X- _ O
successful -X- _ O
, -X- _ O
this -X- _ O
lookup -X- _ O
operation -X- _ O
is -X- _ O
typically -X- _ O
learned -X- _ O
through -X- _ O
co -X- _ O
- -X- _ O
occurrence -X- _ O
objectives -X- _ O
or -X- _ O
a -X- _ O
task -X- _ O
- -X- _ O
dependent -X- _ O
reward -X- _ O
signal -X- _ O
. -X- _ O

The -X- _ O
dominant -X- _ O
approach -X- _ O
to -X- _ O
learning -X- _ O
distributed -X- _ O
word -X- _ O
representations -X- _ O
is -X- _ O
through -X- _ O
indexing -X- _ O
a -X- _ O
learned -X- _ O
matrix -X- _ O
. -X- _ O

One -X- _ O
place -X- _ O
to -X- _ O
incorporate -X- _ O
grounding -X- _ O
is -X- _ O
in -X- _ O
the -X- _ O
lookup -X- _ O
table -X- _ O
that -X- _ O
maps -X- _ O
tokens -X- _ O
to -X- _ O
vectors -X- _ O
. -X- _ O

embodied -X- _ O
cognition -X- _ O
, -X- _ O
search -X- _ O
engines -X- _ O
allow -X- _ O
us -X- _ O
to -X- _ O
get -X- _ O
a -X- _ O
form -X- _ O
of -X- _ O
quasi -X- _ O
- -X- _ O
grounding -X- _ O
from -X- _ O
high -X- _ O
- -X- _ O
coverage -X- _ O
' -X- _ O
snapshots -X- _ O
' -X- _ O
of -X- _ O
our -X- _ O
physical -X- _ O
world -X- _ O
provided -X- _ O
by -X- _ O
the -X- _ O
interaction -X- _ O
of -X- _ O
millions -X- _ O
of -X- _ O
users -X- _ O
. -X- _ O

While -X- _ O
true -X- _ O
natural -X- _ O
language -X- _ O
understanding -X- _ O
may -X- _ O
require -X- _ O
fully -X- _ O
* -X- _ O
Both -X- _ O
authors -X- _ O
contributed -X- _ O
equally -X- _ O
to -X- _ O
this -X- _ O
work -X- _ O
. -X- _ O

Search -X- _ O
engines -X- _ O
allow -X- _ O
us -X- _ O
to -X- _ O
obtain -X- _ O
correspondences -X- _ O
between -X- _ O
language -X- _ O
and -X- _ O
images -X- _ O
that -X- _ O
are -X- _ O
far -X- _ O
less -X- _ O
restricted -X- _ O
than -X- _ O
existing -X- _ O
multimodal -X- _ O
datasets -X- _ O
which -X- _ O
typically -X- _ O
have -X- _ O
restricted -X- _ O
vocabularies -X- _ O
. -X- _ O

One -X- _ O
source -X- _ O
of -X- _ O
grounding -X- _ O
, -X- _ O
which -X- _ O
has -X- _ O
been -X- _ O
utilized -X- _ O
in -X- _ O
existing -X- _ O
work -X- _ O
, -X- _ O
is -X- _ O
image -X- _ O
search -X- _ O
engines -X- _ O
. -X- _ O

In -X- _ O
recent -X- _ O
years -X- _ O
, -X- _ O
a -X- _ O
large -X- _ O
amount -X- _ O
of -X- _ O
research -X- _ O
has -X- _ O
focused -X- _ O
on -X- _ O
integrating -X- _ O
vision -X- _ O
and -X- _ O
language -X- _ O
to -X- _ O
obtain -X- _ O
visually -X- _ O
grounded -X- _ O
word -X- _ O
and -X- _ O
sentence -X- _ O
representations -X- _ O
. -X- _ O

Constructing -X- _ B-TaskName
grounded -X- _ I-TaskName
representations -X- _ I-TaskName
of -X- _ I-TaskName
natural -X- _ I-TaskName
language -X- _ I-TaskName
is -X- _ O
a -X- _ O
promising -X- _ O
step -X- _ O
towards -X- _ O
achieving -X- _ O
human -X- _ O
- -X- _ O
like -X- _ O
language -X- _ O
learning -X- _ O
. -X- _ O

Introduction -X- _ O
. -X- _ O

We -X- _ O
also -X- _ O
show -X- _ O
that -X- _ O
gate -X- _ O
activations -X- _ O
corresponding -X- _ O
to -X- _ O
Picturebook -X- _ B-MethodName
embeddings -X- _ O
are -X- _ O
highly -X- _ O
correlated -X- _ O
to -X- _ O
human -X- _ O
judgments -X- _ O
of -X- _ O
concreteness -X- _ O
ratings -X- _ O
. -X- _ O

We -X- _ O
experiment -X- _ O
and -X- _ O
report -X- _ O
results -X- _ O
across -X- _ O
a -X- _ O
wide -X- _ O
range -X- _ O
of -X- _ O
tasks -X- _ O
: -X- _ O
word -X- _ B-TaskName
similarity -X- _ I-TaskName
, -X- _ O
natural -X- _ B-TaskName
language -X- _ I-TaskName
inference -X- _ I-TaskName
, -X- _ O
semantic -X- _ B-TaskName
relatedness -X- _ I-TaskName
, -X- _ O
sentiment -X- _ B-TaskName
/ -X- _ I-TaskName
topic -X- _ I-TaskName
classification -X- _ I-TaskName
, -X- _ O
image -X- _ B-TaskName
- -X- _ I-TaskName
sentence -X- _ I-TaskName
ranking -X- _ I-TaskName
and -X- _ O
machine -X- _ B-TaskName
translation -X- _ I-TaskName
. -X- _ O

We -X- _ O
also -X- _ O
introduce -X- _ O
Inverse -X- _ B-MethodName
Picturebook -X- _ I-MethodName
, -X- _ O
a -X- _ O
mechanism -X- _ O
to -X- _ O
map -X- _ O
a -X- _ O
Picturebook -X- _ B-MethodName
embedding -X- _ O
back -X- _ O
into -X- _ O
words -X- _ O
. -X- _ O

We -X- _ O
introduce -X- _ O
a -X- _ O
multimodal -X- _ O
gating -X- _ O
function -X- _ O
to -X- _ O
fuse -X- _ O
our -X- _ O
Picturebook -X- _ B-MethodName
embeddings -X- _ O
with -X- _ O
other -X- _ O
word -X- _ O
representations -X- _ O
. -X- _ O

For -X- _ O
each -X- _ O
word -X- _ O
in -X- _ O
a -X- _ O
vocabulary -X- _ O
, -X- _ O
we -X- _ O
extract -X- _ O
the -X- _ O
top -X- _ O
- -X- _ O
k -X- _ O
images -X- _ O
from -X- _ O
Google -X- _ O
image -X- _ O
search -X- _ O
and -X- _ O
feed -X- _ O
the -X- _ O
images -X- _ O
through -X- _ O
a -X- _ O
convolutional -X- _ O
network -X- _ O
to -X- _ O
extract -X- _ O
a -X- _ O
word -X- _ O
embedding -X- _ O
. -X- _ O

We -X- _ O
introduce -X- _ O
Picturebook -X- _ B-MethodName
, -X- _ O
a -X- _ O
large -X- _ O
- -X- _ O
scale -X- _ O
lookup -X- _ O
operation -X- _ O
to -X- _ O
ground -X- _ O
language -X- _ O
via -X- _ O
' -X- _ O
snapshots -X- _ O
' -X- _ O
of -X- _ O
our -X- _ O
physical -X- _ O
world -X- _ O
accessed -X- _ O
through -X- _ O
image -X- _ O
search -X- _ O
. -X- _ O

Illustrative -X- _ B-TaskName
Language -X- _ I-TaskName
Understanding -X- _ I-TaskName
: -X- _ O
Large -X- _ O
- -X- _ O
Scale -X- _ O
Visual -X- _ B-TaskName
Grounding -X- _ I-TaskName
with -X- _ I-TaskName
Image -X- _ I-TaskName
Search -X- _ I-TaskName
. -X- _ O

