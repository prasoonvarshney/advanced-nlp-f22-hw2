-DOCSTART- -X- O
TC -X- _ O
and -X- _ O
TB -X- _ O
were -X- _ O
supported -X- _ O
by -X- _ O
the -X- _ O
Australian -X- _ O
Research -X- _ O
Council -X- _ O
. -X- _ O

LR -X- _ O
was -X- _ O
supported -X- _ O
by -X- _ O
EPSRC -X- _ O
grant -X- _ O
EP -X- _ O
/ -X- _ O
I037512/1 -X- _ O
and -X- _ O
ERC -X- _ O
Starting -X- _ O
Grant -X- _ O
DisCoTex -X- _ O
( -X- _ O
306920 -X- _ O
) -X- _ O
. -X- _ O

Acknowledgments -X- _ O
. -X- _ O

Overall -X- _ O
, -X- _ O
we -X- _ O
conclude -X- _ O
that -X- _ O
the -X- _ O
DIFFVEC -X- _ O
approach -X- _ O
has -X- _ O
impressive -X- _ O
utility -X- _ O
over -X- _ O
a -X- _ O
broad -X- _ O
range -X- _ O
of -X- _ O
lexical -X- _ O
relations -X- _ O
, -X- _ O
especially -X- _ O
under -X- _ O
supervised -X- _ O
classification -X- _ O
. -X- _ O

Negative -X- _ O
sampling -X- _ O
also -X- _ O
improves -X- _ O
classification -X- _ O
when -X- _ O
the -X- _ O
training -X- _ O
and -X- _ O
test -X- _ O
vocabulary -X- _ O
are -X- _ O
split -X- _ O
to -X- _ O
minimise -X- _ O
lexical -X- _ O
memorisation -X- _ O
. -X- _ O

Classification -X- _ O
performs -X- _ O
less -X- _ O
well -X- _ O
over -X- _ O
open -X- _ O
data -X- _ O
, -X- _ O
although -X- _ O
with -X- _ O
the -X- _ O
introduction -X- _ O
of -X- _ O
automatically -X- _ O
- -X- _ O
generated -X- _ O
negative -X- _ O
samples -X- _ O
, -X- _ O
the -X- _ O
results -X- _ O
improve -X- _ O
substantially -X- _ O
. -X- _ O

In -X- _ O
contrast -X- _ O
, -X- _ O
classification -X- _ O
over -X- _ O
the -X- _ O
DIFFVECs -X- _ O
works -X- _ O
extremely -X- _ O
well -X- _ O
in -X- _ O
a -X- _ O
closed -X- _ O
- -X- _ O
world -X- _ O
setting -X- _ O
, -X- _ O
showing -X- _ O
that -X- _ O
dimensions -X- _ O
of -X- _ O
DIFFVECs -X- _ O
encode -X- _ O
lexical -X- _ O
relations -X- _ O
. -X- _ O

Using -X- _ O
clustering -X- _ O
we -X- _ O
showed -X- _ O
that -X- _ O
many -X- _ O
types -X- _ O
of -X- _ O
morphosyntactic -X- _ O
and -X- _ O
morphosemantic -X- _ O
differences -X- _ O
are -X- _ O
captured -X- _ O
by -X- _ O
DIFFVECs -X- _ O
, -X- _ O
but -X- _ O
that -X- _ O
lexical -X- _ O
semantic -X- _ O
relations -X- _ O
are -X- _ O
captured -X- _ O
less -X- _ O
well -X- _ O
, -X- _ O
a -X- _ O
finding -X- _ O
which -X- _ O
is -X- _ O
consistent -X- _ O
with -X- _ O
previous -X- _ O
work -X- _ O
( -X- _ O
Köper -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
. -X- _ O

This -X- _ O
paper -X- _ O
is -X- _ O
the -X- _ O
first -X- _ O
to -X- _ O
test -X- _ O
the -X- _ O
generalisability -X- _ O
of -X- _ O
the -X- _ O
vector -X- _ O
difference -X- _ O
approach -X- _ O
across -X- _ O
a -X- _ O
broad -X- _ O
range -X- _ O
of -X- _ O
lexical -X- _ O
relations -X- _ O
( -X- _ O
in -X- _ O
raw -X- _ O
number -X- _ O
and -X- _ O
also -X- _ O
variety -X- _ O
) -X- _ O
. -X- _ O

Conclusions -X- _ O
. -X- _ O

At -X- _ O
the -X- _ O
maximum -X- _ O
level -X- _ O
of -X- _ O
random -X- _ O
word -X- _ O
pairs -X- _ O
in -X- _ O
the -X- _ O
test -X- _ O
data -X- _ O
, -X- _ O
the -X- _ O
F -X- _ O
- -X- _ O
score -X- _ O
for -X- _ O
the -X- _ O
negative -X- _ O
sampling -X- _ O
classifier -X- _ O
is -X- _ O
higher -X- _ O
than -X- _ O
for -X- _ O
the -X- _ O
standard -X- _ O
classifier -X- _ O
. -X- _ O

This -X- _ O
benefit -X- _ O
comes -X- _ O
at -X- _ O
the -X- _ O
expense -X- _ O
of -X- _ O
recall -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
much -X- _ O
lower -X- _ O
when -X- _ O
negative -X- _ O
sampling -X- _ O
is -X- _ O
used -X- _ O
( -X- _ O
note -X- _ O
that -X- _ O
recall -X- _ O
stays -X- _ O
relatively -X- _ O
constant -X- _ O
as -X- _ O
random -X- _ O
word -X- _ O
pairs -X- _ O
are -X- _ O
added -X- _ O
, -X- _ O
as -X- _ O
the -X- _ O
vast -X- _ O
majority -X- _ O
of -X- _ O
them -X- _ O
do -X- _ O
not -X- _ O
correspond -X- _ O
to -X- _ O
any -X- _ O
relation -X- _ O
) -X- _ O
. -X- _ O

In -X- _ O
comparison -X- _ O
, -X- _ O
the -X- _ O
precision -X- _ O
when -X- _ O
negative -X- _ O
sampling -X- _ O
is -X- _ O
used -X- _ O
shows -X- _ O
only -X- _ O
a -X- _ O
small -X- _ O
drop -X- _ O
- -X- _ O
off -X- _ O
, -X- _ O
indicating -X- _ O
that -X- _ O
negative -X- _ O
sampling -X- _ O
is -X- _ O
effective -X- _ O
at -X- _ O
maintaining -X- _ O
precision -X- _ O
in -X- _ O
an -X- _ O
OPEN -X- _ O
- -X- _ O
WORLD -X- _ O
setting -X- _ O
even -X- _ O
when -X- _ O
the -X- _ O
training -X- _ O
and -X- _ O
test -X- _ O
vocabulary -X- _ O
are -X- _ O
disjoint -X- _ O
. -X- _ O

Observe -X- _ O
that -X- _ O
the -X- _ O
precision -X- _ O
for -X- _ O
the -X- _ O
standard -X- _ O
clas -X- _ O
- -X- _ O
sifier -X- _ O
decreases -X- _ O
rapidly -X- _ O
as -X- _ O
more -X- _ O
random -X- _ O
word -X- _ O
pairs -X- _ O
are -X- _ O
added -X- _ O
to -X- _ O
the -X- _ O
test -X- _ O
data -X- _ O
. -X- _ O

The -X- _ O
results -X- _ O
are -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
4 -X- _ O
. -X- _ O

We -X- _ O
then -X- _ O
train -X- _ O
classifiers -X- _ O
with -X- _ O
and -X- _ O
without -X- _ O
negative -X- _ O
sampling -X- _ O
( -X- _ O
§ -X- _ O
5.3 -X- _ O
) -X- _ O
, -X- _ O
incrementally -X- _ O
adding -X- _ O
the -X- _ O
random -X- _ O
word -X- _ O
pairs -X- _ O
from -X- _ O
§ -X- _ O
5.2 -X- _ O
to -X- _ O
the -X- _ O
test -X- _ O
data -X- _ O
( -X- _ O
from -X- _ O
no -X- _ O
random -X- _ O
word -X- _ O
pairs -X- _ O
to -X- _ O
five -X- _ O
times -X- _ O
the -X- _ O
original -X- _ O
size -X- _ O
of -X- _ O
the -X- _ O
test -X- _ O
data -X- _ O
) -X- _ O
to -X- _ O
investigate -X- _ O
the -X- _ O
interaction -X- _ O
of -X- _ O
negative -X- _ O
sampling -X- _ O
with -X- _ O
greater -X- _ O
diversity -X- _ O
in -X- _ O
the -X- _ O
test -X- _ O
set -X- _ O
when -X- _ O
there -X- _ O
is -X- _ O
a -X- _ O
split -X- _ O
vocabulary -X- _ O
. -X- _ O

( -X- _ O
2015b -X- _ O
) -X- _ O
in -X- _ O
splitting -X- _ O
our -X- _ O
vocabulary -X- _ O
into -X- _ O
training -X- _ O
and -X- _ O
test -X- _ O
partitions -X- _ O
, -X- _ O
to -X- _ O
ensure -X- _ O
there -X- _ O
is -X- _ O
no -X- _ O
overlap -X- _ O
between -X- _ O
training -X- _ O
and -X- _ O
test -X- _ O
vocabulary -X- _ O
. -X- _ O

To -X- _ O
address -X- _ O
this -X- _ O
effect -X- _ O
, -X- _ O
we -X- _ O
follow -X- _ O
Levy -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

Weeds -X- _ O
. -X- _ O

Lexical -X- _ O
Memorisation -X- _ O
. -X- _ O

For -X- _ O
example -X- _ O
, -X- _ O
( -X- _ O
animal -X- _ O
, -X- _ O
cat -X- _ O
) -X- _ O
, -X- _ O
( -X- _ O
animal -X- _ O
, -X- _ O
dog -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
( -X- _ O
animal -X- _ O
, -X- _ O
pig -X- _ O
) -X- _ O
all -X- _ O
share -X- _ O
the -X- _ O
superclass -X- _ O
animal -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
model -X- _ O
thus -X- _ O
learns -X- _ O
to -X- _ O
classify -X- _ O
as -X- _ O
positive -X- _ O
any -X- _ O
word -X- _ O
pair -X- _ O
with -X- _ O
animal -X- _ O
as -X- _ O
the -X- _ O
first -X- _ O
word -X- _ O
. -X- _ O

( -X- _ O
2015b -X- _ O
) -X- _ O
recently -X- _ O
showed -X- _ O
that -X- _ O
supervised -X- _ O
methods -X- _ O
using -X- _ O
DIFF -X- _ O
- -X- _ O
VECs -X- _ O
achieve -X- _ O
artificially -X- _ O
high -X- _ O
results -X- _ O
as -X- _ O
a -X- _ O
result -X- _ O
of -X- _ O
" -X- _ O
lexical -X- _ O
memorisation -X- _ O
" -X- _ O
over -X- _ O
frequent -X- _ O
words -X- _ O
asso- -X- _ O
ciated -X- _ O
with -X- _ O
the -X- _ O
hypernym -X- _ O
relation -X- _ O
. -X- _ O

( -X- _ O
2014 -X- _ O
) -X- _ O
and -X- _ O
Levy -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

et -X- _ O
al -X- _ O
. -X- _ O

The -X- _ O
most -X- _ O
striking -X- _ O
difference -X- _ O
in -X- _ O
performance -X- _ O
was -X- _ O
for -X- _ O
LEXSEM -X- _ O
Mero -X- _ O
, -X- _ O
where -X- _ O
the -X- _ O
standard -X- _ O
classifier -X- _ O
generated -X- _ O
many -X- _ O
false -X- _ O
positive -X- _ O
noun -X- _ O
pairs -X- _ O
( -X- _ O
e.g. -X- _ O
( -X- _ O
series -X- _ O
, -X- _ O
radio -X- _ O
) -X- _ O
) -X- _ O
, -X- _ O
but -X- _ O
the -X- _ O
false -X- _ O
positive -X- _ O
rate -X- _ O
was -X- _ O
considerably -X- _ O
reduced -X- _ O
with -X- _ O
negative -X- _ O
sampling -X- _ O
. -X- _ O

The -X- _ O
classifier -X- _ O
was -X- _ O
able -X- _ O
to -X- _ O
capture -X- _ O
( -X- _ O
herd -X- _ O
, -X- _ O
horses -X- _ O
) -X- _ O
but -X- _ O
not -X- _ O
( -X- _ O
run -X- _ O
, -X- _ O
salmon -X- _ O
) -X- _ O
, -X- _ O
( -X- _ O
party -X- _ O
, -X- _ O
jays -X- _ O
) -X- _ O
or -X- _ O
( -X- _ O
singular -X- _ O
, -X- _ O
boar -X- _ O
) -X- _ O
as -X- _ O
instances -X- _ O
of -X- _ O
NOUN -X- _ O
Coll -X- _ O
, -X- _ O
possibly -X- _ O
because -X- _ O
of -X- _ O
polysemy -X- _ O
. -X- _ O

For -X- _ O
example -X- _ O
, -X- _ O
the -X- _ O
standard -X- _ O
classifier -X- _ O
for -X- _ O
NOUN -X- _ O
Coll -X- _ O
learned -X- _ O
to -X- _ O
match -X- _ O
word -X- _ O
pairs -X- _ O
including -X- _ O
an -X- _ O
animal -X- _ O
name -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
( -X- _ O
plague -X- _ O
, -X- _ O
rats -X- _ O
) -X- _ O
) -X- _ O
, -X- _ O
while -X- _ O
training -X- _ O
with -X- _ O
negative -X- _ O
samples -X- _ O
resulted -X- _ O
in -X- _ O
much -X- _ O
more -X- _ O
conservative -X- _ O
predictions -X- _ O
and -X- _ O
consequently -X- _ O
much -X- _ O
lower -X- _ O
recall -X- _ O
. -X- _ O

Overall -X- _ O
this -X- _ O
leads -X- _ O
to -X- _ O
higher -X- _ O
F -X- _ O
- -X- _ O
scores -X- _ O
, -X- _ O
as -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
3 -X- _ O
, -X- _ O
other -X- _ O
than -X- _ O
for -X- _ O
hypernyms -X- _ O
( -X- _ O
LEXSEM -X- _ O
Hyper -X- _ O
) -X- _ O
and -X- _ O
prefixes -X- _ O
( -X- _ O
PREFIX -X- _ O
) -X- _ O
. -X- _ O

This -X- _ O
follows -X- _ O
from -X- _ O
the -X- _ O
adversarial -X- _ O
training -X- _ O
scenario -X- _ O
: -X- _ O
using -X- _ O
negative -X- _ O
distractors -X- _ O
results -X- _ O
in -X- _ O
a -X- _ O
more -X- _ O
conservative -X- _ O
classifier -X- _ O
, -X- _ O
that -X- _ O
correctly -X- _ O
classifies -X- _ O
the -X- _ O
vast -X- _ O
majority -X- _ O
of -X- _ O
the -X- _ O
random -X- _ O
word -X- _ O
pairs -X- _ O
as -X- _ O
not -X- _ O
corresponding -X- _ O
to -X- _ O
a -X- _ O
given -X- _ O
relation -X- _ O
, -X- _ O
resulting -X- _ O
in -X- _ O
higher -X- _ O
precision -X- _ O
at -X- _ O
the -X- _ O
expense -X- _ O
of -X- _ O
a -X- _ O
small -X- _ O
drop -X- _ O
in -X- _ O
recall -X- _ O
. -X- _ O

Observe -X- _ O
that -X- _ O
the -X- _ O
precision -X- _ O
is -X- _ O
much -X- _ O
higher -X- _ O
and -X- _ O
recall -X- _ O
somewhat -X- _ O
lower -X- _ O
compared -X- _ O
to -X- _ O
the -X- _ O
classifier -X- _ O
trained -X- _ O
with -X- _ O
only -X- _ O
positive -X- _ O
samples -X- _ O
. -X- _ O

12 -X- _ O
The -X- _ O
results -X- _ O
are -X- _ O
shown -X- _ O
in -X- _ O
the -X- _ O
right -X- _ O
half -X- _ O
of -X- _ O
Table -X- _ O
5 -X- _ O
( -X- _ O
as -X- _ O
" -X- _ O
+ -X- _ O
neg -X- _ O
" -X- _ O
) -X- _ O
. -X- _ O

After -X- _ O
training -X- _ O
our -X- _ O
classifier -X- _ O
, -X- _ O
we -X- _ O
evaluate -X- _ O
its -X- _ O
predictions -X- _ O
in -X- _ O
the -X- _ O
same -X- _ O
way -X- _ O
as -X- _ O
in -X- _ O
§ -X- _ O
5.2 -X- _ O
, -X- _ O
using -X- _ O
the -X- _ O
same -X- _ O
test -X- _ O
set -X- _ O
combining -X- _ O
related -X- _ O
and -X- _ O
random -X- _ O
word -X- _ O
pairs -X- _ O
. -X- _ O

Both -X- _ O
types -X- _ O
of -X- _ O
distractors -X- _ O
are -X- _ O
added -X- _ O
to -X- _ O
the -X- _ O
training -X- _ O
set -X- _ O
, -X- _ O
such -X- _ O
that -X- _ O
there -X- _ O
are -X- _ O
equal -X- _ O
numbers -X- _ O
of -X- _ O
valid -X- _ O
relations -X- _ O
, -X- _ O
opposite -X- _ O
pairs -X- _ O
and -X- _ O
shuffled -X- _ O
pairs -X- _ O
. -X- _ O

This -X- _ O
is -X- _ O
targeted -X- _ O
at -X- _ O
relations -X- _ O
that -X- _ O
take -X- _ O
specific -X- _ O
word -X- _ O
classes -X- _ O
in -X- _ O
particular -X- _ O
positions -X- _ O
, -X- _ O
e.g. -X- _ O
, -X- _ O
( -X- _ O
VB -X- _ O
, -X- _ O
VBD -X- _ O
) -X- _ O
word -X- _ O
pairs -X- _ O
, -X- _ O
so -X- _ O
that -X- _ O
the -X- _ O
model -X- _ O
learns -X- _ O
to -X- _ O
encode -X- _ O
the -X- _ O
relation -X- _ O
rather -X- _ O
than -X- _ O
simply -X- _ O
learning -X- _ O
the -X- _ O
properties -X- _ O
of -X- _ O
the -X- _ O
word -X- _ O
classes -X- _ O
. -X- _ O

shuffled -X- _ O
pairs -X- _ O
: -X- _ O
generated -X- _ O
by -X- _ O
replacing -X- _ O
w -X- _ O
2 -X- _ O
with -X- _ O
a -X- _ O
random -X- _ O
word -X- _ O
w -X- _ O
2 -X- _ O
from -X- _ O
the -X- _ O
same -X- _ O
relation -X- _ O
, -X- _ O
Shuff -X- _ O
w1 -X- _ O
, -X- _ O
w2 -X- _ O
= -X- _ O
word -X- _ O
2 -X- _ O
− -X- _ O
word -X- _ O
1 -X- _ O
. -X- _ O

This -X- _ O
ensures -X- _ O
the -X- _ O
classifier -X- _ O
adequately -X- _ O
captures -X- _ O
the -X- _ O
asymmetry -X- _ O
in -X- _ O
the -X- _ O
relations -X- _ O
. -X- _ O

distractors -X- _ O
: -X- _ O
opposite -X- _ O
pairs -X- _ O
: -X- _ O
generated -X- _ O
by -X- _ O
switching -X- _ O
the -X- _ O
order -X- _ O
of -X- _ O
word -X- _ O
pairs -X- _ O
, -X- _ O
Oppos -X- _ O
w1 -X- _ O
, -X- _ O
w2 -X- _ O
= -X- _ O
word -X- _ O
1 -X- _ O
− -X- _ O
word -X- _ O
2 -X- _ O
. -X- _ O

To -X- _ O
this -X- _ O
end -X- _ O
, -X- _ O
we -X- _ O
automatically -X- _ O
generated -X- _ O
two -X- _ O
types -X- _ O
of -X- _ O
negative -X- _ O
dings -X- _ O
. -X- _ O

The -X- _ O
basic -X- _ O
intuition -X- _ O
behind -X- _ O
this -X- _ O
approach -X- _ O
is -X- _ O
to -X- _ O
construct -X- _ O
samples -X- _ O
which -X- _ O
will -X- _ O
force -X- _ O
the -X- _ O
model -X- _ O
to -X- _ O
learn -X- _ O
decision -X- _ O
boundaries -X- _ O
that -X- _ O
more -X- _ O
tightly -X- _ O
capture -X- _ O
the -X- _ O
true -X- _ O
scope -X- _ O
of -X- _ O
a -X- _ O
given -X- _ O
relation -X- _ O
. -X- _ O

To -X- _ O
address -X- _ O
the -X- _ O
problem -X- _ O
of -X- _ O
incorrectly -X- _ O
classifying -X- _ O
random -X- _ O
word -X- _ O
pairs -X- _ O
as -X- _ O
valid -X- _ O
relations -X- _ O
, -X- _ O
we -X- _ O
retrain -X- _ O
the -X- _ O
classifier -X- _ O
on -X- _ O
a -X- _ O
dataset -X- _ O
comprising -X- _ O
both -X- _ O
valid -X- _ O
and -X- _ O
automatically -X- _ O
- -X- _ O
generated -X- _ O
negative -X- _ O
distractor -X- _ O
samples -X- _ O
. -X- _ O

OPEN -X- _ O
- -X- _ O
WORLD -X- _ O
Training -X- _ O
with -X- _ O
Negative -X- _ O
Sampling -X- _ O
. -X- _ O

That -X- _ O
is -X- _ O
, -X- _ O
the -X- _ O
model -X- _ O
captures -X- _ O
syntax -X- _ O
, -X- _ O
but -X- _ O
lacks -X- _ O
the -X- _ O
ability -X- _ O
to -X- _ O
capture -X- _ O
lexical -X- _ O
paradigms -X- _ O
, -X- _ O
and -X- _ O
tends -X- _ O
to -X- _ O
overgenerate -X- _ O
. -X- _ O

For -X- _ O
instance -X- _ O
, -X- _ O
the -X- _ O
random -X- _ O
pairs -X- _ O
( -X- _ O
have -X- _ O
, -X- _ O
works -X- _ O
) -X- _ O
, -X- _ O
( -X- _ O
turn -X- _ O
, -X- _ O
took -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
( -X- _ O
works -X- _ O
, -X- _ O
started -X- _ O
) -X- _ O
were -X- _ O
incorrectly -X- _ O
classified -X- _ O
as -X- _ O
VERB -X- _ O
3 -X- _ O
, -X- _ O
VERB -X- _ O
Past -X- _ O
and -X- _ O
VERB -X- _ O
3Past -X- _ O
, -X- _ O
respectively -X- _ O
. -X- _ O

The -X- _ O
results -X- _ O
are -X- _ O
much -X- _ O
lower -X- _ O
than -X- _ O
for -X- _ O
the -X- _ O
closed -X- _ O
- -X- _ O
word -X- _ O
setting -X- _ O
( -X- _ O
Table -X- _ O
4 -X- _ O
) -X- _ O
, -X- _ O
most -X- _ O
notably -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
precision -X- _ O
( -X- _ O
P -X- _ O
) -X- _ O
. -X- _ O

The -X- _ O
results -X- _ O
of -X- _ O
our -X- _ O
experiments -X- _ O
are -X- _ O
presented -X- _ O
in -X- _ O
the -X- _ O
left -X- _ O
half -X- _ O
of -X- _ O
Table -X- _ O
5 -X- _ O
, -X- _ O
in -X- _ O
which -X- _ O
we -X- _ O
report -X- _ O
on -X- _ O
results -X- _ O
over -X- _ O
the -X- _ O
combination -X- _ O
of -X- _ O
the -X- _ O
original -X- _ O
test -X- _ O
data -X- _ O
from -X- _ O
§ -X- _ O
5.1 -X- _ O
and -X- _ O
the -X- _ O
random -X- _ O
word -X- _ O
pairs -X- _ O
, -X- _ O
noting -X- _ O
that -X- _ O
recall -X- _ O
( -X- _ O
R -X- _ O
) -X- _ O
for -X- _ O
OPEN -X- _ O
- -X- _ O
WORLD -X- _ O
takes -X- _ O
the -X- _ O
form -X- _ O
of -X- _ O
relative -X- _ O
recall -X- _ O
( -X- _ O
Pantel -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2004 -X- _ O
) -X- _ O
over -X- _ O
the -X- _ O
positively -X- _ O
- -X- _ O
classified -X- _ O
word -X- _ O
pairs -X- _ O
. -X- _ O

Fully -X- _ O
annotating -X- _ O
our -X- _ O
random -X- _ O
word -X- _ O
pairs -X- _ O
is -X- _ O
prohibitively -X- _ O
expensive -X- _ O
, -X- _ O
so -X- _ O
instead -X- _ O
, -X- _ O
we -X- _ O
manually -X- _ O
annotated -X- _ O
only -X- _ O
the -X- _ O
word -X- _ O
pairs -X- _ O
which -X- _ O
were -X- _ O
positively -X- _ O
classified -X- _ O
by -X- _ O
one -X- _ O
of -X- _ O
our -X- _ O
models -X- _ O
. -X- _ O

We -X- _ O
train -X- _ O
9 -X- _ O
binary -X- _ O
RBF -X- _ O
- -X- _ O
kernel -X- _ O
SVM -X- _ O
classifiers -X- _ O
on -X- _ O
the -X- _ O
training -X- _ O
partition -X- _ O
, -X- _ O
and -X- _ O
evaluate -X- _ O
on -X- _ O
our -X- _ O
randomly -X- _ O
augmented -X- _ O
test -X- _ O
set -X- _ O
. -X- _ O

This -X- _ O
procedure -X- _ O
generates -X- _ O
word -X- _ O
pairs -X- _ O
that -X- _ O
are -X- _ O
representative -X- _ O
of -X- _ O
the -X- _ O
frequency -X- _ O
profile -X- _ O
of -X- _ O
our -X- _ O
corpus -X- _ O
. -X- _ O

( -X- _ O
2 -X- _ O
) -X- _ O
take -X- _ O
the -X- _ O
Cartesian -X- _ O
product -X- _ O
over -X- _ O
pairs -X- _ O
of -X- _ O
words -X- _ O
from -X- _ O
the -X- _ O
seed -X- _ O
lexicon -X- _ O
; -X- _ O
( -X- _ O
3 -X- _ O
) -X- _ O
sample -X- _ O
word -X- _ O
pairs -X- _ O
uniformly -X- _ O
from -X- _ O
this -X- _ O
set -X- _ O
. -X- _ O

The -X- _ O
test -X- _ O
data -X- _ O
is -X- _ O
augmented -X- _ O
with -X- _ O
an -X- _ O
equal -X- _ O
quantity -X- _ O
of -X- _ O
random -X- _ O
pairs -X- _ O
, -X- _ O
generated -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
sample -X- _ O
a -X- _ O
seed -X- _ O
lexicon -X- _ O
by -X- _ O
drawing -X- _ O
words -X- _ O
proportional -X- _ O
to -X- _ O
their -X- _ O
frequency -X- _ O
in -X- _ O
Wikipedia -X- _ O
; -X- _ O
11 -X- _ O
Table -X- _ O
5 -X- _ O
: -X- _ O
Precision -X- _ O
( -X- _ O
P -X- _ O
) -X- _ O
and -X- _ O
recall -X- _ O
( -X- _ O
R -X- _ O
) -X- _ O
for -X- _ O
OPEN -X- _ O
- -X- _ O
WORLD -X- _ O
classification -X- _ O
, -X- _ O
using -X- _ O
the -X- _ O
binary -X- _ O
classifier -X- _ O
without -X- _ O
( -X- _ O
" -X- _ O
Orig -X- _ O
" -X- _ O
) -X- _ O
and -X- _ O
with -X- _ O
( -X- _ O
" -X- _ O
+ -X- _ O
neg -X- _ O
" -X- _ O
) -X- _ O
negative -X- _ O
samples -X- _ O
. -X- _ O

10 -X- _ O
For -X- _ O
these -X- _ O
experiments -X- _ O
, -X- _ O
we -X- _ O
train -X- _ O
a -X- _ O
binary -X- _ O
classifier -X- _ O
for -X- _ O
each -X- _ O
relation -X- _ O
type -X- _ O
, -X- _ O
using -X- _ O
2 -X- _ O
3 -X- _ O
of -X- _ O
our -X- _ O
relation -X- _ O
data -X- _ O
for -X- _ O
training -X- _ O
and -X- _ O
1 -X- _ O
3 -X- _ O
for -X- _ O
testing -X- _ O
. -X- _ O

This -X- _ O
setting -X- _ O
aims -X- _ O
to -X- _ O
illustrate -X- _ O
whether -X- _ O
a -X- _ O
DIFF -X- _ O
- -X- _ O
VEC -X- _ O
- -X- _ O
based -X- _ O
classifier -X- _ O
is -X- _ O
capable -X- _ O
of -X- _ O
differentiating -X- _ O
related -X- _ O
word -X- _ O
pairs -X- _ O
from -X- _ O
noise -X- _ O
, -X- _ O
and -X- _ O
can -X- _ O
be -X- _ O
applied -X- _ O
to -X- _ O
open -X- _ O
data -X- _ O
to -X- _ O
learn -X- _ O
new -X- _ O
related -X- _ O
word -X- _ O
pairs -X- _ O
. -X- _ O

We -X- _ O
now -X- _ O
turn -X- _ O
to -X- _ O
a -X- _ O
more -X- _ O
challenging -X- _ O
evaluation -X- _ O
setting -X- _ O
: -X- _ O
a -X- _ O
test -X- _ O
set -X- _ O
including -X- _ O
word -X- _ O
pairs -X- _ O
drawn -X- _ O
at -X- _ O
random -X- _ O
. -X- _ O

OPEN -X- _ O
- -X- _ O
WORLD -X- _ O
Classification -X- _ O
. -X- _ O

The -X- _ O
impact -X- _ O
of -X- _ O
the -X- _ O
training -X- _ O
data -X- _ O
volume -X- _ O
for -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
of -X- _ O
the -X- _ O
embeddings -X- _ O
is -X- _ O
also -X- _ O
less -X- _ O
pronounced -X- _ O
than -X- _ O
in -X- _ O
the -X- _ O
case -X- _ O
of -X- _ O
our -X- _ O
clustering -X- _ O
experiment -X- _ O
. -X- _ O

( -X- _ O
2015a -X- _ O
) -X- _ O
that -X- _ O
under -X- _ O
appropriate -X- _ O
parameter -X- _ O
settings -X- _ O
, -X- _ O
count -X- _ O
- -X- _ O
based -X- _ O
methods -X- _ O
achieve -X- _ O
high -X- _ O
results -X- _ O
. -X- _ O

We -X- _ O
observe -X- _ O
no -X- _ O
real -X- _ O
difference -X- _ O
between -X- _ O
w2v -X- _ O
wiki -X- _ O
and -X- _ O
SVD -X- _ O
wiki -X- _ O
, -X- _ O
supporting -X- _ O
the -X- _ O
hypothesis -X- _ O
of -X- _ O
Levy -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

Somewhat -X- _ O
surprisingly -X- _ O
, -X- _ O
given -X- _ O
the -X- _ O
small -X- _ O
dimensionality -X- _ O
of -X- _ O
the -X- _ O
input -X- _ O
( -X- _ O
vectors -X- _ O
of -X- _ O
size -X- _ O
300 -X- _ O
for -X- _ O
all -X- _ O
three -X- _ O
methods -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
found -X- _ O
that -X- _ O
the -X- _ O
linear -X- _ O
SVM -X- _ O
slightly -X- _ O
outperformed -X- _ O
a -X- _ O
non -X- _ O
- -X- _ O
linear -X- _ O
SVM -X- _ O
using -X- _ O
an -X- _ O
RBF -X- _ O
kernel -X- _ O
. -X- _ O

The -X- _ O
PREFIX -X- _ O
relation -X- _ O
achieved -X- _ O
markedly -X- _ O
lower -X- _ O
recall -X- _ O
, -X- _ O
resulting -X- _ O
in -X- _ O
a -X- _ O
lower -X- _ O
F -X- _ O
- -X- _ O
score -X- _ O
, -X- _ O
due -X- _ O
to -X- _ O
large -X- _ O
differences -X- _ O
in -X- _ O
the -X- _ O
predominant -X- _ O
usages -X- _ O
associated -X- _ O
with -X- _ O
the -X- _ O
respective -X- _ O
words -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
( -X- _ O
union -X- _ O
, -X- _ O
reunion -X- _ O
) -X- _ O
, -X- _ O
where -X- _ O
the -X- _ O
vector -X- _ O
for -X- _ O
union -X- _ O
is -X- _ O
heavily -X- _ O
biased -X- _ O
by -X- _ O
contexts -X- _ O
associated -X- _ O
with -X- _ O
trade -X- _ O
unions -X- _ O
, -X- _ O
but -X- _ O
reunion -X- _ O
is -X- _ O
heavily -X- _ O
biased -X- _ O
by -X- _ O
contexts -X- _ O
relating -X- _ O
to -X- _ O
social -X- _ O
get -X- _ O
- -X- _ O
togethers -X- _ O
; -X- _ O
and -X- _ O
( -X- _ O
entry -X- _ O
, -X- _ O
reentry -X- _ O
) -X- _ O
, -X- _ O
where -X- _ O
entry -X- _ O
is -X- _ O
associated -X- _ O
with -X- _ O
competitions -X- _ O
and -X- _ O
entrance -X- _ O
to -X- _ O
schools -X- _ O
, -X- _ O
while -X- _ O
reentry -X- _ O
is -X- _ O
associated -X- _ O
with -X- _ O
space -X- _ O
travel -X- _ O
) -X- _ O
. -X- _ O

That -X- _ O
is -X- _ O
, -X- _ O
with -X- _ O
a -X- _ O
simple -X- _ O
linear -X- _ O
transformation -X- _ O
of -X- _ O
the -X- _ O
embedding -X- _ O
dimensions -X- _ O
, -X- _ O
we -X- _ O
are -X- _ O
able -X- _ O
to -X- _ O
achieve -X- _ O
near -X- _ O
- -X- _ O
perfect -X- _ O
results -X- _ O
. -X- _ O

Most -X- _ O
of -X- _ O
the -X- _ O
relationseven -X- _ O
the -X- _ O
most -X- _ O
difficult -X- _ O
ones -X- _ O
from -X- _ O
our -X- _ O
clustering -X- _ O
experiment -X- _ O
-are -X- _ O
classified -X- _ O
with -X- _ O
very -X- _ O
high -X- _ O
Fscore -X- _ O
. -X- _ O

The -X- _ O
SVM -X- _ O
achieves -X- _ O
a -X- _ O
higher -X- _ O
F -X- _ O
- -X- _ O
score -X- _ O
than -X- _ O
the -X- _ O
baseline -X- _ O
on -X- _ O
almost -X- _ O
every -X- _ O
relation -X- _ O
, -X- _ O
particularly -X- _ O
on -X- _ O
LEXSEM -X- _ O
Hyper -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
lower -X- _ O
- -X- _ O
frequency -X- _ O
NOUN -X- _ O
SP -X- _ O
, -X- _ O
NOUN -X- _ O
Coll -X- _ O
, -X- _ O
and -X- _ O
PREFIX -X- _ O
. -X- _ O

We -X- _ O
use -X- _ O
an -X- _ O
SVM -X- _ O
with -X- _ O
a -X- _ O
linear -X- _ O
kernel -X- _ O
, -X- _ O
and -X- _ O
report -X- _ O
results -X- _ O
from -X- _ O
10 -X- _ O
- -X- _ O
fold -X- _ O
cross -X- _ O
- -X- _ O
validation -X- _ O
in -X- _ O
Table -X- _ O
4 -X- _ O
. -X- _ O

We -X- _ O
label -X- _ O
each -X- _ O
cluster -X- _ O
with -X- _ O
the -X- _ O
majority -X- _ O
class -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
training -X- _ O
instances -X- _ O
, -X- _ O
and -X- _ O
evaluate -X- _ O
the -X- _ O
resultant -X- _ O
labelling -X- _ O
for -X- _ O
the -X- _ O
test -X- _ O
instances -X- _ O
. -X- _ O

As -X- _ O
a -X- _ O
baseline -X- _ O
, -X- _ O
we -X- _ O
cluster -X- _ O
the -X- _ O
data -X- _ O
as -X- _ O
described -X- _ O
in -X- _ O
§ -X- _ O
4 -X- _ O
, -X- _ O
running -X- _ O
the -X- _ O
clusterer -X- _ O
several -X- _ O
times -X- _ O
over -X- _ O
the -X- _ O
9 -X- _ O
- -X- _ O
relation -X- _ O
data -X- _ O
to -X- _ O
select -X- _ O
the -X- _ O
optimal -X- _ O
V -X- _ O
- -X- _ O
Measure -X- _ O
value -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
development -X- _ O
data -X- _ O
, -X- _ O
resulting -X- _ O
in -X- _ O
50 -X- _ O
clusters -X- _ O
. -X- _ O

For -X- _ O
the -X- _ O
CLOSED -X- _ O
- -X- _ O
WORLD -X- _ O
setting -X- _ O
, -X- _ O
we -X- _ O
train -X- _ O
and -X- _ O
test -X- _ O
a -X- _ O
multiclass -X- _ O
classifier -X- _ O
on -X- _ O
datasets -X- _ O
comprising -X- _ O
DIFFVEC -X- _ O
, -X- _ O
r -X- _ O
pairs -X- _ O
, -X- _ O
where -X- _ O
r -X- _ O
is -X- _ O
one -X- _ O
of -X- _ O
our -X- _ O
nine -X- _ O
relation -X- _ O
types -X- _ O
, -X- _ O
and -X- _ O
DIFFVEC -X- _ O
is -X- _ O
based -X- _ O
on -X- _ O
one -X- _ O
of -X- _ O
w2v -X- _ O
, -X- _ O
w2v -X- _ O
wiki -X- _ O
and -X- _ O
SVD -X- _ O
. -X- _ O

CLOSED -X- _ O
- -X- _ O
WORLD -X- _ O
Classification -X- _ O
. -X- _ O

( -X- _ O
2015b -X- _ O
) -X- _ O
for -X- _ O
hypernyms -X- _ O
, -X- _ O
by -X- _ O
experimenting -X- _ O
with -X- _ O
disjoint -X- _ O
training -X- _ O
and -X- _ O
test -X- _ O
vocabulary -X- _ O
. -X- _ O

( -X- _ O
2014 -X- _ O
) -X- _ O
and -X- _ O
Levy -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

For -X- _ O
both -X- _ O
settings -X- _ O
, -X- _ O
we -X- _ O
further -X- _ O
investigate -X- _ O
whether -X- _ O
there -X- _ O
is -X- _ O
a -X- _ O
lexical -X- _ O
memorisation -X- _ O
effect -X- _ O
for -X- _ O
a -X- _ O
broad -X- _ O
range -X- _ O
of -X- _ O
relation -X- _ O
types -X- _ O
of -X- _ O
the -X- _ O
sort -X- _ O
identified -X- _ O
by -X- _ O
Weeds -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

We -X- _ O
consider -X- _ O
two -X- _ O
applications -X- _ O
: -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
a -X- _ O
CLOSED -X- _ O
- -X- _ O
WORLD -X- _ O
setting -X- _ O
similar -X- _ O
to -X- _ O
the -X- _ O
unsupervised -X- _ O
evaluation -X- _ O
, -X- _ O
in -X- _ O
which -X- _ O
the -X- _ O
classifier -X- _ O
only -X- _ O
encounters -X- _ O
word -X- _ O
pairs -X- _ O
which -X- _ O
correspond -X- _ O
to -X- _ O
one -X- _ O
of -X- _ O
the -X- _ O
nine -X- _ O
relations -X- _ O
; -X- _ O
and -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
a -X- _ O
more -X- _ O
challenging -X- _ O
OPEN -X- _ O
- -X- _ O
WORLD -X- _ O
setting -X- _ O
where -X- _ O
random -X- _ O
word -X- _ O
pairs -X- _ O
-which -X- _ O
may -X- _ O
or -X- _ O
may -X- _ O
not -X- _ O
correspond -X- _ O
to -X- _ O
one -X- _ O
of -X- _ O
our -X- _ O
relations -X- _ O
-are -X- _ O
included -X- _ O
in -X- _ O
the -X- _ O
evaluation -X- _ O
. -X- _ O

A -X- _ O
natural -X- _ O
question -X- _ O
is -X- _ O
whether -X- _ O
we -X- _ O
can -X- _ O
accurately -X- _ O
characterise -X- _ O
lexical -X- _ O
relations -X- _ O
through -X- _ O
supervised -X- _ O
learning -X- _ O
over -X- _ O
the -X- _ O
DIFFVECs -X- _ O
. -X- _ O
For -X- _ O
these -X- _ O
experiments -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
w2v -X- _ O
, -X- _ O
w2v -X- _ O
wiki -X- _ O
, -X- _ O
and -X- _ O
SVD -X- _ O
wiki -X- _ O
embeddings -X- _ O
exclusively -X- _ O
( -X- _ O
based -X- _ O
on -X- _ O
their -X- _ O
superior -X- _ O
performance -X- _ O
in -X- _ O
the -X- _ O
clustering -X- _ O
experiment -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
a -X- _ O
subset -X- _ O
of -X- _ O
the -X- _ O
relations -X- _ O
which -X- _ O
is -X- _ O
both -X- _ O
representative -X- _ O
of -X- _ O
the -X- _ O
breadth -X- _ O
of -X- _ O
the -X- _ O
full -X- _ O
relation -X- _ O
set -X- _ O
, -X- _ O
and -X- _ O
for -X- _ O
which -X- _ O
we -X- _ O
have -X- _ O
sufficient -X- _ O
data -X- _ O
for -X- _ O
supervised -X- _ O
training -X- _ O
and -X- _ O
evaluation -X- _ O
, -X- _ O
namely -X- _ O
: -X- _ O
NOUN -X- _ O
Coll -X- _ O
, -X- _ O
LEXSEM -X- _ O
Event -X- _ O
, -X- _ O
LEXSEM -X- _ O
Hyper -X- _ O
, -X- _ O
LEXSEM -X- _ O
Mero -X- _ O
, -X- _ O
NOUN -X- _ O
SP -X- _ O
, -X- _ O
PREFIX -X- _ O
, -X- _ O
VERB -X- _ O
3 -X- _ O
, -X- _ O
VERB -X- _ O
3Past -X- _ O
, -X- _ O
and -X- _ O
VERB -X- _ O
Past -X- _ O
( -X- _ O
see -X- _ O
Table -X- _ O
2 -X- _ O
) -X- _ O
. -X- _ O

Classification -X- _ O
. -X- _ O

Given -X- _ O
the -X- _ O
encouraging -X- _ O
results -X- _ O
from -X- _ O
our -X- _ O
clustering -X- _ O
experiment -X- _ O
, -X- _ O
we -X- _ O
next -X- _ O
evaluate -X- _ O
DIFFVECs -X- _ O
in -X- _ O
a -X- _ O
supervised -X- _ O
relation -X- _ O
classification -X- _ O
setting -X- _ O
. -X- _ O

LEXSEM -X- _ O
Mero -X- _ O
was -X- _ O
also -X- _ O
split -X- _ O
into -X- _ O
multiple -X- _ O
clusters -X- _ O
along -X- _ O
topical -X- _ O
lines -X- _ O
, -X- _ O
with -X- _ O
separate -X- _ O
clusters -X- _ O
for -X- _ O
weapons -X- _ O
, -X- _ O
dwellings -X- _ O
, -X- _ O
vehicles -X- _ O
, -X- _ O
etc -X- _ O
. -X- _ O

This -X- _ O
is -X- _ O
interesting -X- _ O
from -X- _ O
a -X- _ O
DIFFVEC -X- _ O
point -X- _ O
of -X- _ O
view -X- _ O
, -X- _ O
since -X- _ O
it -X- _ O
shows -X- _ O
that -X- _ O
the -X- _ O
lexical -X- _ O
semantics -X- _ O
of -X- _ O
one -X- _ O
word -X- _ O
in -X- _ O
the -X- _ O
pair -X- _ O
can -X- _ O
overwhelm -X- _ O
the -X- _ O
semantic -X- _ O
content -X- _ O
of -X- _ O
the -X- _ O
DIFFVEC -X- _ O
( -X- _ O
something -X- _ O
that -X- _ O
we -X- _ O
return -X- _ O
to -X- _ O
investigate -X- _ O
in -X- _ O
§ -X- _ O
5.4 -X- _ O
) -X- _ O
. -X- _ O

A -X- _ O
related -X- _ O
phenomenon -X- _ O
was -X- _ O
observed -X- _ O
for -X- _ O
NOUN -X- _ O
Coll -X- _ O
, -X- _ O
where -X- _ O
the -X- _ O
instances -X- _ O
were -X- _ O
assigned -X- _ O
to -X- _ O
a -X- _ O
large -X- _ O
mixed -X- _ O
cluster -X- _ O
containing -X- _ O
word -X- _ O
pairs -X- _ O
where -X- _ O
the -X- _ O
second -X- _ O
word -X- _ O
referred -X- _ O
to -X- _ O
an -X- _ O
animal -X- _ O
, -X- _ O
reflecting -X- _ O
the -X- _ O
fact -X- _ O
that -X- _ O
most -X- _ O
of -X- _ O
the -X- _ O
collective -X- _ O
nouns -X- _ O
in -X- _ O
our -X- _ O
dataset -X- _ O
relate -X- _ O
to -X- _ O
animals -X- _ O
, -X- _ O
e.g. -X- _ O
( -X- _ O
stand -X- _ O
, -X- _ O
horse -X- _ O
) -X- _ O
, -X- _ O
( -X- _ O
ambush -X- _ O
, -X- _ O
tigers -X- _ O
) -X- _ O
, -X- _ O
( -X- _ O
antibiotics -X- _ O
, -X- _ O
bacteria -X- _ O
) -X- _ O
. -X- _ O

Here -X- _ O
, -X- _ O
the -X- _ O
noun -X- _ O
saw -X- _ O
is -X- _ O
ambiguous -X- _ O
with -X- _ O
a -X- _ O
high -X- _ O
- -X- _ O
frequency -X- _ O
past -X- _ O
- -X- _ O
tense -X- _ O
verb -X- _ O
; -X- _ O
hurt -X- _ O
and -X- _ O
wipe -X- _ O
also -X- _ O
have -X- _ O
ambigous -X- _ O
POS -X- _ O
. -X- _ O

For -X- _ O
VERB -X- _ O
Past -X- _ O
, -X- _ O
a -X- _ O
single -X- _ O
relatively -X- _ O
pure -X- _ O
cluster -X- _ O
was -X- _ O
generated -X- _ O
, -X- _ O
with -X- _ O
minor -X- _ O
contamination -X- _ O
due -X- _ O
to -X- _ O
pairs -X- _ O
such -X- _ O
as -X- _ O
( -X- _ O
hurt -X- _ O
, -X- _ O
saw -X- _ O
) -X- _ O
, -X- _ O
( -X- _ O
utensil -X- _ O
, -X- _ O
saw -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
( -X- _ O
wipe -X- _ O
, -X- _ O
saw -X- _ O
) -X- _ O
. -X- _ O

This -X- _ O
polysemy -X- _ O
results -X- _ O
in -X- _ O
the -X- _ O
distance -X- _ O
represented -X- _ O
in -X- _ O
the -X- _ O
DIFFVEC -X- _ O
for -X- _ O
such -X- _ O
pairs -X- _ O
being -X- _ O
above -X- _ O
average -X- _ O
for -X- _ O
VERB -X- _ O
3 -X- _ O
, -X- _ O
and -X- _ O
consequently -X- _ O
clustered -X- _ O
with -X- _ O
other -X- _ O
cross -X- _ O
- -X- _ O
POS -X- _ O
relations -X- _ O
. -X- _ O

Example -X- _ O
VERB -X- _ O
3 -X- _ O
pairs -X- _ O
incorrectly -X- _ O
clustered -X- _ O
are -X- _ O
: -X- _ O
( -X- _ O
study -X- _ O
, -X- _ O
studies -X- _ O
) -X- _ O
, -X- _ O
( -X- _ O
run -X- _ O
, -X- _ O
runs -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
( -X- _ O
like -X- _ O
, -X- _ O
likes -X- _ O
) -X- _ O
. -X- _ O

Most -X- _ O
errors -X- _ O
resulted -X- _ O
from -X- _ O
POS -X- _ O
ambiguity -X- _ O
, -X- _ O
leading -X- _ O
to -X- _ O
confusion -X- _ O
with -X- _ O
VERB -X- _ O
- -X- _ O
NOUN -X- _ O
in -X- _ O
particular -X- _ O
. -X- _ O

Considering -X- _ O
w2v -X- _ O
embeddings -X- _ O
, -X- _ O
for -X- _ O
VERB -X- _ O
3 -X- _ O
there -X- _ O
was -X- _ O
a -X- _ O
single -X- _ O
cluster -X- _ O
consisting -X- _ O
of -X- _ O
around -X- _ O
90 -X- _ O
% -X- _ O
of -X- _ O
VERB -X- _ O
3 -X- _ O
word -X- _ O
pairs -X- _ O
. -X- _ O

The -X- _ O
lexical -X- _ O
semantic -X- _ O
relations -X- _ O
, -X- _ O
on -X- _ O
the -X- _ O
other -X- _ O
hand -X- _ O
, -X- _ O
are -X- _ O
the -X- _ O
hardest -X- _ O
to -X- _ O
capture -X- _ O
for -X- _ O
all -X- _ O
embeddings -X- _ O
. -X- _ O

Looking -X- _ O
across -X- _ O
the -X- _ O
different -X- _ O
lexical -X- _ O
relation -X- _ O
types -X- _ O
, -X- _ O
the -X- _ O
morphosyntactic -X- _ O
paradigm -X- _ O
relations -X- _ O
( -X- _ O
NOUN -X- _ O
SP -X- _ O
and -X- _ O
the -X- _ O
three -X- _ O
VERB -X- _ O
relations -X- _ O
) -X- _ O
are -X- _ O
by -X- _ O
far -X- _ O
the -X- _ O
easiest -X- _ O
to -X- _ O
capture -X- _ O
. -X- _ O

The -X- _ O
results -X- _ O
are -X- _ O
in -X- _ O
Table -X- _ O
3 -X- _ O
, -X- _ O
with -X- _ O
the -X- _ O
lowest -X- _ O
entropy -X- _ O
( -X- _ O
purest -X- _ O
clustering -X- _ O
) -X- _ O
for -X- _ O
each -X- _ O
relation -X- _ O
indicated -X- _ O
in -X- _ O
bold -X- _ O
. -X- _ O

Since -X- _ O
the -X- _ O
samples -X- _ O
are -X- _ O
distributed -X- _ O
nonuniformly -X- _ O
, -X- _ O
we -X- _ O
normalise -X- _ O
entropy -X- _ O
results -X- _ O
for -X- _ O
each -X- _ O
method -X- _ O
by -X- _ O
log(n -X- _ O
) -X- _ O
where -X- _ O
n -X- _ O
is -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
samples -X- _ O
in -X- _ O
a -X- _ O
particular -X- _ O
relation -X- _ O
. -X- _ O

For -X- _ O
each -X- _ O
embedding -X- _ O
method -X- _ O
, -X- _ O
we -X- _ O
present -X- _ O
the -X- _ O
entropy -X- _ O
for -X- _ O
the -X- _ O
cluster -X- _ O
size -X- _ O
where -X- _ O
V -X- _ O
- -X- _ O
measure -X- _ O
was -X- _ O
maximised -X- _ O
over -X- _ O
the -X- _ O
development -X- _ O
data -X- _ O
. -X- _ O

We -X- _ O
additionally -X- _ O
calculated -X- _ O
the -X- _ O
entropy -X- _ O
for -X- _ O
each -X- _ O
lexical -X- _ O
relation -X- _ O
, -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
distribution -X- _ O
of -X- _ O
instances -X- _ O
belonging -X- _ O
to -X- _ O
a -X- _ O
given -X- _ O
relation -X- _ O
across -X- _ O
the -X- _ O
different -X- _ O
clusters -X- _ O
( -X- _ O
and -X- _ O
simple -X- _ O
MLE -X- _ O
) -X- _ O
. -X- _ O

( -X- _ O
2015a -X- _ O
) -X- _ O
. -X- _ O

However -X- _ O
, -X- _ O
both -X- _ O
methods -X- _ O
still -X- _ O
perform -X- _ O
well -X- _ O
above -X- _ O
SENNA -X- _ O
and -X- _ O
HLBL -X- _ O
, -X- _ O
and -X- _ O
w2v -X- _ O
has -X- _ O
a -X- _ O
clear -X- _ O
empirical -X- _ O
advantage -X- _ O
over -X- _ O
GloVe -X- _ O
. -X- _ O
We -X- _ O
note -X- _ O
that -X- _ O
SVD -X- _ O
wiki -X- _ O
performs -X- _ O
almost -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
w2v -X- _ O
wiki -X- _ O
, -X- _ O
consistent -X- _ O
with -X- _ O
the -X- _ O
results -X- _ O
of -X- _ O
Levy -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

HLBL -X- _ O
and -X- _ O
SENNA -X- _ O
performed -X- _ O
very -X- _ O
The -X- _ O
lower -X- _ O
V -X- _ O
- -X- _ O
measure -X- _ O
for -X- _ O
w2v -X- _ O
wiki -X- _ O
and -X- _ O
GloVe -X- _ O
wiki -X- _ O
( -X- _ O
as -X- _ O
compared -X- _ O
to -X- _ O
w2v -X- _ O
and -X- _ O
GloVe -X- _ O
, -X- _ O
respectively -X- _ O
) -X- _ O
indicates -X- _ O
that -X- _ O
the -X- _ O
volume -X- _ O
of -X- _ O
training -X- _ O
data -X- _ O
plays -X- _ O
a -X- _ O
role -X- _ O
in -X- _ O
the -X- _ O
clustering -X- _ O
results -X- _ O
. -X- _ O

GloVe -X- _ O
and -X- _ O
SVD -X- _ O
mirror -X- _ O
this -X- _ O
result -X- _ O
, -X- _ O
but -X- _ O
are -X- _ O
consistently -X- _ O
below -X- _ O
w2v -X- _ O
at -X- _ O
a -X- _ O
V -X- _ O
- -X- _ O
Measure -X- _ O
of -X- _ O
around -X- _ O
0.31 -X- _ O
. -X- _ O

8 -X- _ O
Observe -X- _ O
that -X- _ O
w2v -X- _ O
achieves -X- _ O
the -X- _ O
best -X- _ O
results -X- _ O
, -X- _ O
with -X- _ O
a -X- _ O
V -X- _ O
- -X- _ O
Measure -X- _ O
value -X- _ O
of -X- _ O
around -X- _ O
0.36 -X- _ O
, -X- _ O
9 -X- _ O
which -X- _ O
is -X- _ O
relatively -X- _ O
constant -X- _ O
over -X- _ O
varying -X- _ O
numbers -X- _ O
of -X- _ O
clusters -X- _ O
. -X- _ O

We -X- _ O
show -X- _ O
results -X- _ O
for -X- _ O
different -X- _ O
numbers -X- _ O
of -X- _ O
clusters -X- _ O
, -X- _ O
from -X- _ O
N -X- _ O
= -X- _ O
10 -X- _ O
in -X- _ O
steps -X- _ O
of -X- _ O
10 -X- _ O
, -X- _ O
up -X- _ O
to -X- _ O
N -X- _ O
= -X- _ O
80 -X- _ O
( -X- _ O
beyond -X- _ O
which -X- _ O
the -X- _ O
clustering -X- _ O
quality -X- _ O
diminishes -X- _ O
) -X- _ O
. -X- _ O

Figure -X- _ O
2 -X- _ O
presents -X- _ O
V -X- _ O
- -X- _ O
Measure -X- _ O
values -X- _ O
over -X- _ O
the -X- _ O
test -X- _ O
data -X- _ O
for -X- _ O
each -X- _ O
of -X- _ O
the -X- _ O
four -X- _ O
word -X- _ O
embedding -X- _ O
models -X- _ O
. -X- _ O

Spectral -X- _ O
clustering -X- _ O
has -X- _ O
two -X- _ O
hyperparameters -X- _ O
: -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
clusters -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
pairwise -X- _ O
similarity -X- _ O
measure -X- _ O
for -X- _ O
comparing -X- _ O
DIFF -X- _ O
- -X- _ O
VECs -X- _ O
. -X- _ O
We -X- _ O
tune -X- _ O
the -X- _ O
hyperparameters -X- _ O
over -X- _ O
development -X- _ O
data -X- _ O
, -X- _ O
in -X- _ O
the -X- _ O
form -X- _ O
of -X- _ O
15 -X- _ O
% -X- _ O
of -X- _ O
the -X- _ O
data -X- _ O
obtained -X- _ O
by -X- _ O
random -X- _ O
sampling -X- _ O
, -X- _ O
selecting -X- _ O
the -X- _ O
configuration -X- _ O
that -X- _ O
maximises -X- _ O
the -X- _ O
V -X- _ O
- -X- _ O
Measure -X- _ O
( -X- _ O
Rosenberg -X- _ O
and -X- _ O
Hirschberg -X- _ O
, -X- _ O
2007 -X- _ O
) -X- _ O
. -X- _ O

We -X- _ O
cluster -X- _ O
the -X- _ O
DIFFVECs -X- _ O
between -X- _ O
all -X- _ O
word -X- _ O
pairs -X- _ O
in -X- _ O
our -X- _ O
dataset -X- _ O
using -X- _ O
spectral -X- _ O
clustering -X- _ O
( -X- _ O
Von -X- _ O
Luxburg -X- _ O
, -X- _ O
2007 -X- _ O
) -X- _ O
. -X- _ O

In -X- _ O
order -X- _ O
to -X- _ O
test -X- _ O
these -X- _ O
assumptions -X- _ O
, -X- _ O
we -X- _ O
cluster -X- _ O
our -X- _ O
15 -X- _ O
- -X- _ O
relation -X- _ O
closed -X- _ O
- -X- _ O
world -X- _ O
dataset -X- _ O
in -X- _ O
the -X- _ O
first -X- _ O
instance -X- _ O
, -X- _ O
and -X- _ O
evaluate -X- _ O
against -X- _ O
the -X- _ O
lexical -X- _ O
resources -X- _ O
in -X- _ O
§ -X- _ O
3.2 -X- _ O
. -X- _ O
As -X- _ O
further -X- _ O
motivation -X- _ O
, -X- _ O
we -X- _ O
projected -X- _ O
the -X- _ O
DIFF -X- _ O
- -X- _ O
VEC -X- _ O
space -X- _ O
for -X- _ O
a -X- _ O
small -X- _ O
number -X- _ O
of -X- _ O
samples -X- _ O
of -X- _ O
each -X- _ O
class -X- _ O
using -X- _ O
t -X- _ O
- -X- _ O
SNE -X- _ O
( -X- _ O
Van -X- _ O
der -X- _ O
Maaten -X- _ O
and -X- _ O
Hinton -X- _ O
, -X- _ O
2008 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
found -X- _ O
that -X- _ O
many -X- _ O
of -X- _ O
the -X- _ O
morphosyntactic -X- _ O
relations -X- _ O
( -X- _ O
VERB -X- _ O
3 -X- _ O
, -X- _ O
VERB -X- _ O
Past -X- _ O
, -X- _ O
VERB -X- _ O
3Past -X- _ O
, -X- _ O
NOUN -X- _ O
SP -X- _ O
) -X- _ O
form -X- _ O
tight -X- _ O
clusters -X- _ O
( -X- _ O
Figure -X- _ O
1 -X- _ O
) -X- _ O
. -X- _ O

Under -X- _ O
the -X- _ O
additional -X- _ O
assumption -X- _ O
that -X- _ O
a -X- _ O
given -X- _ O
word -X- _ O
pair -X- _ O
corresponds -X- _ O
to -X- _ O
a -X- _ O
unique -X- _ O
lexical -X- _ O
relation -X- _ O
( -X- _ O
in -X- _ O
line -X- _ O
with -X- _ O
our -X- _ O
definition -X- _ O
of -X- _ O
the -X- _ O
lexical -X- _ O
relation -X- _ O
learning -X- _ O
task -X- _ O
in -X- _ O
§ -X- _ O
3 -X- _ O
) -X- _ O
, -X- _ O
a -X- _ O
hard -X- _ O
clustering -X- _ O
approach -X- _ O
is -X- _ O
appropriate -X- _ O
. -X- _ O

Assuming -X- _ O
DIFFVECs -X- _ O
are -X- _ O
capable -X- _ O
of -X- _ O
capturing -X- _ O
all -X- _ O
lexical -X- _ O
relations -X- _ O
equally -X- _ O
, -X- _ O
we -X- _ O
would -X- _ O
expect -X- _ O
clustering -X- _ O
to -X- _ O
be -X- _ O
able -X- _ O
to -X- _ O
identify -X- _ O
sets -X- _ O
of -X- _ O
word -X- _ O
pairs -X- _ O
with -X- _ O
high -X- _ O
relational -X- _ O
similarity -X- _ O
, -X- _ O
or -X- _ O
equivalently -X- _ O
clusters -X- _ O
of -X- _ O
similar -X- _ O
offset -X- _ O
vectors -X- _ O
. -X- _ O

Clustering -X- _ O
. -X- _ O

7 -X- _ O
. -X- _ O

( -X- _ O
2006a -X- _ O
) -X- _ O
, -X- _ O
Princeton -X- _ O
Word -X- _ O
- -X- _ O
Net -X- _ O
( -X- _ O
Fellbaum -X- _ O
, -X- _ O
1998 -X- _ O
) -X- _ O
, -X- _ O
Wiktionary -X- _ O
, -X- _ O
5 -X- _ O
and -X- _ O
a -X- _ O
web -X- _ O
lexicon -X- _ O
of -X- _ O
collective -X- _ O
nouns -X- _ O
, -X- _ O
6 -X- _ O
as -X- _ O
listed -X- _ O
in -X- _ O
Table -X- _ O
2 -X- _ O
. -X- _ O

The -X- _ O
final -X- _ O
dataset -X- _ O
consists -X- _ O
of -X- _ O
12,458 -X- _ O
triples -X- _ O
relation -X- _ O
, -X- _ O
word -X- _ O
1 -X- _ O
, -X- _ O
word -X- _ O
2 -X- _ O
, -X- _ O
comprising -X- _ O
15 -X- _ O
relation -X- _ O
types -X- _ O
, -X- _ O
extracted -X- _ O
from -X- _ O
SemEval'12 -X- _ O
( -X- _ O
Jurgens -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2012 -X- _ O
) -X- _ O
, -X- _ O
BLESS -X- _ O
( -X- _ O
Baroni -X- _ O
and -X- _ O
Lenci -X- _ O
, -X- _ O
2011 -X- _ O
) -X- _ O
, -X- _ O
the -X- _ O
MSR -X- _ O
analogy -X- _ O
dataset -X- _ O
( -X- _ O
Mikolov -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2013c -X- _ O
) -X- _ O
, -X- _ O
the -X- _ O
light -X- _ O
verb -X- _ O
dataset -X- _ O
of -X- _ O
Tan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

We -X- _ O
manually -X- _ O
filtered -X- _ O
the -X- _ O
data -X- _ O
to -X- _ O
remove -X- _ O
duplicates -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
as -X- _ O
part -X- _ O
of -X- _ O
merging -X- _ O
the -X- _ O
two -X- _ O
sources -X- _ O
of -X- _ O
LEXSEM -X- _ O
Hyper -X- _ O
intances -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
normalise -X- _ O
directionality -X- _ O
. -X- _ O

( -X- _ O
2013c -X- _ O
) -X- _ O
, -X- _ O
but -X- _ O
we -X- _ O
include -X- _ O
a -X- _ O
much -X- _ O
wider -X- _ O
range -X- _ O
of -X- _ O
lexical -X- _ O
semantic -X- _ O
relations -X- _ O
, -X- _ O
especially -X- _ O
those -X- _ O
standardly -X- _ O
evaluated -X- _ O
in -X- _ O
the -X- _ O
relation -X- _ O
classification -X- _ O
literature -X- _ O
. -X- _ O

There -X- _ O
is -X- _ O
some -X- _ O
overlap -X- _ O
between -X- _ O
our -X- _ O
relations -X- _ O
and -X- _ O
those -X- _ O
included -X- _ O
in -X- _ O
the -X- _ O
analogy -X- _ O
task -X- _ O
of -X- _ O
Mikolov -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

We -X- _ O
additionally -X- _ O
constrained -X- _ O
the -X- _ O
dataset -X- _ O
to -X- _ O
the -X- _ O
words -X- _ O
occurring -X- _ O
in -X- _ O
all -X- _ O
embedding -X- _ O
sets -X- _ O
. -X- _ O

4 -X- _ O
Consequently -X- _ O
we -X- _ O
excluded -X- _ O
symmetric -X- _ O
lexical -X- _ O
relations -X- _ O
such -X- _ O
as -X- _ O
synonymy -X- _ O
. -X- _ O

We -X- _ O
constrained -X- _ O
the -X- _ O
relations -X- _ O
to -X- _ O
be -X- _ O
binary -X- _ O
and -X- _ O
to -X- _ O
have -X- _ O
fixed -X- _ O
directionality -X- _ O
. -X- _ O

In -X- _ O
order -X- _ O
to -X- _ O
evaluate -X- _ O
the -X- _ O
applicability -X- _ O
of -X- _ O
the -X- _ O
DIFF -X- _ O
- -X- _ O
VEC -X- _ O
approach -X- _ O
to -X- _ O
relations -X- _ O
of -X- _ O
different -X- _ O
types -X- _ O
, -X- _ O
we -X- _ O
assembled -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
lexical -X- _ O
relations -X- _ O
in -X- _ O
three -X- _ O
broad -X- _ O
categories -X- _ O
: -X- _ O
lexical -X- _ O
semantic -X- _ O
relations -X- _ O
, -X- _ O
morphosyntactic -X- _ O
paradigm -X- _ O
relations -X- _ O
, -X- _ O
and -X- _ O
morphosemantic -X- _ O
relations -X- _ O
. -X- _ O

Lexical -X- _ O
Relations -X- _ O
. -X- _ O

For -X- _ O
the -X- _ O
other -X- _ O
models -X- _ O
we -X- _ O
used -X- _ O
the -X- _ O
following -X- _ O
parameter -X- _ O
values -X- _ O
: -X- _ O
for -X- _ O
w2v -X- _ O
, -X- _ O
context -X- _ O
window -X- _ O
= -X- _ O
8 -X- _ O
, -X- _ O
negative -X- _ O
samples -X- _ O
= -X- _ O
25 -X- _ O
, -X- _ O
hs -X- _ O
= -X- _ O
0 -X- _ O
, -X- _ O
sample -X- _ O
= -X- _ O
1e-4 -X- _ O
, -X- _ O
and -X- _ O
iterations -X- _ O
= -X- _ O
15 -X- _ O
; -X- _ O
and -X- _ O
for -X- _ O
GloVe -X- _ O
, -X- _ O
context -X- _ O
window -X- _ O
= -X- _ O
15 -X- _ O
, -X- _ O
x -X- _ O
max -X- _ O
= -X- _ O
10 -X- _ O
, -X- _ O
and -X- _ O
iterations -X- _ O
= -X- _ O
15 -X- _ O
. -X- _ O

( -X- _ O
2015a -X- _ O
) -X- _ O
in -X- _ O
setting -X- _ O
the -X- _ O
context -X- _ O
window -X- _ O
size -X- _ O
to -X- _ O
2 -X- _ O
, -X- _ O
negative -X- _ O
sampling -X- _ O
parameter -X- _ O
to -X- _ O
1 -X- _ O
, -X- _ O
eigenvalue -X- _ O
weighting -X- _ O
to -X- _ O
0.5 -X- _ O
, -X- _ O
and -X- _ O
context -X- _ O
distribution -X- _ O
smoothing -X- _ O
to -X- _ O
0.75 -X- _ O
; -X- _ O
other -X- _ O
parameters -X- _ O
were -X- _ O
assigned -X- _ O
their -X- _ O
default -X- _ O
values -X- _ O
. -X- _ O

For -X- _ O
the -X- _ O
SVD -X- _ O
model -X- _ O
, -X- _ O
we -X- _ O
followed -X- _ O
the -X- _ O
recommendations -X- _ O
of -X- _ O
Levy -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

During -X- _ O
the -X- _ O
training -X- _ O
phase -X- _ O
, -X- _ O
for -X- _ O
each -X- _ O
model -X- _ O
we -X- _ O
set -X- _ O
a -X- _ O
word -X- _ O
frequency -X- _ O
threshold -X- _ O
of -X- _ O
5 -X- _ O
. -X- _ O

( -X- _ O
2015a -X- _ O
) -X- _ O
, -X- _ O
3 -X- _ O
i.e. -X- _ O
, -X- _ O
lower -X- _ O
- -X- _ O
cased -X- _ O
all -X- _ O
words -X- _ O
and -X- _ O
removed -X- _ O
non -X- _ O
- -X- _ O
textual -X- _ O
elements -X- _ O
. -X- _ O

We -X- _ O
followed -X- _ O
the -X- _ O
same -X- _ O
preprocessing -X- _ O
procedure -X- _ O
described -X- _ O
in -X- _ O
Levy -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

For -X- _ O
w2v -X- _ O
wiki -X- _ O
, -X- _ O
GloVe -X- _ O
wiki -X- _ O
and -X- _ O
SVD -X- _ O
wiki -X- _ O
we -X- _ O
used -X- _ O
English -X- _ O
Wikipedia -X- _ O
. -X- _ O

In -X- _ O
both -X- _ O
cases -X- _ O
, -X- _ O
the -X- _ O
embeddings -X- _ O
were -X- _ O
scaled -X- _ O
by -X- _ O
the -X- _ O
global -X- _ O
standard -X- _ O
deviation -X- _ O
over -X- _ O
the -X- _ O
word -X- _ O
- -X- _ O
embedding -X- _ O
matrix -X- _ O
, -X- _ O
W -X- _ O
scaled -X- _ O
= -X- _ O
0.1 -X- _ O
× -X- _ O
W -X- _ O
σ(W -X- _ O
) -X- _ O
. -X- _ O

( -X- _ O
2010 -X- _ O
) -X- _ O
, -X- _ O
trained -X- _ O
on -X- _ O
the -X- _ O
Reuters -X- _ O
English -X- _ O
newswire -X- _ O
corpus -X- _ O
. -X- _ O

For -X- _ O
HLBL -X- _ O
and -X- _ O
SENNA -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
embeddings -X- _ O
from -X- _ O
Turian -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

, -X- _ O
w -X- _ O
i−1 -X- _ O
, -X- _ O
w -X- _ O
k -X- _ O
) -X- _ O
, -X- _ O
where -X- _ O
the -X- _ O
last -X- _ O
c -X- _ O
− -X- _ O
1 -X- _ O
words -X- _ O
are -X- _ O
used -X- _ O
as -X- _ O
context -X- _ O
, -X- _ O
and -X- _ O
f -X- _ O
( -X- _ O
x -X- _ O
) -X- _ O
is -X- _ O
a -X- _ O
non -X- _ O
- -X- _ O
linear -X- _ O
function -X- _ O
of -X- _ O
the -X- _ O
input -X- _ O
, -X- _ O
defined -X- _ O
as -X- _ O
a -X- _ O
multi -X- _ O
- -X- _ O
layer -X- _ O
perceptron -X- _ O
. -X- _ O

, -X- _ O
w -X- _ O
i−1 -X- _ O
, -X- _ O
w -X- _ O
i -X- _ O
) -X- _ O
+ -X- _ O
f -X- _ O
( -X- _ O
w -X- _ O
i−c -X- _ O
, -X- _ O
. -X- _ O

Here -X- _ O
we -X- _ O
focus -X- _ O
on -X- _ O
the -X- _ O
statistical -X- _ O
language -X- _ O
modelling -X- _ O
component -X- _ O
, -X- _ O
which -X- _ O
has -X- _ O
a -X- _ O
pairwise -X- _ O
ranking -X- _ O
objective -X- _ O
to -X- _ O
maximise -X- _ O
the -X- _ O
relative -X- _ O
score -X- _ O
of -X- _ O
each -X- _ O
word -X- _ O
in -X- _ O
its -X- _ O
local -X- _ O
context -X- _ O
: -X- _ O
J -X- _ O
= -X- _ O
1 -X- _ O
T -X- _ O
T -X- _ O
i=1 -X- _ O
V -X- _ O
k=1 -X- _ O
max -X- _ O
0 -X- _ O
, -X- _ O
1 -X- _ O
− -X- _ O
f -X- _ O
( -X- _ O
w -X- _ O
i−c -X- _ O
, -X- _ O
. -X- _ O

The -X- _ O
final -X- _ O
model -X- _ O
, -X- _ O
SENNA -X- _ O
( -X- _ O
Collobert -X- _ O
and -X- _ O
Weston -X- _ O
, -X- _ O
2008 -X- _ O
) -X- _ O
, -X- _ O
was -X- _ O
initially -X- _ O
proposed -X- _ O
for -X- _ O
multi -X- _ O
- -X- _ O
task -X- _ O
training -X- _ O
of -X- _ O
several -X- _ O
language -X- _ O
processing -X- _ O
tasks -X- _ O
, -X- _ O
from -X- _ O
language -X- _ O
modelling -X- _ O
through -X- _ O
to -X- _ O
semantic -X- _ O
role -X- _ O
labelling -X- _ O
. -X- _ O

where -X- _ O
wi -X- _ O
= -X- _ O
n−1 -X- _ O
j=1 -X- _ O
C -X- _ O
j -X- _ O
w -X- _ O
i−j -X- _ O
is -X- _ O
the -X- _ O
context -X- _ O
embedding -X- _ O
, -X- _ O
C -X- _ O
j -X- _ O
is -X- _ O
a -X- _ O
scaling -X- _ O
matrix -X- _ O
, -X- _ O
and -X- _ O
b -X- _ O
* -X- _ O
is -X- _ O
a -X- _ O
bias -X- _ O
term -X- _ O
. -X- _ O

This -X- _ O
leads -X- _ O
to -X- _ O
the -X- _ O
following -X- _ O
training -X- _ O
objective -X- _ O
: -X- _ O
J -X- _ O
= -X- _ O
1 -X- _ O
T -X- _ O
T -X- _ O
i=1 -X- _ O
exp -X- _ O
( -X- _ O
w -X- _ O
i -X- _ O
w -X- _ O
i -X- _ O
+ -X- _ O
b -X- _ O
i -X- _ O
) -X- _ O
V -X- _ O
k=1 -X- _ O
exp -X- _ O
( -X- _ O
w -X- _ O
i -X- _ O
w -X- _ O
k -X- _ O
+ -X- _ O
b -X- _ O
k -X- _ O
) -X- _ O
, -X- _ O
duty -X- _ O
, -X- _ O
denoting -X- _ O
either -X- _ O
the -X- _ O
embedding -X- _ O
for -X- _ O
the -X- _ O
ith -X- _ O
token -X- _ O
, -X- _ O
wi -X- _ O
, -X- _ O
or -X- _ O
kth -X- _ O
word -X- _ O
type -X- _ O
, -X- _ O
w -X- _ O
k -X- _ O
. -X- _ O

, -X- _ O
i -X- _ O
− -X- _ O
2 -X- _ O
, -X- _ O
i -X- _ O
− -X- _ O
1 -X- _ O
) -X- _ O
. -X- _ O

HLBL -X- _ O
( -X- _ O
Mnih -X- _ O
and -X- _ O
Hinton -X- _ O
, -X- _ O
2009 -X- _ O
) -X- _ O
is -X- _ O
a -X- _ O
log -X- _ O
- -X- _ O
bilinear -X- _ O
formulation -X- _ O
of -X- _ O
an -X- _ O
n -X- _ O
- -X- _ O
gram -X- _ O
language -X- _ O
model -X- _ O
, -X- _ O
which -X- _ O
predicts -X- _ O
the -X- _ O
ith -X- _ O
word -X- _ O
based -X- _ O
on -X- _ O
context -X- _ O
words -X- _ O
( -X- _ O
i -X- _ O
− -X- _ O
n -X- _ O
, -X- _ O
. -X- _ O

The -X- _ O
matrix -X- _ O
is -X- _ O
factorised -X- _ O
by -X- _ O
singular -X- _ O
value -X- _ O
decomposition -X- _ O
. -X- _ O

The -X- _ O
SVD -X- _ O
model -X- _ O
( -X- _ O
Levy -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015a -X- _ O
) -X- _ O
uses -X- _ O
positive -X- _ O
pointwise -X- _ O
mutual -X- _ O
information -X- _ O
( -X- _ O
PMI -X- _ O
) -X- _ O
matrix -X- _ O
defined -X- _ O
as -X- _ O
: -X- _ O
PPMI(w -X- _ O
, -X- _ O
c -X- _ O
) -X- _ O
= -X- _ O
max(log -X- _ O
P -X- _ O
( -X- _ O
w -X- _ O
, -X- _ O
c -X- _ O
) -X- _ O
P -X- _ O
( -X- _ O
w -X- _ O
) -X- _ O
P -X- _ O
( -X- _ O
c -X- _ O
) -X- _ O
, -X- _ O
0 -X- _ O
) -X- _ O
, -X- _ O
where -X- _ O
P -X- _ O
( -X- _ O
w -X- _ O
, -X- _ O
c -X- _ O
) -X- _ O
is -X- _ O
the -X- _ O
joint -X- _ O
probability -X- _ O
of -X- _ O
word -X- _ O
w -X- _ O
and -X- _ O
context -X- _ O
c -X- _ O
, -X- _ O
and -X- _ O
P -X- _ O
( -X- _ O
w -X- _ O
) -X- _ O
and -X- _ O
P -X- _ O
( -X- _ O
c -X- _ O
) -X- _ O
are -X- _ O
their -X- _ O
marginal -X- _ O
probabilities -X- _ O
. -X- _ O

The -X- _ O
model -X- _ O
was -X- _ O
trained -X- _ O
on -X- _ O
English -X- _ O
Wikipedia -X- _ O
and -X- _ O
the -X- _ O
English -X- _ O
Gigaword -X- _ O
corpus -X- _ O
version -X- _ O
5 -X- _ O
. -X- _ O

The -X- _ O
GloVe -X- _ O
model -X- _ O
( -X- _ O
Pennington -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
is -X- _ O
based -X- _ O
on -X- _ O
a -X- _ O
similar -X- _ O
bilinear -X- _ O
formulation -X- _ O
, -X- _ O
framed -X- _ O
as -X- _ O
a -X- _ O
low -X- _ O
- -X- _ O
rank -X- _ O
decomposition -X- _ O
of -X- _ O
the -X- _ O
matrix -X- _ O
of -X- _ O
corpus -X- _ O
co -X- _ O
- -X- _ O
occurrence -X- _ O
frequencies -X- _ O
: -X- _ O
J -X- _ O
= -X- _ O
1 -X- _ O
2 -X- _ O
V -X- _ O
i -X- _ O
, -X- _ O
j=1 -X- _ O
f -X- _ O
( -X- _ O
P -X- _ O
ij -X- _ O
) -X- _ O
( -X- _ O
w -X- _ O
i -X- _ O
wj -X- _ O
− -X- _ O
log -X- _ O
P -X- _ O
ij -X- _ O
) -X- _ O
2 -X- _ O
, -X- _ O
where -X- _ O
w -X- _ O
i -X- _ O
is -X- _ O
a -X- _ O
vector -X- _ O
for -X- _ O
the -X- _ O
left -X- _ O
context -X- _ O
, -X- _ O
w -X- _ O
j -X- _ O
is -X- _ O
a -X- _ O
vector -X- _ O
for -X- _ O
the -X- _ O
right -X- _ O
context -X- _ O
, -X- _ O
P -X- _ O
ij -X- _ O
is -X- _ O
the -X- _ O
relative -X- _ O
frequency -X- _ O
of -X- _ O
word -X- _ O
j -X- _ O
in -X- _ O
the -X- _ O
context -X- _ O
of -X- _ O
word -X- _ O
i -X- _ O
, -X- _ O
and -X- _ O
f -X- _ O
is -X- _ O
a -X- _ O
heuristic -X- _ O
weighting -X- _ O
function -X- _ O
to -X- _ O
balance -X- _ O
the -X- _ O
influence -X- _ O
of -X- _ O
high -X- _ O
versus -X- _ O
low -X- _ O
term -X- _ O
frequencies -X- _ O
. -X- _ O

We -X- _ O
use -X- _ O
the -X- _ O
focus -X- _ O
word -X- _ O
vectors -X- _ O
, -X- _ O
W -X- _ O
= -X- _ O
{ -X- _ O
w -X- _ O
k -X- _ O
} -X- _ O
V -X- _ O
k=1 -X- _ O
, -X- _ O
normalised -X- _ O
such -X- _ O
that -X- _ O
each -X- _ O
w -X- _ O
k -X- _ O
= -X- _ O
1 -X- _ O
. -X- _ O

2 -X- _ O
Google -X- _ O
News -X- _ O
data -X- _ O
was -X- _ O
used -X- _ O
to -X- _ O
train -X- _ O
the -X- _ O
model -X- _ O
. -X- _ O

( -X- _ O
2013a -X- _ O
) -X- _ O
) -X- _ O
predicts -X- _ O
a -X- _ O
word -X- _ O
from -X- _ O
its -X- _ O
context -X- _ O
using -X- _ O
a -X- _ O
model -X- _ O
with -X- _ O
the -X- _ O
objective -X- _ O
: -X- _ O
J -X- _ O
= -X- _ O
1 -X- _ O
T -X- _ O
T -X- _ O
i=1 -X- _ O
log -X- _ O
exp -X- _ O
w -X- _ O
i -X- _ O
j∈[−c,+c],j -X- _ O
= -X- _ O
0 -X- _ O
wi+j -X- _ O
V -X- _ O
k=1 -X- _ O
exp -X- _ O
w -X- _ O
k -X- _ O
j∈[−c,+c],j -X- _ O
= -X- _ O
0 -X- _ O
wi+j -X- _ O
where -X- _ O
w -X- _ O
i -X- _ O
and -X- _ O
wi -X- _ O
are -X- _ O
the -X- _ O
vector -X- _ O
representations -X- _ O
for -X- _ O
the -X- _ O
ith -X- _ O
word -X- _ O
( -X- _ O
as -X- _ O
a -X- _ O
focus -X- _ O
or -X- _ O
context -X- _ O
word -X- _ O
, -X- _ O
respectively -X- _ O
) -X- _ O
, -X- _ O
V -X- _ O
is -X- _ O
the -X- _ O
vocabulary -X- _ O
size -X- _ O
, -X- _ O
T -X- _ O
is -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
tokens -X- _ O
in -X- _ O
the -X- _ O
corpus -X- _ O
, -X- _ O
and -X- _ O
c -X- _ O
is -X- _ O
the -X- _ O
context -X- _ O
window -X- _ O
size -X- _ O
. -X- _ O

1 -X- _ O
w2v -X- _ O
CBOW -X- _ O
( -X- _ O
Continuous -X- _ O
Bag -X- _ O
- -X- _ O
Of -X- _ O
- -X- _ O
Words -X- _ O
; -X- _ O
Mikolov -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

We -X- _ O
additionally -X- _ O
normalise -X- _ O
the -X- _ O
w2v -X- _ O
wiki -X- _ O
and -X- _ O
SVD -X- _ O
wiki -X- _ O
vectors -X- _ O
to -X- _ O
unit -X- _ O
length -X- _ O
; -X- _ O
GloVe -X- _ O
wiki -X- _ O
is -X- _ O
natively -X- _ O
normalised -X- _ O
by -X- _ O
column -X- _ O
. -X- _ O

( -X- _ O
2015a -X- _ O
) -X- _ O
. -X- _ O

For -X- _ O
consistency -X- _ O
of -X- _ O
comparison -X- _ O
, -X- _ O
we -X- _ O
train -X- _ O
SVD -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
a -X- _ O
version -X- _ O
of -X- _ O
w2v -X- _ O
and -X- _ O
GloVe -X- _ O
( -X- _ O
which -X- _ O
we -X- _ O
call -X- _ O
w2v -X- _ O
wiki -X- _ O
and -X- _ O
GloVe -X- _ O
wiki -X- _ O
, -X- _ O
respectively -X- _ O
) -X- _ O
on -X- _ O
the -X- _ O
English -X- _ O
Wikipedia -X- _ O
corpus -X- _ O
( -X- _ O
comparable -X- _ O
in -X- _ O
size -X- _ O
to -X- _ O
the -X- _ O
training -X- _ O
data -X- _ O
of -X- _ O
SENNA -X- _ O
and -X- _ O
HLBL -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
apply -X- _ O
the -X- _ O
preprocessing -X- _ O
of -X- _ O
Levy -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

We -X- _ O
also -X- _ O
include -X- _ O
SVD -X- _ O
( -X- _ O
Levy -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015a -X- _ O
) -X- _ O
, -X- _ O
a -X- _ O
count -X- _ O
- -X- _ O
based -X- _ O
model -X- _ O
which -X- _ O
factorises -X- _ O
a -X- _ O
positive -X- _ O
PMI -X- _ O
( -X- _ O
PPMI -X- _ O
) -X- _ O
matrix -X- _ O
. -X- _ O

We -X- _ O
consider -X- _ O
four -X- _ O
highly -X- _ O
successful -X- _ O
word -X- _ O
embedding -X- _ O
models -X- _ O
in -X- _ O
our -X- _ O
experiments -X- _ O
: -X- _ O
w2v -X- _ O
( -X- _ O
Mikolov -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2013a;Mikolov -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2013b -X- _ O
) -X- _ O
, -X- _ O
GloVe -X- _ O
( -X- _ O
Pennington -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
, -X- _ O
SENNA -X- _ O
( -X- _ O
Collobert -X- _ O
and -X- _ O
Weston -X- _ O
, -X- _ O
2008 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
HLBL -X- _ O
( -X- _ O
Mnih -X- _ O
and -X- _ O
Hinton -X- _ O
, -X- _ O
2009 -X- _ O
) -X- _ O
, -X- _ O
as -X- _ O
detailed -X- _ O
below -X- _ O
. -X- _ O

Word -X- _ O
Embeddings -X- _ O
. -X- _ O

Dimensions -X- _ O
. -X- _ O

Name -X- _ O
. -X- _ O

( -X- _ O
2013c -X- _ O
) -X- _ O
) -X- _ O
, -X- _ O
but -X- _ O
also -X- _ O
including -X- _ O
morphosyntactic -X- _ O
and -X- _ O
morphosemantic -X- _ O
relations -X- _ O
( -X- _ O
see -X- _ O
§ -X- _ O
3.2 -X- _ O
) -X- _ O
. -X- _ O

To -X- _ O
this -X- _ O
end -X- _ O
, -X- _ O
we -X- _ O
construct -X- _ O
a -X- _ O
dataset -X- _ O
from -X- _ O
a -X- _ O
variety -X- _ O
of -X- _ O
sources -X- _ O
, -X- _ O
focusing -X- _ O
on -X- _ O
lexical -X- _ O
semantic -X- _ O
relations -X- _ O
( -X- _ O
which -X- _ O
are -X- _ O
less -X- _ O
well -X- _ O
represented -X- _ O
in -X- _ O
the -X- _ O
analogy -X- _ O
dataset -X- _ O
of -X- _ O
Mikolov -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

For -X- _ O
the -X- _ O
lexical -X- _ O
relations -X- _ O
, -X- _ O
we -X- _ O
want -X- _ O
a -X- _ O
range -X- _ O
of -X- _ O
relations -X- _ O
that -X- _ O
is -X- _ O
representative -X- _ O
of -X- _ O
the -X- _ O
types -X- _ O
of -X- _ O
relational -X- _ O
learning -X- _ O
tasks -X- _ O
targeted -X- _ O
in -X- _ O
the -X- _ O
literature -X- _ O
, -X- _ O
and -X- _ O
where -X- _ O
there -X- _ O
is -X- _ O
availability -X- _ O
of -X- _ O
annotated -X- _ O
data -X- _ O
. -X- _ O

( -X- _ O
2015a -X- _ O
) -X- _ O
, -X- _ O
to -X- _ O
test -X- _ O
the -X- _ O
generalisability -X- _ O
of -X- _ O
DIFFVECs -X- _ O
to -X- _ O
count -X- _ O
- -X- _ O
based -X- _ O
word -X- _ O
embeddings -X- _ O
. -X- _ O

As -X- _ O
the -X- _ O
focus -X- _ O
of -X- _ O
this -X- _ O
paper -X- _ O
is -X- _ O
not -X- _ O
the -X- _ O
word -X- _ O
embedding -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
approaches -X- _ O
so -X- _ O
much -X- _ O
as -X- _ O
the -X- _ O
utility -X- _ O
of -X- _ O
the -X- _ O
DIFFVECs -X- _ O
for -X- _ O
lexical -X- _ O
relation -X- _ O
learning -X- _ O
, -X- _ O
we -X- _ O
take -X- _ O
a -X- _ O
selection -X- _ O
of -X- _ O
four -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
word -X- _ O
embeddings -X- _ O
with -X- _ O
strong -X- _ O
currency -X- _ O
in -X- _ O
the -X- _ O
literature -X- _ O
, -X- _ O
as -X- _ O
detailed -X- _ O
in -X- _ O
§ -X- _ O
3.1 -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
include -X- _ O
the -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
count -X- _ O
- -X- _ O
based -X- _ O
approach -X- _ O
of -X- _ O
Levy -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

Such -X- _ O
dimensions -X- _ O
could -X- _ O
be -X- _ O
identified -X- _ O
and -X- _ O
exploited -X- _ O
as -X- _ O
part -X- _ O
of -X- _ O
a -X- _ O
clustering -X- _ O
or -X- _ O
classification -X- _ O
method -X- _ O
, -X- _ O
in -X- _ O
the -X- _ O
context -X- _ O
of -X- _ O
identifying -X- _ O
relations -X- _ O
between -X- _ O
word -X- _ O
pairs -X- _ O
or -X- _ O
classes -X- _ O
of -X- _ O
DIFFVECs -X- _ O
. -X- _ O
In -X- _ O
order -X- _ O
to -X- _ O
test -X- _ O
the -X- _ O
generalisability -X- _ O
of -X- _ O
the -X- _ O
DIFF -X- _ O
- -X- _ O
VEC -X- _ O
method -X- _ O
, -X- _ O
we -X- _ O
require -X- _ O
: -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
word -X- _ O
embeddings -X- _ O
, -X- _ O
and -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
lexical -X- _ O
relations -X- _ O
to -X- _ O
evaluate -X- _ O
against -X- _ O
. -X- _ O

A -X- _ O
second -X- _ O
assumption -X- _ O
is -X- _ O
that -X- _ O
there -X- _ O
exist -X- _ O
dimensions -X- _ O
, -X- _ O
or -X- _ O
directions -X- _ O
, -X- _ O
in -X- _ O
the -X- _ O
embedding -X- _ O
vector -X- _ O
spaces -X- _ O
responsible -X- _ O
for -X- _ O
a -X- _ O
particular -X- _ O
lexical -X- _ O
relation -X- _ O
. -X- _ O

While -X- _ O
a -X- _ O
range -X- _ O
of -X- _ O
methods -X- _ O
have -X- _ O
been -X- _ O
proposed -X- _ O
for -X- _ O
composing -X- _ O
word -X- _ O
vectors -X- _ O
( -X- _ O
Baroni -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2012;Weeds -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2014;Roller -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
, -X- _ O
in -X- _ O
this -X- _ O
research -X- _ O
we -X- _ O
focus -X- _ O
exclusively -X- _ O
on -X- _ O
DIFFVEC -X- _ O
( -X- _ O
i.e. -X- _ O
w -X- _ O
2 -X- _ O
− -X- _ O
w -X- _ O
1 -X- _ O
) -X- _ O
. -X- _ O

Our -X- _ O
starting -X- _ O
point -X- _ O
for -X- _ O
lexical -X- _ O
relation -X- _ O
learning -X- _ O
is -X- _ O
the -X- _ O
assumption -X- _ O
that -X- _ O
important -X- _ O
information -X- _ O
about -X- _ O
various -X- _ O
types -X- _ O
of -X- _ O
relations -X- _ O
is -X- _ O
implicitly -X- _ O
embedded -X- _ O
in -X- _ O
the -X- _ O
offset -X- _ O
vectors -X- _ O
. -X- _ O

We -X- _ O
define -X- _ O
the -X- _ O
task -X- _ O
of -X- _ O
lexical -X- _ O
relation -X- _ O
learning -X- _ O
to -X- _ O
take -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
( -X- _ O
ordered -X- _ O
) -X- _ O
word -X- _ O
pairs -X- _ O
{ -X- _ O
( -X- _ O
w -X- _ O
i -X- _ O
, -X- _ O
w -X- _ O
j -X- _ O
) -X- _ O
} -X- _ O
and -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
binary -X- _ O
lexical -X- _ O
relations -X- _ O
R -X- _ O
= -X- _ O
{ -X- _ O
r -X- _ O
k -X- _ O
} -X- _ O
, -X- _ O
and -X- _ O
map -X- _ O
each -X- _ O
word -X- _ O
pair -X- _ O
( -X- _ O
w -X- _ O
i -X- _ O
, -X- _ O
w -X- _ O
j -X- _ O
) -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O
( -X- _ O
a -X- _ O
) -X- _ O
( -X- _ O
w -X- _ O
i -X- _ O
, -X- _ O
w -X- _ O
j -X- _ O
) -X- _ O
→ -X- _ O
r -X- _ O
k -X- _ O
∈ -X- _ O
R -X- _ O
, -X- _ O
i.e. -X- _ O
the -X- _ O
" -X- _ O
closed -X- _ O
- -X- _ O
world -X- _ O
" -X- _ O
setting -X- _ O
, -X- _ O
where -X- _ O
we -X- _ O
assume -X- _ O
that -X- _ O
all -X- _ O
word -X- _ O
pairs -X- _ O
can -X- _ O
be -X- _ O
uniquely -X- _ O
classified -X- _ O
according -X- _ O
to -X- _ O
a -X- _ O
relation -X- _ O
in -X- _ O
R -X- _ O
; -X- _ O
or -X- _ O
( -X- _ O
b -X- _ O
) -X- _ O
( -X- _ O
w -X- _ O
i -X- _ O
, -X- _ O
w -X- _ O
j -X- _ O
) -X- _ O
→ -X- _ O
r -X- _ O
k -X- _ O
∈ -X- _ O
R -X- _ O
∪ -X- _ O
{ -X- _ O
φ -X- _ O
} -X- _ O
where -X- _ O
φ -X- _ O
signifies -X- _ O
the -X- _ O
fact -X- _ O
that -X- _ O
none -X- _ O
of -X- _ O
the -X- _ O
relations -X- _ O
in -X- _ O
R -X- _ O
apply -X- _ O
to -X- _ O
the -X- _ O
word -X- _ O
pair -X- _ O
in -X- _ O
question -X- _ O
, -X- _ O
i.e. -X- _ O
the -X- _ O
" -X- _ O
open -X- _ O
- -X- _ O
world -X- _ O
" -X- _ O
setting -X- _ O
. -X- _ O

However -X- _ O
, -X- _ O
their -X- _ O
evaluation -X- _ O
is -X- _ O
performed -X- _ O
in -X- _ O
the -X- _ O
context -X- _ O
of -X- _ O
relational -X- _ O
similarity -X- _ O
, -X- _ O
and -X- _ O
they -X- _ O
do -X- _ O
not -X- _ O
perform -X- _ O
clustering -X- _ O
or -X- _ O
classification -X- _ O
on -X- _ O
the -X- _ O
DIFFVECs -X- _ O
. -X- _ O
General -X- _ O
Approach -X- _ O
and -X- _ O
Resources -X- _ O
. -X- _ O

( -X- _ O
2015 -X- _ O
) -X- _ O
is -X- _ O
somewhat -X- _ O
more -X- _ O
constrained -X- _ O
than -X- _ O
the -X- _ O
set -X- _ O
we -X- _ O
use -X- _ O
, -X- _ O
there -X- _ O
is -X- _ O
a -X- _ O
good -X- _ O
deal -X- _ O
of -X- _ O
overlap -X- _ O
. -X- _ O

Although -X- _ O
the -X- _ O
set -X- _ O
of -X- _ O
relations -X- _ O
tested -X- _ O
by -X- _ O
Köper -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

They -X- _ O
test -X- _ O
a -X- _ O
variety -X- _ O
of -X- _ O
relations -X- _ O
including -X- _ O
word -X- _ O
similarity -X- _ O
, -X- _ O
antonyms -X- _ O
, -X- _ O
synonyms -X- _ O
, -X- _ O
hypernyms -X- _ O
, -X- _ O
and -X- _ O
meronyms -X- _ O
, -X- _ O
in -X- _ O
a -X- _ O
novel -X- _ O
analogy -X- _ O
task -X- _ O
. -X- _ O

( -X- _ O
2015 -X- _ O
) -X- _ O
undertake -X- _ O
a -X- _ O
systematic -X- _ O
study -X- _ O
of -X- _ O
morphosyntactic -X- _ O
and -X- _ O
semantic -X- _ O
relations -X- _ O
on -X- _ O
word -X- _ O
embeddings -X- _ O
produced -X- _ O
with -X- _ O
word2vec -X- _ O
( -X- _ O
" -X- _ O
w2v -X- _ O
" -X- _ O
hereafter -X- _ O
; -X- _ O
see -X- _ O
§ -X- _ O
3.1 -X- _ O
) -X- _ O
for -X- _ O
English -X- _ O
and -X- _ O
German -X- _ O
. -X- _ O

Köper -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

Roller -X- _ O
and -X- _ O
Erk -X- _ O
( -X- _ O
2016 -X- _ O
) -X- _ O
analyse -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
vector -X- _ O
concatenation -X- _ O
and -X- _ O
difference -X- _ O
on -X- _ O
the -X- _ O
task -X- _ O
of -X- _ O
predicting -X- _ O
lexical -X- _ O
entailment -X- _ O
and -X- _ O
show -X- _ O
that -X- _ O
vector -X- _ O
concatenation -X- _ O
overwhelmingly -X- _ O
learns -X- _ O
to -X- _ O
detect -X- _ O
Hearst -X- _ O
patterns -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
including -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
) -X- _ O
. -X- _ O

( -X- _ O
2015 -X- _ O
) -X- _ O
train -X- _ O
a -X- _ O
classifier -X- _ O
on -X- _ O
word -X- _ O
pairs -X- _ O
, -X- _ O
using -X- _ O
word -X- _ O
embeddings -X- _ O
to -X- _ O
predict -X- _ O
coordinates -X- _ O
, -X- _ O
hypernyms -X- _ O
, -X- _ O
and -X- _ O
meronyms -X- _ O
. -X- _ O

Necs -X- _ O
¸ulescu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

( -X- _ O
2013 -X- _ O
) -X- _ O
divide -X- _ O
antonym -X- _ O
pairs -X- _ O
into -X- _ O
semantic -X- _ O
classes -X- _ O
such -X- _ O
as -X- _ O
quality -X- _ O
, -X- _ O
time -X- _ O
, -X- _ O
gender -X- _ O
, -X- _ O
and -X- _ O
distance -X- _ O
, -X- _ O
finding -X- _ O
that -X- _ O
for -X- _ O
about -X- _ O
two -X- _ O
- -X- _ O
thirds -X- _ O
of -X- _ O
antonym -X- _ O
classes -X- _ O
, -X- _ O
DIFFVECs -X- _ O
are -X- _ O
significantly -X- _ O
more -X- _ O
correlated -X- _ O
than -X- _ O
random -X- _ O
. -X- _ O

Makrai -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

However -X- _ O
, -X- _ O
there -X- _ O
has -X- _ O
been -X- _ O
no -X- _ O
systematic -X- _ O
investigation -X- _ O
of -X- _ O
the -X- _ O
range -X- _ O
of -X- _ O
relations -X- _ O
for -X- _ O
which -X- _ O
the -X- _ O
vector -X- _ O
difference -X- _ O
method -X- _ O
is -X- _ O
most -X- _ O
effective -X- _ O
, -X- _ O
although -X- _ O
there -X- _ O
have -X- _ O
been -X- _ O
some -X- _ O
smallerscale -X- _ O
investigations -X- _ O
in -X- _ O
this -X- _ O
direction -X- _ O
. -X- _ O

Another -X- _ O
strand -X- _ O
of -X- _ O
work -X- _ O
responding -X- _ O
to -X- _ O
the -X- _ O
vector -X- _ O
difference -X- _ O
approach -X- _ O
has -X- _ O
analysed -X- _ O
the -X- _ O
structure -X- _ O
of -X- _ O
predict -X- _ O
- -X- _ O
based -X- _ O
embedding -X- _ O
models -X- _ O
in -X- _ O
order -X- _ O
to -X- _ O
help -X- _ O
explain -X- _ O
their -X- _ O
success -X- _ O
on -X- _ O
the -X- _ O
analogy -X- _ O
and -X- _ O
other -X- _ O
tasks -X- _ O
( -X- _ O
Levy -X- _ O
and -X- _ O
Goldberg -X- _ O
, -X- _ O
2014a;Levy -X- _ O
and -X- _ O
Goldberg -X- _ O
, -X- _ O
2014b;Arora -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
. -X- _ O

Neural -X- _ O
networks -X- _ O
have -X- _ O
also -X- _ O
been -X- _ O
developed -X- _ O
for -X- _ O
joint -X- _ O
learning -X- _ O
of -X- _ O
lexical -X- _ O
and -X- _ O
relational -X- _ O
similarity -X- _ O
, -X- _ O
making -X- _ O
use -X- _ O
of -X- _ O
the -X- _ O
WordNet -X- _ O
relation -X- _ O
hierarchy -X- _ O
( -X- _ O
Bordes -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2013;Socher -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2013;Xu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2014;Yu -X- _ O
and -X- _ O
Dredze -X- _ O
, -X- _ O
2014;Faruqui -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015;Fried -X- _ O
and -X- _ O
Duh -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
. -X- _ O

( -X- _ O
2014 -X- _ O
) -X- _ O
similarly -X- _ O
use -X- _ O
embeddings -X- _ O
to -X- _ O
predict -X- _ O
hypernym -X- _ O
relations -X- _ O
, -X- _ O
in -X- _ O
this -X- _ O
case -X- _ O
clustering -X- _ O
words -X- _ O
by -X- _ O
topic -X- _ O
to -X- _ O
show -X- _ O
that -X- _ O
hypernym -X- _ O
DIFFVECs -X- _ O
can -X- _ O
be -X- _ O
broken -X- _ O
down -X- _ O
into -X- _ O
more -X- _ O
fine -X- _ O
- -X- _ O
grained -X- _ O
relations -X- _ O
. -X- _ O

Fu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

Kim -X- _ O
and -X- _ O
de -X- _ O
Marneffe -X- _ O
( -X- _ O
2013 -X- _ O
) -X- _ O
use -X- _ O
word -X- _ O
embeddings -X- _ O
to -X- _ O
derive -X- _ O
representations -X- _ O
of -X- _ O
adjective -X- _ O
scales -X- _ O
, -X- _ O
e.g. -X- _ O
hot -X- _ O
- -X- _ O
warm -X- _ O
- -X- _ O
coolcold -X- _ O
. -X- _ O

( -X- _ O
2013 -X- _ O
) -X- _ O
, -X- _ O
who -X- _ O
combine -X- _ O
a -X- _ O
neural -X- _ O
language -X- _ O
model -X- _ O
with -X- _ O
a -X- _ O
pattern -X- _ O
- -X- _ O
based -X- _ O
classifier -X- _ O
. -X- _ O

The -X- _ O
original -X- _ O
analogy -X- _ O
dataset -X- _ O
has -X- _ O
been -X- _ O
used -X- _ O
to -X- _ O
evaluate -X- _ O
predict -X- _ O
- -X- _ O
based -X- _ O
language -X- _ O
models -X- _ O
by -X- _ O
Mnih -X- _ O
and -X- _ O
Kavukcuoglu -X- _ O
( -X- _ O
2013 -X- _ O
) -X- _ O
and -X- _ O
also -X- _ O
Zhila -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

This -X- _ O
has -X- _ O
given -X- _ O
rise -X- _ O
to -X- _ O
a -X- _ O
series -X- _ O
of -X- _ O
papers -X- _ O
exploring -X- _ O
the -X- _ O
DIFFVEC -X- _ O
idea -X- _ O
in -X- _ O
different -X- _ O
contexts -X- _ O
. -X- _ O

An -X- _ O
exciting -X- _ O
development -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
inspiration -X- _ O
for -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
has -X- _ O
been -X- _ O
the -X- _ O
demonstration -X- _ O
that -X- _ O
vector -X- _ O
difference -X- _ O
over -X- _ O
word -X- _ O
embeddings -X- _ O
( -X- _ O
Mikolov -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2013c -X- _ O
) -X- _ O
can -X- _ O
be -X- _ O
used -X- _ O
to -X- _ O
model -X- _ O
word -X- _ O
analogy -X- _ O
tasks -X- _ O
. -X- _ O

Distributional -X- _ O
word -X- _ O
vectors -X- _ O
have -X- _ O
been -X- _ O
used -X- _ O
for -X- _ O
detection -X- _ O
of -X- _ O
relations -X- _ O
such -X- _ O
as -X- _ O
hypernymy -X- _ O
( -X- _ O
Geffet -X- _ O
and -X- _ O
Dagan -X- _ O
, -X- _ O
2005;Kotlerman -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2010;Lenci -X- _ O
and -X- _ O
Benotto -X- _ O
, -X- _ O
2012;Weeds -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2014;Rimell -X- _ O
, -X- _ O
2014;Santus -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
and -X- _ O
qualia -X- _ O
structure -X- _ O
( -X- _ O
Yamada -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2009 -X- _ O
) -X- _ O
. -X- _ O

Recently -X- _ O
, -X- _ O
attention -X- _ O
has -X- _ O
turned -X- _ O
to -X- _ O
using -X- _ O
vector -X- _ O
space -X- _ O
models -X- _ O
of -X- _ O
words -X- _ O
for -X- _ O
relation -X- _ O
classification -X- _ O
and -X- _ O
relational -X- _ O
similarity -X- _ O
prediction -X- _ O
. -X- _ O

Relation -X- _ O
learning -X- _ O
is -X- _ O
an -X- _ O
important -X- _ O
and -X- _ O
long -X- _ O
- -X- _ O
standing -X- _ O
task -X- _ O
in -X- _ O
NLP -X- _ O
and -X- _ O
has -X- _ O
been -X- _ O
the -X- _ O
focus -X- _ O
of -X- _ O
a -X- _ O
number -X- _ O
of -X- _ O
shared -X- _ O
tasks -X- _ O
( -X- _ O
Girju -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2007;Hendrickx -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2010;Jurgens -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2012 -X- _ O
) -X- _ O
. -X- _ O

On -X- _ O
the -X- _ O
other -X- _ O
hand -X- _ O
, -X- _ O
relational -X- _ O
similarity -X- _ O
prediction -X- _ O
involves -X- _ O
assessing -X- _ O
the -X- _ O
degree -X- _ O
to -X- _ O
which -X- _ O
a -X- _ O
word -X- _ O
pair -X- _ O
( -X- _ O
A -X- _ O
, -X- _ O
B -X- _ O
) -X- _ O
stands -X- _ O
in -X- _ O
the -X- _ O
same -X- _ O
relation -X- _ O
as -X- _ O
another -X- _ O
pair -X- _ O
( -X- _ O
C -X- _ O
, -X- _ O
D -X- _ O
) -X- _ O
, -X- _ O
or -X- _ O
to -X- _ O
complete -X- _ O
an -X- _ O
analogy -X- _ O
A -X- _ O
: -X- _ O
B -X- _ O
: -X- _ O
: -X- _ O
C -X- _ O
: -X- _ O
-?- -X- _ O
. -X- _ O

In -X- _ O
the -X- _ O
Open -X- _ O
Information -X- _ O
Extraction -X- _ O
paradigm -X- _ O
( -X- _ O
Banko -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2007;Weikum -X- _ O
and -X- _ O
Theobald -X- _ O
, -X- _ O
2010 -X- _ O
) -X- _ O
, -X- _ O
also -X- _ O
known -X- _ O
as -X- _ O
unsupervised -X- _ O
relation -X- _ O
extraction -X- _ O
, -X- _ O
the -X- _ O
relations -X- _ O
themselves -X- _ O
are -X- _ O
also -X- _ O
learned -X- _ O
from -X- _ O
the -X- _ O
text -X- _ O
( -X- _ O
e.g. -X- _ O
in -X- _ O
the -X- _ O
form -X- _ O
of -X- _ O
text -X- _ O
labels -X- _ O
) -X- _ O
. -X- _ O

Given -X- _ O
a -X- _ O
word -X- _ O
pair -X- _ O
, -X- _ O
the -X- _ O
relation -X- _ O
classification -X- _ O
task -X- _ O
involves -X- _ O
assigning -X- _ O
a -X- _ O
word -X- _ O
pair -X- _ O
to -X- _ O
the -X- _ O
correct -X- _ O
relation -X- _ O
from -X- _ O
a -X- _ O
pre -X- _ O
- -X- _ O
defined -X- _ O
set -X- _ O
. -X- _ O

In -X- _ O
relation -X- _ O
extraction -X- _ O
, -X- _ O
related -X- _ O
word -X- _ O
pairs -X- _ O
in -X- _ O
a -X- _ O
corpus -X- _ O
and -X- _ O
the -X- _ O
relevant -X- _ O
relation -X- _ O
are -X- _ O
identified -X- _ O
. -X- _ O

Relation -X- _ O
learning -X- _ O
in -X- _ O
NLP -X- _ O
includes -X- _ O
relation -X- _ O
extraction -X- _ O
, -X- _ O
relation -X- _ O
classification -X- _ O
, -X- _ O
and -X- _ O
relational -X- _ O
similarity -X- _ O
prediction -X- _ O
. -X- _ O

A -X- _ O
lexical -X- _ O
relation -X- _ O
is -X- _ O
a -X- _ O
binary -X- _ O
relation -X- _ O
r -X- _ O
holding -X- _ O
between -X- _ O
a -X- _ O
word -X- _ O
pair -X- _ O
( -X- _ O
w -X- _ O
i -X- _ O
, -X- _ O
w -X- _ O
j -X- _ O
) -X- _ O
; -X- _ O
for -X- _ O
example -X- _ O
, -X- _ O
the -X- _ O
pair -X- _ O
( -X- _ O
cart -X- _ O
, -X- _ O
wheel -X- _ O
) -X- _ O
stands -X- _ O
in -X- _ O
the -X- _ O
WHOLE -X- _ O
- -X- _ O
PART -X- _ O
relation -X- _ O
. -X- _ O

Background -X- _ O
and -X- _ O
Related -X- _ O
Work -X- _ O
. -X- _ O

( -X- _ O
2015a -X- _ O
) -X- _ O
. -X- _ O

We -X- _ O
also -X- _ O
find -X- _ O
that -X- _ O
hyper -X- _ O
- -X- _ O
parameter -X- _ O
optimised -X- _ O
count -X- _ O
- -X- _ O
based -X- _ O
methods -X- _ O
are -X- _ O
competitive -X- _ O
with -X- _ O
predictbased -X- _ O
methods -X- _ O
under -X- _ O
both -X- _ O
clustering -X- _ O
and -X- _ O
supervised -X- _ O
relation -X- _ O
classification -X- _ O
, -X- _ O
in -X- _ O
line -X- _ O
with -X- _ O
the -X- _ O
findings -X- _ O
of -X- _ O
Levy -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

We -X- _ O
find -X- _ O
that -X- _ O
this -X- _ O
improves -X- _ O
the -X- _ O
model -X- _ O
performance -X- _ O
substantially -X- _ O
. -X- _ O

We -X- _ O
then -X- _ O
investigate -X- _ O
methods -X- _ O
for -X- _ O
better -X- _ O
attuning -X- _ O
the -X- _ O
learned -X- _ O
class -X- _ O
representation -X- _ O
to -X- _ O
the -X- _ O
lexical -X- _ O
relations -X- _ O
, -X- _ O
focusing -X- _ O
on -X- _ O
methods -X- _ O
for -X- _ O
automatically -X- _ O
synthesising -X- _ O
negative -X- _ O
instances -X- _ O
. -X- _ O

When -X- _ O
we -X- _ O
move -X- _ O
to -X- _ O
an -X- _ O
open -X- _ O
- -X- _ O
world -X- _ O
setting -X- _ O
including -X- _ O
random -X- _ O
word -X- _ O
pairs -X- _ O
-many -X- _ O
of -X- _ O
which -X- _ O
do -X- _ O
not -X- _ O
correspond -X- _ O
to -X- _ O
any -X- _ O
lexical -X- _ O
relation -X- _ O
in -X- _ O
the -X- _ O
training -X- _ O
data -X- _ O
-the -X- _ O
results -X- _ O
are -X- _ O
poor -X- _ O
. -X- _ O

Second -X- _ O
, -X- _ O
we -X- _ O
perform -X- _ O
classification -X- _ O
over -X- _ O
the -X- _ O
DIFF -X- _ O
- -X- _ O
VECs -X- _ O
and -X- _ O
obtain -X- _ O
remarkably -X- _ O
high -X- _ O
accuracy -X- _ O
in -X- _ O
a -X- _ O
closed -X- _ O
- -X- _ O
world -X- _ O
setting -X- _ O
( -X- _ O
over -X- _ O
a -X- _ O
predefined -X- _ O
set -X- _ O
of -X- _ O
word -X- _ O
pairs -X- _ O
, -X- _ O
each -X- _ O
of -X- _ O
which -X- _ O
corresponds -X- _ O
to -X- _ O
a -X- _ O
lexical -X- _ O
relation -X- _ O
in -X- _ O
the -X- _ O
training -X- _ O
data -X- _ O
) -X- _ O
. -X- _ O

We -X- _ O
find -X- _ O
that -X- _ O
the -X- _ O
clustering -X- _ O
works -X- _ O
remarkably -X- _ O
well -X- _ O
, -X- _ O
although -X- _ O
syntactic -X- _ O
relations -X- _ O
are -X- _ O
captured -X- _ O
better -X- _ O
than -X- _ O
semantic -X- _ O
ones -X- _ O
. -X- _ O

First -X- _ O
, -X- _ O
we -X- _ O
cluster -X- _ O
the -X- _ O
DIFFVECs -X- _ O
to -X- _ O
test -X- _ O
whether -X- _ O
the -X- _ O
clusters -X- _ O
map -X- _ O
onto -X- _ O
true -X- _ O
lexical -X- _ O
relations -X- _ O
. -X- _ O

We -X- _ O
then -X- _ O
apply -X- _ O
DIFFVECs -X- _ O
to -X- _ O
two -X- _ O
new -X- _ O
tasks -X- _ O
: -X- _ O
unsupervised -X- _ O
and -X- _ O
supervised -X- _ O
relation -X- _ O
extraction -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
introduce -X- _ O
a -X- _ O
new -X- _ O
, -X- _ O
larger -X- _ O
dataset -X- _ O
covering -X- _ O
many -X- _ O
well -X- _ O
- -X- _ O
known -X- _ O
lexical -X- _ O
relation -X- _ O
types -X- _ O
from -X- _ O
the -X- _ O
linguistics -X- _ O
and -X- _ O
cognitive -X- _ O
science -X- _ O
literature -X- _ O
. -X- _ O

Moreover -X- _ O
, -X- _ O
the -X- _ O
task -X- _ O
does -X- _ O
not -X- _ O
explore -X- _ O
the -X- _ O
full -X- _ O
implications -X- _ O
of -X- _ O
DIFFVECs -X- _ O
as -X- _ O
meaningful -X- _ O
vector -X- _ O
space -X- _ O
objects -X- _ O
in -X- _ O
their -X- _ O
own -X- _ O
right -X- _ O
, -X- _ O
because -X- _ O
it -X- _ O
only -X- _ O
looks -X- _ O
for -X- _ O
a -X- _ O
one -X- _ O
- -X- _ O
best -X- _ O
answer -X- _ O
to -X- _ O
the -X- _ O
particular -X- _ O
lexical -X- _ O
analogies -X- _ O
in -X- _ O
the -X- _ O
test -X- _ O
set -X- _ O
. -X- _ O

Previous -X- _ O
analogy -X- _ O
completion -X- _ O
tasks -X- _ O
used -X- _ O
with -X- _ O
word -X- _ O
embeddings -X- _ O
have -X- _ O
limited -X- _ O
coverage -X- _ O
of -X- _ O
lexical -X- _ O
relation -X- _ O
types -X- _ O
. -X- _ O

The -X- _ O
success -X- _ O
of -X- _ O
the -X- _ O
simple -X- _ O
offset -X- _ O
method -X- _ O
on -X- _ O
analogy -X- _ O
completion -X- _ O
suggests -X- _ O
that -X- _ O
the -X- _ O
difference -X- _ O
vectors -X- _ O
( -X- _ O
" -X- _ O
DIFFVEC -X- _ O
" -X- _ O
hereafter -X- _ O
) -X- _ O
must -X- _ O
themselves -X- _ O
be -X- _ O
meaningful -X- _ O
: -X- _ O
their -X- _ O
direction -X- _ O
and/or -X- _ O
magnitude -X- _ O
encodes -X- _ O
a -X- _ O
lexical -X- _ O
relation -X- _ O
. -X- _ O

For -X- _ O
example -X- _ O
, -X- _ O
the -X- _ O
paris -X- _ O
− -X- _ O
france -X- _ O
vector -X- _ O
appears -X- _ O
to -X- _ O
encode -X- _ O
CAPITAL -X- _ O
- -X- _ O
OF -X- _ O
, -X- _ O
presumably -X- _ O
by -X- _ O
cancelling -X- _ O
out -X- _ O
the -X- _ O
features -X- _ O
of -X- _ O
paris -X- _ O
that -X- _ O
are -X- _ O
France -X- _ O
- -X- _ O
specific -X- _ O
, -X- _ O
and -X- _ O
retaining -X- _ O
the -X- _ O
features -X- _ O
that -X- _ O
distinguish -X- _ O
a -X- _ O
capital -X- _ O
city -X- _ O
( -X- _ O
Levy -X- _ O
and -X- _ O
Goldberg -X- _ O
, -X- _ O
2014a -X- _ O
) -X- _ O
. -X- _ O

The -X- _ O
key -X- _ O
operation -X- _ O
in -X- _ O
these -X- _ O
models -X- _ O
is -X- _ O
vector -X- _ O
difference -X- _ O
, -X- _ O
or -X- _ O
vector -X- _ O
offset -X- _ O
. -X- _ O

Remarkably -X- _ O
, -X- _ O
since -X- _ O
the -X- _ O
model -X- _ O
is -X- _ O
not -X- _ O
trained -X- _ O
for -X- _ O
this -X- _ O
task -X- _ O
, -X- _ O
the -X- _ O
relational -X- _ O
structure -X- _ O
of -X- _ O
the -X- _ O
vector -X- _ O
space -X- _ O
appears -X- _ O
to -X- _ O
be -X- _ O
an -X- _ O
emergent -X- _ O
property -X- _ O
. -X- _ O

The -X- _ O
results -X- _ O
extend -X- _ O
to -X- _ O
several -X- _ O
semantic -X- _ O
relations -X- _ O
such -X- _ O
as -X- _ O
CAPITAL -X- _ O
- -X- _ O
OF -X- _ O
( -X- _ O
paris−france+poland -X- _ O
≈ -X- _ O
warsaw -X- _ O
) -X- _ O
and -X- _ O
morphosyntactic -X- _ O
relations -X- _ O
such -X- _ O
as -X- _ O
PLURALISATION -X- _ O
( -X- _ O
cars -X- _ O
− -X- _ O
car -X- _ O
+ -X- _ O
apple -X- _ O
≈ -X- _ O
apples -X- _ O
) -X- _ O
. -X- _ O

A -X- _ O
well -X- _ O
- -X- _ O
known -X- _ O
example -X- _ O
involves -X- _ O
predicting -X- _ O
the -X- _ O
vector -X- _ O
queen -X- _ O
from -X- _ O
the -X- _ O
vector -X- _ O
combination -X- _ O
king -X- _ O
− -X- _ O
man -X- _ O
+ -X- _ O
woman -X- _ O
, -X- _ O
where -X- _ O
linear -X- _ O
operations -X- _ O
on -X- _ O
word -X- _ O
vectors -X- _ O
appear -X- _ O
to -X- _ O
capture -X- _ O
the -X- _ O
lexical -X- _ O
relation -X- _ O
governing -X- _ O
the -X- _ O
analogy -X- _ O
, -X- _ O
in -X- _ O
this -X- _ O
case -X- _ O
OPPOSITE -X- _ O
- -X- _ O
GENDER -X- _ O
. -X- _ O

( -X- _ O
2013a -X- _ O
) -X- _ O
and -X- _ O
other -X- _ O
similar -X- _ O
language -X- _ O
models -X- _ O
have -X- _ O
been -X- _ O
shown -X- _ O
to -X- _ O
perform -X- _ O
well -X- _ O
on -X- _ O
an -X- _ O
analogy -X- _ O
completion -X- _ O
task -X- _ O
( -X- _ O
Mikolov -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2013b;Mikolov -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2013c;Levy -X- _ O
and -X- _ O
Goldberg -X- _ O
, -X- _ O
2014a -X- _ O
) -X- _ O
, -X- _ O
in -X- _ O
the -X- _ O
space -X- _ O
of -X- _ O
relational -X- _ O
sim -X- _ O
- -X- _ O
ilarity -X- _ O
prediction -X- _ O
( -X- _ O
Turney -X- _ O
, -X- _ O
2006 -X- _ O
) -X- _ O
, -X- _ O
where -X- _ O
the -X- _ O
task -X- _ O
is -X- _ O
to -X- _ O
predict -X- _ O
the -X- _ O
missing -X- _ O
word -X- _ O
in -X- _ O
analogies -X- _ O
such -X- _ O
as -X- _ O
A -X- _ O
: -X- _ O
B -X- _ O
: -X- _ O
: -X- _ O
C -X- _ O
: -X- _ O
-?- -X- _ O
. -X- _ O

The -X- _ O
skipgram -X- _ O
model -X- _ O
of -X- _ O
Mikolov -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

Recently -X- _ O
, -X- _ O
attention -X- _ O
has -X- _ O
been -X- _ O
focused -X- _ O
on -X- _ O
identifying -X- _ O
lexical -X- _ O
relations -X- _ O
using -X- _ O
word -X- _ O
embeddings -X- _ O
, -X- _ O
which -X- _ O
are -X- _ O
dense -X- _ O
, -X- _ O
low -X- _ O
- -X- _ O
dimensional -X- _ O
vectors -X- _ O
obtained -X- _ O
either -X- _ O
from -X- _ O
a -X- _ O
" -X- _ O
predict -X- _ O
- -X- _ O
based -X- _ O
" -X- _ O
neural -X- _ O
network -X- _ O
trained -X- _ O
to -X- _ O
predict -X- _ O
word -X- _ O
contexts -X- _ O
, -X- _ O
or -X- _ O
a -X- _ O
" -X- _ O
countbased -X- _ O
" -X- _ O
traditional -X- _ O
distributional -X- _ O
similarity -X- _ O
method -X- _ O
combined -X- _ O
with -X- _ O
dimensionality -X- _ O
reduction -X- _ O
. -X- _ O

Learning -X- _ O
to -X- _ O
identify -X- _ O
lexical -X- _ O
relations -X- _ O
is -X- _ O
a -X- _ O
fundamental -X- _ O
task -X- _ O
in -X- _ O
natural -X- _ O
language -X- _ O
processing -X- _ O
( -X- _ O
" -X- _ O
NLP -X- _ O
" -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
can -X- _ O
contribute -X- _ O
to -X- _ O
many -X- _ O
NLP -X- _ O
applications -X- _ O
including -X- _ O
paraphrasing -X- _ O
and -X- _ O
generation -X- _ O
, -X- _ O
machine -X- _ O
translation -X- _ O
, -X- _ O
and -X- _ O
ontology -X- _ O
building -X- _ O
( -X- _ O
Banko -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2007;Hendrickx -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2010 -X- _ O
) -X- _ O
. -X- _ O

Introduction -X- _ O
. -X- _ O

We -X- _ O
find -X- _ O
that -X- _ O
word -X- _ O
embeddings -X- _ O
capture -X- _ O
a -X- _ O
surprising -X- _ O
amount -X- _ O
of -X- _ O
information -X- _ O
, -X- _ O
and -X- _ O
that -X- _ O
, -X- _ O
under -X- _ O
suitable -X- _ O
supervised -X- _ O
training -X- _ O
, -X- _ O
vector -X- _ O
subtraction -X- _ O
generalises -X- _ O
well -X- _ O
to -X- _ O
a -X- _ O
broad -X- _ O
range -X- _ O
of -X- _ O
relations -X- _ O
, -X- _ O
including -X- _ O
over -X- _ O
unseen -X- _ O
lexical -X- _ O
items -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
carry -X- _ O
out -X- _ O
such -X- _ O
an -X- _ O
evaluation -X- _ O
in -X- _ O
two -X- _ O
learning -X- _ O
settings -X- _ O
: -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
spectral -X- _ O
clustering -X- _ O
to -X- _ O
induce -X- _ O
word -X- _ O
relations -X- _ O
, -X- _ O
and -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
supervised -X- _ O
learning -X- _ O
to -X- _ O
classify -X- _ O
vector -X- _ O
differences -X- _ O
into -X- _ O
relation -X- _ O
types -X- _ O
. -X- _ O

Prior -X- _ O
work -X- _ O
has -X- _ O
evaluated -X- _ O
this -X- _ O
intriguing -X- _ O
result -X- _ O
using -X- _ O
a -X- _ O
word -X- _ O
analogy -X- _ O
prediction -X- _ O
formulation -X- _ O
and -X- _ O
hand -X- _ O
- -X- _ O
selected -X- _ O
relations -X- _ O
, -X- _ O
but -X- _ O
the -X- _ O
generality -X- _ O
of -X- _ O
the -X- _ O
finding -X- _ O
over -X- _ O
a -X- _ O
broader -X- _ O
range -X- _ O
of -X- _ O
lexical -X- _ O
relation -X- _ O
types -X- _ O
and -X- _ O
different -X- _ O
learning -X- _ O
settings -X- _ O
has -X- _ O
not -X- _ O
been -X- _ O
evaluated -X- _ O
. -X- _ O

Recent -X- _ O
work -X- _ O
has -X- _ O
shown -X- _ O
that -X- _ O
simple -X- _ O
vector -X- _ O
subtraction -X- _ O
over -X- _ O
word -X- _ O
embeddings -X- _ O
is -X- _ O
surprisingly -X- _ O
effective -X- _ O
at -X- _ O
capturing -X- _ O
different -X- _ O
lexical -X- _ O
relations -X- _ O
, -X- _ O
despite -X- _ O
lacking -X- _ O
explicit -X- _ O
supervision -X- _ O
. -X- _ O

Take -X- _ O
and -X- _ O
Took -X- _ O
, -X- _ O
Gaggle -X- _ O
and -X- _ O
Goose -X- _ O
, -X- _ O
Book -X- _ O
and -X- _ O
Read -X- _ O
: -X- _ O
Evaluating -X- _ O
the -X- _ O
Utility -X- _ O
of -X- _ O
Vector -X- _ O
Differences -X- _ O
for -X- _ O
Lexical -X- _ O
Relation -X- _ O
Learning -X- _ O
. -X- _ O

