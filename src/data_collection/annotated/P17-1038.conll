Acknowledgments	O
.	O

In	O
the	O
future	O
,	O
we	O
will	O
use	O
the	O
proposed	O
automatically	O
data	O
labeling	O
method	O
to	O
more	O
event	O
types	O
and	O
explore	O
more	O
models	O
to	O
extract	O
events	O
by	O
using	O
automatically	O
labeled	O
data	O
.	O

The	O
experimental	O
results	O
show	O
the	O
quality	O
of	O
our	O
large	O
scale	O
automatically	O
labeled	O
data	O
is	O
competitive	O
with	O
elaborately	O
human	O
-	O
annotated	O
data	O
.	O

In	O
this	O
paper	O
,	O
we	O
present	O
an	O
approach	O
to	O
automatically	O
label	O
training	O
data	O
for	O
EE	B-TaskName
.	O

Conclusion	O
and	O
Future	O
Work	O
.	O

In	O
other	O
words	O
,	O
the	O
approach	O
can	O
not	O
extract	O
whole	O
event	O
with	O
different	O
types	O
automatically	O
.	O

However	O
,	O
the	O
method	O
can	O
only	O
extract	O
arguments	O
of	O
one	O
plane	O
crash	O
type	O
and	O
need	O
flight	O
number	O
strings	O
as	O
input	O
.	O

(	O
2014	O
)	O
extended	O
the	O
distant	O
supervision	O
approach	O
to	O
fill	O
slots	O
in	O
plane	O
crash	O
.	O

Reschke	O
et	O
al	O
.	O

4	B-MetricValue
%	I-MetricValue
(	O
Nguyen	O
et	O
al	O
.	O
,	O
2016	O
)	O
respectively	O
.	O

The	O
best	O
reported	O
supervised	O
RE	B-TaskName
and	O
EE	B-TaskName
system	O
got	O
a	O
F1	B-MetricName
-	O
score	O
of	O
88.0	B-MetricValue
%	I-MetricValue
(	O
Wang	O
et	O
al	O
.	O
,	O
2016	O
)	O
and	O
55	B-MetricValue
.	O

For	O
the	O
reasons	O
that	O
an	O
event	O
is	O
more	O
complicated	O
than	O
a	O
relation	O
and	O
the	O
task	O
of	O
EE	B-TaskName
is	O
more	O
difficult	O
than	O
RE	B-TaskName
.	O

But	O
DS	O
for	O
RE	B-TaskName
can	O
not	O
directly	O
use	O
for	O
EE	B-TaskName
.	O

Distant	O
supervision	O
have	O
been	O
used	O
in	O
relation	B-TaskName
extraction	I-TaskName
for	O
automatically	O
labeling	O
training	O
data	O
(	O
Mintz	O
et	O
al	O
.	O
,	O
2009;Hinton	O
et	O
al	O
.	O
,	O
2012;Krause	O
et	O
al	O
.	O
,	O
2012;Krishnamurthy	O
and	O
Mitchell	O
,	O
2012;Berant	O
et	O
al	O
.	O
,	O
2013;Surdeanu	O
et	O
al	O
.	O
,	O
2012;Zeng	O
et	O
al	O
.	O
,	O
2015	O
)	O
.	O

But	O
extracted	O
events	O
may	O
not	O
be	O
easy	O
to	O
be	O
mapped	O
to	O
events	O
for	O
a	O
particular	O
knowledge	O
base	O
.	O

Unsupervised	O
methods	O
can	O
extract	O
large	O
numbers	O
of	O
events	O
without	O
using	O
labeled	O
data	O
(	O
Chambers	O
and	O
Jurafsky	O
,	O
2011;Cheung	O
et	O
al	O
.	O
,	O
2013;Huang	O
et	O
al	O
.	O
,	O
2016	O
)	O
.	O

However	O
,	O
these	O
supervised	O
methods	O
depend	O
on	O
the	O
quality	O
of	O
the	O
training	O
data	O
and	O
labeled	O
training	O
data	O
is	O
expensive	O
to	O
produce	O
.	O

(	O
Ahn	O
,	O
2006;Ji	O
and	O
Grishman	O
,	O
2008;Hong	O
et	O
al	O
.	O
,	O
2011;McClosky	O
et	O
al	O
.	O
,	O
2011;Li	O
et	O
al	O
.	O
,	O
2013Li	O
et	O
al	O
.	O
,	O
,	O
2014;;Chen	O
et	O
al	O
.	O
,	O
2015;Nguyen	O
and	O
Grishman	O
,	O
2015;Nguyen	O
et	O
al	O
.	O
,	O
2016	O
)	O
.	O

The	O
human	O
evaluation	O
results	O
are	O
presented	O
in	O
Table	O
7	O
.	O

Instead	O
,	O
we	O
calculate	O
the	O
precision	B-MetricName
of	O
the	O
top	O
n	O
extracted	O
event	O
instances	O
.	O

Because	O
the	O
number	O
of	O
these	O
event	O
instances	O
in	O
the	O
test	O
data	O
is	O
unknown	O
,	O
we	O
can	O
not	O
calculate	O
the	O
recall	B-MetricName
in	O
this	O
case	O
.	O

In	O
the	O
manual	O
evaluation	O
,	O
we	O
manually	O
check	O
the	O
newly	O
discovered	O
event	O
instances	O
that	O
are	O
not	O
in	O
Freebase	B-DatasetName
.	O

We	O
also	O
perform	O
a	O
manual	O
evaluation	O
to	O
eliminate	O
these	O
problems	O
.	O

Because	O
the	O
incomplete	O
nature	O
of	O
Freebase	B-DatasetName
,	O
heldout	O
evaluation	O
suffers	O
from	O
false	O
negatives	O
problem	O
.	O

Human	O
Evaluation	O
.	O

We	O
can	O
see	O
that	O
multi	O
-	O
instance	O
learning	O
is	O
effective	O
to	O
alleviate	O
the	O
noise	O
problem	O
in	O
our	O
distant	B-TaskName
supervised	I-TaskName
event	I-TaskName
extraction	I-TaskName
.	O

Figure	O
7	O
and	O
Figure	O
8	O
show	O
the	O
precision	B-MetricName
-	I-MetricName
recall	I-MetricName
(	O
P	B-MetricName
-	I-MetricName
R	I-MetricName
)	O
curves	O
for	O
each	O
method	O
in	O
the	O
two	O
stages	O
of	O
event	O
extraction	O
respectively	O
.	O

We	O
use	O
the	O
following	O
criteria	O
to	O
judge	O
the	O
correctness	O
of	O
each	O
predicted	O
event	O
automatically	O
:	O
(	O
1	O
)	O
An	O
event	O
is	O
correct	O
if	O
its	O
key	O
arguments	O
and	O
event	O
type	O
match	O
those	O
of	O
an	O
event	O
instance	O
in	O
Freebase	B-DatasetName
;	O
(	O
2	O
)	O
An	O
argument	O
is	O
correctly	O
classified	O
if	O
its	O
event	O
type	O
and	O
argument	O
role	O
match	O
those	O
of	O
any	O
of	O
the	O
argument	O
instance	O
in	O
the	O
corresponding	O
Freebase	B-DatasetName
event	O
.	O

In	O
the	O
held	O
-	O
out	O
evaluation	O
,	O
we	O
hold	O
out	O
part	O
of	O
the	O
Freebase	B-DatasetName
event	O
data	O
during	O
training	O
,	O
and	O
compare	O
newly	O
discovered	O
event	O
instances	O
against	O
this	O
heldout	O
data	O
.	O

Held	O
-	O
out	O
Evaluation	O
.	O

Following	O
previous	O
work	O
(	O
Mintz	O
et	O
al	O
.	O
,	O
2009	O
)	O
in	O
distant	O
supervised	O
RE	B-TaskName
,	O
we	O
evaluate	O
our	O
method	O
in	O
two	O
ways	O
:	O
held	O
-	O
out	O
and	O
manual	O
evaluation	O
.	O

Table	O
6	O
:	O
Effects	O
of	O
TCF	O
,	O
TETF	O
,	O
TR	O
and	O
FrameNet	B-DatasetName
.	O

Such	O
improvements	O
are	O
higher	O
than	O
improvements	O
gained	O
by	O
other	O
methods	O
(	O
TCF	B-MethodName
,	O
IEF	B-MethodName
,	O
TR	B-MethodName
)	O
,	O
which	O
demonstrates	O
the	O
effectiveness	O
of	O
the	O
usage	O
of	O
FrameNet	B-DatasetName
.	O

When	O
we	O
use	O
FrameNet	B-DatasetName
to	O
generate	O
triggers	O
,	O
compared	O
with	O
ACE+TR	B-MethodName
,	O
we	O
get	O
a	O
1.0	O
improvement	O
on	O
trigger	O
classification	O
and	O
a	O
1.7	O
improvement	O
on	O
argument	O
classification	O
.	O

Results	O
are	O
shown	O
in	O
Table	O
6	O
,	O
Compared	O
with	O
ACE+TCF	B-MethodName
and	O
ACE+TETF	B-MethodName
,	O
ACE+TR	B-MethodName
gains	O
a	O
higher	O
performance	O
in	O
both	O
stages	O
.	O

Then	O
we	O
evaluate	O
the	O
performance	O
of	O
these	O
methods	O
by	O
using	O
above	O
automatic	O
evaluations	O
.	O

Trigger	O
examples	O
generated	O
by	O
TR+Framenet	B-MethodName
are	O
shown	O
in	O
Table	O
2	O
.	O

FrameNet	B-DatasetName
was	O
used	O
to	O
filter	O
noisy	O
verbal	O
triggers	O
and	O
expand	O
nominal	O
triggers	O
.	O

We	O
set	O
these	O
hyper	O
parameters	O
as	O
0.8	B-HyperparameterValue
,	O
0.9	B-HyperparameterValue
and	O
0.8	B-HyperparameterValue
,	O
respectively	O
,	O
which	O
are	O
determined	O
by	O
grid	O
search	O
from	O
(	O
0.5	O
,	O
0.6	O
,	O
0.7	O
,	O
0.8	O
,	O
0.9	O
,	O
1.0	O
)	O
.	O

TCF	B-HyperparameterName
,	O
TETF	B-HyperparameterName
and	O
TR	B-HyperparameterName
respectively	O
use	O
the	O
trigger	B-HyperparameterName
candidate	I-HyperparameterName
frequency	I-HyperparameterName
,	O
trigger	B-HyperparameterName
event	I-HyperparameterName
type	I-HyperparameterName
frequency	I-HyperparameterName
and	O
trigger	B-HyperparameterName
rate	I-HyperparameterName
to	O
sort	O
trigger	O
candidates	O
of	O
each	O
type	O
of	O
events	O
.	O

We	O
specifically	O
select	O
two	O
methods	O
as	O
baselines	O
:	O
TCF	B-MethodName
and	O
TETF	B-MethodName
.	O

In	O
this	O
section	O
,	O
we	O
prove	O
the	O
effectiveness	O
of	O
TR	B-HyperparameterName
and	O
FrameNet	B-DatasetName
to	O
find	O
triggers	O
.	O

Impact	O
of	O
Trigger	B-HyperparameterName
Rate	I-HyperparameterName
and	O
FrameNet	B-DatasetName
.	O

However	O
,	O
when	O
we	O
set	O
k	B-HyperparameterName
=	O
1	B-HyperparameterValue
,	O
although	O
more	O
labeled	O
data	O
are	O
generated	O
,	O
the	O
precision	O
could	O
not	O
be	O
guaranteed	O
.	O

For	O
example	O
,	O
if	O
k	B-HyperparameterName
=	O
2	B-HyperparameterValue
,	O
we	O
will	O
get	O
25	O
,	O
797	O
sentences	O
labeled	O
as	O
people.marriage	O
events	O
and	O
we	O
will	O
get	O
534	O
labeled	O
sentences	O
,	O
if	O
k	B-HyperparameterName
=	O
3	B-HyperparameterValue
.	O

As	O
a	O
result	O
,	O
less	O
training	O
data	O
is	O
generated	O
.	O

The	O
reason	O
is	O
that	O
the	O
heuristics	O
for	O
data	O
labeling	O
are	O
stricter	O
as	O
k	B-HyperparameterName
grows	O
.	O

Then	O
,	O
the	O
F1	B-MetricName
value	O
reduces	O
as	O
k	B-HyperparameterName
grows	O
.	O

Figure	O
6	O
shows	O
the	O
results	O
,	O
when	O
we	O
set	O
k	B-HyperparameterName
=	O
2	B-HyperparameterValue
,	O
the	O
method	O
achieves	O
a	O
best	O
Figure	O
6	O
:	O
Effects	O
of	O
the	O
number	B-HyperparameterName
of	I-HyperparameterName
key	I-HyperparameterName
arguments	I-HyperparameterName
performance	O
in	O
both	O
stages	O
.	O

To	O
explore	O
the	O
impact	O
of	O
different	O
numbers	O
of	O
key	O
arguments	O
,	O
we	O
sort	O
all	O
arguments	O
of	O
each	O
type	O
of	O
events	O
according	O
to	O
KR	O
value	O
and	O
select	O
top	O
k	B-HyperparameterName
arguments	O
as	O
the	O
key	O
arguments	O
.	O

Examples	O
are	O
shown	O
in	O
Table	O
2	O
.	O

ACE+KR	B-MethodName
achieve	O
the	O
best	O
performance	O
in	O
both	O
stages	O
.	O

Results	O
are	O
shown	O
in	O
Table	O
5	O
.	O

After	O
that	O
we	O
evaluate	O
these	O
methods	O
by	O
using	O
above	O
automatic	O
evaluations	O
based	O
on	O
ACE	B-DatasetName
data	O
.	O

Then	O
we	O
choose	O
the	O
same	O
number	B-HyperparameterName
of	I-HyperparameterName
key	I-HyperparameterName
arguments	I-HyperparameterName
in	O
all	O
methods	O
and	O
use	O
these	O
key	O
arguments	O
to	O
label	O
data	O
.	O

We	O
specifically	O
select	O
two	O
methods	O
as	O
baselines	O
for	O
comparison	O
with	O
our	O
KR	O
method	O
:	O
ER	O
and	O
RS	O
,	O
which	O
use	O
the	O
event	O
relevance	O
and	O
role	O
salience	O
to	O
sort	O
arguments	O
of	O
each	O
type	O
of	O
events	O
respectively	O
.	O

In	O
this	O
section	O
,	O
we	O
prove	O
the	O
effectiveness	O
of	O
KR	O
to	O
find	O
key	O
arguments	O
and	O
explore	O
the	O
impact	O
of	O
different	O
numbers	O
of	O
key	O
arguments	O
to	O
automatically	O
generate	O
data	O
.	O

Impact	O
of	O
Key	O
Rate	O
.	O

Discussion	O
.	O

This	O
demonstrates	O
that	O
our	O
large	O
scale	O
automatically	O
labeled	O
data	O
is	O
competitive	O
with	O
elaborately	O
humanannotated	O
data	O
.	O

Also	O
,	O
we	O
provide	O
a	O
DMCNN	B-MethodName
-	I-MethodName
MIL	I-MethodName
model	O
for	O
this	O
data	O
as	O
a	O
baseline	O
for	O
further	O
research	O
.	O

We	O
can	O
see	O
that	O
DMCNNs	B-MethodName
-	I-MethodName
MIL	I-MethodName
achieves	O
the	O
best	O
performance	O
.	O

Performance	O
of	O
DMCNN	B-MethodName
-	I-MethodName
MIL	I-MethodName
.	O

(	O
2	O
)	O
Chen	O
's	O
DMCNN	B-MethodName
,	O
which	O
is	O
the	O
best	O
reported	O
CNN	O
-	O
based	O
system	O
(	O
Chen	O
et	O
al	O
.	O
,	O
2015	O
)	O
.	O

Finally	O
,	O
we	O
shows	O
the	O
performance	O
of	O
DMCNNs	B-MethodName
-	I-MethodName
MIL	I-MethodName
on	O
our	O
automatically	O
labeled	O
data	O
.	O

In	O
order	O
to	O
alleviate	O
the	O
wrong	O
label	O
problem	O
,	O
we	O
use	O
Multi	B-MethodName
-	I-MethodName
instance	I-MethodName
Learning	I-MethodName
(	O
MIL	B-MethodName
)	O
for	O
two	O
DMCNNs	B-MethodName
.	O
Because	O
the	O
second	O
stage	O
is	O
more	O
complicated	O
and	O
limited	O
in	O
space	O
,	O
we	O
take	O
the	O
MIL	O
used	O
in	O
arguments	O
classification	O
as	O
an	O
example	O
and	O
describes	O
as	O
follows	O
:	O
We	O
define	O
all	O
of	O
the	O
parameters	O
for	O
the	O
stage	O
of	O
argument	O
classification	O
to	O
be	O
trained	O
in	O
DM	B-MethodName
-	I-MethodName
CNNs	I-MethodName
as	O
θ	O
.	O

We	O
employ	O
two	O
similar	O
Dynamic	B-MethodName
Multi	I-MethodName
-	I-MethodName
pooling	I-MethodName
Convolutional	I-MethodName
Neural	I-MethodName
Networks	I-MethodName
with	O
Multi	B-MethodName
-	I-MethodName
instance	I-MethodName
Learning	I-MethodName
(	O
DMCNNs	B-MethodName
-	I-MethodName
MIL	I-MethodName
)	O
for	O
above	O
two	O
stages	O
.	O

The	O
Dynamic	B-MethodName
Multi	I-MethodName
-	I-MethodName
pooling	I-MethodName
Convolutional	I-MethodName
Neural	I-MethodName
Networks	I-MethodName
(	O
DMCNNs	B-MethodName
)	O
is	O
the	O
best	O
reported	O
CNN	O
-	O
based	O
model	O
for	O
event	O
extraction	O
(	O
Chen	O
et	O
al	O
.	O
,	O
2015	O
)	O
by	O
using	O
human	O
-	O
annotated	O
training	O
data	O
.	O

We	O
call	O
this	O
Expanded	B-DatasetName
Data	I-DatasetName
(	O
ED	B-DatasetName
)	O
as	O
ED	B-DatasetName
Only	I-DatasetName
.	O

Moreover	O
,	O
compared	O
with	O
Chen	O
's	O
DM	B-MethodName
-	I-MethodName
CNN	I-MethodName
trained	O
with	O
ACE	B-DatasetName
,	O
DMCNN	B-MethodName
trained	O
with	O
ED	B-DatasetName
Only	I-DatasetName
achieves	O
a	O
competitive	O
performance	O
.	O

This	O
demonstrates	O
that	O
our	O
automatically	O
generated	O
labeled	O
data	O
could	O
expand	O
human	O
annotated	O
training	O
data	O
effectively	O
.	O

Compared	O
with	O
all	O
models	O
,	O
DMCNN	B-MethodName
trained	O
with	O
ACE+ED	B-DatasetName
achieves	O
the	O
highest	O
performance	O
.	O

The	O
results	O
are	O
shown	O
in	O
Table	O
4	O
.	O

(	O
3	O
)	O
Nguyen	O
's	O
JRNN	O
,	O
which	O
is	O
the	O
state	O
-	O
ofthe	O
-	O
arts	O
system	O
(	O
Nguyen	O
et	O
al	O
.	O
,	O
2016	O
)	O
.	O

(	O
1	O
)	O
Li	O
's	O
structure	O
,	O
which	O
is	O
the	O
best	O
reported	O
structured	O
-	O
based	O
system	O
(	O
Li	O
et	O
al	O
.	O
,	O
2013	O
)	O
.	O

We	O
select	O
three	O
baselines	O
trained	O
with	O
ACE	B-DatasetName
data	O
.	O

And	O
we	O
use	O
the	O
same	O
evaluation	O
metric	O
P	B-MetricName
,	O
R	B-MetricName
,	O
F	B-MetricName
as	O
ACE	B-DatasetName
task	O
defined	O
.	O

Then	O
we	O
use	O
such	O
data	O
to	O
train	O
the	O
same	O
event	O
extraction	O
model	O
(	O
DMCNN	B-MethodName
)	O
and	O
evaluate	O
them	O
on	O
the	O
ACE	B-DatasetName
testing	O
data	O
set	O
.	O

(	O
2	O
)	O
We	O
directly	O
add	O
our	O
automatically	O
labeled	O
data	O
of	O
mapped	O
event	O
types	O
to	O
ACE	B-DatasetName
training	O
data	O
and	O
we	O
call	O
this	O
training	O
data	O
as	O
ACE+ED	B-DatasetName
.	O

(	O
1	O
)	O
we	O
delete	O
the	O
human	O
annotated	O
ACE	B-DatasetName
data	O
for	O
these	O
mapped	O
event	O
types	O
in	O
ACE	B-DatasetName
dataset	O
and	O
add	O
our	O
automatically	O
labeled	O
data	O
to	O
remainder	O
ACE	B-DatasetName
training	O
data	O
.	O

We	O
mapped	O
these	O
types	O
of	O
events	O
manually	O
and	O
we	O
add	O
them	O
into	O
ACE	B-DatasetName
training	O
corpus	O
in	O
two	O
ways	O
.	O

For	O
example	O
,	O
our	O
people.marriage	O
events	O
can	O
be	O
mapped	O
to	O
life.marry	O
events	O
in	O
ACE2005	B-DatasetName
dataset	O
.	O

In	O
our	O
automatically	O
labeled	O
data	O
,	O
there	O
are	O
some	O
event	O
types	O
that	O
can	O
correspond	O
to	O
those	O
in	O
ACE	B-DatasetName
dataset	O
.	O

To	O
prove	O
the	O
effectiveness	O
of	O
the	O
proposed	O
approach	O
automatically	O
,	O
we	O
add	O
automatically	O
generated	O
labeled	O
data	O
into	O
ACE	B-DatasetName
dataset	O
to	O
expand	O
the	O
training	O
sets	O
and	O
see	O
whether	O
the	O
performance	O
of	O
the	O
event	O
extractor	O
trained	O
on	O
such	O
expanded	O
training	O
sets	O
is	O
improved	O
.	O

Automatic	O
Evaluations	O
of	O
Labeled	O
Data	O
.	O

Our	O
automatically	O
generated	O
data	O
can	O
achieve	O
a	O
precision	B-MetricName
of	O
88.9	B-MetricValue
and	O
85.4	B-MetricValue
for	O
trigger	O
labeling	O
and	O
argument	O
labeling	O
re-	O
Table	O
4	O
:	O
Overall	O
performance	O
on	O
ACE	B-DatasetName
blind	O
test	O
data	O
spectively	O
,	O
which	O
demonstrates	O
that	O
our	O
automatically	O
labeled	O
data	O
is	O
of	O
high	O
quality	O
.	O

Average	B-MetricName
Precision	I-MetricName
Trigger	O
Labeling	O
88.9	B-MetricValue
Argument	O
Labeling	O
85.4	B-MetricValue
Table	O
3	O
:	O
Manual	O
Evaluation	O
Results	O
We	O
repeat	O
above	O
evaluation	O
process	O
on	O
the	O
final	O
72	O
,	O
611	O
labeled	O
data	O
three	O
times	O
and	O
the	O
average	O
precision	O
is	O
shown	O
in	O
Table	O
3	O
.	O

Two	O
hyper	O
parameters	O
,	O
the	O
number	B-HyperparameterName
of	I-HyperparameterName
key	I-HyperparameterName
arguments	I-HyperparameterName
and	O
the	O
value	O
of	O
TR	B-HyperparameterName
in	O
our	O
automatically	O
data	O
labeling	O
,	O
are	O
set	O
as	O
2	O
and	O
0.8	O
,	O
by	O
grid	O
search	O
respectively	O
.	O

Method	O
of	O
Event	B-TaskName
Extraction	I-TaskName
.	O

Finally	O
,	O
we	O
propose	O
a	O
Soft	O
Distant	O
Supervision	O
and	O
use	O
it	O
to	O
automatically	O
generate	O
training	O
data	O
,	O
which	O
assumes	O
that	O
any	O
sentence	O
containing	O
all	O
key	O
arguments	O
in	O
Freebase	B-DatasetName
and	O
a	O
corresponding	O
trigger	O
word	O
is	O
likely	O
to	O
express	O
that	O
event	O
in	O
some	O
way	O
,	O
and	O
arguments	O
occurring	O
in	O
that	O
sentence	O
are	O
likely	O
to	O
play	O
the	O
corresponding	O
roles	O
in	O
that	O
event	O
.	O

Finally	O
,	O
we	O
choose	O
verbs	O
with	O
high	O
T	B-HyperparameterName
R	I-HyperparameterName
values	O
as	O
the	O
trigger	O
words	O
for	O
each	O
event	O
type	O
.	O

Finally	O
we	O
employ	O
Trigger	B-HyperparameterName
Rate	I-HyperparameterName
(	O
TR	B-HyperparameterName
)	O
,	O
which	O
is	O
the	O
product	O
of	O
TCF	B-HyperparameterName
and	O
TETF	B-HyperparameterName
to	O
estimate	O
the	O
probability	O
of	O
a	O
verb	O
to	O
be	O
a	O
trigger	O
,	O
which	O
is	O
formulated	O
as	O
follows	O
:	O
T	O
R	O
ij	O
=	O
T	O
CF	O
ij	O
*	O
T	O
ET	O
F	O
i	O
(	O
4	O
)	O
T	O
CF	O
ij	O
=	O
Count(V	O
i	O
,	O
ET	O
S	O
j	O
)	O
Count(ET	O
S	O
j	O
)	O
(	O
5	O
)	O
T	O
ET	O
F	O
i	O
=	O
log	O
Sum(ET	O
)	O
1	O
+	O
Count(ET	O
I	O
i	O
)	O
(	O
6	O
)	O
where	O
T	O
R	O
ij	O
is	O
the	O
trigger	O
rate	O
of	O
i	O
-	O
th	O
verb	O
to	O
jth	O
event	O
type	O
,	O
Count(V	O
i	O
,	O
ET	O
S	O
j	O
)	O
is	O
the	O
number	O
of	O
sentences	O
,	O
which	O
express	O
j	O
-	O
th	O
type	O
of	O
event	O
and	O
contain	O
i	O
-	O
th	O
verb	O
,	O
Count(ET	O
S	O
j	O
)	O
is	O
the	O
number	O
of	O
sentences	O
expressing	O
j	O
-	O
th	O
event	O
type	O
,	O
Count(ET	O
I	O
i	O
)	O
is	O
the	O
number	O
of	O
event	O
types	O
,	O
which	O
have	O
the	O
labeled	O
sentences	O
containing	O
i	O
-	O
th	O
verb	O
.	O

Thus	O
we	O
propose	O
Trigger	B-HyperparameterName
Candidate	I-HyperparameterName
Frequency	I-HyperparameterName
(	O
TCF	B-HyperparameterName
)	O
and	O
Trigger	B-HyperparameterName
Event	I-HyperparameterName
Type	I-HyperparameterName
Frequency	I-HyperparameterName
(	O
TETF	B-HyperparameterName
)	O
to	O
evaluate	O
above	O
two	O
aspects	O
.	O

Finally	O
,	O
KR	O
is	O
computed	O
as	O
follows	O
:	O
KR	O
ij	O
=	O
RS	O
ij	O
*	O
ER	O
i	O
(	O
3	O
)	O
We	O
compute	O
KR	O
for	O
all	O
arguments	O
of	O
each	O
event	O
type	O
,	O
and	O
sort	O
them	O
according	O
to	O
KR	O
.	O

We	O
propose	O
to	O
compute	O
ER	O
as	O
follows	O
:	O
ER	O
i	O
=	O
log	O
Sum(ET	O
)	O
1	O
+	O
Count(ET	O
Ci	O
)	O
(	O
2	O
)	O
where	O
ER	O
i	O
is	O
the	O
event	O
relevance	O
of	O
i	O
-	O
th	O
argument	O
,	O
Sum	O
(	O
ET	O
)	O
is	O
the	O
number	O
of	O
all	O
event	O
types	O
in	O
knowledge	O
base	O
and	O
Count(ET	O
C	O
i	O
)	O
is	O
the	O
number	O
of	O
event	O
types	O
containing	O
i	O
-	O
th	O
argument	O
.	O

Event	O
Relevance	O
(	O
ER	O
)	O
reflects	O
the	O
ability	O
in	O
which	O
an	O
argument	O
can	O
be	O
used	O
to	O
discriminate	O
d	O
-	O
ifferent	O
event	O
types	O
.	O

We	O
define	O
RS	O
as	O
follows	O
:	O
RS	O
ij	O
=	O
Count(A	O
i	O
,	O
ET	O
j	O
)	O
Count(ET	O
j	O
)	O
(	O
1	O
)	O
where	O
RS	O
ij	O
is	O
the	O
role	O
saliency	O
of	O
i	O
-	O
th	O
argument	O
to	O
j	O
-	O
th	O
event	O
type	O
,	O
Count(A	O
i	O
,	O
ET	O
j	O
)	O
is	O
the	O
number	O
of	O
Arguemnt	O
i	O
occurring	O
in	O
all	O
instances	O
of	O
eventT	O
ype	O
j	O
in	O
Freebase	O
and	O
Count(ET	O
j	O
)	O
is	O
the	O
number	O
of	O
instances	O
of	O
eventT	O
ype	O
j	O
in	O
Freebase	O
.	O

Role	O
Saliency	O
(	O
RS	O
)	O
reflects	O
the	O
saliency	O
of	O
an	O
argument	O
to	O
represent	O
a	O
specific	O
event	O
instance	O
of	O
a	O
given	O
event	O
type	O
.	O

We	O
propose	O
to	O
use	O
Key	O
Rate	O
(	O
KR	O
)	O
to	O
estimate	O
the	O
importance	O
of	O
an	O
argument	O
to	O
a	O
type	O
of	O
event	O
,	O
which	O
is	O
decided	O
by	O
two	O
factors	O
:	O
Role	O
Saliency	O
and	O
Event	O
Relevance	O
.	O

Each	O
frame	O
has	O
a	O
set	O
of	O
lemmas	O
with	O
part	O
of	O
speech	O
tags	O
that	O
can	O
evoke	O
the	O
frame	O
,	O
which	O
are	O
called	O
LUs	O
.	O
For	O
example	O
,	O
appoint.v	O
is	O
a	O
LU	O
of	O
Appointing	O
frame	O
in	O
FrameNet	B-DatasetName
,	O
which	O
can	O
be	O
mapped	O
to	O
people.appointment	O
events	O
in	O
Freebase	B-DatasetName
.	O

FrameNet	B-DatasetName
3	I-DatasetName
is	O
a	O
linguistic	O
resource	O
storing	O
information	O
about	O
lexical	O
and	O
predicate	O
argument	O
semantics	O
(	O
Baker	O
et	O
al	O
.	O
,	O
1998	O
)	O
.	O

According	O
to	O
the	O
statistics	O
of	O
the	O
Freebase	B-DatasetName
released	O
on	O
23	O
th	O
April	O
,	O
2015	O
,	O
there	O
are	O
around	O
1885	O
CVTs	O
and	O
around	O
14	O
million	O
CVTs	O
instances	O
.	O

To	O
solve	O
the	O
data	O
labeling	O
problem	O
,	O
we	O
propose	O
to	O
automatically	O
label	O
training	O
data	O
for	O
event	B-TaskName
extraction	I-TaskName
via	O
world	O
knowledge	O
and	O
linguistic	O
knowledge	O
,	O
which	O
can	O
detect	O
key	O
arguments	O
and	O
trigger	O
words	O
for	O
each	O
event	O
type	O
and	O
employ	O
them	O
to	O
label	O
events	O
in	O
texts	O
automatically	O
.	O

Stage	O
.	O

Manual	O
Evaluations	O
of	O
Labeled	O
Data	O
.	O

Each	O
sample	O
is	O
independently	O
annotated	O
by	O
three	O
annotators	O
6	O
(	O
including	O
one	O
of	O
the	O
authors	O
and	O
two	O
of	O
our	O
colleagues	O
who	O
are	O
familiar	O
with	O
event	O
extraction	O
task	O
)	O
and	O
the	O
final	O
decision	O
is	O
made	O
by	O
voting	O
.	O

It	O
is	O
very	O
easy	O
to	O
annotate	O
a	O
sample	O
for	O
annotators	O
,	O
thus	O
the	O
annotated	O
results	O
are	O
expected	O
to	O
be	O
of	O
high	O
quality	O
.	O

Otherwise	O
"	O
N	O
"	O
is	O
labeled	O
.	O

"	O
Y	O
"	O
:	O
the	O
word	O
highlighted	O
in	O
the	O
given	O
sentence	O
indeed	O
triggers	O
an	O
event	O
of	O
the	O
corresponding	O
type	O
or	O
the	O
word	O
indeed	O
plays	O
the	O
corresponding	O
role	O
in	O
that	O
event	O
.	O

Annotators	O
are	O
asked	O
to	O
assign	O
one	O
of	O
two	O
labels	O
to	O
each	O
sample	O
.	O

Figure	O
5	O
gives	O
some	O
samples	O
.	O

Each	O
selected	O
sample	O
is	O
a	O
sentence	O
with	O
a	O
highlighted	O
trigger	O
,	O
labeled	O
arguments	O
and	O
corresponding	O
event	O
type	O
and	O
argument	O
roles	O
.	O

We	O
randomly	O
select	O
500	O
samples	O
from	O
our	O
automatically	O
labeled	O
data	O
.	O

We	O
firstly	O
manually	O
evaluate	O
the	O
precision	B-MetricName
of	O
our	O
automatically	O
generated	O
labeled	O
data	O
.	O

Compared	O
with	O
nearly	O
6	O
,	O
000	O
human	O
annotated	O
labeled	O
sentence	O
in	O
ACE	B-DatasetName
,	O
our	O
method	O
can	O
automatically	O
generate	O
large	O
scale	O
labeled	O
training	O
data	O
.	O

Finally	O
,	O
72	O
,	O
611	O
labeled	O
sentences	O
are	O
generated	O
automatically	O
.	O

Thus	O
,	O
we	O
leverage	O
these	O
rough	O
labeled	O
data	O
and	O
FrameNet	B-DatasetName
to	O
find	O
triggers	O
and	O
use	O
SDS	O
to	O
generate	O
labeled	O
data	O
.	O

However	O
,	O
these	O
sentences	O
miss	O
labeling	O
triggers	O
.	O

When	O
we	O
merely	O
use	O
two	O
key	O
arguments	O
to	O
label	O
data	O
,	O
we	O
will	O
obtain	O
421	O
,	O
602	O
labeled	O
sentences	O
.	O

Table	O
2	O
shows	O
the	O
statistics	O
of	O
the	O
five	O
largest	O
automatically	O
labeled	O
events	O
among	O
selected	O
21	O
Freebase	B-DatasetName
events	O
.	O

By	O
using	O
the	O
proposed	O
methods	O
,	O
a	O
large	O
set	O
of	O
labeled	O
data	O
could	O
be	O
generated	O
automatically	O
.	O

Our	O
Automatically	O
Labeled	O
Data	O
.	O

Then	O
,	O
we	O
conduct	O
automatic	O
evaluations	O
for	O
our	O
labeled	O
data	O
based	O
on	O
ACE	B-DatasetName
corpus	O
and	O
analyze	O
effects	O
of	O
different	O
approaches	O
to	O
automatically	O
label	O
training	O
data	O
.	O

In	O
this	O
section	O
,	O
we	O
first	O
manually	O
evaluate	O
our	O
automatically	O
labeled	O
data	O
.	O

Experiments	O
.	O

Given	O
all	O
(	O
T	O
)	O
training	O
bags	O
(	O
M	O
i	O
,	O
y	O
i	O
)	O
,	O
we	O
can	O
define	O
the	O
objective	O
function	O
using	O
cross	O
-	O
entropy	O
at	O
the	O
bag	O
level	O
as	O
follows	O
:	O
J	O
(	O
θ	O
)	O
=	O
T	O
i=1	O
log	O
p(y	O
i	O
|m	O
j	O
i	O
,	O
θ	O
)	O
(	O
9	O
)	O
where	O
j	O
is	O
constrained	O
as	O
follows	O
:	O
j	O
*	O
=	O
arg	O
max	O
j	O
p(r|m	O
j	O
i	O
,	O
θ	O
)	O
1	O
≤	O
j	O
≤	O
q	O
i	O
(	O
10	O
)	O
To	O
compute	O
the	O
network	O
parameter	O
θ	O
,	O
we	O
maximize	O
the	O
log	O
likelihood	O
J	O
(	O
θ	O
)	O
through	O
stochastic	O
gradient	O
descent	O
over	O
mini	O
-	O
batches	O
with	O
the	O
Adadelta	O
(	O
Zeiler	O
,	O
2012	O
)	O
update	O
rule	O
.	O

Thus	O
,	O
we	O
define	O
the	O
objective	O
function	O
on	O
the	O
bags	O
.	O

And	O
the	O
objective	O
of	O
multi	O
-	O
instance	O
learning	O
is	O
to	O
discriminate	O
bags	O
rather	O
than	O
instances	O
.	O

To	O
obtain	O
the	O
conditional	O
probability	O
p(r|m	O
j	O
i	O
,	O
θ	O
)	O
,	O
we	O
apply	O
a	O
softmax	O
operation	O
over	O
all	O
argument	O
role	O
types	O
:	O
p(r|m	O
j	O
i	O
,	O
θ	O
)	O
=	O
e	O
or	O
n	O
k=1	O
e	O
o	O
k	O
(	O
8)	O
where	O
,	O
n	O
is	O
the	O
number	O
of	O
roles	O
.	O

Given	O
an	O
input	O
instance	O
m	O
j	O
i	O
,	O
the	O
network	O
with	O
the	O
parameter	O
θ	O
outputs	O
a	O
vector	O
O	O
,	O
where	O
the	O
r	O
-	O
th	O
component	O
O	O
r	O
corresponds	O
to	O
the	O
score	O
associated	O
with	O
argument	O
role	O
r.	O

In	O
stage	O
of	O
argument	O
classification	O
,	O
we	O
take	O
sentences	O
containing	O
the	O
same	O
argument	O
candidate	O
and	O
triggers	O
with	O
a	O
same	O
event	O
type	O
as	O
a	O
bag	O
and	O
all	O
instances	O
in	O
a	O
bag	O
are	O
considered	O
independently	O
.	O

Suppose	O
that	O
there	O
are	O
T	O
bags	O
{	O
M	O
1	O
,	O
M	O
2	O
,	O
...	O
,	O
M	O
T	O
}	O
and	O
that	O
the	O
i	O
-	O
th	O
bag	O
contains	O
q	O
i	O
instances	O
(	O
sentences	O
)	O
M	O
i	O
=	O
m	O
1	O
i	O
,	O
m	O
2	O
i	O
,	O
...	O
,	O
m	O
q	O
i	O
i	O
,	O
the	O
objective	O
of	O
multi	O
-	O
instance	O
learning	O
is	O
to	O
predict	O
the	O
labels	O
of	O
the	O
unseen	O
bags	O
.	O

However	O
,	O
our	O
automatically	O
labeled	O
data	O
face	O
a	O
noise	O
problem	O
,	O
which	O
is	O
a	O
intrinsic	O
problem	O
of	O
using	O
DS	O
to	O
construct	O
training	O
data	O
(	O
Hoffmann	O
et	O
al	O
.	O
,	O
2011;Surdeanu	O
et	O
al	O
.	O
,	O
2012	O
)	O
.	O

We	O
call	O
this	O
stage	O
as	O
argument	O
classification	O
.	O

If	O
the	O
key	O
arguments	O
participate	O
a	O
Freebase	B-DatasetName
event	O
,	O
the	O
second	O
stage	O
is	O
conducted	O
,	O
which	O
aims	O
to	O
assign	O
arguments	O
to	O
the	O
event	O
and	O
identify	O
their	O
corresponding	O
roles	O
.	O

The	O
first	O
stage	O
is	O
called	O
Event	O
Classification	O
,	O
which	O
aims	O
to	O
predict	O
whether	O
the	O
key	O
argument	O
candidates	O
participate	O
in	O
a	O
Freebase	B-DatasetName
event	O
.	O

In	O
this	O
paper	O
,	O
event	B-TaskName
extraction	I-TaskName
is	O
formulated	O
as	O
a	O
two	O
-	O
stage	O
,	O
multi	O
-	O
class	O
classification	O
task	O
.	O

Automatically	O
labeled	O
data	O
generation	O
.	O

And	O
we	O
use	O
nouns	O
with	O
high	O
confidence	O
in	O
the	O
mapped	O
frame	O
to	O
expand	O
trigger	O
lexicon	O
.	O

Finally	O
,	O
we	O
select	O
the	O
frame	O
contains	O
max	O
similarity	O
of	O
e	O
i	O
and	O
e	O
j	O
,	O
k	O
as	O
the	O
mapped	O
frame	O
,	O
which	O
can	O
be	O
formulated	O
as	O
follows	O
:	O
f	O
rame(i	O
)	O
=	O
arg	O
max	O
j	O
(	O
similarity(e	O
i	O
,	O
e	O
j	O
,	O
k	O
)	O
)	O
(	O
7	O
)	O
Then	O
,	O
we	O
filter	O
the	O
verb	O
,	O
which	O
is	O
in	O
initial	O
verbal	O
trigger	O
word	O
lexicon	O
and	O
not	O
in	O
the	O
mapping	O
frame	O
.	O

Specifically	O
,	O
we	O
use	O
the	O
average	O
word	O
embedding	O
of	O
all	O
words	O
in	O
i	O
-	O
th	O
Freebase	B-DatasetName
event	O
type	O
name	O
e	O
i	O
and	O
word	O
embedding	O
of	O
k	O
-	O
th	O
lexical	O
units	O
of	O
j	O
-	O
th	O
frame	O
e	O
j	O
,	O
k	O
to	O
compute	O
the	O
semantic	O
similarity	O
.	O

As	O
the	O
success	O
of	O
word	O
embedding	O
in	O
capturing	O
semantics	O
of	O
words	O
(	O
Turian	O
et	O
al	O
.	O
,	O
2010	O
)	O
,	O
we	O
employ	O
word	O
embedding	O
to	O
map	O
the	O
events	O
in	O
Freebase	B-DatasetName
to	O
frames	O
in	O
FrameNet	B-DatasetName
.	O

Thus	O
,	O
we	O
propose	O
to	O
use	O
linguistic	O
resource	O
FrameNet	B-DatasetName
to	O
filter	O
noisy	O
verbal	O
triggers	O
and	O
expand	O
nominal	O
triggers	O
.	O

Because	O
the	O
number	O
of	O
nouns	O
in	O
one	O
sentence	O
is	O
usually	O
larger	O
than	O
that	O
of	O
verbs	O
,	O
it	O
is	O
hard	O
to	O
use	O
TR	O
to	O
find	O
nominal	O
triggers	O
.	O

The	O
nominal	O
triggers	O
like	O
marriage	O
are	O
missing	O
.	O

However	O
,	O
this	O
initial	O
trigger	O
lexicon	O
is	O
noisy	O
and	O
merely	O
contains	O
verbal	O
triggers	O
.	O

We	O
can	O
obtain	O
an	O
initial	O
verbal	O
trigger	O
lexicon	O
by	O
above	O
trigger	O
word	O
detection	O
.	O

Trigger	O
Word	O
Filtering	O
and	O
Expansion	O
.	O

Intuitively	O
,	O
if	O
a	O
verb	O
occurs	O
more	O
times	O
than	O
other	O
verbs	O
in	O
the	O
labeled	O
sentences	O
of	O
one	O
event	O
type	O
,	O
the	O
verb	O
tends	O
to	O
trigger	O
this	O
type	O
of	O
event	O
;	O
and	O
if	O
a	O
verb	O
occurs	O
in	O
sentences	O
of	O
every	O
event	O
types	O
,	O
like	O
is	O
,	O
the	O
verb	O
will	O
have	O
a	O
low	O
probability	O
to	O
trigger	O
events	O
.	O

As	O
shown	O
in	O
Figure	O
1	O
,	O
threw	O
is	O
a	O
trigger	O
of	O
Attack	O
event	O
.	O

For	O
example	O
,	O
in	O
ACE	B-DatasetName
2005	I-DatasetName
English	O
data	O
,	O
there	O
are	O
60	O
%	O
of	O
events	O
triggered	O
by	O
verbs	O
.	O

In	O
a	O
sentence	O
,	O
a	O
verb	O
tend	O
to	O
express	O
an	O
occurrence	O
of	O
an	O
event	O
.	O

Then	O
we	O
use	O
these	O
labeled	O
sentences	O
to	O
detect	O
triggers	O
.	O

Finally	O
,	O
we	O
select	O
sentences	O
that	O
contains	O
all	O
key	O
arguments	O
of	O
an	O
event	O
instance	O
in	O
Freebase	B-DatasetName
as	O
sentences	O
expressing	O
corresponding	O
events	O
.	O

At	O
first	O
,	O
we	O
use	O
Standford	O
CoreNLP	O
tool	O
5	O
to	O
converts	O
the	O
raw	O
Wikipedia	O
texts	O
into	O
a	O
sequence	O
of	O
sentences	O
,	O
attaches	O
NLP	O
annotations	O
(	O
POS	O
tag	O
,	O
NER	O
tag	O
)	O
.	O

After	O
detecting	O
key	O
arguments	O
for	O
every	O
event	O
types	O
,	O
we	O
use	O
these	O
key	O
arguments	O
to	O
label	O
sentences	O
that	O
may	O
express	O
events	O
in	O
Wikipedia	O
.	O

Trigger	O
Word	O
Detection	O
.	O

Then	O
we	O
choose	O
top	O
K	O
arguments	O
as	O
key	O
arguments	O
.	O

If	O
an	O
argument	O
occurs	O
in	O
every	O
event	O
type	O
,	O
the	O
argument	O
will	O
have	O
a	O
low	O
event	O
relevance	O
.	O

If	O
we	O
tend	O
to	O
use	O
an	O
argument	O
to	O
distinguish	O
one	O
event	O
instance	O
form	O
other	O
instances	O
of	O
a	O
given	O
event	O
type	O
,	O
this	O
argument	O
will	O
play	O
a	O
salient	O
role	O
in	O
the	O
given	O
event	O
type	O
.	O

We	O
call	O
these	O
arguments	O
as	O
key	O
arguments	O
.	O

For	O
example	O
,	O
compared	O
with	O
arguments	O
like	O
time	O
,	O
location	O
and	O
so	O
on	O
,	O
spouses	O
are	O
key	O
arguments	O
in	O
a	O
marriage	O
event	O
.	O

Some	O
arguments	O
play	O
indispensable	O
roles	O
in	O
an	O
event	O
,	O
and	O
serve	O
as	O
vital	O
clues	O
when	O
distinguishing	O
different	O
events	O
.	O

Intuitively	O
,	O
arguments	O
of	O
a	O
type	O
of	O
event	O
play	O
different	O
roles	O
.	O

This	O
section	O
illustrates	O
how	O
to	O
detect	O
key	O
arguments	O
for	O
each	O
event	O
type	O
via	O
Freebase	B-DatasetName
.	O

Key	O
Argument	O
Detection	O
.	O

Method	O
of	O
Generating	O
Training	O
Data	O
.	O

tection	O
,	O
which	O
prioritizes	O
arguments	O
of	O
each	O
event	O
type	O
and	O
selects	O
key	O
arguments	O
for	O
each	O
type	O
of	O
event	O
;	O
(	O
ii	O
)	O
Trigger	O
word	O
detection	O
,	O
which	O
uses	O
key	O
arguments	O
to	O
label	O
sentences	O
that	O
may	O
express	O
events	O
preliminarily	O
,	O
and	O
then	O
detect	O
triggers	O
;	O
(	O
iii	O
)	O
Trigger	O
word	O
filtering	O
and	O
expansion	O
,	O
which	O
uses	O
FrameNet	B-DatasetName
to	O
filter	O
noisy	O
triggers	O
and	O
expand	O
triggers	O
;	O
(	O
iv	O
)	O
Automatically	O
labeled	O
data	O
generation	O
,	O
which	O
uses	O
a	O
SDS	O
to	O
label	O
events	O
in	O
sentences	O
.	O

We	O
use	O
Wikipedia	O
because	O
it	O
is	O
relatively	O
up	O
-	O
to	O
-	O
date	O
,	O
and	O
much	O
of	O
the	O
information	O
in	O
Freebase	B-DatasetName
is	O
derived	O
from	O
Wikipedia	O
.	O

All	O
6.3	O
million	O
articles	O
in	O
it	O
are	O
used	O
in	O
our	O
experiments	O
.	O

Wikipedia	O
4	O
that	O
we	O
used	O
was	O
released	O
on	O
January	O
,	O
2016	O
.	O

Thus	O
we	O
use	O
FrameNet	B-DatasetName
to	O
detect	O
triggers	O
in	O
our	O
automatically	O
data	O
labeling	O
process	O
.	O

And	O
a	O
LUs	O
of	O
the	O
frame	O
plays	O
a	O
similar	O
role	O
as	O
the	O
trigger	O
of	O
an	O
event	O
.	O

Each	O
frame	O
of	O
FrameNet	B-DatasetName
can	O
be	O
taken	O
as	O
a	O
semantic	O
frame	O
of	O
a	O
type	O
of	O
events	O
(	O
Liu	O
et	O
al	O
.	O
,	O
2016	O
)	O
.	O

FrameNet	B-DatasetName
contains	O
more	O
than	O
1	O
,	O
000	O
frames	O
and	O
10	O
,	O
000	O
Lexical	O
Units	O
(	O
LUs	O
)	O
.	O

After	O
filtering	O
out	O
useless	O
and	O
meaningless	O
CVTs	O
,	O
such	O
as	O
CVTs	O
about	O
user	O
profiles	O
and	O
website	O
information	O
,	O
we	O
select	O
21	O
types	O
of	O
CVTs	O
with	O
around	O
3.8	O
million	O
instances	O
for	O
experiments	O
,	O
which	O
mainly	O
involves	O
events	O
about	O
education	O
,	O
military	O
,	O
sports	O
and	O
so	O
on	O
.	O

In	O
this	O
paper	O
,	O
we	O
regard	O
these	O
CVTs	O
as	O
events	O
,	O
type	O
of	O
CVTs	O
as	O
event	O
type	O
,	O
CVT	O
instances	O
as	O
event	O
instances	O
,	O
values	O
in	O
CVTs	O
as	O
arguments	O
in	O
events	O
and	O
roles	O
of	O
CVTs	O
as	O
the	O
roles	O
of	O
arguments	O
play	O
in	O
the	O
event	O
,	O
respectively	O
.	O

Spouse	O
,	O
from	O
,	O
to	O
and	O
location	O
of	O
ceremony	O
are	O
roles	O
of	O
the	O
people.marriage	O
CVTs	O
.	O
Barack	O
Obama	O
,	O
Michelle	O
Obama	O
,	O
10/3/1992	O
and	O
Trinity	O
United	O
Church	O
of	O
Christ	O
are	O
the	O
values	O
of	O
the	O
instances	O
.	O

As	O
shown	O
in	O
Figure	O
3	O
,	O
people.marriage	O
is	O
one	O
type	O
of	O
CVTs	O
.	O
There	O
are	O
many	O
instances	O
of	O
people.marriage	O
and	O
the	O
marriage	O
of	O
Barack	O
Obama	O
and	O
Michelle	O
Obama	O
is	O
numbered	O
as	O
m.02nqglv	O
.	O

To	O
understand	O
our	O
method	O
easily	O
,	O
we	O
first	O
introduce	O
them	O
as	O
follows	O
:	O
Freebase	B-DatasetName
is	O
a	O
semantic	O
knowledge	O
base	O
(	O
Bollacker	O
et	O
al	O
.	O
,	O
2008	O
)	O
,	O
which	O
makes	O
use	O
of	O
mediators	O
(	O
also	O
called	O
compound	O
value	O
types	O
,	O
CVTs	O
)	O
to	O
merge	O
multiple	O
values	O
into	O
a	O
single	O
value	O
.	O

The	O
articles	O
in	O
Wikipedia	O
are	O
used	O
as	O
unstructured	O
texts	O
to	O
be	O
labeled	O
.	O

In	O
this	O
paper	O
,	O
we	O
respectively	O
use	O
Freebase	B-DatasetName
as	O
our	O
world	O
knowledge	O
containing	O
event	O
instance	O
and	O
FrameNet	B-DatasetName
as	O
the	O
linguistic	O
knowledge	O
containing	O
trigger	O
information	O
.	O

Background	O
.	O

Also	O
,	O
our	O
automatically	O
labeled	O
data	O
can	O
augment	O
traditional	O
humanannotated	O
data	O
,	O
which	O
could	O
significantly	O
improve	O
the	O
extraction	O
performance	O
.	O

•	O
The	O
experimental	O
results	O
show	O
that	O
the	O
quality	O
of	O
our	O
large	O
scale	O
automatically	O
labeled	O
data	O
is	O
competitive	O
with	O
elaborately	O
humanannotated	O
data	O
.	O

Moreover	O
,	O
we	O
employ	O
FrameNet	B-DatasetName
to	O
filter	O
noisy	O
triggers	O
and	O
expand	O
more	O
triggers	O
.	O

•	O
We	O
propose	O
an	O
approach	O
to	O
figure	O
out	O
key	O
arguments	O
of	O
an	O
event	O
by	O
using	O
Freebase	B-DatasetName
,	O
and	O
use	O
them	O
to	O
automatically	O
detect	O
events	O
and	O
corresponding	O
trigger	O
words	O
.	O

All	O
the	O
labeled	O
data	O
in	O
this	O
paper	O
have	O
been	O
released	O
and	O
can	O
be	O
downloaded	O
freely	O
2	O
.	O

In	O
summary	O
,	O
the	O
contributions	O
of	O
this	O
paper	O
are	O
as	O
follows	O
:	O
•	O
To	O
our	O
knowledge	O
,	O
it	O
is	O
the	O
first	O
work	O
to	O
automatically	O
label	O
data	O
for	O
large	O
scale	O
EE	B-TaskName
via	O
world	O
knowledge	O
and	O
linguistic	O
knowledge	O
.	O

In	O
addition	O
,	O
we	O
employ	O
a	O
CNNbased	O
EE	B-TaskName
approach	O
with	O
multi	O
-	O
instance	O
learning	O
for	O
the	O
automatically	O
labeled	O
data	O
as	O
a	O
baseline	O
for	O
further	O
research	O
on	O
this	O
data	O
.	O

Finally	O
,	O
we	O
evaluate	O
the	O
quality	O
of	O
the	O
automatically	O
labeled	O
training	O
data	O
by	O
both	O
manual	O
and	O
automatic	O
evaluations	O
.	O

At	O
first	O
,	O
we	O
put	O
forward	O
an	O
approach	O
to	O
prioritize	O
arguments	O
and	O
select	O
key	O
or	O
representative	O
arguments	O
(	O
see	O
details	O
in	O
Section	O
3.1	O
)	O
for	O
each	O
event	O
type	O
by	O
using	O
Freebase	B-DatasetName
;	O
Secondly	O
,	O
we	O
merely	O
use	O
key	O
arguments	O
to	O
label	O
events	O
and	O
figure	O
out	O
trigger	O
words	O
;	O
Thirdly	O
,	O
an	O
external	O
linguistic	O
knowledge	O
resource	O
,	O
FrameNet	B-DatasetName
,	O
is	O
employed	O
to	O
filter	O
noisy	O
trigger	O
words	O
and	O
expand	O
more	O
triggers	O
;	O
After	O
that	O
,	O
we	O
propose	O
a	O
Soft	O
Distant	O
Supervision	O
(	O
SDS	O
)	O
for	O
EE	B-TaskName
to	O
automatically	O
label	O
training	O
data	O
,	O
which	O
assumes	O
that	O
any	O
sentence	O
containing	O
all	O
key	O
arguments	O
in	O
Freebase	B-DatasetName
and	O
a	O
corresponding	O
trigger	O
word	O
is	O
likely	O
to	O
express	O
that	O
event	O
in	O
some	O
way	O
,	O
and	O
arguments	O
occurring	O
in	O
that	O
sentence	O
are	O
likely	O
to	O
play	O
the	O
corresponding	O
roles	O
in	O
that	O
event	O
.	O

As	O
shown	O
in	O
To	O
solve	O
above	O
problems	O
,	O
we	O
propose	O
an	O
approach	O
to	O
automatically	O
generate	O
labeled	O
data	O
for	O
large	O
scale	O
EE	B-TaskName
by	O
jointly	O
using	O
world	O
knowledge	O
(	O
Freebase	B-DatasetName
)	O
and	O
linguistic	O
knowledge	O
(	O
FrameNet	B-DatasetName
)	O
.	O

Simply	O
employing	O
all	O
arguments	O
in	O
the	O
knowledge	O
base	O
to	O
label	O
back	O
in	O
sentences	O
will	O
generate	O
few	O
sentences	O
as	O
training	O
samples	O
.	O

However	O
,	O
arguments	O
for	O
a	O
specific	O
event	O
instance	O
are	O
usually	O
mentioned	O
in	O
multiple	O
sentences	O
.	O

Following	O
DS	O
in	O
RE	B-TaskName
,	O
we	O
could	O
naturally	O
assume	O
that	O
a	O
sentence	O
contains	O
all	O
arguments	O
of	O
an	O
event	O
in	O
the	O
knowledge	O
base	O
tend	O
to	O
express	O
that	O
event	O
,	O
and	O
the	O
verbs	O
occur	O
in	O
these	O
sentences	O
tend	O
to	O
evoke	O
this	O
type	O
of	O
events	O
.	O

To	O
resolve	O
the	O
trigger	O
missing	O
problem	O
mentioned	O
above	O
,	O
we	O
need	O
to	O
discover	O
trigger	O
words	O
before	O
employing	O
distant	O
supervision	O
to	O
automatically	O
label	O
event	O
arguments	O
.	O

Unfortunately	O
,	O
triggers	O
are	O
not	O
given	O
out	O
in	O
existing	O
knowledge	O
bases	O
.	O

Following	O
ACE	B-DatasetName
,	O
we	O
can	O
use	O
trigger	O
words	O
to	O
represent	O
event	O
instance	O
,	O
like	O
married	O
for	O
people.marriage	O
event	O
instance	O
.	O

In	O
ACE	B-DatasetName
event	O
extraction	O
program	O
,	O
an	O
event	O
instance	O
is	O
represented	O
as	O
a	O
trigger	O
word	O
,	O
which	O
is	O
the	O
main	O
word	O
that	O
most	O
clearly	O
represents	O
an	O
event	O
occurrence	O
in	O
sentences	O
,	O
like	O
threw	O
in	O
Figure	O
1	O
.	O

Thus	O
we	O
can	O
not	O
directly	O
use	O
an	O
event	O
instance	O
and	O
an	O
argument	O
,	O
like	O
m.02nqglv	O
and	O
Barack	O
Obama	O
,	O
to	O
label	O
back	O
in	O
sentences	O
.	O

For	O
example	O
,	O
in	O
Freebase	B-DatasetName
,	O
the	O
aforementioned	O
marriage	O
event	O
instance	O
is	O
represented	O
as	O
m.02nqglv	O
(	O
see	O
details	O
in	O
Section	O
2	O
)	O
.	O

However	O
,	O
an	O
event	O
instance	O
is	O
a	O
virtual	O
node	O
in	O
existing	O
knowledge	O
bases	O
and	O
mentioned	O
implicitly	O
in	O
texts	O
.	O

It	O
seems	O
that	O
we	O
could	O
use	O
an	O
event	O
instance	O
and	O
an	O
argument	O
to	O
automatically	O
generate	O
training	O
data	O
for	O
argument	O
identification	O
just	O
like	O
DS	O
for	O
RE	B-TaskName
.	O

For	O
example	O
,	O
Barack	O
Obama	O
plays	O
a	O
Spouse	O
role	O
in	O
this	O
marriage	O
event	O
instance	O
.	O

DS	O
for	O
RE	B-TaskName
uses	O
two	O
entities	O
to	O
automatically	O
label	O
training	O
data	O
;	O
In	O
comparison	O
,	O
the	O
left	O
part	O
in	O
Figure	O
3	O
shows	O
a	O
marriage	O
event	O
of	O
Barack	O
Obama	O
and	O
M	O
ichelle	O
Obama	O
,	O
where	O
the	O
dash	O
circle	O
represents	O
the	O
marriage	O
event	O
instance	O
of	O
Barack	O
Obama	O
and	O
M	O
ichelle	O
Obama	O
,	O
rectangles	O
represent	O
arguments	O
of	O
the	O
event	O
instance	O
,	O
and	O
each	O
edge	O
connecting	O
an	O
argument	O
and	O
the	O
event	O
instance	O
expresses	O
the	O
role	O
of	O
the	O
argument	O
.	O

In	O
Figure	O
3	O
,	O
the	O
right	O
part	O
shows	O
an	O
example	O
of	O
spouse	O
of	O
relation	O
between	O
Barack	O
Obama	O
and	O
M	O
ichelle	O
Obama	O
,	O
where	O
two	O
rectangles	O
represent	O
two	O
entities	O
and	O
the	O
edge	O
connecting	O
them	O
represents	O
their	O
relation	O
.	O

EE	B-TaskName
aims	O
to	O
detect	O
an	O
event	O
instance	O
of	O
a	O
specific	O
type	O
and	O
extract	O
their	O
arguments	O
and	O
roles	O
,	O
formulated	O
as	O
(	O
event	O
instance	O
,	O
event	O
type	O
;	O
role	O
1	O
,	O
argument	O
1	O
;	O
role	O
2	O
,	O
argument	O
2	O
;	O
...	O
;	O
role	O
n	O
,	O
argument	O
n	O
)	O
,	O
which	O
can	O
be	O
regarded	O
as	O
a	O
kind	O
of	O
multiple	O
or	O
complicated	O
relational	O
data	O
.	O

However	O
,	O
when	O
we	O
use	O
DS	O
for	O
RE	B-TaskName
to	O
EE	B-TaskName
,	O
we	O
meet	O
following	O
challenges	O
:	O
Triggers	O
are	O
not	O
given	O
out	O
in	O
existing	O
knowledge	O
bases	O
.	O

And	O
DS	O
for	O
RE	B-TaskName
assumes	O
that	O
if	O
two	O
entities	O
have	O
a	O
relationship	O
in	O
a	O
known	O
knowledge	O
base	O
,	O
then	O
all	O
sentences	O
that	O
mention	O
these	O
two	O
entities	O
will	O
express	O
that	O
relationship	O
in	O
some	O
way	O
(	O
Mintz	O
et	O
al	O
.	O
,	O
2009	O
)	O
.	O

Recent	O
improvements	O
of	O
Distant	O
Supervision	O
(	O
DS	O
)	O
have	O
been	O
proven	O
to	O
be	O
effective	O
to	O
label	O
training	O
data	O
for	O
Relation	B-TaskName
Extraction	I-TaskName
(	O
RE	B-TaskName
)	O
,	O
which	O
aims	O
to	O
predict	O
semantic	O
re-	O
lations	O
between	O
pairs	O
of	O
entities	O
,	O
formulated	O
as	O
(	O
entity	O
1	O
,	O
relation	O
,	O
entity	O
2	O
)	O
.	O

Figure	O
1	O
shows	O
an	O
example	O
of	O
labeled	O
sentence	O
.	O

This	O
paper	O
aims	O
to	O
automatically	O
generate	O
training	O
data	O
for	O
EE	B-TaskName
,	O
which	O
involves	O
labeling	O
triggers	O
,	O
event	O
types	O
,	O
arguments	O
and	O
their	O
roles	O
.	O

Person	O
Time	O
Therefore	O
,	O
for	O
extracting	O
large	O
scale	O
events	O
,	O
especially	O
in	O
open	O
domain	O
scenarios	O
,	O
how	O
to	O
automatically	O
and	O
efficiently	O
generate	O
sufficient	O
training	O
data	O
is	O
an	O
important	O
problem	O
.	O

Marry	O
Person	O
.	O

Moreover	O
,	O
those	O
predefined	O
33	O
event	O
types	O
are	O
in	O
low	O
coverage	O
for	O
Natural	O
Language	O
Processing	O
(	O
NLP	O
)	O
applications	O
on	O
large	O
-	O
scale	O
data	O
.	O

As	O
Figure	O
2	O
shown	O
,	O
nearly	O
60	O
%	O
of	O
event	O
types	O
in	O
ACE	B-DatasetName
2005	I-DatasetName
have	O
less	O
than	O
100	O
labeled	O
samples	O
and	O
there	O
are	O
even	O
three	O
event	O
types	O
which	O
have	O
less	O
than	O
ten	O
labeled	O
samples	O
.	O

In	O
ACE	B-DatasetName
2005	I-DatasetName
,	O
all	O
33	O
event	O
types	O
are	O
manually	O
predefined	O
and	O
the	O
corresponding	O
event	O
information	O
(	O
including	O
triggers	O
,	O
event	O
types	O
,	O
arguments	O
and	O
their	O
roles	O
)	O
are	O
manually	O
annotated	O
only	O
in	O
599	O
English	O
documents	O
since	O
the	O
annotation	O
process	O
is	O
extremely	O
expensive	O
.	O

Although	O
this	O
paradigm	O
was	O
widely	O
studied	O
,	O
existing	O
approaches	O
still	O
suffer	O
from	O
high	O
costs	O
for	O
manually	O
labeling	O
training	O
data	O
and	O
low	O
coverage	O
of	O
predefined	O
event	O
types	O
.	O

2016	O
;	O
Chen	O
et	O
al	O
.	O
,	O
2015;Li	O
et	O
al	O
.	O
,	O
2014;Hong	O
et	O
al	O
.	O
,	O
2011;Ji	O
and	O
Grishman	O
,	O
2008	O
)	O
usually	O
adopted	O
supervised	O
learning	O
paradigm	O
which	O
relies	O
on	O
elaborate	O
human	O
-	O
annotated	O
data	O
,	O
such	O
as	O
ACE	B-DatasetName
2005	I-DatasetName
1	O
,	O
to	O
train	O
extractors	O
.	O

To	O
this	O
end	O
,	O
so	O
far	O
most	O
methods	O
(	O
Nguyen	O
et	O
al	O
.	O
,	O
Mi	O
chel	O
l	O
e	O
Obama	O
and	O
Barack	O
Obama	O
were	O
on	O
October	O
3	O
,	O
1992	O
.	O

For	O
example	O
,	O
in	O
the	O
sentence	O
shown	O
in	O
Figure	O
1	O
,	O
an	O
EE	B-TaskName
system	O
is	O
expected	O
to	O
identify	O
an	O
Attack	O
event	O
triggered	O
by	O
threw	O
and	O
extract	O
the	O
corresponding	O
five	O
augments	O
with	O
different	O
roles	O
:	O
Yesterday	O
(	O
Role	O
=	O
Time	O
)	O
,	O
demonstrators	O
(	O
Role	O
=	O
Attacker	O
)	O
,	O
stones	O
(	O
Role	O
=	O
Instrument	O
)	O
,	O
soldiers	O
(	O
Role	O
=	O
Target	O
)	O
,	O
and	O
Israeli	O
(	O
Role	O
=	O
Place	O
)	O
.	O

Event	B-TaskName
Extraction	I-TaskName
(	O
EE	B-TaskName
)	O
,	O
a	O
challenging	O
task	O
in	O
Information	O
Extraction	O
,	O
aims	O
at	O
detecting	O
and	O
typing	O
events	O
(	O
Event	O
Detection	O
)	O
,	O
and	O
extracting	O
arguments	O
with	O
different	O
roles	O
(	O
Argument	O
Identification	O
)	O
from	O
natural	O
-	O
language	O
texts	O
.	O

Introduction	O
.	O

And	O
our	O
automatically	O
labeled	O
data	O
can	O
incorporate	O
with	O
human	O
-	O
labeled	O
data	O
,	O
then	O
improve	O
the	O
performance	O
of	O
models	O
learned	O
from	O
these	O
data	O
.	O

The	O
experimental	O
results	O
show	O
that	O
the	O
quality	O
of	O
our	O
large	O
scale	O
automatically	O
labeled	O
data	O
is	O
competitive	O
with	O
elaborately	O
human	O
-	O
labeled	O
data	O
.	O

However	O
,	O
hand	O
-	O
labeled	O
training	O
data	O
is	O
expensive	O
to	O
produce	O
,	O
in	O
low	O
coverage	O
of	O
event	O
types	O
,	O
and	O
limited	O
in	O
size	O
,	O
which	O
makes	O
supervised	O
methods	O
hard	O
to	O
extract	O
large	O
scale	O
of	O
events	O
for	O
knowledge	O
base	O
population	O
.	O

Modern	O
models	O
of	O
event	B-TaskName
extraction	I-TaskName
for	O
tasks	O
like	O
ACE	B-DatasetName
are	O
based	O
on	O
supervised	O
learning	O
of	O
events	O
from	O
small	O
hand	O
-	O
labeled	O
data	O
.	O

Automatically	O
Labeled	O
Data	O
Generation	O
for	O
Large	O
Scale	O
Event	B-TaskName
Extraction	I-TaskName
.	O

It	O
demonstrates	O
the	O
effectiveness	O
of	O
our	O
TR	O
methods	O
.	O

Then	O
we	O
generate	O
initial	O
trigger	O
lexicon	O
by	O
using	O
all	O
trigger	O
candidates	O
with	O
high	O
TCF	O
value	O
,	O
TETF	O
value	O
or	O
TR	O
value	O
.	O

Then	O
we	O
automatically	O
evaluate	O
the	O
performance	O
by	O
using	O
automatic	O
evaluations	O
proposed	O
above	O
.	O

Following	O
(	O
Nguyen	O
et	O
al	O
.	O
,	O
2016;Chen	O
et	O
al	O
.	O
,	O
2015;Li	O
et	O
al	O
.	O
,	O
2013	O
)	O
,	O
we	O
used	O
the	O
same	O
test	O
set	O
with	O
40	O
newswire	O
articles	O
and	O
the	O
same	O
development	O
set	O
with	O
30	O
documents	O
and	O
the	O
rest	O
529	O
documents	O
are	O
used	O
for	O
ACE	O
training	O
set	O
.	O

