-DOCSTART- -X- O
The -X- _ O
advantage -X- _ O
of -X- _ O
this -X- _ O
procedure -X- _ O
is -X- _ O
that -X- _ O
the -X- _ O
Transformer -X- _ O
encoder -X- _ O
does -X- _ O
not -X- _ O
know -X- _ O
which -X- _ O
words -X- _ O
it -X- _ O
will -X- _ O
be -X- _ O
asked -X- _ O
to -X- _ O
predict -X- _ O
or -X- _ O
which -X- _ O
have -X- _ O
been -X- _ O
replaced -X- _ O
by -X- _ O
random -X- _ O
words -X- _ O
, -X- _ O
so -X- _ O
it -X- _ O
is -X- _ O
forced -X- _ O
to -X- _ O
keep -X- _ O
a -X- _ O
distributional -X- _ O
contextual -X- _ O
representation -X- _ O
of -X- _ O
every -X- _ O
input -X- _ O
token -X- _ O
. -X- _ O

The -X- _ O
numbers -X- _ O
in -X- _ O
the -X- _ O
left -X- _ O
part -X- _ O
of -X- _ O
the -X- _ O
table -X- _ O
represent -X- _ O
the -X- _ O
probabilities -X- _ O
of -X- _ O
the -X- _ O
specific -X- _ O
strategies -X- _ O
used -X- _ O
during -X- _ O
MLM -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
( -X- _ O
BERT -X- _ B-MethodName
uses -X- _ O
80 -X- _ B-HyperparameterValue
% -X- _ I-HyperparameterValue
, -X- _ O
10 -X- _ B-HyperparameterValue
% -X- _ I-HyperparameterValue
, -X- _ O
10 -X- _ B-HyperparameterValue
% -X- _ I-HyperparameterValue
) -X- _ O
. -X- _ O

The -X- _ O
GLUE -X- _ B-DatasetName
webpage -X- _ O
notes -X- _ O
that -X- _ O
there -X- _ O
are -X- _ O
issues -X- _ O
with -X- _ O
the -X- _ O
construction -X- _ O
of -X- _ O
this -X- _ O
dataset -X- _ O
, -X- _ O
15 -X- _ O
and -X- _ O
every -X- _ O
trained -X- _ O
system -X- _ O
that -X- _ O
's -X- _ O
been -X- _ O
submitted -X- _ O
to -X- _ O
GLUE -X- _ B-DatasetName
has -X- _ O
performed -X- _ O
worse -X- _ O
than -X- _ O
the -X- _ O
65.1 -X- _ B-MetricValue
baseline -X- _ O
accuracy -X- _ B-MetricName
of -X- _ O
predicting -X- _ O
the -X- _ O
majority -X- _ O
class -X- _ O
. -X- _ O

We -X- _ O
therefore -X- _ O
exclude -X- _ O
this -X- _ O
set -X- _ O
to -X- _ O
be -X- _ O
fair -X- _ O
to -X- _ O
OpenAI -X- _ B-MethodName
GPT -X- _ I-MethodName
. -X- _ O

CoLA -X- _ B-DatasetName
The -X- _ O
Corpus -X- _ B-DatasetName
of -X- _ I-DatasetName
Linguistic -X- _ I-DatasetName
Acceptability -X- _ I-DatasetName
is -X- _ O
a -X- _ O
binary -X- _ B-TaskName
single -X- _ I-TaskName
- -X- _ I-TaskName
sentence -X- _ I-TaskName
classification -X- _ I-TaskName
task -X- _ O
, -X- _ O
where -X- _ O
the -X- _ O
goal -X- _ O
is -X- _ O
to -X- _ O
predict -X- _ O
whether -X- _ O
an -X- _ O
English -X- _ O
sentence -X- _ O
is -X- _ O
linguistically -X- _ O
" -X- _ O
acceptable -X- _ O
" -X- _ O
or -X- _ O
not -X- _ O
( -X- _ O
Warstadt -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O

BERT -X- _ B-MethodName
Tok -X- _ O
1 -X- _ O
Tok -X- _ O
2 -X- _ O
Tok -X- _ O
N -X- _ O
... -X- _ O

Tok -X- _ O
M -X- _ O
Question -X- _ O
Paragraph -X- _ O
BERT -X- _ B-MethodName
E -X- _ O
[ -X- _ O
CLS -X- _ O
] -X- _ O
E -X- _ O
1 -X- _ O
E -X- _ O
2 -X- _ O
E -X- _ O
N -X- _ O
C -X- _ O
T -X- _ O
1 -X- _ O
T -X- _ O
2 -X- _ O
T -X- _ O
N -X- _ O
Single -X- _ O
Sentence -X- _ O
... -X- _ O

QQP -X- _ B-DatasetName
Quora -X- _ B-DatasetName
Question -X- _ I-DatasetName
Pairs -X- _ I-DatasetName
is -X- _ O
a -X- _ O
binary -X- _ B-TaskName
classification -X- _ I-TaskName
task -X- _ O
where -X- _ O
the -X- _ O
goal -X- _ O
is -X- _ O
to -X- _ O
determine -X- _ O
if -X- _ O
two -X- _ O
questions -X- _ O
asked -X- _ O
on -X- _ O
Quora -X- _ O
are -X- _ O
semantically -X- _ O
equivalent -X- _ O
( -X- _ O
Chen -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O

( -X- _ O
2018a -X- _ O
): -X- _ O
MNLI -X- _ B-DatasetName
Multi -X- _ B-DatasetName
- -X- _ I-DatasetName
Genre -X- _ I-DatasetName
Natural -X- _ I-DatasetName
Language -X- _ I-DatasetName
Inference -X- _ I-DatasetName
is -X- _ O
a -X- _ O
large -X- _ O
- -X- _ O
scale -X- _ O
, -X- _ O
crowdsourced -X- _ O
entailment -X- _ B-TaskName
classification -X- _ I-TaskName
task -X- _ O
( -X- _ O
Williams -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O

• -X- _ O
GPT -X- _ B-MethodName
was -X- _ O
trained -X- _ O
for -X- _ O
1 -X- _ B-HyperparameterValue
M -X- _ I-HyperparameterValue
steps -X- _ B-HyperparameterName
with -X- _ O
a -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
of -X- _ O
32,000 -X- _ B-HyperparameterValue
words -X- _ I-HyperparameterValue
; -X- _ O
BERT -X- _ B-MethodName
was -X- _ O
trained -X- _ O
for -X- _ O
1 -X- _ B-HyperparameterValue
M -X- _ I-HyperparameterValue
steps -X- _ B-HyperparameterName
with -X- _ O
a -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
of -X- _ O
128,000 -X- _ B-HyperparameterValue
words -X- _ I-HyperparameterValue
. -X- _ O

6 -X- _ O
he -X- _ O
likes -X- _ O
play -X- _ O
# -X- _ O
# -X- _ O
ing -X- _ O
[ -X- _ O
SEP -X- _ O
] -X- _ O
my -X- _ O
dog -X- _ O
is -X- _ O
cute -X- _ O
[ -X- _ O
SEP -X- _ O
] -X- _ O
Input -X- _ O
E -X- _ O
[ -X- _ O
CLS -X- _ O
] -X- _ O
E -X- _ O
he -X- _ O
E -X- _ O
likes -X- _ O
E -X- _ O
play -X- _ O
E -X- _ O
# -X- _ O
# -X- _ O
ing -X- _ O
E -X- _ O
[ -X- _ O
SEP -X- _ O
] -X- _ O
E -X- _ O
my -X- _ O
E -X- _ O
dog -X- _ O
E -X- _ O
is -X- _ O
E -X- _ O
cute -X- _ O
E -X- _ O
[ -X- _ O
SEP -X- _ O
] -X- _ O
Token -X- _ O
Embeddings -X- _ O
E -X- _ O
A -X- _ O
E -X- _ O
B -X- _ O
E -X- _ O
B -X- _ O
E -X- _ O
B -X- _ O
E -X- _ O
B -X- _ O
E -X- _ O
B -X- _ O
E -X- _ O
A -X- _ O
E -X- _ O
A -X- _ O
E -X- _ O
A -X- _ O
E -X- _ O
A -X- _ O
E -X- _ O
A -X- _ O
Segment -X- _ O
Embeddings -X- _ O
E -X- _ O
0 -X- _ O
E -X- _ O
6 -X- _ O
E -X- _ O
7 -X- _ O
E -X- _ O
8 -X- _ O
E -X- _ O
9 -X- _ O
E -X- _ O
10 -X- _ O
E -X- _ O
1 -X- _ O
E -X- _ O
2 -X- _ O
E -X- _ O
3 -X- _ O
E -X- _ O
4 -X- _ O
E -X- _ O
5 -X- _ O
Position -X- _ O
Embeddings -X- _ O
The -X- _ O
NSP -X- _ O
task -X- _ O
is -X- _ O
closely -X- _ O
related -X- _ O
to -X- _ O
representationlearning -X- _ O
objectives -X- _ O
used -X- _ O
in -X- _ O
Jernite -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

As -X- _ O
we -X- _ O
show -X- _ O
in -X- _ O
Figure -X- _ O
1 -X- _ O
, -X- _ O
C -X- _ O
is -X- _ O
used -X- _ O
for -X- _ O
next -X- _ O
sentence -X- _ O
prediction -X- _ O
( -X- _ O
NSP -X- _ O
) -X- _ O
. -X- _ O

We -X- _ O
compare -X- _ O
variations -X- _ O
of -X- _ O
this -X- _ O
procedure -X- _ O
in -X- _ O
Appendix -X- _ O
C.2 -X- _ O
. -X- _ O
Task -X- _ O
# -X- _ O
2 -X- _ O
: -X- _ O
Next -X- _ O
Sentence -X- _ O
Prediction -X- _ O
( -X- _ O
NSP -X- _ O
) -X- _ O
Many -X- _ O
important -X- _ O
downstream -X- _ O
tasks -X- _ O
such -X- _ O
as -X- _ O
Question -X- _ B-TaskName
Answering -X- _ I-TaskName
( -X- _ O
QA -X- _ B-TaskName
) -X- _ O
and -X- _ O
Natural -X- _ B-TaskName
Language -X- _ I-TaskName
Inference -X- _ I-TaskName
( -X- _ O
NLI -X- _ B-TaskName
) -X- _ O
are -X- _ O
based -X- _ O
on -X- _ O
understanding -X- _ O
the -X- _ O
relationship -X- _ O
between -X- _ O
two -X- _ O
sentences -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
not -X- _ O
directly -X- _ O
captured -X- _ O
by -X- _ O
language -X- _ O
modeling -X- _ O
. -X- _ O

We -X- _ O
refer -X- _ O
to -X- _ O
this -X- _ O
procedure -X- _ O
as -X- _ O
a -X- _ O
" -X- _ O
masked -X- _ O
LM -X- _ O
" -X- _ O
( -X- _ O
MLM -X- _ O
) -X- _ O
, -X- _ O
although -X- _ O
it -X- _ O
is -X- _ O
often -X- _ O
referred -X- _ O
to -X- _ O
as -X- _ O
a -X- _ O
Cloze -X- _ O
task -X- _ O
in -X- _ O
the -X- _ O
literature -X- _ O
( -X- _ O
Taylor -X- _ O
, -X- _ O
1953 -X- _ O
) -X- _ O
. -X- _ O

Task -X- _ O
# -X- _ O
1 -X- _ O
: -X- _ O
Masked -X- _ O
LM -X- _ O
Intuitively -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
reasonable -X- _ O
to -X- _ O
believe -X- _ O
that -X- _ O
a -X- _ O
deep -X- _ O
bidirectional -X- _ O
model -X- _ O
is -X- _ O
strictly -X- _ O
more -X- _ O
powerful -X- _ O
than -X- _ O
either -X- _ O
a -X- _ O
left -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
right -X- _ O
model -X- _ O
or -X- _ O
the -X- _ O
shallow -X- _ O
concatenation -X- _ O
of -X- _ O
a -X- _ O
left -X- _ O
- -X- _ O
toright -X- _ O
and -X- _ O
a -X- _ O
right -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
left -X- _ O
model -X- _ O
. -X- _ O

1 -X- _ O
Because -X- _ O
the -X- _ O
use -X- _ O
of -X- _ O
Transformers -X- _ O
has -X- _ O
become -X- _ O
common -X- _ O
and -X- _ O
our -X- _ O
implementation -X- _ O
is -X- _ O
almost -X- _ O
identical -X- _ O
to -X- _ O
the -X- _ O
original -X- _ O
, -X- _ O
we -X- _ O
will -X- _ O
omit -X- _ O
an -X- _ O
exhaustive -X- _ O
background -X- _ O
description -X- _ O
of -X- _ O
the -X- _ O
model -X- _ O
architecture -X- _ O
and -X- _ O
refer -X- _ O
readers -X- _ O
to -X- _ O
Vaswani -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

Model -X- _ O
Architecture -X- _ O
BERT -X- _ B-MethodName
's -X- _ O
model -X- _ O
architecture -X- _ O
is -X- _ O
a -X- _ O
multi -X- _ O
- -X- _ O
layer -X- _ O
bidirectional -X- _ O
Transformer -X- _ O
encoder -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
original -X- _ O
implementation -X- _ O
described -X- _ O
in -X- _ O
Vaswani -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

More -X- _ O
recently -X- _ O
, -X- _ O
sentence -X- _ O
or -X- _ O
document -X- _ O
encoders -X- _ O
which -X- _ O
produce -X- _ O
contextual -X- _ O
token -X- _ O
representations -X- _ O
have -X- _ O
been -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
from -X- _ O
unlabeled -X- _ O
text -X- _ O
and -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
for -X- _ O
a -X- _ O
supervised -X- _ O
downstream -X- _ O
task -X- _ O
( -X- _ O
Dai -X- _ O
and -X- _ O
Le -X- _ O
, -X- _ O
2015;Howard -X- _ O
and -X- _ O
Ruder -X- _ O
, -X- _ O
2018;Radford -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O

( -X- _ O
2018 -X- _ O
) -X- _ O
shows -X- _ O
that -X- _ O
the -X- _ O
cloze -X- _ O
task -X- _ O
can -X- _ O
be -X- _ O
used -X- _ O
to -X- _ O
improve -X- _ O
the -X- _ O
robustness -X- _ O
of -X- _ O
text -X- _ O
generation -X- _ O
models -X- _ O
. -X- _ O

To -X- _ O
train -X- _ O
sentence -X- _ O
representations -X- _ O
, -X- _ O
prior -X- _ O
work -X- _ O
has -X- _ O
used -X- _ O
objectives -X- _ O
to -X- _ O
rank -X- _ O
candidate -X- _ O
next -X- _ O
sentences -X- _ O
( -X- _ O
Jernite -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017;Logeswaran -X- _ O
and -X- _ O
Lee -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
left -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
right -X- _ O
generation -X- _ O
of -X- _ O
next -X- _ O
sentence -X- _ O
words -X- _ O
given -X- _ O
a -X- _ O
representation -X- _ O
of -X- _ O
the -X- _ O
previous -X- _ O
sentence -X- _ O
( -X- _ O
Kiros -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
, -X- _ O
or -X- _ O
denoising -X- _ B-MethodName
autoencoder -X- _ I-MethodName
derived -X- _ O
objectives -X- _ O
( -X- _ O
Hill -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
. -X- _ O

The -X- _ O
code -X- _ O
and -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
models -X- _ O
are -X- _ O
available -X- _ O
at -X- _ O
https://github.com/ -X- _ O
google -X- _ O
- -X- _ O
research -X- _ O
/ -X- _ O
bert -X- _ O
. -X- _ O

In -X- _ O
addition -X- _ O
to -X- _ O
the -X- _ O
masked -X- _ O
language -X- _ O
model -X- _ O
, -X- _ O
we -X- _ O
also -X- _ O
use -X- _ O
a -X- _ O
" -X- _ O
next -X- _ O
sentence -X- _ O
prediction -X- _ O
" -X- _ O
task -X- _ O
that -X- _ O
jointly -X- _ O
pretrains -X- _ O
text -X- _ O
- -X- _ O
pair -X- _ O
representations -X- _ O
. -X- _ O

The -X- _ O
contributions -X- _ O
of -X- _ O
our -X- _ O
paper -X- _ O
are -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O
• -X- _ O
We -X- _ O
demonstrate -X- _ O
the -X- _ O
importance -X- _ O
of -X- _ O
bidirectional -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
for -X- _ O
language -X- _ O
representations -X- _ O
. -X- _ O

It -X- _ O
obtains -X- _ O
new -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
results -X- _ O
on -X- _ O
eleven -X- _ O
natural -X- _ O
language -X- _ O
processing -X- _ O
tasks -X- _ O
, -X- _ O
including -X- _ O
pushing -X- _ O
the -X- _ O
GLUE -X- _ B-MetricName
score -X- _ O
to -X- _ O
80.5 -X- _ B-MetricValue
% -X- _ I-MetricValue
( -X- _ O
7.7 -X- _ B-MetricValue
% -X- _ I-MetricValue
point -X- _ O
absolute -X- _ O
improvement -X- _ O
) -X- _ O
, -X- _ O
MultiNLI -X- _ B-DatasetName
accuracy -X- _ B-MetricName
to -X- _ O
86.7 -X- _ B-MetricValue
% -X- _ I-MetricValue
( -X- _ O
4.6 -X- _ B-MetricValue
% -X- _ I-MetricValue
absolute -X- _ O
improvement -X- _ O
) -X- _ O
, -X- _ O
SQuAD -X- _ B-DatasetName
v1.1 -X- _ I-DatasetName
question -X- _ B-TaskName
answering -X- _ I-TaskName
Test -X- _ O
F1 -X- _ B-MetricName
to -X- _ O
93.2 -X- _ B-MetricValue
( -X- _ O
1.5 -X- _ B-MetricValue
point -X- _ O
absolute -X- _ O
improvement -X- _ O
) -X- _ O
and -X- _ O
SQuAD -X- _ B-DatasetName
v2.0 -X- _ I-DatasetName
Test -X- _ O
F1 -X- _ B-MetricName
to -X- _ O
83.1 -X- _ B-MetricValue
( -X- _ O
5.1 -X- _ B-MetricValue
point -X- _ O
absolute -X- _ O
improvement -X- _ O
) -X- _ O
. -X- _ O

BERT -X- _ B-MethodName
: -X- _ O
Pre -X- _ O
- -X- _ O
training -X- _ O
of -X- _ O
Deep -X- _ O
Bidirectional -X- _ O
Transformers -X- _ O
for -X- _ O
Language -X- _ O
Understanding -X- _ O
. -X- _ O

BERT -X- _ B-MethodName
alleviates -X- _ O
the -X- _ O
previously -X- _ O
mentioned -X- _ O
unidirectionality -X- _ O
constraint -X- _ O
by -X- _ O
using -X- _ O
a -X- _ O
" -X- _ O
masked -X- _ O
language -X- _ O
model -X- _ O
" -X- _ O
( -X- _ O
MLM -X- _ O
) -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
objective -X- _ O
, -X- _ O
inspired -X- _ O
by -X- _ O
the -X- _ O
Cloze -X- _ O
task -X- _ O
( -X- _ O
Taylor -X- _ O
, -X- _ O
1953 -X- _ O
) -X- _ O
. -X- _ O

For -X- _ O
the -X- _ O
feature -X- _ O
- -X- _ O
based -X- _ O
approach -X- _ O
, -X- _ O
we -X- _ O
concatenate -X- _ O
the -X- _ O
last -X- _ O
4 -X- _ O
layers -X- _ O
of -X- _ O
BERT -X- _ B-MethodName
as -X- _ O
the -X- _ O
features -X- _ O
, -X- _ O
which -X- _ O
was -X- _ O
shown -X- _ O
to -X- _ O
be -X- _ O
the -X- _ O
best -X- _ O
approach -X- _ O
in -X- _ O
Section -X- _ O
5.3 -X- _ O
. -X- _ O
From -X- _ O
the -X- _ O
table -X- _ O
it -X- _ O
can -X- _ O
be -X- _ O
seen -X- _ O
that -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
is -X- _ O
surprisingly -X- _ O
robust -X- _ O
to -X- _ O
different -X- _ O
masking -X- _ O
strategies -X- _ O
. -X- _ O

The -X- _ O
right -X- _ O
part -X- _ O
of -X- _ O
the -X- _ O
paper -X- _ O
represents -X- _ O
the -X- _ O
Dev -X- _ O
set -X- _ O
results -X- _ O
. -X- _ O

In -X- _ O
the -X- _ O
table -X- _ O
, -X- _ O
MASK -X- _ O
means -X- _ O
that -X- _ O
we -X- _ O
replace -X- _ O
the -X- _ O
target -X- _ O
token -X- _ O
with -X- _ O
the -X- _ O
[ -X- _ O
MASK -X- _ O
] -X- _ O
symbol -X- _ O
for -X- _ O
MLM -X- _ O
; -X- _ O
SAME -X- _ O
means -X- _ O
that -X- _ O
we -X- _ O
keep -X- _ O
the -X- _ O
target -X- _ O
token -X- _ O
as -X- _ O
is -X- _ O
; -X- _ O
RND -X- _ O
means -X- _ O
that -X- _ O
we -X- _ O
replace -X- _ O
the -X- _ O
target -X- _ O
token -X- _ O
with -X- _ O
another -X- _ O
random -X- _ O
token -X- _ O
. -X- _ O

The -X- _ O
results -X- _ O
are -X- _ O
presented -X- _ O
in -X- _ O
Table -X- _ O
8 -X- _ O
. -X- _ O

For -X- _ O
NER -X- _ B-TaskName
, -X- _ O
we -X- _ O
report -X- _ O
both -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
and -X- _ O
feature -X- _ O
- -X- _ O
based -X- _ O
approaches -X- _ O
, -X- _ O
as -X- _ O
we -X- _ O
expect -X- _ O
the -X- _ O
mismatch -X- _ O
will -X- _ O
be -X- _ O
amplified -X- _ O
for -X- _ O
the -X- _ O
feature -X- _ O
- -X- _ O
based -X- _ O
approach -X- _ O
as -X- _ O
the -X- _ O
model -X- _ O
will -X- _ O
not -X- _ O
have -X- _ O
the -X- _ O
chance -X- _ O
to -X- _ O
adjust -X- _ O
the -X- _ O
representations -X- _ O
. -X- _ O

We -X- _ O
report -X- _ O
the -X- _ O
Dev -X- _ O
results -X- _ O
for -X- _ O
both -X- _ O
MNLI -X- _ B-DatasetName
and -X- _ O
NER -X- _ B-TaskName
. -X- _ O

Note -X- _ O
that -X- _ O
the -X- _ O
purpose -X- _ O
of -X- _ O
the -X- _ O
masking -X- _ O
strategies -X- _ O
is -X- _ O
to -X- _ O
reduce -X- _ O
the -X- _ O
mismatch -X- _ O
between -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
and -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
, -X- _ O
as -X- _ O
the -X- _ O
[ -X- _ O
MASK -X- _ O
] -X- _ O
symbol -X- _ O
never -X- _ O
appears -X- _ O
during -X- _ O
the -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
stage -X- _ O
. -X- _ O

The -X- _ O
following -X- _ O
is -X- _ O
an -X- _ O
ablation -X- _ O
study -X- _ O
to -X- _ O
evaluate -X- _ O
the -X- _ O
effect -X- _ O
of -X- _ O
different -X- _ O
masking -X- _ O
strategies -X- _ O
. -X- _ O

In -X- _ O
Section -X- _ O
3.1 -X- _ O
, -X- _ O
we -X- _ O
mention -X- _ O
that -X- _ O
BERT -X- _ B-MethodName
uses -X- _ O
a -X- _ O
mixed -X- _ O
strategy -X- _ O
for -X- _ O
masking -X- _ O
the -X- _ O
target -X- _ O
tokens -X- _ O
when -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
with -X- _ O
the -X- _ O
masked -X- _ O
language -X- _ O
model -X- _ O
( -X- _ O
MLM -X- _ O
) -X- _ O
objective -X- _ O
. -X- _ O

C.2 -X- _ O
Ablation -X- _ O
for -X- _ O
Different -X- _ O
Masking -X- _ O
Procedures -X- _ O
. -X- _ O

C -X- _ O
Additional -X- _ O
Ablation -X- _ O
Studies -X- _ O
. -X- _ O

For -X- _ O
our -X- _ O
GLUE -X- _ B-DatasetName
submission -X- _ O
, -X- _ O
we -X- _ O
always -X- _ O
predicted -X- _ O
the -X- _ O
majority -X- _ O
class -X- _ O
. -X- _ O

14 -X- _ O
WNLI -X- _ B-DatasetName
Winograd -X- _ B-DatasetName
NLI -X- _ I-DatasetName
is -X- _ O
a -X- _ O
small -X- _ O
natural -X- _ B-TaskName
language -X- _ I-TaskName
inference -X- _ I-TaskName
dataset -X- _ O
( -X- _ O
Levesque -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2011 -X- _ O
) -X- _ O
. -X- _ O

RTE -X- _ B-DatasetName
Recognizing -X- _ B-DatasetName
Textual -X- _ I-DatasetName
Entailment -X- _ I-DatasetName
is -X- _ O
a -X- _ O
binary -X- _ B-TaskName
entailment -X- _ I-TaskName
task -X- _ O
similar -X- _ O
to -X- _ O
MNLI -X- _ B-DatasetName
, -X- _ O
but -X- _ O
with -X- _ O
much -X- _ O
less -X- _ O
training -X- _ O
data -X- _ O
( -X- _ O
Bentivogli -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2009 -X- _ O
) -X- _ O
. -X- _ O

MRPC -X- _ B-DatasetName
Microsoft -X- _ B-DatasetName
Research -X- _ I-DatasetName
Paraphrase -X- _ I-DatasetName
Corpus -X- _ I-DatasetName
consists -X- _ O
of -X- _ O
sentence -X- _ O
pairs -X- _ O
automatically -X- _ O
extracted -X- _ O
from -X- _ O
online -X- _ O
news -X- _ O
sources -X- _ O
, -X- _ O
with -X- _ O
human -X- _ O
annotations -X- _ O
for -X- _ O
whether -X- _ O
the -X- _ O
sentences -X- _ O
in -X- _ O
the -X- _ O
pair -X- _ O
are -X- _ O
semantically -X- _ O
equivalent -X- _ O
( -X- _ O
Dolan -X- _ O
and -X- _ O
Brockett -X- _ O
, -X- _ O
2005 -X- _ O
) -X- _ O
. -X- _ O

They -X- _ O
were -X- _ O
annotated -X- _ O
with -X- _ O
a -X- _ O
score -X- _ O
from -X- _ O
1 -X- _ O
to -X- _ O
5 -X- _ O
denoting -X- _ O
how -X- _ O
similar -X- _ O
the -X- _ O
two -X- _ O
sentences -X- _ O
are -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
semantic -X- _ O
meaning -X- _ O
. -X- _ O

The -X- _ O
Semantic -X- _ B-DatasetName
Textual -X- _ I-DatasetName
Similarity -X- _ I-DatasetName
Benchmark -X- _ I-DatasetName
is -X- _ O
a -X- _ O
collection -X- _ O
of -X- _ O
sentence -X- _ O
pairs -X- _ O
drawn -X- _ O
from -X- _ O
news -X- _ O
headlines -X- _ O
and -X- _ O
other -X- _ O
sources -X- _ O
( -X- _ O
Cer -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
. -X- _ O

STS -X- _ O
- -X- _ O
B. -X- _ O

with -X- _ O
human -X- _ O
annotations -X- _ O
of -X- _ O
their -X- _ O
sentiment -X- _ O
( -X- _ O
Socher -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2013 -X- _ O
) -X- _ O
. -X- _ O

E -X- _ O
M -X- _ O
' -X- _ O
C -X- _ O
T -X- _ O
1 -X- _ O
T -X- _ O
[ -X- _ O
SEP -X- _ O
] -X- _ O
... -X- _ O

E -X- _ O
N -X- _ O
E -X- _ O
1 -X- _ O
' -X- _ O
... -X- _ O

E -X- _ O
[ -X- _ O
CLS -X- _ O
] -X- _ O
E -X- _ O
1 -X- _ O
E -X- _ O
[ -X- _ O
SEP -X- _ O
] -X- _ O
Class -X- _ O
Label -X- _ O
... -X- _ O

... -X- _ O

[ -X- _ O
CLS -X- _ O
] -X- _ O
E -X- _ O
[ -X- _ O
CLS -X- _ O
] -X- _ O
E -X- _ O
1 -X- _ O
E -X- _ O
2 -X- _ O
E -X- _ O
N -X- _ O
C -X- _ O
T -X- _ O
1 -X- _ O
T -X- _ O
2 -X- _ O
T -X- _ O
N -X- _ O
Single -X- _ O
Sentence -X- _ O
B -X- _ O
- -X- _ O
PER -X- _ O
O -X- _ O
O -X- _ O
... -X- _ O

... -X- _ O

T -X- _ O
M -X- _ O
' -X- _ O
[ -X- _ O
CLS -X- _ O
] -X- _ O
Tok -X- _ O
1 -X- _ O
[ -X- _ O
SEP -X- _ O
] -X- _ O
... -X- _ O

T -X- _ O
N -X- _ O
T -X- _ O
1 -X- _ O
' -X- _ O
... -X- _ O

E -X- _ O
M -X- _ O
' -X- _ O
C -X- _ O
T -X- _ O
1 -X- _ O
T -X- _ O
[ -X- _ O
SEP -X- _ O
] -X- _ O
... -X- _ O

E -X- _ O
N -X- _ O
E -X- _ O
1 -X- _ O
' -X- _ O
... -X- _ O

QNLI -X- _ B-DatasetName
Question -X- _ B-DatasetName
Natural -X- _ I-DatasetName
Language -X- _ I-DatasetName
Inference -X- _ I-DatasetName
is -X- _ O
a -X- _ O
version -X- _ O
of -X- _ O
the -X- _ O
Stanford -X- _ B-DatasetName
Question -X- _ I-DatasetName
Answering -X- _ I-DatasetName
Dataset -X- _ I-DatasetName
( -X- _ O
Rajpurkar -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
which -X- _ O
has -X- _ O
been -X- _ O
converted -X- _ O
to -X- _ O
a -X- _ O
binary -X- _ B-TaskName
classification -X- _ I-TaskName
task -X- _ O
( -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018a -X- _ O
... -X- _ O

Given -X- _ O
a -X- _ O
pair -X- _ O
of -X- _ O
sentences -X- _ O
, -X- _ O
the -X- _ O
goal -X- _ O
is -X- _ O
to -X- _ O
predict -X- _ O
whether -X- _ O
the -X- _ O
second -X- _ O
sentence -X- _ O
is -X- _ O
an -X- _ O
entailment -X- _ O
, -X- _ O
contradiction -X- _ O
, -X- _ O
or -X- _ O
neutral -X- _ O
with -X- _ O
respect -X- _ O
to -X- _ O
the -X- _ O
first -X- _ O
one -X- _ O
. -X- _ O

The -X- _ O
GLUE -X- _ B-DatasetName
benchmark -X- _ O
includes -X- _ O
the -X- _ O
following -X- _ O
datasets -X- _ O
, -X- _ O
the -X- _ O
descriptions -X- _ O
of -X- _ O
which -X- _ O
were -X- _ O
originally -X- _ O
summarized -X- _ O
in -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

Our -X- _ O
task -X- _ O
- -X- _ O
specific -X- _ O
models -X- _ O
are -X- _ O
formed -X- _ O
by -X- _ O
incorporating -X- _ O
BERT -X- _ B-MethodName
with -X- _ O
one -X- _ O
additional -X- _ O
output -X- _ O
layer -X- _ O
, -X- _ O
so -X- _ O
a -X- _ O
minimal -X- _ O
number -X- _ O
of -X- _ O
parameters -X- _ O
need -X- _ O
to -X- _ O
be -X- _ O
learned -X- _ O
from -X- _ O
scratch -X- _ O
. -X- _ O

The -X- _ O
illustration -X- _ O
of -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
BERT -X- _ B-MethodName
on -X- _ O
different -X- _ O
tasks -X- _ O
can -X- _ O
be -X- _ O
seen -X- _ O
in -X- _ O
Figure -X- _ O
4 -X- _ O
. -X- _ O

A.5 -X- _ O
Illustrations -X- _ O
of -X- _ O
Fine -X- _ O
- -X- _ O
tuning -X- _ O
on -X- _ O
Different -X- _ O
Tasks -X- _ O
. -X- _ O

To -X- _ O
isolate -X- _ O
the -X- _ O
effect -X- _ O
of -X- _ O
these -X- _ O
differences -X- _ O
, -X- _ O
we -X- _ O
perform -X- _ O
ablation -X- _ O
experiments -X- _ O
in -X- _ O
Section -X- _ O
5.1 -X- _ O
which -X- _ O
demonstrate -X- _ O
that -X- _ O
the -X- _ O
majority -X- _ O
of -X- _ O
the -X- _ O
improvements -X- _ O
are -X- _ O
in -X- _ O
fact -X- _ O
coming -X- _ O
from -X- _ O
the -X- _ O
two -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
tasks -X- _ O
and -X- _ O
the -X- _ O
bidirectionality -X- _ O
they -X- _ O
enable -X- _ O
. -X- _ O

• -X- _ O
GPT -X- _ B-MethodName
used -X- _ O
the -X- _ O
same -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
of -X- _ O
5e-5 -X- _ B-HyperparameterValue
for -X- _ O
all -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
experiments -X- _ O
; -X- _ O
BERT -X- _ B-MethodName
chooses -X- _ O
a -X- _ O
task -X- _ O
- -X- _ O
specific -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
learning -X- _ O
rate -X- _ O
which -X- _ O
performs -X- _ O
the -X- _ O
best -X- _ O
on -X- _ O
the -X- _ O
development -X- _ O
set -X- _ O
. -X- _ O

• -X- _ O
GPT -X- _ B-MethodName
uses -X- _ O
a -X- _ O
sentence -X- _ O
separator -X- _ O
( -X- _ O
[ -X- _ O
SEP -X- _ O
] -X- _ O
) -X- _ O
and -X- _ O
classifier -X- _ O
token -X- _ O
( -X- _ O
[ -X- _ O
CLS -X- _ O
] -X- _ O
) -X- _ O
which -X- _ O
are -X- _ O
only -X- _ O
introduced -X- _ O
at -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
time -X- _ O
; -X- _ O
BERT -X- _ B-MethodName
learns -X- _ O
[ -X- _ O
SEP -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
CLS -X- _ O
] -X- _ O
and -X- _ O
sentence -X- _ O
A -X- _ O
/ -X- _ O
B -X- _ O
embeddings -X- _ O
during -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
. -X- _ O

The -X- _ O
core -X- _ O
argument -X- _ O
of -X- _ O
this -X- _ O
work -X- _ O
is -X- _ O
that -X- _ O
the -X- _ O
bi -X- _ O
- -X- _ O
directionality -X- _ O
and -X- _ O
the -X- _ O
two -X- _ O
pretraining -X- _ O
tasks -X- _ O
presented -X- _ O
in -X- _ O
Section -X- _ O
3.1 -X- _ O
account -X- _ O
for -X- _ O
the -X- _ O
majority -X- _ O
of -X- _ O
the -X- _ O
empirical -X- _ O
improvements -X- _ O
, -X- _ O
but -X- _ O
we -X- _ O
do -X- _ O
note -X- _ O
that -X- _ O
there -X- _ O
are -X- _ O
several -X- _ O
other -X- _ O
differences -X- _ O
between -X- _ O
how -X- _ O
BERT -X- _ B-MethodName
and -X- _ O
GPT -X- _ B-MethodName
were -X- _ O
trained -X- _ O
: -X- _ O
• -X- _ O
GPT -X- _ B-MethodName
is -X- _ O
trained -X- _ O
on -X- _ O
the -X- _ O
BooksCorpus -X- _ B-DatasetName
( -X- _ O
800 -X- _ O
M -X- _ O
words -X- _ O
) -X- _ O
; -X- _ O
BERT -X- _ B-MethodName
is -X- _ O
trained -X- _ O
on -X- _ O
the -X- _ O
BooksCorpus -X- _ B-DatasetName
( -X- _ O
800 -X- _ O
M -X- _ O
words -X- _ O
) -X- _ O
and -X- _ O
Wikipedia -X- _ B-DatasetName
( -X- _ O
2,500 -X- _ O
M -X- _ O
words -X- _ O
) -X- _ O
. -X- _ O

In -X- _ O
fact -X- _ O
, -X- _ O
many -X- _ O
of -X- _ O
the -X- _ O
design -X- _ O
decisions -X- _ O
in -X- _ O
BERT -X- _ B-MethodName
were -X- _ O
intentionally -X- _ O
made -X- _ O
to -X- _ O
make -X- _ O
it -X- _ O
as -X- _ O
close -X- _ O
to -X- _ O
GPT -X- _ B-MethodName
as -X- _ O
possible -X- _ O
so -X- _ O
that -X- _ O
the -X- _ O
two -X- _ O
methods -X- _ O
could -X- _ O
be -X- _ O
minimally -X- _ O
compared -X- _ O
. -X- _ O

The -X- _ O
most -X- _ O
comparable -X- _ O
existing -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
method -X- _ O
to -X- _ O
BERT -X- _ B-MethodName
is -X- _ O
OpenAI -X- _ B-MethodName
GPT -X- _ I-MethodName
, -X- _ O
which -X- _ O
trains -X- _ O
a -X- _ O
left -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
right -X- _ O
Transformer -X- _ O
LM -X- _ O
on -X- _ O
a -X- _ O
large -X- _ O
text -X- _ O
corpus -X- _ O
. -X- _ O

Note -X- _ O
that -X- _ O
in -X- _ O
addition -X- _ O
to -X- _ O
the -X- _ O
architecture -X- _ O
differences -X- _ O
, -X- _ O
BERT -X- _ B-MethodName
and -X- _ O
OpenAI -X- _ B-MethodName
GPT -X- _ I-MethodName
are -X- _ O
finetuning -X- _ O
approaches -X- _ O
, -X- _ O
while -X- _ O
ELMo -X- _ B-MethodName
is -X- _ O
a -X- _ O
feature -X- _ O
- -X- _ O
based -X- _ O
approach -X- _ O
. -X- _ O

The -X- _ O
comparisons -X- _ O
between -X- _ O
the -X- _ O
model -X- _ O
architectures -X- _ O
are -X- _ O
shown -X- _ O
visually -X- _ O
in -X- _ O
Figure -X- _ O
3 -X- _ O
. -X- _ O

A.4 -X- _ O
Comparison -X- _ O
of -X- _ O
BERT -X- _ B-MethodName
, -X- _ O
ELMo -X- _ B-MethodName
, -X- _ O
and -X- _ O
OpenAI -X- _ B-MethodName
GPT -X- _ I-MethodName
Here -X- _ O
we -X- _ O
studies -X- _ O
the -X- _ O
differences -X- _ O
in -X- _ O
recent -X- _ O
popular -X- _ O
representation -X- _ O
learning -X- _ O
models -X- _ O
including -X- _ O
ELMo -X- _ B-MethodName
, -X- _ O
OpenAI -X- _ B-MethodName
GPT -X- _ I-MethodName
and -X- _ O
BERT -X- _ B-MethodName
. -X- _ O

Fine -X- _ O
- -X- _ O
tuning -X- _ O
is -X- _ O
typically -X- _ O
very -X- _ O
fast -X- _ O
, -X- _ O
so -X- _ O
it -X- _ O
is -X- _ O
reasonable -X- _ O
to -X- _ O
simply -X- _ O
run -X- _ O
an -X- _ O
exhaustive -X- _ O
search -X- _ O
over -X- _ O
the -X- _ O
above -X- _ O
parameters -X- _ O
and -X- _ O
choose -X- _ O
the -X- _ O
model -X- _ O
that -X- _ O
performs -X- _ O
best -X- _ O
on -X- _ O
the -X- _ O
development -X- _ O
set -X- _ O
. -X- _ O

The -X- _ O
dropout -X- _ B-HyperparameterName
probability -X- _ I-HyperparameterName
was -X- _ O
always -X- _ O
kept -X- _ O
at -X- _ O
0.1 -X- _ B-HyperparameterValue
. -X- _ O
The -X- _ O
optimal -X- _ O
hyperparameter -X- _ O
values -X- _ O
are -X- _ O
task -X- _ O
- -X- _ O
specific -X- _ O
, -X- _ O
but -X- _ O
we -X- _ O
found -X- _ O
the -X- _ O
following -X- _ O
range -X- _ O
of -X- _ O
possible -X- _ O
values -X- _ O
to -X- _ O
work -X- _ O
well -X- _ O
across -X- _ O
all -X- _ O
tasks -X- _ O
: -X- _ O
• -X- _ O
Batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
: -X- _ O
16 -X- _ B-HyperparameterValue
, -X- _ O
32 -X- _ B-HyperparameterValue
We -X- _ O
also -X- _ O
observed -X- _ O
that -X- _ O
large -X- _ O
data -X- _ O
sets -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
100k+ -X- _ O
labeled -X- _ O
training -X- _ O
examples -X- _ O
) -X- _ O
were -X- _ O
far -X- _ O
less -X- _ O
sensitive -X- _ O
to -X- _ O
hyperparameter -X- _ O
choice -X- _ O
than -X- _ O
small -X- _ O
data -X- _ O
sets -X- _ O
. -X- _ O

For -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
, -X- _ O
most -X- _ O
model -X- _ O
hyperparameters -X- _ O
are -X- _ O
the -X- _ O
same -X- _ O
as -X- _ O
in -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
, -X- _ O
with -X- _ O
the -X- _ O
exception -X- _ O
of -X- _ O
the -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
, -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
, -X- _ O
and -X- _ O
number -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
training -X- _ I-HyperparameterName
epochs -X- _ I-HyperparameterName
. -X- _ O

A.3 -X- _ O
Fine -X- _ O
- -X- _ O
tuning -X- _ O
Procedure -X- _ O
. -X- _ O

Then -X- _ O
, -X- _ O
we -X- _ O
train -X- _ O
the -X- _ O
rest -X- _ O
10 -X- _ O
% -X- _ O
of -X- _ O
the -X- _ O
steps -X- _ O
of -X- _ O
sequence -X- _ O
of -X- _ O
512 -X- _ O
to -X- _ O
learn -X- _ O
the -X- _ O
positional -X- _ O
embeddings -X- _ O
. -X- _ O

Longer -X- _ O
sequences -X- _ O
are -X- _ O
disproportionately -X- _ O
expensive -X- _ O
because -X- _ O
attention -X- _ O
is -X- _ O
quadratic -X- _ O
to -X- _ O
the -X- _ O
sequence -X- _ O
length -X- _ O
. -X- _ O

Each -X- _ O
pretraining -X- _ O
took -X- _ O
4 -X- _ O
days -X- _ O
to -X- _ O
complete -X- _ O
. -X- _ O

13 -X- _ O
Training -X- _ O
of -X- _ O
BERT -X- _ B-MethodName
LARGE -X- _ I-MethodName
was -X- _ O
performed -X- _ O
on -X- _ O
16 -X- _ O
Cloud -X- _ O
TPUs -X- _ O
( -X- _ O
64 -X- _ O
TPU -X- _ O
chips -X- _ O
total -X- _ O
) -X- _ O
. -X- _ O

Training -X- _ O
of -X- _ O
BERT -X- _ B-MethodName
BASE -X- _ I-MethodName
was -X- _ O
performed -X- _ O
on -X- _ O
4 -X- _ O
Cloud -X- _ O
TPUs -X- _ O
in -X- _ O
Pod -X- _ O
configuration -X- _ O
( -X- _ O
16 -X- _ O
TPU -X- _ O
chips -X- _ O
total -X- _ O
) -X- _ O
. -X- _ O

E -X- _ O
1 -X- _ O
E -X- _ O
2 -X- _ O
E -X- _ O
N -X- _ O
... -X- _ O

T -X- _ O
1 -X- _ O
T -X- _ O
2 -X- _ O
T -X- _ O
N -X- _ O
... -X- _ O

E -X- _ O
1 -X- _ O
E -X- _ O
2 -X- _ O
E -X- _ O
N -X- _ O
... -X- _ O

T -X- _ O
1 -X- _ O
T -X- _ O
2 -X- _ O
T -X- _ O
N -X- _ O
... -X- _ O

E -X- _ O
N -X- _ O
... -X- _ O

The -X- _ O
training -X- _ O
loss -X- _ O
is -X- _ O
the -X- _ O
sum -X- _ O
of -X- _ O
the -X- _ O
mean -X- _ O
masked -X- _ O
LM -X- _ O
likelihood -X- _ O
and -X- _ O
the -X- _ O
mean -X- _ O
next -X- _ O
sentence -X- _ O
prediction -X- _ O
likelihood -X- _ O
. -X- _ O

We -X- _ O
use -X- _ O
a -X- _ O
gelu -X- _ O
activation -X- _ O
( -X- _ O
Hendrycks -X- _ O
and -X- _ O
Gimpel -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
rather -X- _ O
than -X- _ O
the -X- _ O
standard -X- _ O
relu -X- _ O
, -X- _ O
following -X- _ O
OpenAI -X- _ B-MethodName
GPT -X- _ I-MethodName
. -X- _ O

We -X- _ O
use -X- _ O
a -X- _ O
dropout -X- _ B-HyperparameterName
probability -X- _ I-HyperparameterName
of -X- _ O
0.1 -X- _ B-HyperparameterValue
on -X- _ O
all -X- _ O
layers -X- _ O
. -X- _ O

We -X- _ O
use -X- _ O
Adam -X- _ O
with -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
of -X- _ O
1e-4 -X- _ B-HyperparameterValue
, -X- _ O
β -X- _ B-HyperparameterName
1 -X- _ I-HyperparameterName
= -X- _ O
0.9 -X- _ B-HyperparameterValue
, -X- _ O
β -X- _ B-HyperparameterName
2 -X- _ I-HyperparameterName
= -X- _ O
0.999 -X- _ B-HyperparameterValue
, -X- _ O
L2 -X- _ B-HyperparameterName
weight -X- _ I-HyperparameterName
decay -X- _ I-HyperparameterName
of -X- _ O
0.01 -X- _ B-HyperparameterValue
, -X- _ O
learning -X- _ O
rate -X- _ O
warmup -X- _ O
over -X- _ O
the -X- _ O
first -X- _ O
10,000 -X- _ O
steps -X- _ O
, -X- _ O
and -X- _ O
linear -X- _ O
decay -X- _ O
of -X- _ O
the -X- _ O
learning -X- _ O
rate -X- _ O
. -X- _ O

We -X- _ O
train -X- _ O
with -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
of -X- _ O
256 -X- _ B-HyperparameterValue
sequences -X- _ O
( -X- _ O
256 -X- _ O
sequences -X- _ O
* -X- _ O
512 -X- _ O
tokens -X- _ O
= -X- _ O
128,000 -X- _ O
tokens -X- _ O
/ -X- _ O
batch -X- _ O
) -X- _ O
for -X- _ O
1,000,000 -X- _ B-HyperparameterValue
steps -X- _ B-HyperparameterName
, -X- _ O
which -X- _ O
is -X- _ O
approximately -X- _ O
40 -X- _ O
epochs -X- _ O
over -X- _ O
the -X- _ O
3.3 -X- _ O
billion -X- _ O
word -X- _ O
corpus -X- _ O
. -X- _ O

The -X- _ O
LM -X- _ O
masking -X- _ O
is -X- _ O
applied -X- _ O
after -X- _ O
WordPiece -X- _ O
tokenization -X- _ O
with -X- _ O
a -X- _ O
uniform -X- _ O
masking -X- _ O
rate -X- _ O
of -X- _ O
15 -X- _ O
% -X- _ O
, -X- _ O
and -X- _ O
no -X- _ O
special -X- _ O
consideration -X- _ O
given -X- _ O
to -X- _ O
partial -X- _ O
word -X- _ O
pieces -X- _ O
. -X- _ O

They -X- _ O
are -X- _ O
sampled -X- _ O
such -X- _ O
that -X- _ O
the -X- _ O
combined -X- _ O
length -X- _ O
is -X- _ O
≤ -X- _ O
512 -X- _ O
tokens -X- _ O
. -X- _ O

50 -X- _ O
% -X- _ O
of -X- _ O
the -X- _ O
time -X- _ O
B -X- _ O
is -X- _ O
the -X- _ O
actual -X- _ O
next -X- _ O
sentence -X- _ O
that -X- _ O
follows -X- _ O
A -X- _ O
and -X- _ O
50 -X- _ O
% -X- _ O
of -X- _ O
the -X- _ O
time -X- _ O
it -X- _ O
is -X- _ O
a -X- _ O
random -X- _ O
sentence -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
done -X- _ O
for -X- _ O
the -X- _ O
" -X- _ B-TaskName
next -X- _ I-TaskName
sentence -X- _ I-TaskName
prediction -X- _ I-TaskName
" -X- _ O
task -X- _ O
. -X- _ O

The -X- _ O
first -X- _ O
sentence -X- _ O
receives -X- _ O
the -X- _ O
A -X- _ O
embedding -X- _ O
and -X- _ O
the -X- _ O
second -X- _ O
receives -X- _ O
the -X- _ O
B -X- _ O
embedding -X- _ O
. -X- _ O

To -X- _ O
generate -X- _ O
each -X- _ O
training -X- _ O
input -X- _ O
sequence -X- _ O
, -X- _ O
we -X- _ O
sample -X- _ O
two -X- _ O
spans -X- _ O
of -X- _ O
text -X- _ O
from -X- _ O
the -X- _ O
corpus -X- _ O
, -X- _ O
which -X- _ O
we -X- _ O
refer -X- _ O
to -X- _ O
as -X- _ O
" -X- _ O
sentences -X- _ O
" -X- _ O
even -X- _ O
though -X- _ O
they -X- _ O
are -X- _ O
typically -X- _ O
much -X- _ O
longer -X- _ O
than -X- _ O
single -X- _ O
sentences -X- _ O
( -X- _ O
but -X- _ O
can -X- _ O
be -X- _ O
shorter -X- _ O
also -X- _ O
) -X- _ O
. -X- _ O

Our -X- _ O
major -X- _ O
contribution -X- _ O
is -X- _ O
further -X- _ O
generalizing -X- _ O
these -X- _ O
findings -X- _ O
to -X- _ O
deep -X- _ O
bidirectional -X- _ O
architectures -X- _ O
, -X- _ O
allowing -X- _ O
the -X- _ O
same -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
model -X- _ O
to -X- _ O
successfully -X- _ O
tackle -X- _ O
a -X- _ O
broad -X- _ O
set -X- _ O
of -X- _ O
NLP -X- _ O
tasks -X- _ O
. -X- _ O

In -X- _ O
particular -X- _ O
, -X- _ O
these -X- _ O
results -X- _ O
enable -X- _ O
even -X- _ O
low -X- _ O
- -X- _ O
resource -X- _ O
tasks -X- _ O
to -X- _ O
benefit -X- _ O
from -X- _ O
deep -X- _ O
unidirectional -X- _ O
architectures -X- _ O
. -X- _ O

Recent -X- _ O
empirical -X- _ O
improvements -X- _ O
due -X- _ O
to -X- _ O
transfer -X- _ O
learning -X- _ O
with -X- _ O
language -X- _ O
models -X- _ O
have -X- _ O
demonstrated -X- _ O
that -X- _ O
rich -X- _ O
, -X- _ O
unsupervised -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
is -X- _ O
an -X- _ O
integral -X- _ O
part -X- _ O
of -X- _ O
many -X- _ O
language -X- _ O
understanding -X- _ O
systems -X- _ O
. -X- _ O

Conclusion -X- _ O
. -X- _ O

This -X- _ O
demonstrates -X- _ O
that -X- _ O
BERT -X- _ B-MethodName
is -X- _ O
effective -X- _ O
for -X- _ O
both -X- _ O
finetuning -X- _ O
and -X- _ O
feature -X- _ O
- -X- _ O
based -X- _ O
approaches -X- _ O
. -X- _ O

The -X- _ O
best -X- _ O
performing -X- _ O
method -X- _ O
concatenates -X- _ O
the -X- _ O
token -X- _ O
representations -X- _ O
from -X- _ O
the -X- _ O
top -X- _ O
four -X- _ O
hidden -X- _ O
layers -X- _ O
of -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
Transformer -X- _ B-MethodName
, -X- _ O
which -X- _ O
is -X- _ O
only -X- _ O
0.3 -X- _ B-MetricValue
F1 -X- _ B-MetricName
behind -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
the -X- _ O
entire -X- _ O
model -X- _ O
. -X- _ O

BERT -X- _ B-MethodName
LARGE -X- _ I-MethodName
performs -X- _ O
competitively -X- _ O
with -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
methods -X- _ O
. -X- _ O

Results -X- _ O
are -X- _ O
presented -X- _ O
in -X- _ O
Table -X- _ O
7 -X- _ O
. -X- _ O

These -X- _ O
contextual -X- _ O
embeddings -X- _ O
are -X- _ O
used -X- _ O
as -X- _ O
input -X- _ O
to -X- _ O
a -X- _ O
randomly -X- _ O
initialized -X- _ O
two -X- _ O
- -X- _ O
layer -X- _ O
768 -X- _ O
- -X- _ O
dimensional -X- _ O
BiLSTM -X- _ B-MethodName
before -X- _ O
the -X- _ O
classification -X- _ O
layer -X- _ O
. -X- _ O

To -X- _ O
ablate -X- _ O
the -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
approach -X- _ O
, -X- _ O
we -X- _ O
apply -X- _ O
the -X- _ O
feature -X- _ O
- -X- _ O
based -X- _ O
approach -X- _ O
by -X- _ O
extracting -X- _ O
the -X- _ O
activations -X- _ O
from -X- _ O
one -X- _ O
or -X- _ O
more -X- _ O
layers -X- _ O
without -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
any -X- _ O
parameters -X- _ O
of -X- _ O
BERT -X- _ B-MethodName
. -X- _ O

We -X- _ O
use -X- _ O
the -X- _ O
representation -X- _ O
of -X- _ O
the -X- _ O
first -X- _ O
sub -X- _ O
- -X- _ O
token -X- _ O
as -X- _ O
the -X- _ O
input -X- _ O
to -X- _ O
the -X- _ O
token -X- _ O
- -X- _ O
level -X- _ O
classifier -X- _ O
over -X- _ O
the -X- _ O
NER -X- _ B-TaskName
label -X- _ O
set -X- _ O
. -X- _ O

Following -X- _ O
standard -X- _ O
practice -X- _ O
, -X- _ O
we -X- _ O
formulate -X- _ O
this -X- _ O
as -X- _ O
a -X- _ O
tagging -X- _ O
task -X- _ O
but -X- _ O
do -X- _ O
not -X- _ O
use -X- _ O
a -X- _ O
CRF -X- _ O
layer -X- _ O
in -X- _ O
the -X- _ O
output -X- _ O
. -X- _ O

In -X- _ O
the -X- _ O
input -X- _ O
to -X- _ O
BERT -X- _ B-MethodName
, -X- _ O
we -X- _ O
use -X- _ O
a -X- _ O
case -X- _ O
- -X- _ O
preserving -X- _ O
WordPiece -X- _ O
model -X- _ O
, -X- _ O
and -X- _ O
we -X- _ O
include -X- _ O
the -X- _ O
maximal -X- _ O
document -X- _ O
context -X- _ O
provided -X- _ O
by -X- _ O
the -X- _ O
data -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
section -X- _ O
, -X- _ O
we -X- _ O
compare -X- _ O
the -X- _ O
two -X- _ O
approaches -X- _ O
by -X- _ O
applying -X- _ O
BERT -X- _ B-MethodName
to -X- _ O
the -X- _ O
CoNLL-2003 -X- _ O
Named -X- _ B-TaskName
Entity -X- _ I-TaskName
Recognition -X- _ I-TaskName
( -X- _ O
NER -X- _ B-TaskName
) -X- _ O
task -X- _ O
( -X- _ O
Tjong -X- _ O
Kim -X- _ O
Sang -X- _ O
and -X- _ O
De -X- _ O
Meulder -X- _ O
, -X- _ O
2003 -X- _ O
) -X- _ O
. -X- _ O

Second -X- _ O
, -X- _ O
there -X- _ O
are -X- _ O
major -X- _ O
computational -X- _ O
benefits -X- _ O
to -X- _ O
pre -X- _ O
- -X- _ O
compute -X- _ O
an -X- _ O
expensive -X- _ O
representation -X- _ O
of -X- _ O
the -X- _ O
training -X- _ O
data -X- _ O
once -X- _ O
and -X- _ O
then -X- _ O
run -X- _ O
many -X- _ O
experiments -X- _ O
with -X- _ O
cheaper -X- _ O
models -X- _ O
on -X- _ O
top -X- _ O
of -X- _ O
this -X- _ O
representation -X- _ O
. -X- _ O

First -X- _ O
, -X- _ O
not -X- _ O
all -X- _ O
tasks -X- _ O
can -X- _ O
be -X- _ O
easily -X- _ O
represented -X- _ O
by -X- _ O
a -X- _ O
Transformer -X- _ B-MethodName
encoder -X- _ O
architecture -X- _ O
, -X- _ O
and -X- _ O
therefore -X- _ O
require -X- _ O
a -X- _ O
task -X- _ O
- -X- _ O
specific -X- _ O
model -X- _ O
architecture -X- _ O
to -X- _ O
be -X- _ O
added -X- _ O
. -X- _ O

However -X- _ O
, -X- _ O
the -X- _ O
feature -X- _ O
- -X- _ O
based -X- _ O
approach -X- _ O
, -X- _ O
where -X- _ O
fixed -X- _ O
features -X- _ O
are -X- _ O
extracted -X- _ O
from -X- _ O
the -X- _ O
pretrained -X- _ O
model -X- _ O
, -X- _ O
has -X- _ O
certain -X- _ O
advantages -X- _ O
. -X- _ O

All -X- _ O
of -X- _ O
the -X- _ O
BERT -X- _ B-MethodName
results -X- _ O
presented -X- _ O
so -X- _ O
far -X- _ O
have -X- _ O
used -X- _ O
the -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
approach -X- _ O
, -X- _ O
where -X- _ O
a -X- _ O
simple -X- _ O
classification -X- _ O
layer -X- _ O
is -X- _ O
added -X- _ O
to -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
model -X- _ O
, -X- _ O
and -X- _ O
all -X- _ O
parameters -X- _ O
are -X- _ O
jointly -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
on -X- _ O
a -X- _ O
downstream -X- _ O
task -X- _ O
. -X- _ O

However -X- _ O
, -X- _ O
as -X- _ O
expected -X- _ O
, -X- _ O
using -X- _ O
only -X- _ O
the -X- _ O
MASK -X- _ O
strategy -X- _ O
was -X- _ O
problematic -X- _ O
when -X- _ O
applying -X- _ O
the -X- _ O
featurebased -X- _ O
approach -X- _ O
to -X- _ O
NER -X- _ B-TaskName
. -X- _ O

Interestingly -X- _ O
, -X- _ O
using -X- _ O
only -X- _ O
the -X- _ O
RND -X- _ O
strategy -X- _ O
performs -X- _ O
much -X- _ O
worse -X- _ O
than -X- _ O
our -X- _ O
strategy -X- _ O
as -X- _ O
well -X- _ O
. -X- _ O

Appendix -X- _ O
for -X- _ O
" -X- _ O
BERT -X- _ B-MethodName
: -X- _ O
Pre -X- _ O
- -X- _ O
training -X- _ O
of -X- _ O
Deep -X- _ O
Bidirectional -X- _ B-MethodName
Transformers -X- _ I-MethodName
for -X- _ O
Language -X- _ O
Understanding -X- _ O
" -X- _ O
We -X- _ O
organize -X- _ O
the -X- _ O
appendix -X- _ O
into -X- _ O
three -X- _ O
sections -X- _ O
: -X- _ O
• -X- _ O
Additional -X- _ O
implementation -X- _ O
details -X- _ O
for -X- _ O
BERT -X- _ B-MethodName
are -X- _ O
presented -X- _ O
in -X- _ O
Appendix -X- _ O
A -X- _ O
; -X- _ O
. -X- _ O

A -X- _ O
Additional -X- _ O
Details -X- _ O
for -X- _ O
BERT -X- _ B-MethodName
. -X- _ O

A.1 -X- _ O
Illustration -X- _ O
of -X- _ O
the -X- _ O
Pre -X- _ O
- -X- _ O
training -X- _ O
Tasks -X- _ O
We -X- _ O
provide -X- _ O
examples -X- _ O
of -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
tasks -X- _ O
in -X- _ O
the -X- _ O
following -X- _ O
. -X- _ O

Masked -X- _ O
LM -X- _ O
and -X- _ O
the -X- _ O
Masking -X- _ O
Procedure -X- _ O
Assuming -X- _ O
the -X- _ O
unlabeled -X- _ O
sentence -X- _ O
is -X- _ O
my -X- _ O
dog -X- _ O
is -X- _ O
hairy -X- _ O
, -X- _ O
and -X- _ O
during -X- _ O
the -X- _ O
random -X- _ O
masking -X- _ O
procedure -X- _ O
we -X- _ O
chose -X- _ O
the -X- _ O
4 -X- _ O
- -X- _ O
th -X- _ O
token -X- _ O
( -X- _ O
which -X- _ O
corresponding -X- _ O
to -X- _ O
hairy -X- _ O
) -X- _ O
, -X- _ O
our -X- _ O
masking -X- _ O
procedure -X- _ O
can -X- _ O
be -X- _ O
further -X- _ O
illustrated -X- _ O
by -X- _ O
• -X- _ O
10 -X- _ O
% -X- _ O
of -X- _ O
the -X- _ O
time -X- _ O
: -X- _ O
Replace -X- _ O
the -X- _ O
word -X- _ O
with -X- _ O
a -X- _ O
random -X- _ O
word -X- _ O
, -X- _ O
e.g. -X- _ O
, -X- _ O
my -X- _ O
dog -X- _ O
is -X- _ O
hairy -X- _ O
→ -X- _ O
my -X- _ O
dog -X- _ O
is -X- _ O
apple -X- _ O
• -X- _ O
10 -X- _ O
% -X- _ O
of -X- _ O
the -X- _ O
time -X- _ O
: -X- _ O
Keep -X- _ O
the -X- _ O
word -X- _ O
unchanged -X- _ O
, -X- _ O
e.g. -X- _ O
, -X- _ O
my -X- _ O
dog -X- _ O
is -X- _ O
hairy -X- _ O
→ -X- _ O
my -X- _ O
dog -X- _ O
is -X- _ O
hairy -X- _ O
. -X- _ O

The -X- _ O
purpose -X- _ O
of -X- _ O
this -X- _ O
is -X- _ O
to -X- _ O
bias -X- _ O
the -X- _ O
representation -X- _ O
towards -X- _ O
the -X- _ O
actual -X- _ O
observed -X- _ O
word -X- _ O
. -X- _ O

Compared -X- _ O
to -X- _ O
standard -X- _ O
langauge -X- _ O
model -X- _ O
training -X- _ O
, -X- _ O
the -X- _ O
masked -X- _ O
LM -X- _ O
only -X- _ O
make -X- _ O
predictions -X- _ O
on -X- _ O
15 -X- _ O
% -X- _ O
of -X- _ O
tokens -X- _ O
in -X- _ O
each -X- _ O
batch -X- _ O
, -X- _ O
which -X- _ O
suggests -X- _ O
that -X- _ O
more -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
steps -X- _ O
may -X- _ O
be -X- _ O
required -X- _ O
for -X- _ O
the -X- _ O
model -X- _ O
. -X- _ O

Additionally -X- _ O
, -X- _ O
because -X- _ O
random -X- _ O
replacement -X- _ O
only -X- _ O
occurs -X- _ O
for -X- _ O
1.5 -X- _ O
% -X- _ O
of -X- _ O
all -X- _ O
tokens -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
10 -X- _ O
% -X- _ O
of -X- _ O
15 -X- _ O
% -X- _ O
) -X- _ O
, -X- _ O
this -X- _ O
does -X- _ O
not -X- _ O
seem -X- _ O
to -X- _ O
harm -X- _ O
the -X- _ O
model -X- _ O
's -X- _ O
language -X- _ O
understanding -X- _ O
capability -X- _ O
. -X- _ O

In -X- _ O
Section -X- _ O
C.2 -X- _ O
, -X- _ O
we -X- _ O
evaluate -X- _ O
the -X- _ O
impact -X- _ O
this -X- _ O
procedure -X- _ O
. -X- _ O

Feature -X- _ O
- -X- _ O
based -X- _ O
Approach -X- _ O
with -X- _ O
BERT -X- _ B-MethodName
. -X- _ O

Both -X- _ O
of -X- _ O
these -X- _ O
prior -X- _ O
works -X- _ O
used -X- _ O
a -X- _ O
featurebased -X- _ O
approach -X- _ O
-we -X- _ O
hypothesize -X- _ O
that -X- _ O
when -X- _ O
the -X- _ O
model -X- _ O
is -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
directly -X- _ O
on -X- _ O
the -X- _ O
downstream -X- _ O
tasks -X- _ O
and -X- _ O
uses -X- _ O
only -X- _ O
a -X- _ O
very -X- _ O
small -X- _ O
number -X- _ O
of -X- _ O
randomly -X- _ O
initialized -X- _ O
additional -X- _ O
parameters -X- _ O
, -X- _ O
the -X- _ O
taskspecific -X- _ O
models -X- _ O
can -X- _ O
benefit -X- _ O
from -X- _ O
the -X- _ O
larger -X- _ O
, -X- _ O
more -X- _ O
expressive -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
representations -X- _ O
even -X- _ O
when -X- _ O
downstream -X- _ O
task -X- _ O
data -X- _ O
is -X- _ O
very -X- _ O
small -X- _ O
. -X- _ O

( -X- _ O
2016 -X- _ O
) -X- _ O
mentioned -X- _ O
in -X- _ O
passing -X- _ O
that -X- _ O
increasing -X- _ O
hidden -X- _ B-HyperparameterName
dimension -X- _ I-HyperparameterName
size -X- _ I-HyperparameterName
from -X- _ O
200 -X- _ B-HyperparameterValue
to -X- _ O
600 -X- _ B-HyperparameterValue
helped -X- _ O
, -X- _ O
but -X- _ O
increasing -X- _ O
further -X- _ O
to -X- _ O
1,000 -X- _ B-HyperparameterValue
did -X- _ O
not -X- _ O
bring -X- _ O
further -X- _ O
improvements -X- _ O
. -X- _ O

( -X- _ O
2018b -X- _ O
) -X- _ O
presented -X- _ O
mixed -X- _ O
results -X- _ O
on -X- _ O
the -X- _ O
downstream -X- _ O
task -X- _ O
impact -X- _ O
of -X- _ O
increasing -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
bi -X- _ O
- -X- _ O
LM -X- _ O
size -X- _ O
from -X- _ O
two -X- _ O
to -X- _ O
four -X- _ O
layers -X- _ O
and -X- _ O
Melamud -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

Peters -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

However -X- _ O
, -X- _ O
we -X- _ O
believe -X- _ O
that -X- _ O
this -X- _ O
is -X- _ O
the -X- _ O
first -X- _ O
work -X- _ O
to -X- _ O
demonstrate -X- _ O
convincingly -X- _ O
that -X- _ O
scaling -X- _ O
to -X- _ O
extreme -X- _ O
model -X- _ O
sizes -X- _ O
also -X- _ O
leads -X- _ O
to -X- _ O
large -X- _ O
improvements -X- _ O
on -X- _ O
very -X- _ O
small -X- _ O
scale -X- _ O
tasks -X- _ O
, -X- _ O
provided -X- _ O
that -X- _ O
the -X- _ O
model -X- _ O
has -X- _ O
been -X- _ O
sufficiently -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
. -X- _ O

It -X- _ O
has -X- _ O
long -X- _ O
been -X- _ O
known -X- _ O
that -X- _ O
increasing -X- _ O
the -X- _ O
model -X- _ O
size -X- _ O
will -X- _ O
lead -X- _ O
to -X- _ O
continual -X- _ O
improvements -X- _ O
on -X- _ O
large -X- _ O
- -X- _ O
scale -X- _ O
tasks -X- _ O
such -X- _ O
as -X- _ O
machine -X- _ B-TaskName
translation -X- _ I-TaskName
and -X- _ O
language -X- _ O
modeling -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
demonstrated -X- _ O
by -X- _ O
the -X- _ O
LM -X- _ O
perplexity -X- _ O
of -X- _ O
held -X- _ O
- -X- _ O
out -X- _ O
training -X- _ O
data -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
6 -X- _ O
. -X- _ O

By -X- _ O
contrast -X- _ O
, -X- _ O
BERT -X- _ B-MethodName
BASE -X- _ I-MethodName
contains -X- _ O
110 -X- _ O
M -X- _ O
parameters -X- _ O
and -X- _ O
BERT -X- _ B-MethodName
LARGE -X- _ I-MethodName
contains -X- _ O
340 -X- _ O
M -X- _ O
parameters -X- _ O
. -X- _ O

( -X- _ O
2017 -X- _ O
) -X- _ O
is -X- _ O
( -X- _ O
L=6 -X- _ B-HyperparameterName
, -X- _ O
H=1024 -X- _ B-HyperparameterName
, -X- _ O
A=16 -X- _ B-HyperparameterName
) -X- _ O
with -X- _ O
100 -X- _ O
M -X- _ O
parameters -X- _ O
for -X- _ O
the -X- _ O
encoder -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
largest -X- _ O
Transformer -X- _ O
we -X- _ O
have -X- _ O
found -X- _ O
in -X- _ O
the -X- _ O
literature -X- _ O
is -X- _ O
( -X- _ O
L=64 -X- _ B-HyperparameterName
, -X- _ O
H=512 -X- _ B-HyperparameterName
, -X- _ O
A=2 -X- _ B-HyperparameterName
) -X- _ O
with -X- _ O
235 -X- _ O
M -X- _ O
parameters -X- _ O
( -X- _ O
Al -X- _ O
- -X- _ O
Rfou -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O

For -X- _ O
example -X- _ O
, -X- _ O
the -X- _ O
largest -X- _ O
Transformer -X- _ B-MethodName
explored -X- _ O
in -X- _ O
Vaswani -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

It -X- _ O
is -X- _ O
also -X- _ O
perhaps -X- _ O
surprising -X- _ O
that -X- _ O
we -X- _ O
are -X- _ O
able -X- _ O
to -X- _ O
achieve -X- _ O
such -X- _ O
significant -X- _ O
improvements -X- _ O
on -X- _ O
top -X- _ O
of -X- _ O
models -X- _ O
which -X- _ O
are -X- _ O
already -X- _ O
quite -X- _ O
large -X- _ O
relative -X- _ O
to -X- _ O
the -X- _ O
existing -X- _ O
literature -X- _ O
. -X- _ O

We -X- _ O
can -X- _ O
see -X- _ O
that -X- _ O
larger -X- _ O
models -X- _ O
lead -X- _ O
to -X- _ O
a -X- _ O
strict -X- _ O
accuracy -X- _ O
improvement -X- _ O
across -X- _ O
all -X- _ O
four -X- _ O
datasets -X- _ O
, -X- _ O
even -X- _ O
for -X- _ O
MRPC -X- _ B-DatasetName
which -X- _ O
only -X- _ O
has -X- _ O
3,600 -X- _ O
labeled -X- _ O
training -X- _ O
examples -X- _ O
, -X- _ O
and -X- _ O
is -X- _ O
substantially -X- _ O
different -X- _ O
from -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
tasks -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
table -X- _ O
, -X- _ O
we -X- _ O
report -X- _ O
the -X- _ O
average -X- _ O
Dev -X- _ O
Set -X- _ O
accuracy -X- _ B-MetricName
from -X- _ O
5 -X- _ O
random -X- _ O
restarts -X- _ O
of -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
. -X- _ O

Results -X- _ O
on -X- _ O
selected -X- _ O
GLUE -X- _ B-DatasetName
tasks -X- _ O
are -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
6 -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
section -X- _ O
, -X- _ O
we -X- _ O
explore -X- _ O
the -X- _ O
effect -X- _ O
of -X- _ O
model -X- _ O
size -X- _ O
on -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
task -X- _ O
accuracy -X- _ O
. -X- _ O

Effect -X- _ O
of -X- _ O
Model -X- _ O
Size -X- _ O
. -X- _ O

We -X- _ O
recognize -X- _ O
that -X- _ O
it -X- _ O
would -X- _ O
also -X- _ O
be -X- _ O
possible -X- _ O
to -X- _ O
train -X- _ O
separate -X- _ O
LTR -X- _ O
and -X- _ O
RTL -X- _ O
models -X- _ O
and -X- _ O
represent -X- _ O
each -X- _ O
token -X- _ O
as -X- _ O
the -X- _ O
concatenation -X- _ O
of -X- _ O
the -X- _ O
two -X- _ O
models -X- _ O
, -X- _ O
as -X- _ O
ELMo -X- _ B-MethodName
does -X- _ O
. -X- _ O

However -X- _ O
: -X- _ O
( -X- _ O
a -X- _ O
) -X- _ O
this -X- _ O
is -X- _ O
twice -X- _ O
as -X- _ O
expensive -X- _ O
as -X- _ O
a -X- _ O
single -X- _ O
bidirectional -X- _ O
model -X- _ O
; -X- _ O
( -X- _ O
b -X- _ O
) -X- _ O
this -X- _ O
is -X- _ O
non -X- _ O
- -X- _ O
intuitive -X- _ O
for -X- _ O
tasks -X- _ O
like -X- _ O
QA -X- _ B-TaskName
, -X- _ O
since -X- _ O
the -X- _ O
RTL -X- _ O
model -X- _ O
would -X- _ O
not -X- _ O
be -X- _ O
able -X- _ O
to -X- _ O
condition -X- _ O
the -X- _ O
answer -X- _ O
on -X- _ O
the -X- _ O
question -X- _ O
; -X- _ O
( -X- _ O
c -X- _ O
) -X- _ O
this -X- _ O
it -X- _ O
is -X- _ O
strictly -X- _ O
less -X- _ O
powerful -X- _ O
than -X- _ O
a -X- _ O
deep -X- _ O
bidirectional -X- _ O
model -X- _ O
, -X- _ O
since -X- _ O
it -X- _ O
can -X- _ O
use -X- _ O
both -X- _ O
left -X- _ O
and -X- _ O
right -X- _ O
context -X- _ O
at -X- _ O
every -X- _ O
layer -X- _ O
. -X- _ O

The -X- _ O
BiLSTM -X- _ B-MethodName
hurts -X- _ O
performance -X- _ O
on -X- _ O
the -X- _ O
GLUE -X- _ B-DatasetName
tasks -X- _ O
. -X- _ O

This -X- _ O
does -X- _ O
significantly -X- _ O
improve -X- _ O
results -X- _ O
on -X- _ O
SQuAD -X- _ B-DatasetName
, -X- _ O
but -X- _ O
the -X- _ O
results -X- _ O
are -X- _ O
still -X- _ O
far -X- _ O
worse -X- _ O
than -X- _ O
those -X- _ O
of -X- _ O
the -X- _ O
pretrained -X- _ O
bidirectional -X- _ O
models -X- _ O
. -X- _ O

In -X- _ O
order -X- _ O
to -X- _ O
make -X- _ O
a -X- _ O
good -X- _ O
faith -X- _ O
attempt -X- _ O
at -X- _ O
strengthening -X- _ O
the -X- _ O
LTR -X- _ O
system -X- _ O
, -X- _ O
we -X- _ O
added -X- _ O
a -X- _ O
randomly -X- _ O
initialized -X- _ O
BiLSTM -X- _ B-MethodName
on -X- _ O
top -X- _ O
. -X- _ O

For -X- _ O
SQuAD -X- _ B-DatasetName
it -X- _ O
is -X- _ O
intuitively -X- _ O
clear -X- _ O
that -X- _ O
a -X- _ O
LTR -X- _ O
model -X- _ O
will -X- _ O
perform -X- _ O
poorly -X- _ O
at -X- _ O
token -X- _ O
predictions -X- _ O
, -X- _ O
since -X- _ O
the -X- _ O
token -X- _ O
- -X- _ O
level -X- _ O
hidden -X- _ O
states -X- _ O
have -X- _ O
no -X- _ O
rightside -X- _ O
context -X- _ O
. -X- _ O

The -X- _ O
LTR -X- _ O
model -X- _ O
performs -X- _ O
worse -X- _ O
than -X- _ O
the -X- _ O
MLM -X- _ O
model -X- _ O
on -X- _ O
all -X- _ O
tasks -X- _ O
, -X- _ O
with -X- _ O
large -X- _ O
drops -X- _ O
on -X- _ O
MRPC -X- _ B-DatasetName
and -X- _ O
SQuAD -X- _ B-DatasetName
. -X- _ O

In -X- _ O
Table -X- _ O
5 -X- _ O
, -X- _ O
we -X- _ O
show -X- _ O
that -X- _ O
removing -X- _ O
NSP -X- _ B-TaskName
hurts -X- _ O
performance -X- _ O
significantly -X- _ O
on -X- _ O
QNLI -X- _ B-DatasetName
, -X- _ O
MNLI -X- _ B-DatasetName
, -X- _ O
and -X- _ O
SQuAD -X- _ B-DatasetName
1.1 -X- _ I-DatasetName
. -X- _ O
Next -X- _ O
, -X- _ O
we -X- _ O
evaluate -X- _ O
the -X- _ O
impact -X- _ O
of -X- _ O
training -X- _ O
bidirectional -X- _ O
representations -X- _ O
by -X- _ O
comparing -X- _ O
" -X- _ O
No -X- _ O
NSP -X- _ B-TaskName
" -X- _ O
to -X- _ O
" -X- _ O
LTR -X- _ O
& -X- _ O
No -X- _ O
NSP -X- _ B-TaskName
" -X- _ O
. -X- _ O

We -X- _ O
first -X- _ O
examine -X- _ O
the -X- _ O
impact -X- _ O
brought -X- _ O
by -X- _ O
the -X- _ O
NSP -X- _ B-TaskName
task -X- _ O
. -X- _ O

This -X- _ O
is -X- _ O
directly -X- _ O
comparable -X- _ O
to -X- _ O
OpenAI -X- _ B-MethodName
GPT -X- _ I-MethodName
, -X- _ O
but -X- _ O
using -X- _ O
our -X- _ O
larger -X- _ O
training -X- _ O
dataset -X- _ O
, -X- _ O
our -X- _ O
input -X- _ O
representation -X- _ O
, -X- _ O
and -X- _ O
our -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
scheme -X- _ O
. -X- _ O

Additionally -X- _ O
, -X- _ O
this -X- _ O
model -X- _ O
was -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
without -X- _ O
the -X- _ O
NSP -X- _ B-TaskName
task -X- _ O
. -X- _ O

The -X- _ O
left -X- _ O
- -X- _ O
only -X- _ O
constraint -X- _ O
was -X- _ O
also -X- _ O
applied -X- _ O
at -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
, -X- _ O
because -X- _ O
removing -X- _ O
it -X- _ O
introduced -X- _ O
a -X- _ O
pre -X- _ O
- -X- _ O
train -X- _ O
/ -X- _ O
fine -X- _ O
- -X- _ O
tune -X- _ O
mismatch -X- _ O
that -X- _ O
degraded -X- _ O
downstream -X- _ O
performance -X- _ O
. -X- _ O

A -X- _ O
left -X- _ O
- -X- _ O
context -X- _ O
- -X- _ O
only -X- _ O
model -X- _ O
which -X- _ O
is -X- _ O
trained -X- _ O
using -X- _ O
a -X- _ O
standard -X- _ O
Left -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
Right -X- _ O
( -X- _ O
LTR -X- _ O
) -X- _ O
LM -X- _ O
, -X- _ O
rather -X- _ O
than -X- _ O
an -X- _ O
MLM -X- _ O
. -X- _ O

LTR -X- _ O
& -X- _ O
No -X- _ O
NSP -X- _ B-TaskName
: -X- _ O
. -X- _ O

We -X- _ O
demonstrate -X- _ O
the -X- _ O
importance -X- _ O
of -X- _ O
the -X- _ O
deep -X- _ O
bidirectionality -X- _ O
of -X- _ O
BERT -X- _ B-MethodName
by -X- _ O
evaluating -X- _ O
two -X- _ O
pretraining -X- _ O
objectives -X- _ O
using -X- _ O
exactly -X- _ O
the -X- _ O
same -X- _ O
pretraining -X- _ O
data -X- _ O
, -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
scheme -X- _ O
, -X- _ O
and -X- _ O
hyperparameters -X- _ O
as -X- _ O
BERT -X- _ B-MethodName
BASE -X- _ I-MethodName
: -X- _ O
No -X- _ O
NSP -X- _ O
: -X- _ O
A -X- _ O
bidirectional -X- _ O
model -X- _ O
which -X- _ O
is -X- _ O
trained -X- _ O
using -X- _ O
the -X- _ O
" -X- _ O
masked -X- _ O
LM -X- _ O
" -X- _ O
( -X- _ O
MLM -X- _ O
) -X- _ O
but -X- _ O
without -X- _ O
the -X- _ O
" -X- _ O
next -X- _ B-TaskName
sentence -X- _ I-TaskName
prediction -X- _ I-TaskName
" -X- _ O
( -X- _ O
NSP -X- _ B-TaskName
) -X- _ O
task -X- _ O
. -X- _ O

Effect -X- _ O
of -X- _ O
Pre -X- _ O
- -X- _ O
training -X- _ O
Tasks -X- _ O
. -X- _ O

Additional -X- _ O
ablation -X- _ O
studies -X- _ O
can -X- _ O
be -X- _ O
found -X- _ O
in -X- _ O
Appendix -X- _ O
C. -X- _ O

In -X- _ O
this -X- _ O
section -X- _ O
, -X- _ O
we -X- _ O
perform -X- _ O
ablation -X- _ O
experiments -X- _ O
over -X- _ O
a -X- _ O
number -X- _ O
of -X- _ O
facets -X- _ O
of -X- _ O
BERT -X- _ B-MethodName
in -X- _ O
order -X- _ O
to -X- _ O
better -X- _ O
understand -X- _ O
their -X- _ O
relative -X- _ O
importance -X- _ O
. -X- _ O

Ablation -X- _ O
Studies -X- _ O
. -X- _ O

BERT -X- _ B-MethodName
LARGE -X- _ I-MethodName
outperforms -X- _ O
the -X- _ O
authors -X- _ O
' -X- _ O
baseline -X- _ O
ESIM+ELMo -X- _ B-MethodName
system -X- _ O
by -X- _ O
+27.1 -X- _ B-MetricValue
% -X- _ I-MetricValue
and -X- _ O
OpenAI -X- _ B-MethodName
GPT -X- _ I-MethodName
by -X- _ O
8.3 -X- _ B-MetricValue
% -X- _ I-MetricValue
. -X- _ O

Results -X- _ O
are -X- _ O
presented -X- _ O
in -X- _ O
Table -X- _ O
4 -X- _ O
. -X- _ O

We -X- _ O
fine -X- _ O
- -X- _ O
tune -X- _ O
the -X- _ O
model -X- _ O
for -X- _ O
3 -X- _ O
epochs -X- _ O
with -X- _ O
a -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
of -X- _ O
2e-5 -X- _ B-HyperparameterValue
and -X- _ O
a -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
of -X- _ O
16 -X- _ B-HyperparameterValue
. -X- _ O

The -X- _ O
only -X- _ O
task -X- _ O
- -X- _ O
specific -X- _ O
parameters -X- _ O
introduced -X- _ O
is -X- _ O
a -X- _ O
vector -X- _ O
whose -X- _ O
dot -X- _ O
product -X- _ O
with -X- _ O
the -X- _ O
[ -X- _ O
CLS -X- _ O
] -X- _ O
token -X- _ O
representation -X- _ O
C -X- _ O
denotes -X- _ O
a -X- _ O
score -X- _ O
for -X- _ O
each -X- _ O
choice -X- _ O
which -X- _ O
is -X- _ O
normalized -X- _ O
with -X- _ O
a -X- _ O
softmax -X- _ O
layer -X- _ O
. -X- _ O

When -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
on -X- _ O
the -X- _ O
SWAG -X- _ B-DatasetName
dataset -X- _ O
, -X- _ O
we -X- _ O
construct -X- _ O
four -X- _ O
input -X- _ O
sequences -X- _ O
, -X- _ O
each -X- _ O
containing -X- _ O
the -X- _ O
concatenation -X- _ O
of -X- _ O
the -X- _ O
given -X- _ O
sentence -X- _ O
( -X- _ O
sentence -X- _ O
A -X- _ O
) -X- _ O
and -X- _ O
a -X- _ O
possible -X- _ O
continuation -X- _ O
( -X- _ O
sentence -X- _ O
B -X- _ O
) -X- _ O
. -X- _ O

Given -X- _ O
a -X- _ O
sentence -X- _ O
, -X- _ O
the -X- _ O
task -X- _ O
is -X- _ O
to -X- _ O
choose -X- _ O
the -X- _ O
most -X- _ O
plausible -X- _ O
continuation -X- _ O
among -X- _ O
four -X- _ O
choices -X- _ O
. -X- _ O

The -X- _ O
Situations -X- _ B-DatasetName
With -X- _ I-DatasetName
Adversarial -X- _ I-DatasetName
Generations -X- _ I-DatasetName
( -X- _ O
SWAG -X- _ B-DatasetName
) -X- _ O
dataset -X- _ O
contains -X- _ O
113k -X- _ O
sentence -X- _ O
- -X- _ O
pair -X- _ O
completion -X- _ O
examples -X- _ O
that -X- _ O
evaluate -X- _ O
grounded -X- _ O
commonsense -X- _ O
inference -X- _ O
( -X- _ O
Zellers -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O

SWAG -X- _ B-DatasetName
. -X- _ O

We -X- _ O
observe -X- _ O
a -X- _ O
+5.1 -X- _ B-MetricValue
F1 -X- _ B-MetricName
improvement -X- _ O
over -X- _ O
the -X- _ O
previous -X- _ O
best -X- _ O
system -X- _ O
. -X- _ O

The -X- _ O
results -X- _ O
compared -X- _ O
to -X- _ O
prior -X- _ O
leaderboard -X- _ O
entries -X- _ O
and -X- _ O
top -X- _ O
published -X- _ O
work -X- _ O
( -X- _ O
Sun -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018;Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018b -X- _ O
) -X- _ O
are -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
3 -X- _ O
, -X- _ O
excluding -X- _ O
systems -X- _ O
that -X- _ O
use -X- _ O
BERT -X- _ B-MethodName
as -X- _ O
one -X- _ O
of -X- _ O
their -X- _ O
components -X- _ O
. -X- _ O

System -X- _ O
. -X- _ O

We -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
for -X- _ O
2 -X- _ O
epochs -X- _ O
with -X- _ O
a -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
of -X- _ O
5e-5 -X- _ B-HyperparameterValue
and -X- _ O
a -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
of -X- _ O
48 -X- _ B-HyperparameterValue
. -X- _ O

We -X- _ O
did -X- _ O
not -X- _ O
use -X- _ O
TriviaQA -X- _ B-DatasetName
data -X- _ O
for -X- _ O
this -X- _ O
model -X- _ O
. -X- _ O

We -X- _ O
predict -X- _ O
a -X- _ O
non -X- _ O
- -X- _ O
null -X- _ O
answer -X- _ O
when -X- _ O
ŝ -X- _ O
i -X- _ O
, -X- _ O
j -X- _ O
> -X- _ O
s -X- _ O
null -X- _ O
+ -X- _ O
τ -X- _ O
, -X- _ O
where -X- _ O
the -X- _ O
threshold -X- _ O
τ -X- _ O
is -X- _ O
selected -X- _ O
on -X- _ O
the -X- _ O
dev -X- _ O
set -X- _ O
to -X- _ O
maximize -X- _ O
F1 -X- _ B-MetricName
. -X- _ O

ŝ -X- _ O
i -X- _ O
, -X- _ O
j -X- _ O
= -X- _ O
max -X- _ O
j≥i -X- _ O
S•T -X- _ O
i -X- _ O
+ -X- _ O
E•T -X- _ O
j -X- _ O
. -X- _ O

For -X- _ O
prediction -X- _ O
, -X- _ O
we -X- _ O
compare -X- _ O
the -X- _ O
score -X- _ O
of -X- _ O
the -X- _ O
no -X- _ O
- -X- _ O
answer -X- _ O
span -X- _ O
: -X- _ O
s -X- _ O
null -X- _ O
= -X- _ O
S•C -X- _ O
+ -X- _ O
E•C -X- _ O
to -X- _ O
the -X- _ O
score -X- _ O
of -X- _ O
the -X- _ O
best -X- _ O
non -X- _ O
- -X- _ O
null -X- _ O
span -X- _ O
12 -X- _ O
The -X- _ O
TriviaQA -X- _ B-DatasetName
data -X- _ O
we -X- _ O
used -X- _ O
consists -X- _ O
of -X- _ O
paragraphs -X- _ O
from -X- _ O
TriviaQA -X- _ B-DatasetName
- -X- _ I-DatasetName
Wiki -X- _ I-DatasetName
formed -X- _ O
of -X- _ O
the -X- _ O
first -X- _ O
400 -X- _ O
tokens -X- _ O
in -X- _ O
documents -X- _ O
, -X- _ O
that -X- _ O
contain -X- _ O
at -X- _ O
least -X- _ O
one -X- _ O
of -X- _ O
the -X- _ O
provided -X- _ O
possible -X- _ O
answers -X- _ O
. -X- _ O

The -X- _ O
probability -X- _ O
space -X- _ O
for -X- _ O
the -X- _ O
start -X- _ O
and -X- _ O
end -X- _ O
answer -X- _ O
span -X- _ O
positions -X- _ O
is -X- _ O
extended -X- _ O
to -X- _ O
include -X- _ O
the -X- _ O
position -X- _ O
of -X- _ O
the -X- _ O
[ -X- _ O
CLS -X- _ O
] -X- _ O
token -X- _ O
. -X- _ O

We -X- _ O
treat -X- _ O
questions -X- _ O
that -X- _ O
do -X- _ O
not -X- _ O
have -X- _ O
an -X- _ O
answer -X- _ O
as -X- _ O
having -X- _ O
an -X- _ O
answer -X- _ O
span -X- _ O
with -X- _ O
start -X- _ O
and -X- _ O
end -X- _ O
at -X- _ O
the -X- _ O
[ -X- _ O
CLS -X- _ O
] -X- _ O
token -X- _ O
. -X- _ O

We -X- _ O
use -X- _ O
a -X- _ O
simple -X- _ O
approach -X- _ O
to -X- _ O
extend -X- _ O
the -X- _ O
SQuAD -X- _ B-DatasetName
v1.1 -X- _ I-DatasetName
BERT -X- _ B-MethodName
model -X- _ O
for -X- _ O
this -X- _ O
task -X- _ O
. -X- _ O

12 -X- _ O
4.3 -X- _ O
SQuAD -X- _ B-DatasetName
v2.0 -X- _ I-DatasetName
The -X- _ O
SQuAD -X- _ B-DatasetName
2.0 -X- _ I-DatasetName
task -X- _ O
extends -X- _ O
the -X- _ O
SQuAD -X- _ B-DatasetName
1.1 -X- _ I-DatasetName
problem -X- _ O
definition -X- _ O
by -X- _ O
allowing -X- _ O
for -X- _ O
the -X- _ O
possibility -X- _ O
that -X- _ O
no -X- _ O
short -X- _ O
answer -X- _ O
exists -X- _ O
in -X- _ O
the -X- _ O
provided -X- _ O
paragraph -X- _ O
, -X- _ O
making -X- _ O
the -X- _ O
problem -X- _ O
more -X- _ O
realistic -X- _ O
. -X- _ O

tuning -X- _ O
data -X- _ O
, -X- _ O
we -X- _ O
only -X- _ O
lose -X- _ O
0.1 -X- _ B-MetricValue
- -X- _ O
0.4 -X- _ B-MetricValue
F1 -X- _ B-MetricName
, -X- _ O
still -X- _ O
outperforming -X- _ O
all -X- _ O
existing -X- _ O
systems -X- _ O
by -X- _ O
a -X- _ O
wide -X- _ O
margin -X- _ O
. -X- _ O

In -X- _ O
fact -X- _ O
, -X- _ O
our -X- _ O
single -X- _ O
BERT -X- _ B-MethodName
model -X- _ O
outperforms -X- _ O
the -X- _ O
top -X- _ O
ensemble -X- _ O
system -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
F1 -X- _ B-MetricName
score -X- _ O
. -X- _ O

Our -X- _ O
best -X- _ O
performing -X- _ O
system -X- _ O
outperforms -X- _ O
the -X- _ O
top -X- _ O
leaderboard -X- _ O
system -X- _ O
by -X- _ O
+1.5 -X- _ B-MetricValue
F1 -X- _ B-MetricName
in -X- _ O
ensembling -X- _ O
and -X- _ O
+1.3 -X- _ B-MetricValue
F1 -X- _ B-MetricName
as -X- _ O
a -X- _ O
single -X- _ O
system -X- _ O
. -X- _ O

We -X- _ O
therefore -X- _ O
use -X- _ O
modest -X- _ O
data -X- _ O
augmentation -X- _ O
in -X- _ O
our -X- _ O
system -X- _ O
by -X- _ O
first -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
on -X- _ O
TriviaQA -X- _ B-DatasetName
( -X- _ O
Joshi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
befor -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
on -X- _ O
SQuAD -X- _ B-DatasetName
. -X- _ O

The -X- _ O
top -X- _ O
results -X- _ O
from -X- _ O
the -X- _ O
SQuAD -X- _ B-DatasetName
leaderboard -X- _ O
do -X- _ O
not -X- _ O
have -X- _ O
up -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
date -X- _ O
public -X- _ O
system -X- _ O
descriptions -X- _ O
available -X- _ O
, -X- _ O
11 -X- _ O
and -X- _ O
are -X- _ O
allowed -X- _ O
to -X- _ O
use -X- _ O
any -X- _ O
public -X- _ O
data -X- _ O
when -X- _ O
training -X- _ O
their -X- _ O
systems -X- _ O
. -X- _ O

Table -X- _ O
2 -X- _ O
shows -X- _ O
top -X- _ O
leaderboard -X- _ O
entries -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
results -X- _ O
from -X- _ O
top -X- _ O
published -X- _ O
systems -X- _ O
( -X- _ O
Seo -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017;Clark -X- _ O
and -X- _ O
Gardner -X- _ O
, -X- _ O
2018;Peters -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018a;Hu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O

We -X- _ O
fine -X- _ O
- -X- _ O
tune -X- _ O
for -X- _ O
3 -X- _ O
epochs -X- _ O
with -X- _ O
a -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
of -X- _ O
5e-5 -X- _ B-HyperparameterValue
and -X- _ O
a -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
of -X- _ O
32 -X- _ B-HyperparameterValue
. -X- _ O

The -X- _ O
training -X- _ O
objective -X- _ O
is -X- _ O
the -X- _ O
sum -X- _ O
of -X- _ O
the -X- _ O
log -X- _ O
- -X- _ O
likelihoods -X- _ O
of -X- _ O
the -X- _ O
correct -X- _ O
start -X- _ O
and -X- _ O
end -X- _ O
positions -X- _ O
. -X- _ O

The -X- _ O
score -X- _ O
of -X- _ O
a -X- _ O
candidate -X- _ O
span -X- _ O
from -X- _ O
position -X- _ O
i -X- _ O
to -X- _ O
position -X- _ O
j -X- _ O
is -X- _ O
defined -X- _ O
as -X- _ O
S•T -X- _ O
i -X- _ O
+ -X- _ O
E•T -X- _ O
j -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
maximum -X- _ O
scoring -X- _ O
span -X- _ O
where -X- _ O
j -X- _ O
≥ -X- _ O
i -X- _ O
is -X- _ O
used -X- _ O
as -X- _ O
a -X- _ O
prediction -X- _ O
. -X- _ O

The -X- _ O
analogous -X- _ O
formula -X- _ O
is -X- _ O
used -X- _ O
for -X- _ O
the -X- _ O
end -X- _ O
of -X- _ O
the -X- _ O
answer -X- _ O
span -X- _ O
. -X- _ O

The -X- _ O
probability -X- _ O
of -X- _ O
word -X- _ O
i -X- _ O
being -X- _ O
the -X- _ O
start -X- _ O
of -X- _ O
the -X- _ O
answer -X- _ O
span -X- _ O
is -X- _ O
computed -X- _ O
as -X- _ O
a -X- _ O
dot -X- _ O
product -X- _ O
between -X- _ O
T -X- _ O
i -X- _ O
and -X- _ O
S -X- _ O
followed -X- _ O
by -X- _ O
a -X- _ O
softmax -X- _ O
over -X- _ O
all -X- _ O
of -X- _ O
the -X- _ O
words -X- _ O
in -X- _ O
the -X- _ O
paragraph -X- _ O
: -X- _ O
P -X- _ O
i -X- _ O
= -X- _ O
e -X- _ O
S•T -X- _ O
i -X- _ O
j -X- _ O
e -X- _ O
S•T -X- _ O
j -X- _ O
. -X- _ O

We -X- _ O
only -X- _ O
introduce -X- _ O
a -X- _ O
start -X- _ O
vector -X- _ O
S -X- _ O
∈ -X- _ O
R -X- _ O
H -X- _ O
and -X- _ O
an -X- _ O
end -X- _ O
vector -X- _ O
E -X- _ O
∈ -X- _ O
R -X- _ O
H -X- _ O
during -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
. -X- _ O

As -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
1 -X- _ O
, -X- _ O
in -X- _ O
the -X- _ O
question -X- _ B-TaskName
answering -X- _ I-TaskName
task -X- _ O
, -X- _ O
we -X- _ O
represent -X- _ O
the -X- _ O
input -X- _ O
question -X- _ O
and -X- _ O
passage -X- _ O
as -X- _ O
a -X- _ O
single -X- _ O
packed -X- _ O
sequence -X- _ O
, -X- _ O
with -X- _ O
the -X- _ O
question -X- _ O
using -X- _ O
the -X- _ O
A -X- _ O
embedding -X- _ O
and -X- _ O
the -X- _ O
passage -X- _ O
using -X- _ O
the -X- _ O
B -X- _ O
embedding -X- _ O
. -X- _ O

10 -X- _ O
https://gluebenchmark.com/leaderboard -X- _ O
Wikipedia -X- _ O
containing -X- _ O
the -X- _ O
answer -X- _ O
, -X- _ O
the -X- _ O
task -X- _ O
is -X- _ O
to -X- _ O
predict -X- _ O
the -X- _ O
answer -X- _ O
text -X- _ O
span -X- _ O
in -X- _ O
the -X- _ O
passage -X- _ O
. -X- _ O

Given -X- _ O
a -X- _ O
question -X- _ O
and -X- _ O
a -X- _ O
passage -X- _ O
from -X- _ O
9 -X- _ O
The -X- _ O
GLUE -X- _ B-DatasetName
data -X- _ O
set -X- _ O
distribution -X- _ O
does -X- _ O
not -X- _ O
include -X- _ O
the -X- _ O
Test -X- _ O
labels -X- _ O
, -X- _ O
and -X- _ O
we -X- _ O
only -X- _ O
made -X- _ O
a -X- _ O
single -X- _ O
GLUE -X- _ B-DatasetName
evaluation -X- _ O
server -X- _ O
submission -X- _ O
for -X- _ O
each -X- _ O
of -X- _ O
BERTBASE -X- _ B-MethodName
and -X- _ O
BERTLARGE -X- _ B-MethodName
. -X- _ O

The -X- _ O
effect -X- _ O
of -X- _ O
model -X- _ O
size -X- _ O
is -X- _ O
explored -X- _ O
more -X- _ O
thoroughly -X- _ O
in -X- _ O
Section -X- _ O
5.2 -X- _ O
. -X- _ O
SQuAD -X- _ B-DatasetName
v1.1 -X- _ I-DatasetName
. -X- _ O
The -X- _ O
Stanford -X- _ B-DatasetName
Question -X- _ I-DatasetName
Answering -X- _ I-DatasetName
Dataset -X- _ I-DatasetName
( -X- _ O
SQuAD -X- _ B-DatasetName
v1.1 -X- _ I-DatasetName
) -X- _ O
is -X- _ O
a -X- _ O
collection -X- _ O
of -X- _ O
100k -X- _ O
crowdsourced -X- _ O
question -X- _ O
/ -X- _ O
answer -X- _ O
pairs -X- _ O
( -X- _ O
Rajpurkar -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
. -X- _ O

We -X- _ O
find -X- _ O
that -X- _ O
BERT -X- _ B-MethodName
LARGE -X- _ I-MethodName
significantly -X- _ O
outperforms -X- _ O
BERT -X- _ B-MethodName
BASE -X- _ I-MethodName
across -X- _ O
all -X- _ O
tasks -X- _ O
, -X- _ O
especially -X- _ O
those -X- _ O
with -X- _ O
very -X- _ O
little -X- _ O
training -X- _ O
data -X- _ O
. -X- _ O

For -X- _ O
the -X- _ O
largest -X- _ O
and -X- _ O
most -X- _ O
widely -X- _ O
reported -X- _ O
GLUE -X- _ B-DatasetName
task -X- _ O
, -X- _ O
MNLI -X- _ B-DatasetName
, -X- _ O
BERT -X- _ B-MethodName
obtains -X- _ O
a -X- _ O
4.6 -X- _ B-MetricValue
% -X- _ I-MetricValue
absolute -X- _ O
accuracy -X- _ B-MetricName
improvement -X- _ O
. -X- _ O

On -X- _ O
the -X- _ O
official -X- _ O
GLUE -X- _ B-DatasetName
leaderboard -X- _ O
10 -X- _ O
, -X- _ O
BERT -X- _ B-MethodName
LARGE -X- _ I-MethodName
obtains -X- _ O
a -X- _ O
score -X- _ B-MetricName
of -X- _ O
80.5 -X- _ B-MetricValue
, -X- _ O
compared -X- _ O
to -X- _ O
OpenAI -X- _ B-MethodName
GPT -X- _ I-MethodName
, -X- _ O
which -X- _ O
obtains -X- _ O
72.8 -X- _ B-MetricValue
as -X- _ O
of -X- _ O
the -X- _ O
date -X- _ O
of -X- _ O
writing -X- _ O
. -X- _ O

Note -X- _ O
that -X- _ O
BERT -X- _ B-MethodName
BASE -X- _ I-MethodName
and -X- _ O
OpenAI -X- _ B-MethodName
GPT -X- _ I-MethodName
are -X- _ O
nearly -X- _ O
identical -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
model -X- _ O
architecture -X- _ O
apart -X- _ O
from -X- _ O
the -X- _ O
attention -X- _ O
masking -X- _ O
. -X- _ O

Both -X- _ O
BERT -X- _ B-MethodName
BASE -X- _ I-MethodName
and -X- _ O
BERT -X- _ B-MethodName
LARGE -X- _ I-MethodName
outperform -X- _ O
all -X- _ O
systems -X- _ O
on -X- _ O
all -X- _ O
tasks -X- _ O
by -X- _ O
a -X- _ O
substantial -X- _ O
margin -X- _ O
, -X- _ O
obtaining -X- _ O
4.5 -X- _ B-MetricValue
% -X- _ I-MetricValue
and -X- _ O
7.0 -X- _ B-MetricValue
% -X- _ I-MetricValue
respective -X- _ O
average -X- _ O
accuracy -X- _ B-MethodName
improvement -X- _ O
over -X- _ O
the -X- _ O
prior -X- _ O
state -X- _ O
of -X- _ O
the -X- _ O
art -X- _ O
. -X- _ O

The -X- _ O
General -X- _ B-DatasetName
Language -X- _ I-DatasetName
Understanding -X- _ I-DatasetName
Evaluation -X- _ I-DatasetName
( -X- _ O
GLUE -X- _ B-DatasetName
) -X- _ O
benchmark -X- _ O
( -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018a -X- _ O
) -X- _ O
is -X- _ O
a -X- _ O
collection -X- _ O
of -X- _ O
diverse -X- _ O
natural -X- _ B-TaskName
language -X- _ I-TaskName
understanding -X- _ I-TaskName
tasks -X- _ O
. -X- _ O

9 -X- _ O
Results -X- _ O
are -X- _ O
presented -X- _ O
in -X- _ O
Table -X- _ O
1 -X- _ O
. -X- _ O

With -X- _ O
random -X- _ O
restarts -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
same -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
checkpoint -X- _ O
but -X- _ O
perform -X- _ O
different -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
data -X- _ O
shuffling -X- _ O
and -X- _ O
classifier -X- _ O
layer -X- _ O
initialization -X- _ O
. -X- _ O

Additionally -X- _ O
, -X- _ O
for -X- _ O
BERT -X- _ B-MethodName
LARGE -X- _ I-MethodName
we -X- _ O
found -X- _ O
that -X- _ O
finetuning -X- _ O
was -X- _ O
sometimes -X- _ O
unstable -X- _ O
on -X- _ O
small -X- _ O
datasets -X- _ O
, -X- _ O
so -X- _ O
we -X- _ O
ran -X- _ O
several -X- _ O
random -X- _ O
restarts -X- _ O
and -X- _ O
selected -X- _ O
the -X- _ O
best -X- _ O
model -X- _ O
on -X- _ O
the -X- _ O
Dev -X- _ O
set -X- _ O
. -X- _ O

For -X- _ O
each -X- _ O
task -X- _ O
, -X- _ O
we -X- _ O
selected -X- _ O
the -X- _ O
best -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
( -X- _ O
among -X- _ O
5e-5 -X- _ B-HyperparameterValue
, -X- _ O
4e-5 -X- _ B-HyperparameterValue
, -X- _ O
3e-5 -X- _ B-HyperparameterValue
, -X- _ O
and -X- _ O
2e-5 -X- _ B-HyperparameterValue
) -X- _ O
on -X- _ O
the -X- _ O
Dev -X- _ O
set -X- _ O
. -X- _ O

We -X- _ O
use -X- _ O
a -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
of -X- _ O
32 -X- _ B-HyperparameterValue
and -X- _ O
fine -X- _ O
- -X- _ O
tune -X- _ O
for -X- _ O
3 -X- _ O
epochs -X- _ O
over -X- _ O
the -X- _ O
data -X- _ O
for -X- _ O
all -X- _ O
GLUE -X- _ B-DatasetName
tasks -X- _ O
. -X- _ O

We -X- _ O
compute -X- _ O
a -X- _ O
standard -X- _ O
classification -X- _ O
loss -X- _ O
with -X- _ O
C -X- _ O
and -X- _ O
W -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
log(softmax(CW -X- _ O
T -X- _ O
) -X- _ O
) -X- _ O
. -X- _ O

The -X- _ O
only -X- _ O
new -X- _ O
parameters -X- _ O
introduced -X- _ O
during -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
are -X- _ O
classification -X- _ O
layer -X- _ O
weights -X- _ O
W -X- _ O
∈ -X- _ O
R -X- _ O
K×H -X- _ O
, -X- _ O
where -X- _ O
K -X- _ O
is -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
labels -X- _ O
. -X- _ O

Detailed -X- _ O
descriptions -X- _ O
of -X- _ O
GLUE -X- _ B-DatasetName
datasets -X- _ O
are -X- _ O
included -X- _ O
in -X- _ O
Appendix -X- _ O
B.1 -X- _ O
. -X- _ O
To -X- _ O
fine -X- _ O
- -X- _ O
tune -X- _ O
on -X- _ O
GLUE -X- _ B-DatasetName
, -X- _ O
we -X- _ O
represent -X- _ O
the -X- _ O
input -X- _ O
sequence -X- _ O
( -X- _ O
for -X- _ O
single -X- _ O
sentence -X- _ O
or -X- _ O
sentence -X- _ O
pairs -X- _ O
) -X- _ O
as -X- _ O
described -X- _ O
in -X- _ O
Section -X- _ O
3 -X- _ O
, -X- _ O
and -X- _ O
use -X- _ O
the -X- _ O
final -X- _ O
hidden -X- _ O
vector -X- _ O
C -X- _ O
∈ -X- _ O
R -X- _ O
H -X- _ O
corresponding -X- _ O
to -X- _ O
the -X- _ O
first -X- _ O
input -X- _ O
token -X- _ O
( -X- _ O
[ -X- _ O
CLS -X- _ O
] -X- _ O
) -X- _ O
as -X- _ O
the -X- _ O
aggregate -X- _ O
representation -X- _ O
. -X- _ O

GLUE -X- _ B-DatasetName
. -X- _ O

In -X- _ O
this -X- _ O
section -X- _ O
, -X- _ O
we -X- _ O
present -X- _ O
BERT -X- _ B-MethodName
fine -X- _ O
- -X- _ O
tuning -X- _ O
results -X- _ O
on -X- _ O
11 -X- _ O
NLP -X- _ O
tasks -X- _ O
. -X- _ O

More -X- _ O
details -X- _ O
can -X- _ O
be -X- _ O
found -X- _ O
in -X- _ O
Appendix -X- _ O
A.5 -X- _ O
. -X- _ O
Experiments -X- _ O
. -X- _ O

7 -X- _ O
We -X- _ O
describe -X- _ O
the -X- _ O
task -X- _ O
- -X- _ O
specific -X- _ O
details -X- _ O
in -X- _ O
the -X- _ O
corresponding -X- _ O
subsections -X- _ O
of -X- _ O
Section -X- _ O
4 -X- _ O
. -X- _ O

All -X- _ O
of -X- _ O
the -X- _ O
results -X- _ O
in -X- _ O
the -X- _ O
paper -X- _ O
can -X- _ O
be -X- _ O
replicated -X- _ O
in -X- _ O
at -X- _ O
most -X- _ O
1 -X- _ O
hour -X- _ O
on -X- _ O
a -X- _ O
single -X- _ O
Cloud -X- _ O
TPU -X- _ O
, -X- _ O
or -X- _ O
a -X- _ O
few -X- _ O
hours -X- _ O
on -X- _ O
a -X- _ O
GPU -X- _ O
, -X- _ O
starting -X- _ O
from -X- _ O
the -X- _ O
exact -X- _ O
same -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
model -X- _ O
. -X- _ O

Compared -X- _ O
to -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
, -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
is -X- _ O
relatively -X- _ O
inexpensive -X- _ O
. -X- _ O

At -X- _ O
the -X- _ O
output -X- _ O
, -X- _ O
the -X- _ O
token -X- _ O
representations -X- _ O
are -X- _ O
fed -X- _ O
into -X- _ O
an -X- _ O
output -X- _ O
layer -X- _ O
for -X- _ O
tokenlevel -X- _ O
tasks -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
sequence -X- _ B-TaskName
tagging -X- _ I-TaskName
or -X- _ O
question -X- _ B-TaskName
answering -X- _ I-TaskName
, -X- _ O
and -X- _ O
the -X- _ O
[ -X- _ O
CLS -X- _ O
] -X- _ O
representation -X- _ O
is -X- _ O
fed -X- _ O
into -X- _ O
an -X- _ O
output -X- _ O
layer -X- _ O
for -X- _ O
classification -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
entailment -X- _ B-TaskName
or -X- _ O
sentiment -X- _ B-TaskName
analysis -X- _ I-TaskName
. -X- _ O

For -X- _ O
each -X- _ O
task -X- _ O
, -X- _ O
we -X- _ O
simply -X- _ O
plug -X- _ O
in -X- _ O
the -X- _ O
taskspecific -X- _ O
inputs -X- _ O
and -X- _ O
outputs -X- _ O
into -X- _ O
BERT -X- _ B-MethodName
and -X- _ O
finetune -X- _ O
all -X- _ O
the -X- _ O
parameters -X- _ O
end -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
end -X- _ O
. -X- _ O

At -X- _ O
the -X- _ O
input -X- _ O
, -X- _ O
sentence -X- _ O
A -X- _ O
and -X- _ O
sentence -X- _ O
B -X- _ O
from -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
are -X- _ O
analogous -X- _ O
to -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
sentence -X- _ O
pairs -X- _ O
in -X- _ O
paraphrasing -X- _ O
, -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
hypothesis -X- _ O
- -X- _ O
premise -X- _ O
pairs -X- _ O
in -X- _ O
entailment -X- _ B-TaskName
, -X- _ O
( -X- _ O
3 -X- _ O
) -X- _ O
question -X- _ O
- -X- _ O
passage -X- _ O
pairs -X- _ O
in -X- _ O
question -X- _ B-TaskName
answering -X- _ I-TaskName
, -X- _ O
and -X- _ O
( -X- _ O
4 -X- _ O
) -X- _ O
a -X- _ O
degenerate -X- _ O
text-∅ -X- _ O
pair -X- _ O
in -X- _ O
text -X- _ B-TaskName
classification -X- _ I-TaskName
or -X- _ O
sequence -X- _ B-TaskName
tagging -X- _ I-TaskName
. -X- _ O

BERT -X- _ B-MethodName
instead -X- _ O
uses -X- _ O
the -X- _ O
self -X- _ O
- -X- _ O
attention -X- _ O
mechanism -X- _ O
to -X- _ O
unify -X- _ O
these -X- _ O
two -X- _ O
stages -X- _ O
, -X- _ O
as -X- _ O
encoding -X- _ O
a -X- _ O
concatenated -X- _ O
text -X- _ O
pair -X- _ O
with -X- _ O
self -X- _ O
- -X- _ O
attention -X- _ O
effectively -X- _ O
includes -X- _ O
bidirectional -X- _ O
cross -X- _ O
attention -X- _ O
between -X- _ O
two -X- _ O
sentences -X- _ O
. -X- _ O

( -X- _ O
2017 -X- _ O
) -X- _ O
. -X- _ O

( -X- _ O
2016 -X- _ O
) -X- _ O
; -X- _ O
Seo -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

For -X- _ O
applications -X- _ O
involving -X- _ O
text -X- _ O
pairs -X- _ O
, -X- _ O
a -X- _ O
common -X- _ O
pattern -X- _ O
is -X- _ O
to -X- _ O
independently -X- _ O
encode -X- _ O
text -X- _ O
pairs -X- _ O
before -X- _ O
applying -X- _ O
bidirectional -X- _ O
cross -X- _ O
attention -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
Parikh -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

Fine -X- _ O
- -X- _ O
tuning -X- _ O
is -X- _ O
straightforward -X- _ O
since -X- _ O
the -X- _ O
selfattention -X- _ O
mechanism -X- _ O
in -X- _ O
the -X- _ O
Transformer -X- _ B-MethodName
allows -X- _ O
BERT -X- _ B-MethodName
to -X- _ O
model -X- _ O
many -X- _ O
downstream -X- _ O
taskswhether -X- _ O
they -X- _ O
involve -X- _ O
single -X- _ O
text -X- _ O
or -X- _ O
text -X- _ O
pairs -X- _ O
- -X- _ O
by -X- _ O
swapping -X- _ O
out -X- _ O
the -X- _ O
appropriate -X- _ O
inputs -X- _ O
and -X- _ O
outputs -X- _ O
. -X- _ O

Fine -X- _ O
- -X- _ O
tuning -X- _ O
BERT -X- _ O
. -X- _ O

It -X- _ O
is -X- _ O
critical -X- _ O
to -X- _ O
use -X- _ O
a -X- _ O
document -X- _ O
- -X- _ O
level -X- _ O
corpus -X- _ O
rather -X- _ O
than -X- _ O
a -X- _ O
shuffled -X- _ O
sentence -X- _ O
- -X- _ O
level -X- _ O
corpus -X- _ O
such -X- _ O
as -X- _ O
the -X- _ O
Billion -X- _ B-DatasetName
Word -X- _ I-DatasetName
Benchmark -X- _ I-DatasetName
( -X- _ O
Chelba -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2013 -X- _ O
) -X- _ O
in -X- _ O
order -X- _ O
to -X- _ O
extract -X- _ O
long -X- _ O
contiguous -X- _ O
sequences -X- _ O
. -X- _ O

For -X- _ O
Wikipedia -X- _ O
we -X- _ O
extract -X- _ O
only -X- _ O
the -X- _ O
text -X- _ O
passages -X- _ O
and -X- _ O
ignore -X- _ O
lists -X- _ O
, -X- _ O
tables -X- _ O
, -X- _ O
and -X- _ O
headers -X- _ O
. -X- _ O

For -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
corpus -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
BooksCorpus -X- _ B-DatasetName
( -X- _ O
800 -X- _ O
M -X- _ O
words -X- _ O
) -X- _ O
( -X- _ O
Zhu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
and -X- _ O
English -X- _ B-DatasetName
Wikipedia -X- _ I-DatasetName
( -X- _ O
2,500 -X- _ O
M -X- _ O
words -X- _ O
) -X- _ O
. -X- _ O

The -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
procedure -X- _ O
largely -X- _ O
follows -X- _ O
the -X- _ O
existing -X- _ O
literature -X- _ O
on -X- _ O
language -X- _ O
model -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
. -X- _ O

Pre -X- _ O
- -X- _ O
training -X- _ O
data -X- _ O
. -X- _ O

However -X- _ O
, -X- _ O
in -X- _ O
prior -X- _ O
work -X- _ O
, -X- _ O
only -X- _ O
sentence -X- _ O
embeddings -X- _ O
are -X- _ O
transferred -X- _ O
to -X- _ O
down -X- _ O
- -X- _ O
stream -X- _ O
tasks -X- _ O
, -X- _ O
where -X- _ O
BERT -X- _ B-MethodName
transfers -X- _ O
all -X- _ O
parameters -X- _ O
to -X- _ O
initialize -X- _ O
end -X- _ O
- -X- _ O
task -X- _ O
model -X- _ O
parameters -X- _ O
. -X- _ O

( -X- _ O
2017 -X- _ O
) -X- _ O
and -X- _ O
Logeswaran -X- _ O
and -X- _ O
Lee -X- _ O
( -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O

5 -X- _ O
Despite -X- _ O
its -X- _ O
simplicity -X- _ O
, -X- _ O
we -X- _ O
demonstrate -X- _ O
in -X- _ O
Section -X- _ O
5.1 -X- _ O
that -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
towards -X- _ O
this -X- _ O
task -X- _ O
is -X- _ O
very -X- _ O
beneficial -X- _ O
to -X- _ O
both -X- _ O
QA -X- _ B-TaskName
and -X- _ O
NLI -X- _ B-TaskName
. -X- _ O

Specifically -X- _ O
, -X- _ O
when -X- _ O
choosing -X- _ O
the -X- _ O
sentences -X- _ O
A -X- _ O
and -X- _ O
B -X- _ O
for -X- _ O
each -X- _ O
pretraining -X- _ O
example -X- _ O
, -X- _ O
50 -X- _ O
% -X- _ O
of -X- _ O
the -X- _ O
time -X- _ O
B -X- _ O
is -X- _ O
the -X- _ O
actual -X- _ O
next -X- _ O
sentence -X- _ O
that -X- _ O
follows -X- _ O
A -X- _ O
( -X- _ O
labeled -X- _ O
as -X- _ O
IsNext -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
50 -X- _ O
% -X- _ O
of -X- _ O
the -X- _ O
time -X- _ O
it -X- _ O
is -X- _ O
a -X- _ O
random -X- _ O
sentence -X- _ O
from -X- _ O
the -X- _ O
corpus -X- _ O
( -X- _ O
labeled -X- _ O
as -X- _ O
NotNext -X- _ O
) -X- _ O
. -X- _ O

In -X- _ O
order -X- _ O
to -X- _ O
train -X- _ O
a -X- _ O
model -X- _ O
that -X- _ O
understands -X- _ O
sentence -X- _ O
relationships -X- _ O
, -X- _ O
we -X- _ O
pre -X- _ O
- -X- _ O
train -X- _ O
for -X- _ O
a -X- _ O
binarized -X- _ O
next -X- _ O
sentence -X- _ O
prediction -X- _ O
task -X- _ O
that -X- _ O
can -X- _ O
be -X- _ O
trivially -X- _ O
generated -X- _ O
from -X- _ O
any -X- _ O
monolingual -X- _ O
corpus -X- _ O
. -X- _ O

Then -X- _ O
, -X- _ O
T -X- _ O
i -X- _ O
will -X- _ O
be -X- _ O
used -X- _ O
to -X- _ O
predict -X- _ O
the -X- _ O
original -X- _ O
token -X- _ O
with -X- _ O
cross -X- _ O
entropy -X- _ O
loss -X- _ O
. -X- _ O

In -X- _ O
all -X- _ O
of -X- _ O
our -X- _ O
experiments -X- _ O
, -X- _ O
we -X- _ O
mask -X- _ O
15 -X- _ O
% -X- _ O
of -X- _ O
all -X- _ O
WordPiece -X- _ O
tokens -X- _ O
in -X- _ O
each -X- _ O
sequence -X- _ O
at -X- _ O
random -X- _ O
. -X- _ O

If -X- _ O
the -X- _ O
i -X- _ O
- -X- _ O
th -X- _ O
token -X- _ O
is -X- _ O
chosen -X- _ O
, -X- _ O
we -X- _ O
replace -X- _ O
the -X- _ O
i -X- _ O
- -X- _ O
th -X- _ O
token -X- _ O
with -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
the -X- _ O
[ -X- _ O
MASK -X- _ O
] -X- _ O
token -X- _ O
80 -X- _ O
% -X- _ O
of -X- _ O
the -X- _ O
time -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
a -X- _ O
random -X- _ O
token -X- _ O
10 -X- _ O
% -X- _ O
of -X- _ O
the -X- _ O
time -X- _ O
( -X- _ O
3 -X- _ O
) -X- _ O
the -X- _ O
unchanged -X- _ O
i -X- _ O
- -X- _ O
th -X- _ O
token -X- _ O
10 -X- _ O
% -X- _ O
of -X- _ O
the -X- _ O
time -X- _ O
. -X- _ O

The -X- _ O
training -X- _ O
data -X- _ O
generator -X- _ O
chooses -X- _ O
15 -X- _ O
% -X- _ O
of -X- _ O
the -X- _ O
token -X- _ O
positions -X- _ O
at -X- _ O
random -X- _ O
for -X- _ O
prediction -X- _ O
. -X- _ O

To -X- _ O
mitigate -X- _ O
this -X- _ O
, -X- _ O
we -X- _ O
do -X- _ O
not -X- _ O
always -X- _ O
replace -X- _ O
" -X- _ O
masked -X- _ O
" -X- _ O
words -X- _ O
with -X- _ O
the -X- _ O
actual -X- _ O
[ -X- _ O
MASK -X- _ O
] -X- _ O
token -X- _ O
. -X- _ O

Although -X- _ O
this -X- _ O
allows -X- _ O
us -X- _ O
to -X- _ O
obtain -X- _ O
a -X- _ O
bidirectional -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
model -X- _ O
, -X- _ O
a -X- _ O
downside -X- _ O
is -X- _ O
that -X- _ O
we -X- _ O
are -X- _ O
creating -X- _ O
a -X- _ O
mismatch -X- _ O
between -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
and -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
, -X- _ O
since -X- _ O
the -X- _ O
[ -X- _ O
MASK -X- _ O
] -X- _ O
token -X- _ O
does -X- _ O
not -X- _ O
appear -X- _ O
during -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
. -X- _ O

In -X- _ O
contrast -X- _ O
to -X- _ O
denoising -X- _ B-MethodName
auto -X- _ I-MethodName
- -X- _ I-MethodName
encoders -X- _ I-MethodName
( -X- _ O
Vincent -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2008 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
only -X- _ O
predict -X- _ O
the -X- _ O
masked -X- _ O
words -X- _ O
rather -X- _ O
than -X- _ O
reconstructing -X- _ O
the -X- _ O
entire -X- _ O
input -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
case -X- _ O
, -X- _ O
the -X- _ O
final -X- _ O
hidden -X- _ O
vectors -X- _ O
corresponding -X- _ O
to -X- _ O
the -X- _ O
mask -X- _ O
tokens -X- _ O
are -X- _ O
fed -X- _ O
into -X- _ O
an -X- _ O
output -X- _ O
softmax -X- _ O
over -X- _ O
the -X- _ O
vocabulary -X- _ O
, -X- _ O
as -X- _ O
in -X- _ O
a -X- _ O
standard -X- _ O
LM -X- _ O
. -X- _ O

In -X- _ O
order -X- _ O
to -X- _ O
train -X- _ O
a -X- _ O
deep -X- _ O
bidirectional -X- _ O
representation -X- _ O
, -X- _ O
we -X- _ O
simply -X- _ O
mask -X- _ O
some -X- _ O
percentage -X- _ O
of -X- _ O
the -X- _ O
input -X- _ O
tokens -X- _ O
at -X- _ O
random -X- _ O
, -X- _ O
and -X- _ O
then -X- _ O
predict -X- _ O
those -X- _ O
masked -X- _ O
tokens -X- _ O
. -X- _ O

former -X- _ O
is -X- _ O
often -X- _ O
referred -X- _ O
to -X- _ O
as -X- _ O
a -X- _ O
" -X- _ O
Transformer -X- _ O
encoder -X- _ O
" -X- _ O
while -X- _ O
the -X- _ O
left -X- _ O
- -X- _ O
context -X- _ O
- -X- _ O
only -X- _ O
version -X- _ O
is -X- _ O
referred -X- _ O
to -X- _ O
as -X- _ O
a -X- _ O
" -X- _ O
Transformer -X- _ O
decoder -X- _ O
" -X- _ O
since -X- _ O
it -X- _ O
can -X- _ O
be -X- _ O
used -X- _ O
for -X- _ O
text -X- _ O
generation -X- _ O
. -X- _ O

Unfortunately -X- _ O
, -X- _ O
standard -X- _ O
conditional -X- _ O
language -X- _ O
models -X- _ O
can -X- _ O
only -X- _ O
be -X- _ O
trained -X- _ O
left -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
right -X- _ O
or -X- _ O
right -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
left -X- _ O
, -X- _ O
since -X- _ O
bidirectional -X- _ O
conditioning -X- _ O
would -X- _ O
allow -X- _ O
each -X- _ O
word -X- _ O
to -X- _ O
indirectly -X- _ O
" -X- _ O
see -X- _ O
itself -X- _ O
" -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
model -X- _ O
could -X- _ O
trivially -X- _ O
predict -X- _ O
the -X- _ O
target -X- _ O
word -X- _ O
in -X- _ O
a -X- _ O
multi -X- _ O
- -X- _ O
layered -X- _ O
context -X- _ O
. -X- _ O

This -X- _ O
step -X- _ O
is -X- _ O
presented -X- _ O
in -X- _ O
the -X- _ O
left -X- _ O
part -X- _ O
of -X- _ O
Figure -X- _ O
1 -X- _ O
. -X- _ O

Instead -X- _ O
, -X- _ O
we -X- _ O
pre -X- _ O
- -X- _ O
train -X- _ O
BERT -X- _ B-MethodName
using -X- _ O
two -X- _ O
unsupervised -X- _ O
tasks -X- _ O
, -X- _ O
described -X- _ O
in -X- _ O
this -X- _ O
section -X- _ O
. -X- _ O

( -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
do -X- _ O
not -X- _ O
use -X- _ O
traditional -X- _ O
left -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
right -X- _ O
or -X- _ O
right -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
left -X- _ O
language -X- _ O
models -X- _ O
to -X- _ O
pre -X- _ O
- -X- _ O
train -X- _ O
BERT -X- _ B-MethodName
. -X- _ O

( -X- _ O
2018a -X- _ O
) -X- _ O
and -X- _ O
Radford -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

Unlike -X- _ O
Peters -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

Pre -X- _ O
- -X- _ O
training -X- _ O
BERT -X- _ B-MethodName
. -X- _ O

A -X- _ O
visualization -X- _ O
of -X- _ O
this -X- _ O
construction -X- _ O
can -X- _ O
be -X- _ O
seen -X- _ O
in -X- _ O
Figure -X- _ O
2 -X- _ O
. -X- _ O

For -X- _ O
a -X- _ O
given -X- _ O
token -X- _ O
, -X- _ O
its -X- _ O
input -X- _ O
representation -X- _ O
is -X- _ O
constructed -X- _ O
by -X- _ O
summing -X- _ O
the -X- _ O
corresponding -X- _ O
token -X- _ O
, -X- _ O
segment -X- _ O
, -X- _ O
and -X- _ O
position -X- _ O
embeddings -X- _ O
. -X- _ O

As -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
1 -X- _ O
, -X- _ O
we -X- _ O
denote -X- _ O
input -X- _ O
embedding -X- _ O
as -X- _ O
E -X- _ O
, -X- _ O
the -X- _ O
final -X- _ O
hidden -X- _ O
vector -X- _ O
of -X- _ O
the -X- _ O
special -X- _ O
[ -X- _ O
CLS -X- _ O
] -X- _ O
token -X- _ O
as -X- _ O
C -X- _ O
∈ -X- _ O
R -X- _ O
H -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
final -X- _ O
hidden -X- _ O
vector -X- _ O
for -X- _ O
the -X- _ O
i -X- _ O
th -X- _ O
input -X- _ O
token -X- _ O
as -X- _ O
T -X- _ O
i -X- _ O
∈ -X- _ O
R -X- _ O
H -X- _ O
. -X- _ O

Second -X- _ O
, -X- _ O
we -X- _ O
add -X- _ O
a -X- _ O
learned -X- _ O
embedding -X- _ O
to -X- _ O
every -X- _ O
token -X- _ O
indicating -X- _ O
whether -X- _ O
it -X- _ O
belongs -X- _ O
to -X- _ O
sentence -X- _ O
A -X- _ O
or -X- _ O
sentence -X- _ O
B. -X- _ O

First -X- _ O
, -X- _ O
we -X- _ O
separate -X- _ O
them -X- _ O
with -X- _ O
a -X- _ O
special -X- _ O
token -X- _ O
( -X- _ O
[ -X- _ O
SEP -X- _ O
] -X- _ O
) -X- _ O
. -X- _ O

We -X- _ O
differentiate -X- _ O
the -X- _ O
sentences -X- _ O
in -X- _ O
two -X- _ O
ways -X- _ O
. -X- _ O

Sentence -X- _ O
pairs -X- _ O
are -X- _ O
packed -X- _ O
together -X- _ O
into -X- _ O
a -X- _ O
single -X- _ O
sequence -X- _ O
. -X- _ O

The -X- _ O
final -X- _ O
hidden -X- _ O
state -X- _ O
corresponding -X- _ O
to -X- _ O
this -X- _ O
token -X- _ O
is -X- _ O
used -X- _ O
as -X- _ O
the -X- _ O
aggregate -X- _ O
sequence -X- _ O
representation -X- _ O
for -X- _ O
classification -X- _ O
tasks -X- _ O
. -X- _ O

The -X- _ O
first -X- _ O
token -X- _ O
of -X- _ O
every -X- _ O
sequence -X- _ O
is -X- _ O
always -X- _ O
a -X- _ O
special -X- _ O
classification -X- _ O
token -X- _ O
( -X- _ O
[ -X- _ O
CLS -X- _ O
] -X- _ O
) -X- _ O
. -X- _ O

We -X- _ O
use -X- _ O
WordPiece -X- _ O
embeddings -X- _ O
( -X- _ O
Wu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
with -X- _ O
a -X- _ O
30,000 -X- _ O
token -X- _ O
vocabulary -X- _ O
. -X- _ O

A -X- _ O
" -X- _ O
sequence -X- _ O
" -X- _ O
refers -X- _ O
to -X- _ O
the -X- _ O
input -X- _ O
token -X- _ O
sequence -X- _ O
to -X- _ O
BERT -X- _ B-MethodName
, -X- _ O
which -X- _ O
may -X- _ O
be -X- _ O
a -X- _ O
single -X- _ O
sentence -X- _ O
or -X- _ O
two -X- _ O
sentences -X- _ O
packed -X- _ O
together -X- _ O
. -X- _ O

Throughout -X- _ O
this -X- _ O
work -X- _ O
, -X- _ O
a -X- _ O
" -X- _ O
sentence -X- _ O
" -X- _ O
can -X- _ O
be -X- _ O
an -X- _ O
arbitrary -X- _ O
span -X- _ O
of -X- _ O
contiguous -X- _ O
text -X- _ O
, -X- _ O
rather -X- _ O
than -X- _ O
an -X- _ O
actual -X- _ O
linguistic -X- _ O
sentence -X- _ O
. -X- _ O

4 -X- _ O
Input -X- _ O
/ -X- _ O
Output -X- _ O
Representations -X- _ O
To -X- _ O
make -X- _ O
BERT -X- _ B-MethodName
handle -X- _ O
a -X- _ O
variety -X- _ O
of -X- _ O
down -X- _ O
- -X- _ O
stream -X- _ O
tasks -X- _ O
, -X- _ O
our -X- _ O
input -X- _ O
representation -X- _ O
is -X- _ O
able -X- _ O
to -X- _ O
unambiguously -X- _ O
represent -X- _ O
both -X- _ O
a -X- _ O
single -X- _ O
sentence -X- _ O
and -X- _ O
a -X- _ O
pair -X- _ O
of -X- _ O
sentences -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
Question -X- _ O
, -X- _ O
Answer -X- _ O
) -X- _ O
in -X- _ O
one -X- _ O
token -X- _ O
sequence -X- _ O
. -X- _ O

Critically -X- _ O
, -X- _ O
however -X- _ O
, -X- _ O
the -X- _ O
BERT -X- _ B-MethodName
Transformer -X- _ O
uses -X- _ O
bidirectional -X- _ O
self -X- _ O
- -X- _ O
attention -X- _ O
, -X- _ O
while -X- _ O
the -X- _ O
GPT -X- _ B-MethodName
Transformer -X- _ O
uses -X- _ O
constrained -X- _ O
self -X- _ O
- -X- _ O
attention -X- _ O
where -X- _ O
every -X- _ O
token -X- _ O
can -X- _ O
only -X- _ O
attend -X- _ O
to -X- _ O
context -X- _ O
to -X- _ O
its -X- _ O
left -X- _ O
. -X- _ O

BERT -X- _ B-MethodName
BASE -X- _ I-MethodName
was -X- _ O
chosen -X- _ O
to -X- _ O
have -X- _ O
the -X- _ O
same -X- _ O
model -X- _ O
size -X- _ O
as -X- _ O
OpenAI -X- _ B-MethodName
GPT -X- _ I-MethodName
for -X- _ O
comparison -X- _ O
purposes -X- _ O
. -X- _ O

3 -X- _ O
We -X- _ O
primarily -X- _ O
report -X- _ O
results -X- _ O
on -X- _ O
two -X- _ O
model -X- _ O
sizes -X- _ O
: -X- _ O
BERT -X- _ B-MethodName
BASE -X- _ I-MethodName
( -X- _ O
L=12 -X- _ B-HyperparameterName
, -X- _ O
H=768 -X- _ B-HyperparameterName
, -X- _ O
A=12 -X- _ B-HyperparameterValue
, -X- _ O
Total -X- _ B-HyperparameterName
Param -X- _ I-HyperparameterName
- -X- _ I-HyperparameterName
eters=110 -X- _ I-HyperparameterName
M -X- _ B-HyperparameterValue
) -X- _ O
and -X- _ O
BERT -X- _ B-MethodName
LARGE -X- _ I-MethodName
( -X- _ O
L=24 -X- _ B-HyperparameterName
, -X- _ O
H=1024 -X- _ B-HyperparameterName
, -X- _ O
A=16 -X- _ B-HyperparameterName
, -X- _ O
Total -X- _ B-HyperparameterName
Parameters=340 -X- _ I-HyperparameterName
M -X- _ B-HyperparameterValue
) -X- _ O
. -X- _ O

( -X- _ O
2017 -X- _ O
) -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
excellent -X- _ O
guides -X- _ O
such -X- _ O
as -X- _ O
" -X- _ O
The -X- _ O
Annotated -X- _ O
Transformer -X- _ O
. -X- _ O
" -X- _ O
2 -X- _ O
In -X- _ O
this -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
denote -X- _ O
the -X- _ O
number -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
layers -X- _ I-HyperparameterName
( -X- _ O
i.e. -X- _ O
, -X- _ O
Transformer -X- _ O
blocks -X- _ O
) -X- _ O
as -X- _ O
L -X- _ B-HyperparameterName
, -X- _ O
the -X- _ O
hidden -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
as -X- _ O
H -X- _ B-HyperparameterName
, -X- _ O
and -X- _ O
the -X- _ O
number -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
self -X- _ I-HyperparameterName
- -X- _ I-HyperparameterName
attention -X- _ I-HyperparameterName
heads -X- _ I-HyperparameterName
as -X- _ O
A. -X- _ B-HyperparameterName

( -X- _ O
2017 -X- _ O
) -X- _ O
and -X- _ O
released -X- _ O
in -X- _ O
the -X- _ O
tensor2tensor -X- _ O
library -X- _ O
. -X- _ O

There -X- _ O
is -X- _ O
mini -X- _ O
- -X- _ O
mal -X- _ O
difference -X- _ O
between -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
architecture -X- _ O
and -X- _ O
the -X- _ O
final -X- _ O
downstream -X- _ O
architecture -X- _ O
. -X- _ O

The -X- _ O
question -X- _ B-TaskName
- -X- _ I-TaskName
answering -X- _ I-TaskName
example -X- _ O
in -X- _ O
Figure -X- _ O
1 -X- _ O
will -X- _ O
serve -X- _ O
as -X- _ O
a -X- _ O
running -X- _ O
example -X- _ O
for -X- _ O
this -X- _ O
section -X- _ O
. -X- _ O

A -X- _ O
distinctive -X- _ O
feature -X- _ O
of -X- _ O
BERT -X- _ B-MethodName
is -X- _ O
its -X- _ O
unified -X- _ O
architecture -X- _ O
across -X- _ O
different -X- _ O
tasks -X- _ O
. -X- _ O

Each -X- _ O
downstream -X- _ O
task -X- _ O
has -X- _ O
separate -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
models -X- _ O
, -X- _ O
even -X- _ O
though -X- _ O
they -X- _ O
are -X- _ O
initialized -X- _ O
with -X- _ O
the -X- _ O
same -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
parameters -X- _ O
. -X- _ O

For -X- _ O
finetuning -X- _ O
, -X- _ O
the -X- _ O
BERT -X- _ B-MethodName
model -X- _ O
is -X- _ O
first -X- _ O
initialized -X- _ O
with -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
parameters -X- _ O
, -X- _ O
and -X- _ O
all -X- _ O
of -X- _ O
the -X- _ O
parameters -X- _ O
are -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
using -X- _ O
labeled -X- _ O
data -X- _ O
from -X- _ O
the -X- _ O
downstream -X- _ O
tasks -X- _ O
. -X- _ O

During -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
, -X- _ O
the -X- _ O
model -X- _ O
is -X- _ O
trained -X- _ O
on -X- _ O
unlabeled -X- _ O
data -X- _ O
over -X- _ O
different -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
tasks -X- _ O
. -X- _ O

There -X- _ O
are -X- _ O
two -X- _ O
steps -X- _ O
in -X- _ O
our -X- _ O
framework -X- _ O
: -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
and -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
. -X- _ O

We -X- _ O
introduce -X- _ O
BERT -X- _ B-MethodName
and -X- _ O
its -X- _ O
detailed -X- _ O
implementation -X- _ O
in -X- _ O
this -X- _ O
section -X- _ O
. -X- _ O

Computer -X- _ O
vision -X- _ O
research -X- _ O
has -X- _ O
also -X- _ O
demonstrated -X- _ O
the -X- _ O
importance -X- _ O
of -X- _ O
transfer -X- _ O
learning -X- _ O
from -X- _ O
large -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
models -X- _ O
, -X- _ O
where -X- _ O
an -X- _ O
effective -X- _ O
recipe -X- _ O
is -X- _ O
to -X- _ O
fine -X- _ O
- -X- _ O
tune -X- _ O
models -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
with -X- _ O
Ima -X- _ B-DatasetName
- -X- _ I-DatasetName
geNet -X- _ I-DatasetName
( -X- _ O
Deng -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2009;Yosinski -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
. -X- _ O

BERT -X- _ B-MethodName
. -X- _ O

There -X- _ O
has -X- _ O
also -X- _ O
been -X- _ O
work -X- _ O
showing -X- _ O
effective -X- _ O
transfer -X- _ O
from -X- _ O
supervised -X- _ O
tasks -X- _ O
with -X- _ O
large -X- _ O
datasets -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
natural -X- _ B-TaskName
language -X- _ I-TaskName
inference -X- _ I-TaskName
( -X- _ O
Conneau -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
and -X- _ O
machine -X- _ B-TaskName
translation -X- _ I-TaskName
( -X- _ O
McCann -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
. -X- _ O

Transfer -X- _ O
Learning -X- _ O
from -X- _ O
Supervised -X- _ O
Data -X- _ O
. -X- _ O

ing -X- _ O
and -X- _ O
auto -X- _ B-MethodName
- -X- _ I-MethodName
encoder -X- _ I-MethodName
objectives -X- _ O
have -X- _ O
been -X- _ O
used -X- _ O
for -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
such -X- _ O
models -X- _ O
( -X- _ O
Howard -X- _ O
and -X- _ O
Ruder -X- _ O
, -X- _ O
2018;Radford -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018;Dai -X- _ O
and -X- _ O
Le -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
. -X- _ O

E -X- _ O
M -X- _ O
' -X- _ O
C -X- _ O
T -X- _ O
1 -X- _ O
T -X- _ O
[ -X- _ O
SEP -X- _ O
] -X- _ O
... -X- _ O

E -X- _ O
N -X- _ O
E -X- _ O
1 -X- _ O
' -X- _ O
... -X- _ O

... -X- _ O

... -X- _ O

E -X- _ O
M -X- _ O
' -X- _ O
C -X- _ O
T -X- _ O
1 -X- _ O
T -X- _ O
[ -X- _ O
SEP -X- _ O
] -X- _ O
... -X- _ O

E -X- _ O
N -X- _ O
E -X- _ O
1 -X- _ O
' -X- _ O
... -X- _ O

Left -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
right -X- _ O
language -X- _ O
model -X- _ O
- -X- _ O
BERT -X- _ B-MethodName
BERT -X- _ B-MethodName
E -X- _ O
[ -X- _ O
CLS -X- _ O
] -X- _ O
E -X- _ O
1 -X- _ O
E -X- _ O
[ -X- _ O
SEP -X- _ O
] -X- _ O
... -X- _ O

The -X- _ O
advantage -X- _ O
of -X- _ O
these -X- _ O
approaches -X- _ O
is -X- _ O
that -X- _ O
few -X- _ O
parameters -X- _ O
need -X- _ O
to -X- _ O
be -X- _ O
learned -X- _ O
from -X- _ O
scratch -X- _ O
. -X- _ O

At -X- _ O
least -X- _ O
partly -X- _ O
due -X- _ O
to -X- _ O
this -X- _ O
advantage -X- _ O
, -X- _ O
OpenAI -X- _ B-MethodName
GPT -X- _ I-MethodName
( -X- _ O
Radford -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
achieved -X- _ O
previously -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
results -X- _ O
on -X- _ O
many -X- _ O
sentencelevel -X- _ O
tasks -X- _ O
from -X- _ O
the -X- _ O
GLUE -X- _ B-DatasetName
benchmark -X- _ O
( -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018a -X- _ O
) -X- _ O
. -X- _ O

As -X- _ O
with -X- _ O
the -X- _ O
feature -X- _ O
- -X- _ O
based -X- _ O
approaches -X- _ O
, -X- _ O
the -X- _ O
first -X- _ O
works -X- _ O
in -X- _ O
this -X- _ O
direction -X- _ O
only -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
word -X- _ O
embedding -X- _ O
parameters -X- _ O
from -X- _ O
unlabeled -X- _ O
text -X- _ O
( -X- _ O
Collobert -X- _ O
and -X- _ O
Weston -X- _ O
, -X- _ O
2008 -X- _ O
) -X- _ O
. -X- _ O

Unsupervised -X- _ O
Fine -X- _ O
- -X- _ O
tuning -X- _ O
Approaches -X- _ O
. -X- _ O

Fedus -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

( -X- _ O
2016 -X- _ O
) -X- _ O
proposed -X- _ O
learning -X- _ O
contextual -X- _ O
representations -X- _ O
through -X- _ O
a -X- _ O
task -X- _ O
to -X- _ O
predict -X- _ O
a -X- _ O
single -X- _ O
word -X- _ O
from -X- _ O
both -X- _ O
left -X- _ O
and -X- _ O
right -X- _ O
context -X- _ O
using -X- _ O
LSTMs -X- _ B-MethodName
. -X- _ O
Similar -X- _ O
to -X- _ O
ELMo -X- _ B-MethodName
, -X- _ O
their -X- _ O
model -X- _ O
is -X- _ O
feature -X- _ O
- -X- _ O
based -X- _ O
and -X- _ O
not -X- _ O
deeply -X- _ O
bidirectional -X- _ O
. -X- _ O

When -X- _ O
integrating -X- _ O
contextual -X- _ O
word -X- _ O
embeddings -X- _ O
with -X- _ O
existing -X- _ O
task -X- _ O
- -X- _ O
specific -X- _ O
architectures -X- _ O
, -X- _ O
ELMo -X- _ B-MethodName
advances -X- _ O
the -X- _ O
state -X- _ O
of -X- _ O
the -X- _ O
art -X- _ O
for -X- _ O
several -X- _ O
major -X- _ O
NLP -X- _ O
benchmarks -X- _ O
( -X- _ O
Peters -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018a -X- _ O
) -X- _ O
including -X- _ O
question -X- _ B-TaskName
answering -X- _ I-TaskName
( -X- _ O
Rajpurkar -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
, -X- _ O
sentiment -X- _ B-TaskName
analysis -X- _ I-TaskName
( -X- _ O
Socher -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2013 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
named -X- _ B-TaskName
entity -X- _ I-TaskName
recognition -X- _ I-TaskName
( -X- _ O
Tjong -X- _ O
Kim -X- _ O
Sang -X- _ O
and -X- _ O
De -X- _ O
Meulder -X- _ O
, -X- _ O
2003 -X- _ O
) -X- _ O
. -X- _ O

( -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
uses -X- _ O
unidirectional -X- _ O
language -X- _ O
models -X- _ O
for -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
, -X- _ O
BERT -X- _ B-MethodName
uses -X- _ O
masked -X- _ O
language -X- _ O
models -X- _ O
to -X- _ O
enable -X- _ O
pretrained -X- _ O
deep -X- _ O
bidirectional -X- _ O
representations -X- _ O
. -X- _ O

For -X- _ O
example -X- _ O
, -X- _ O
in -X- _ O
OpenAI -X- _ B-MethodName
GPT -X- _ I-MethodName
, -X- _ O
the -X- _ O
authors -X- _ O
use -X- _ O
a -X- _ O
left -X- _ O
- -X- _ O
toright -X- _ O
architecture -X- _ O
, -X- _ O
where -X- _ O
every -X- _ O
token -X- _ O
can -X- _ O
only -X- _ O
attend -X- _ O
to -X- _ O
previous -X- _ O
tokens -X- _ O
in -X- _ O
the -X- _ O
self -X- _ O
- -X- _ O
attention -X- _ O
layers -X- _ O
of -X- _ O
the -X- _ O
Transformer -X- _ B-MethodName
( -X- _ O
Vaswani -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
. -X- _ O

We -X- _ O
introduce -X- _ O
a -X- _ O
new -X- _ O
language -X- _ O
representation -X- _ O
model -X- _ O
called -X- _ O
BERT -X- _ B-MethodName
, -X- _ O
which -X- _ O
stands -X- _ O
for -X- _ O
Bidirectional -X- _ B-MethodName
Encoder -X- _ I-MethodName
Representations -X- _ I-MethodName
from -X- _ I-MethodName
Transformers -X- _ I-MethodName
. -X- _ O

Melamud -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

The -X- _ O
contextual -X- _ O
representation -X- _ O
of -X- _ O
each -X- _ O
token -X- _ O
is -X- _ O
the -X- _ O
concatenation -X- _ O
of -X- _ O
the -X- _ O
left -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
right -X- _ O
and -X- _ O
right -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
left -X- _ O
representations -X- _ O
. -X- _ O

They -X- _ O
extract -X- _ O
context -X- _ O
- -X- _ O
sensitive -X- _ O
features -X- _ O
from -X- _ O
a -X- _ O
left -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
right -X- _ O
and -X- _ O
a -X- _ O
right -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
left -X- _ O
language -X- _ O
model -X- _ O
. -X- _ O

ELMo -X- _ B-MethodName
and -X- _ O
its -X- _ O
predecessor -X- _ O
( -X- _ O
Peters -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017(Peters -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
, -X- _ O
2018a -X- _ O
) -X- _ O
) -X- _ O
generalize -X- _ O
traditional -X- _ O
word -X- _ O
embedding -X- _ O
research -X- _ O
along -X- _ O
a -X- _ O
different -X- _ O
dimension -X- _ O
. -X- _ O

These -X- _ O
approaches -X- _ O
have -X- _ O
been -X- _ O
generalized -X- _ O
to -X- _ O
coarser -X- _ O
granularities -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
sentence -X- _ O
embeddings -X- _ O
( -X- _ O
Kiros -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015;Logeswaran -X- _ O
and -X- _ O
Lee -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
or -X- _ O
paragraph -X- _ O
embeddings -X- _ O
( -X- _ O
Le -X- _ O
and -X- _ O
Mikolov -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
. -X- _ O

To -X- _ O
pretrain -X- _ O
word -X- _ O
embedding -X- _ O
vectors -X- _ O
, -X- _ O
left -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
right -X- _ O
language -X- _ O
modeling -X- _ O
objectives -X- _ O
have -X- _ O
been -X- _ O
used -X- _ O
( -X- _ O
Mnih -X- _ O
and -X- _ O
Hinton -X- _ O
, -X- _ O
2009 -X- _ O
) -X- _ O
, -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
objectives -X- _ O
to -X- _ O
discriminate -X- _ O
correct -X- _ O
from -X- _ O
incorrect -X- _ O
words -X- _ O
in -X- _ O
left -X- _ O
and -X- _ O
right -X- _ O
context -X- _ O
( -X- _ O
Mikolov -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2013 -X- _ O
) -X- _ O
. -X- _ O

Pre -X- _ O
- -X- _ O
trained -X- _ O
word -X- _ O
embeddings -X- _ O
are -X- _ O
an -X- _ O
integral -X- _ O
part -X- _ O
of -X- _ O
modern -X- _ O
NLP -X- _ O
systems -X- _ O
, -X- _ O
offering -X- _ O
significant -X- _ O
improvements -X- _ O
over -X- _ O
embeddings -X- _ O
learned -X- _ O
from -X- _ O
scratch -X- _ O
( -X- _ O
Turian -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2010 -X- _ O
) -X- _ O
. -X- _ O

Learning -X- _ O
widely -X- _ O
applicable -X- _ O
representations -X- _ O
of -X- _ O
words -X- _ O
has -X- _ O
been -X- _ O
an -X- _ O
active -X- _ O
area -X- _ O
of -X- _ O
research -X- _ O
for -X- _ O
decades -X- _ O
, -X- _ O
including -X- _ O
non -X- _ O
- -X- _ O
neural -X- _ O
( -X- _ O
Brown -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
1992;Ando -X- _ O
and -X- _ O
Zhang -X- _ O
, -X- _ O
2005;Blitzer -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2006 -X- _ O
) -X- _ O
and -X- _ O
neural -X- _ O
( -X- _ O
Mikolov -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2013;Pennington -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
methods -X- _ O
. -X- _ O

Unsupervised -X- _ O
Feature -X- _ O
- -X- _ O
based -X- _ O
Approaches -X- _ O
. -X- _ O

There -X- _ O
is -X- _ O
a -X- _ O
long -X- _ O
history -X- _ O
of -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
general -X- _ O
language -X- _ O
representations -X- _ O
, -X- _ O
and -X- _ O
we -X- _ O
briefly -X- _ O
review -X- _ O
the -X- _ O
most -X- _ O
widely -X- _ O
- -X- _ O
used -X- _ O
approaches -X- _ O
in -X- _ O
this -X- _ O
section -X- _ O
. -X- _ O

Related -X- _ O
Work -X- _ O
. -X- _ O

• -X- _ O
BERT -X- _ B-MethodName
advances -X- _ O
the -X- _ O
state -X- _ O
of -X- _ O
the -X- _ O
art -X- _ O
for -X- _ O
eleven -X- _ O
NLP -X- _ O
tasks -X- _ O
. -X- _ O

BERT -X- _ B-MethodName
is -X- _ O
the -X- _ O
first -X- _ O
finetuning -X- _ O
based -X- _ O
representation -X- _ O
model -X- _ O
that -X- _ O
achieves -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
performance -X- _ O
on -X- _ O
a -X- _ O
large -X- _ O
suite -X- _ O
of -X- _ O
sentence -X- _ O
- -X- _ O
level -X- _ O
and -X- _ O
token -X- _ O
- -X- _ O
level -X- _ O
tasks -X- _ O
, -X- _ O
outperforming -X- _ O
many -X- _ O
task -X- _ O
- -X- _ O
specific -X- _ O
architectures -X- _ O
. -X- _ O

( -X- _ O
2018a -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
uses -X- _ O
a -X- _ O
shallow -X- _ O
concatenation -X- _ O
of -X- _ O
independently -X- _ O
trained -X- _ O
left -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
right -X- _ O
and -X- _ O
right -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
left -X- _ O
LMs -X- _ O
. -X- _ O
• -X- _ O
We -X- _ O
show -X- _ O
that -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
representations -X- _ O
reduce -X- _ O
the -X- _ O
need -X- _ O
for -X- _ O
many -X- _ O
heavily -X- _ O
- -X- _ O
engineered -X- _ O
taskspecific -X- _ O
architectures -X- _ O
. -X- _ O

This -X- _ O
is -X- _ O
also -X- _ O
in -X- _ O
contrast -X- _ O
to -X- _ O
Peters -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

Unlike -X- _ O
Radford -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

Unlike -X- _ O
left -X- _ O
- -X- _ O
toright -X- _ O
language -X- _ O
model -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
, -X- _ O
the -X- _ O
MLM -X- _ O
objective -X- _ O
enables -X- _ O
the -X- _ O
representation -X- _ O
to -X- _ O
fuse -X- _ O
the -X- _ O
left -X- _ O
and -X- _ O
the -X- _ O
right -X- _ O
context -X- _ O
, -X- _ O
which -X- _ O
allows -X- _ O
us -X- _ O
to -X- _ O
pretrain -X- _ O
a -X- _ O
deep -X- _ O
bidirectional -X- _ O
Transformer -X- _ O
. -X- _ O

The -X- _ O
masked -X- _ O
language -X- _ O
model -X- _ O
randomly -X- _ O
masks -X- _ O
some -X- _ O
of -X- _ O
the -X- _ O
tokens -X- _ O
from -X- _ O
the -X- _ O
input -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
objective -X- _ O
is -X- _ O
to -X- _ O
predict -X- _ O
the -X- _ O
original -X- _ O
vocabulary -X- _ O
i -X- _ O
d -X- _ O
of -X- _ O
the -X- _ O
masked -X- _ O
word -X- _ O
based -X- _ O
only -X- _ O
on -X- _ O
its -X- _ O
context -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
improve -X- _ O
the -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
based -X- _ O
approaches -X- _ O
by -X- _ O
proposing -X- _ O
BERT -X- _ B-MethodName
: -X- _ O
Bidirectional -X- _ B-MethodName
Encoder -X- _ I-MethodName
Representations -X- _ I-MethodName
from -X- _ I-MethodName
Transformers -X- _ I-MethodName
. -X- _ O

Such -X- _ O
restrictions -X- _ O
are -X- _ O
sub -X- _ O
- -X- _ O
optimal -X- _ O
for -X- _ O
sentence -X- _ O
- -X- _ O
level -X- _ O
tasks -X- _ O
, -X- _ O
and -X- _ O
could -X- _ O
be -X- _ O
very -X- _ O
harmful -X- _ O
when -X- _ O
applying -X- _ O
finetuning -X- _ O
based -X- _ O
approaches -X- _ O
to -X- _ O
token -X- _ O
- -X- _ O
level -X- _ O
tasks -X- _ O
such -X- _ O
as -X- _ O
question -X- _ B-TaskName
answering -X- _ I-TaskName
, -X- _ O
where -X- _ O
it -X- _ O
is -X- _ O
crucial -X- _ O
to -X- _ O
incorporate -X- _ O
context -X- _ O
from -X- _ O
both -X- _ O
directions -X- _ O
. -X- _ O

The -X- _ O
major -X- _ O
limitation -X- _ O
is -X- _ O
that -X- _ O
standard -X- _ O
language -X- _ O
models -X- _ O
are -X- _ O
unidirectional -X- _ O
, -X- _ O
and -X- _ O
this -X- _ O
limits -X- _ O
the -X- _ O
choice -X- _ O
of -X- _ O
architectures -X- _ O
that -X- _ O
can -X- _ O
be -X- _ O
used -X- _ O
during -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
. -X- _ O

We -X- _ O
argue -X- _ O
that -X- _ O
current -X- _ O
techniques -X- _ O
restrict -X- _ O
the -X- _ O
power -X- _ O
of -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
representations -X- _ O
, -X- _ O
especially -X- _ O
for -X- _ O
the -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
approaches -X- _ O
. -X- _ O

The -X- _ O
two -X- _ O
approaches -X- _ O
share -X- _ O
the -X- _ O
same -X- _ O
objective -X- _ O
function -X- _ O
during -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
, -X- _ O
where -X- _ O
they -X- _ O
use -X- _ O
unidirectional -X- _ O
language -X- _ O
models -X- _ O
to -X- _ O
learn -X- _ O
general -X- _ O
language -X- _ O
representations -X- _ O
. -X- _ O

The -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
approach -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
the -X- _ O
Generative -X- _ B-MethodName
Pre -X- _ I-MethodName
- -X- _ I-MethodName
trained -X- _ I-MethodName
Transformer -X- _ I-MethodName
( -X- _ O
OpenAI -X- _ B-MethodName
GPT -X- _ I-MethodName
) -X- _ O
( -X- _ O
Radford -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
introduces -X- _ O
minimal -X- _ O
task -X- _ O
- -X- _ O
specific -X- _ O
parameters -X- _ O
, -X- _ O
and -X- _ O
is -X- _ O
trained -X- _ O
on -X- _ O
the -X- _ O
downstream -X- _ O
tasks -X- _ O
by -X- _ O
simply -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
all -X- _ O
pretrained -X- _ O
parameters -X- _ O
. -X- _ O

The -X- _ O
feature -X- _ O
- -X- _ O
based -X- _ O
approach -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
ELMo -X- _ B-MethodName
( -X- _ O
Peters -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018a -X- _ O
) -X- _ O
, -X- _ O
uses -X- _ O
task -X- _ O
- -X- _ O
specific -X- _ O
architectures -X- _ O
that -X- _ O
include -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
representations -X- _ O
as -X- _ O
additional -X- _ O
features -X- _ O
. -X- _ O

There -X- _ O
are -X- _ O
two -X- _ O
existing -X- _ O
strategies -X- _ O
for -X- _ O
applying -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
language -X- _ O
representations -X- _ O
to -X- _ O
downstream -X- _ O
tasks -X- _ O
: -X- _ O
feature -X- _ O
- -X- _ O
based -X- _ O
and -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
. -X- _ O

These -X- _ O
include -X- _ O
sentence -X- _ O
- -X- _ O
level -X- _ O
tasks -X- _ O
such -X- _ O
as -X- _ O
natural -X- _ B-TaskName
language -X- _ I-TaskName
inference -X- _ I-TaskName
( -X- _ O
Bowman -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015;Williams -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
and -X- _ O
paraphrasing -X- _ O
( -X- _ O
Dolan -X- _ O
and -X- _ O
Brockett -X- _ O
, -X- _ O
2005 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
aim -X- _ O
to -X- _ O
predict -X- _ O
the -X- _ O
relationships -X- _ O
between -X- _ O
sentences -X- _ O
by -X- _ O
analyzing -X- _ O
them -X- _ O
holistically -X- _ O
, -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
token -X- _ O
- -X- _ O
level -X- _ O
tasks -X- _ O
such -X- _ O
as -X- _ O
named -X- _ B-TaskName
entity -X- _ I-TaskName
recognition -X- _ I-TaskName
and -X- _ O
question -X- _ B-TaskName
answering -X- _ I-TaskName
, -X- _ O
where -X- _ O
models -X- _ O
are -X- _ O
required -X- _ O
to -X- _ O
produce -X- _ O
fine -X- _ O
- -X- _ O
grained -X- _ O
output -X- _ O
at -X- _ O
the -X- _ O
token -X- _ O
level -X- _ O
( -X- _ O
Tjong -X- _ O
Kim -X- _ O
Sang -X- _ O
and -X- _ O
De -X- _ O
Meulder -X- _ O
, -X- _ O
2003;Rajpurkar -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
. -X- _ O

Language -X- _ O
model -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
has -X- _ O
been -X- _ O
shown -X- _ O
to -X- _ O
be -X- _ O
effective -X- _ O
for -X- _ O
improving -X- _ O
many -X- _ O
natural -X- _ O
language -X- _ O
processing -X- _ O
tasks -X- _ O
( -X- _ O
Dai -X- _ O
and -X- _ O
Le -X- _ O
, -X- _ O
2015 -X- _ O
; -X- _ O
Peters -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018a;Radford -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018;Howard -X- _ O
and -X- _ O
Ruder -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O

Introduction -X- _ O
. -X- _ O

BERT -X- _ B-MethodName
is -X- _ O
conceptually -X- _ O
simple -X- _ O
and -X- _ O
empirically -X- _ O
powerful -X- _ O
. -X- _ O

As -X- _ O
a -X- _ O
result -X- _ O
, -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
BERT -X- _ B-MethodName
model -X- _ O
can -X- _ O
be -X- _ O
finetuned -X- _ O
with -X- _ O
just -X- _ O
one -X- _ O
additional -X- _ O
output -X- _ O
layer -X- _ O
to -X- _ O
create -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
models -X- _ O
for -X- _ O
a -X- _ O
wide -X- _ O
range -X- _ O
of -X- _ O
tasks -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
question -X- _ B-TaskName
answering -X- _ I-TaskName
and -X- _ O
language -X- _ B-TaskName
inference -X- _ I-TaskName
, -X- _ O
without -X- _ O
substantial -X- _ O
taskspecific -X- _ O
architecture -X- _ O
modifications -X- _ O
. -X- _ O

Unlike -X- _ O
recent -X- _ O
language -X- _ O
representation -X- _ O
models -X- _ O
( -X- _ O
Peters -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018a;Radford -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
BERT -X- _ B-MethodName
is -X- _ O
designed -X- _ O
to -X- _ O
pretrain -X- _ O
deep -X- _ O
bidirectional -X- _ O
representations -X- _ O
from -X- _ O
unlabeled -X- _ O
text -X- _ O
by -X- _ O
jointly -X- _ O
conditioning -X- _ O
on -X- _ O
both -X- _ O
left -X- _ O
and -X- _ O
right -X- _ O
context -X- _ O
in -X- _ O
all -X- _ O
layers -X- _ O
. -X- _ O

